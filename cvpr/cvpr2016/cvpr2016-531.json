"{\"abstract\":\"Recently, algorithms for object recognition and related tasks have become sufficiently proficient that new vision tasks can now be pursued. In this paper, we build a system capable of answering open-ended text-based questions about images, which is known as Visual Question Answering (VQA). Our approach's key insight is that we can predict the form of the answer from the question. We formulate our solution in a Bayesian framework. When our approach is combined with a discriminative model, the combined model achieves state-of-the-art results on four benchmark datasets for open-ended VQA: DAQUAR, COCO-QA, The VQA Dataset, and Visual7W.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\",\"url\":\"https://www.semanticscholar.org/author/33315685\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\",\"url\":\"https://www.semanticscholar.org/author/3290098\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":\"1610.04062\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"title\":\"Video Fill in the Blank with Merging LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"title\":\"Jointly Learning Attentions with Semantic Cross-Modal Correlation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8937909\",\"name\":\"Nazneen Fatema Rajani\"}],\"doi\":\"10.15781/T2XW48H2X\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d861bcf0af23ed4fb2dbcb226b74e138d902e1c7\",\"title\":\"Explainable improved ensembling for natural language and vision\",\"url\":\"https://www.semanticscholar.org/paper/d861bcf0af23ed4fb2dbcb226b74e138d902e1c7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152902853\",\"name\":\"Vedant Singh\"},{\"authorId\":\"144833581\",\"name\":\"V. Doshi\"},{\"authorId\":\"66507017\",\"name\":\"Mitali Dave\"},{\"authorId\":\"144301613\",\"name\":\"A. Desai\"},{\"authorId\":\"1729588200\",\"name\":\"Smith Agrawal\"},{\"authorId\":\"144791188\",\"name\":\"J. Shah\"},{\"authorId\":\"9272713\",\"name\":\"P. Kanani\"}],\"doi\":\"10.1007/978-981-15-4451-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5730053fd973426028fa3b47a55be9d7fd2938d\",\"title\":\"Answering Questions in Natural Language About Images Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/e5730053fd973426028fa3b47a55be9d7fd2938d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493665\",\"name\":\"Dafang He\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"1745900\",\"name\":\"Alexander N. Gorban\"},{\"authorId\":\"39099960\",\"name\":\"Derrall Heath\"},{\"authorId\":\"46920727\",\"name\":\"J. Ibarz\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1852261\",\"name\":\"D. Kifer\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"title\":\"Guided Attention for Large Scale Scene Text Verification\",\"url\":\"https://www.semanticscholar.org/paper/b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33626762\",\"name\":\"J. Ordonez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"96094b030013ca2d9b6d5a14b6f1fbbc57eb8a89\",\"title\":\"What is in that picture ? Visual Question Answering System\",\"url\":\"https://www.semanticscholar.org/paper/96094b030013ca2d9b6d5a14b6f1fbbc57eb8a89\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1145/3240508.3240513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"title\":\"Object-Difference Attention: A Simple Relational Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":\"1802.02305\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/TIP.2018.2814344\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f97e9818a8055668f9db7967b076dd036d25c417\",\"title\":\"Self-Supervised Video Hashing With Hierarchical Binary Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/f97e9818a8055668f9db7967b076dd036d25c417\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":null,\"name\":\"Long Chen\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2549731\",\"name\":\"Jian Shao\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1007/s11063-019-10003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bf0b37ed005285b6cbef70a78434978ca065120\",\"title\":\"Hierarchical Temporal Fusion of Multi-grained Attention Features for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8bf0b37ed005285b6cbef70a78434978ca065120\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"30076791\",\"name\":\"Zhilong Zhou\"},{\"authorId\":\"35153304\",\"name\":\"Lijiang Chen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11280-018-0531-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7eb3ac4ccb30a2ce759094f3972a018575f74b6\",\"title\":\"Residual attention-based LSTM for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/f7eb3ac4ccb30a2ce759094f3972a018575f74b6\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48925229\",\"name\":\"Byung-Ju Kim\"},{\"authorId\":\"100498018\",\"name\":\"\\uae40\\ubcd1\\uc8fc\"}],\"doi\":\"10.1049/EL.2017.1881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b86686436608b4083bbca19e6e71e2f780ff3ef7\",\"title\":\"Question aware prediction with candidate answer recommendation for visual question answering = \\ud6c4\\ubcf4 \\ub2f5\\ubcc0 \\uc608\\uce21\\uc744 \\ud1b5\\ud55c \\uc601\\uc0c1 \\uae30\\ubc18 \\uc9c8\\uc758\\uc751\\ub2f5\\uc5d0 \\ub300\\ud55c \\uc5f0\\uad6c\",\"url\":\"https://www.semanticscholar.org/paper/b86686436608b4083bbca19e6e71e2f780ff3ef7\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1145/3126686.3126695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"title\":\"Generative Attention Model with Adversarial Self-learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027237323\",\"name\":\"Ni Xubin\"},{\"authorId\":\"1490666252\",\"name\":\"Lirong Yin\"},{\"authorId\":\"1797365\",\"name\":\"X. Chen\"},{\"authorId\":\"48641357\",\"name\":\"S. Liu\"},{\"authorId\":\"48641357\",\"name\":\"S. Liu\"},{\"authorId\":\"1708276147\",\"name\":\"Bo Yang\"},{\"authorId\":\"121667485\",\"name\":\"Wenfeng Zheng\"}],\"doi\":\"10.1051/MATECCONF/201927702006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79035815feff776be9ab127499944e6f86efa034\",\"title\":\"Semantic representation for visual reasoning\",\"url\":\"https://www.semanticscholar.org/paper/79035815feff776be9ab127499944e6f86efa034\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.06492\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"title\":\"VQABQ: Visual Question Answering by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2310836\",\"name\":\"Bashar Talafha\"},{\"authorId\":\"1398466553\",\"name\":\"Mahmoud Al-Ayyoub\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"title\":\"JUST at VQA-Med: A VGG-Seq2Seq Model\",\"url\":\"https://www.semanticscholar.org/paper/4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/WACV.2019.00026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"183bf77d4f9b4eb227ba1d5a26eff5b6ab3d889d\",\"title\":\"Going Deeper With Semantics: Video Activity Interpretation Using Semantic Contextualization\",\"url\":\"https://www.semanticscholar.org/paper/183bf77d4f9b4eb227ba1d5a26eff5b6ab3d889d\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"144118452\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1912.00124\",\"authors\":[{\"authorId\":\"5007179\",\"name\":\"Jihyeon Janel Lee\"},{\"authorId\":\"32576042\",\"name\":\"S. Arora\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11f84eaa4eed54fe37f33e7b31f5781843ec05da\",\"title\":\"A Free Lunch in Generating Datasets: Building a VQG and VQA System with Attention and Humans in the Loop\",\"url\":\"https://www.semanticscholar.org/paper/11f84eaa4eed54fe37f33e7b31f5781843ec05da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.02509\",\"authors\":[{\"authorId\":\"31449728\",\"name\":\"T. Hayes\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1007/978-3-030-58598-3_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6c3e8b8e6d647ebb61833e9105d2147e472f534\",\"title\":\"REMIND Your Neural Network to Prevent Catastrophic Forgetting\",\"url\":\"https://www.semanticscholar.org/paper/f6c3e8b8e6d647ebb61833e9105d2147e472f534\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145102294\",\"name\":\"Moreira de Souza\"},{\"authorId\":\"123900281\",\"name\":\"Fillipe Dias\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"title\":\"Semantic Description of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35458817\",\"name\":\"Sudan Jha\"},{\"authorId\":\"143699471\",\"name\":\"Anirban Dey\"},{\"authorId\":\"145835018\",\"name\":\"R. Kumar\"},{\"authorId\":\"2245174\",\"name\":\"Vijender Kumar Solanki\"}],\"doi\":\"10.9781/IJIMAI.2018.08.004\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"title\":\"A Novel Approach on Visual Question Answering by Parameter Prediction using Faster Region Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"venue\":\"Int. J. Interact. Multim. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150926473\",\"name\":\"Avi Turner\"},{\"authorId\":\"150924392\",\"name\":\"Assaf Spanier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"891344051b52f12c81df33238eaf1d10af44ca33\",\"title\":\"LSTM in VQA-Med, is It Really Needed? JCE Study on the ImageCLEF 2019 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/891344051b52f12c81df33238eaf1d10af44ca33\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"1812.00344\",\"authors\":[{\"authorId\":\"1769749\",\"name\":\"S. Wang\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"16132631\",\"name\":\"Z. Kou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7d1c2d4b4ca2bf3109757f181bc2cf15240fcc5\",\"title\":\"How to Make a BLT Sandwich? Learning to Reason towards Understanding Web Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/e7d1c2d4b4ca2bf3109757f181bc2cf15240fcc5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8937909\",\"name\":\"Nazneen Rajani\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":\"10.1007/978-3-319-98131-4_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9d2c96cead937e53e614abb9fd051574a55c77a\",\"title\":\"Ensembling Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/a9d2c96cead937e53e614abb9fd051574a55c77a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"144914662\",\"name\":\"F. Xiao\"},{\"authorId\":\"143728443\",\"name\":\"Le An\"},{\"authorId\":\"2989422\",\"name\":\"Xianzhong Long\"},{\"authorId\":\"48305363\",\"name\":\"Xiaochuan Sun\"}],\"doi\":\"10.1145/3300938\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"title\":\"Semantic Concept Network and Deep Walk-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1906.02850\",\"authors\":[{\"authorId\":\"48240607\",\"name\":\"C. Chen\"},{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"145381969\",\"name\":\"T. Yu\"},{\"authorId\":\"3139133\",\"name\":\"Razvan C. Bunescu\"},{\"authorId\":\"47131074\",\"name\":\"Razvan Bunescu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"755dd3628b04adad423d2418f98c156123ebac2a\",\"title\":\"Figure Captioning with Reasoning and Sequence-Level Training\",\"url\":\"https://www.semanticscholar.org/paper/755dd3628b04adad423d2418f98c156123ebac2a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.03895\",\"authors\":[{\"authorId\":\"10730666\",\"name\":\"Siddha Ganju\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"title\":\"What's in a Question: Using Visual Questions as a Form of Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"48566761\",\"name\":\"Jiang Zhu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3240876.3240885\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e599fa3ca042d30321aa5502a135c1de87e688\",\"title\":\"Video question answering via multi-granularity temporal attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/e4e599fa3ca042d30321aa5502a135c1de87e688\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"2706315\",\"name\":\"Ya\\u011fmur G\\u00fc\\u00e7l\\u00fct\\u00fcrk\"},{\"authorId\":\"80777440\",\"name\":\"U. G\\u00fc\\u00e7l\\u00fc\"},{\"authorId\":\"103366015\",\"name\":\"M. V. Gerven\"}],\"doi\":\"10.1007/978-3-319-98131-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a217389b365d06ae323fee744304067c8f62be7\",\"title\":\"Explainable and Interpretable Models in Computer Vision and Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/8a217389b365d06ae323fee744304067c8f62be7\",\"venue\":\"The Springer Series on Challenges in Machine Learning\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"48669907\",\"name\":\"X. Xu\"},{\"authorId\":\"145496508\",\"name\":\"J. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be63949be4151ed73503b3eb218aa9175233661b\",\"title\":\"Question-Led object attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/be63949be4151ed73503b3eb218aa9175233661b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50994378\",\"name\":\"Chen Chen\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"35365476\",\"name\":\"R. Rossi\"}],\"doi\":\"10.1109/WACV45572.2020.9093592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40e09c8e31bc859d90ba8ceeb70ef7534bf6b7a5\",\"title\":\"Figure Captioning with Relation Maps for Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/40e09c8e31bc859d90ba8ceeb70ef7534bf6b7a5\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"title\":\"Research Statement Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2009.11118\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"47787551\",\"name\":\"Binh X. Nguyen\"},{\"authorId\":\"1981175\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"31534280\",\"name\":\"Q. D. Tran\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"30173e8b551c0655e2036aba7fedf354f1ef5658\",\"title\":\"Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/30173e8b551c0655e2036aba7fedf354f1ef5658\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08717\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"144481186\",\"name\":\"Guillem Collell\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bc42a9ebf099b84c02feac5b99e81ce5777eb07\",\"title\":\"Giving Commands to a Self-driving Car: A Multimodal Reasoner for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2bc42a9ebf099b84c02feac5b99e81ce5777eb07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.03725\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc7a3573a464bca2cdca71f6f32e798464b85ee6\",\"title\":\"Exploiting Semantic Contextualization for Interpretation of Human Activity in Videos\",\"url\":\"https://www.semanticscholar.org/paper/bc7a3573a464bca2cdca71f6f32e798464b85ee6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145478715\",\"name\":\"I. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.1109/ICIP.2017.8296600\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"title\":\"A cascaded long short-term memory (LSTM) driven generic visual question answering (VQA)\",\"url\":\"https://www.semanticscholar.org/paper/4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"46264522\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICCV.2019.00470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"title\":\"From Strings to Things: Knowledge-Enabled VQA Model That Can Read and Reason\",\"url\":\"https://www.semanticscholar.org/paper/ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73453616\",\"name\":\"S. Sarath\"},{\"authorId\":\"67097178\",\"name\":\"J. Amudha\"}],\"doi\":\"10.1109/incet49848.2020.9154094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48495aac7c5b958f27f5d32951db35590dfb7e6e\",\"title\":\"V\\u03b9sual question answering models Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/48495aac7c5b958f27f5d32951db35590dfb7e6e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581441035\",\"name\":\"Afrae Bghiel\"},{\"authorId\":\"1581444871\",\"name\":\"Yousra Dahdouh\"},{\"authorId\":\"51162320\",\"name\":\"Imane Allaouzi\"},{\"authorId\":\"143678432\",\"name\":\"M. Ahmed\"},{\"authorId\":\"47708727\",\"name\":\"A. Boudhir\"}],\"doi\":\"10.1007/978-3-030-37629-1_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ba86d31844d9a1bb1c26928f555025508e7f963\",\"title\":\"Visual Question Answering System for Identifying Medical Images Attributes\",\"url\":\"https://www.semanticscholar.org/paper/1ba86d31844d9a1bb1c26928f555025508e7f963\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1709.04625\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"28853de59af8560dca5ff83f68f5af1cec0493d9\",\"title\":\"Robustness Analysis of Visual QA Models by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/28853de59af8560dca5ff83f68f5af1cec0493d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1705.03865\",\"authors\":[{\"authorId\":\"50178628\",\"name\":\"Akshay Kumar Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"637648198f9e91654ce27eaaa40512f2dc870fc1\",\"title\":\"Survey of Visual Question Answering: Datasets and Techniques\",\"url\":\"https://www.semanticscholar.org/paper/637648198f9e91654ce27eaaa40512f2dc870fc1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1017/S1351324918000104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a69f7e80bae350dd51518424abd2d63b73cb6ee6\",\"title\":\"Understanding visual scenes\",\"url\":\"https://www.semanticscholar.org/paper/a69f7e80bae350dd51518424abd2d63b73cb6ee6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1810.12440\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1609/aaai.v33i01.33018076\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"634161e4759616dbe06f0b1465999d3df122f366\",\"title\":\"TallyQA: Answering Complex Counting Questions\",\"url\":\"https://www.semanticscholar.org/paper/634161e4759616dbe06f0b1465999d3df122f366\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1907.04380\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"48926630\",\"name\":\"Adam Poliak\"},{\"authorId\":\"1692491\",\"name\":\"S. Shieber\"},{\"authorId\":\"7536576\",\"name\":\"Benjamin Van Durme\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":\"10.18653/v1/P19-1084\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6540ee01a87c3b3435da73f4e3297489d525c151\",\"title\":\"Don't Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/6540ee01a87c3b3435da73f4e3297489d525c151\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"144493052\",\"name\":\"Z. Zhao\"},{\"authorId\":\"2577617\",\"name\":\"Yueying He\"}],\"doi\":\"10.1016/j.knosys.2018.07.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"title\":\"From content to links: Social image embedding with deep multimodal model\",\"url\":\"https://www.semanticscholar.org/paper/31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"venue\":\"Knowl. Based Syst.\",\"year\":2018},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1801.08163\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2018.00592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"title\":\"DVQA: Understanding Data Visualizations via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2010.03160\",\"authors\":[{\"authorId\":\"1557299630\",\"name\":\"Xiaoyu Zeng\"},{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"3428457\",\"name\":\"Tai-Yin Chiu\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1145/3415220\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"72f5a58ac11e98a15e96c413178198b6f1b6e736\",\"title\":\"Vision Skills Needed to Answer Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/72f5a58ac11e98a15e96c413178198b6f1b6e736\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2009.12770\",\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"1492191087\",\"name\":\"Swati Suman\"},{\"authorId\":\"152800923\",\"name\":\"A. Ekbal\"}],\"doi\":\"10.1016/J.ESWA.2020.113993\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"title\":\"Hierarchical Deep Multi-modal Network for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":\"2005.09241\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"1692540612\",\"name\":\"Christopher Kanan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad322ec0617a9bdf1dabd2a51e626a9c474ed9e3\",\"title\":\"On the Value of Out-of-Distribution Testing: An Example of Goodhart's Law\",\"url\":\"https://www.semanticscholar.org/paper/ad322ec0617a9bdf1dabd2a51e626a9c474ed9e3\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1708.02071\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"49339267\",\"name\":\"Yanpeng Zhao\"},{\"authorId\":\"24027493\",\"name\":\"Shuaiyi Huang\"},{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1109/ICCV.2017.145\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5823d18cd378898b12de537862d996443ce9c9e8\",\"title\":\"Structured Attentions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5823d18cd378898b12de537862d996443ce9c9e8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"corpusId\":8409675,\"doi\":\"10.1109/CVPR.2016.538\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784682\",\"name\":\"T. Hastie\"},{\"authorId\":\"1761784\",\"name\":\"R. Tibshirani\"},{\"authorId\":\"3056361\",\"name\":\"J. Friedman\"}],\"doi\":\"10.1007/BF02985802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bee570503aaa0ed5bc5dd4cf6aa742df0b5cef87\",\"title\":\"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd Edition\",\"url\":\"https://www.semanticscholar.org/paper/bee570503aaa0ed5bc5dd4cf6aa742df0b5cef87\",\"venue\":\"Springer Series in Statistics\",\"year\":2009},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"90929a6aa901ba958eb4960aeeb594c752e08369\",\"title\":\"On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes\",\"url\":\"https://www.semanticscholar.org/paper/90929a6aa901ba958eb4960aeeb594c752e08369\",\"venue\":\"NIPS\",\"year\":2001},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/ICDAR.2013.11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ff6f73c4608e7557559d567c97ecd196a564bcf\",\"title\":\"Locally Smoothed Modified Quadratic Discriminant Function\",\"url\":\"https://www.semanticscholar.org/paper/2ff6f73c4608e7557559d567c97ecd196a564bcf\",\"venue\":\"2013 12th International Conference on Document Analysis and Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2979876\",\"name\":\"R. Raina\"},{\"authorId\":\"2416039\",\"name\":\"Yirong Shen\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"143753639\",\"name\":\"A. McCallum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e0801da1a187d90862cd00ce7f12222ff965ef0\",\"title\":\"Classification with Hybrid Generative/Discriminative Models\",\"url\":\"https://www.semanticscholar.org/paper/0e0801da1a187d90862cd00ce7f12222ff965ef0\",\"venue\":\"NIPS\",\"year\":2003},{\"arxivId\":\"cmp-lg/9406033\",\"authors\":[{\"authorId\":\"2459057\",\"name\":\"Z. Wu\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":\"10.3115/981732.981751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"title\":\"Verb Semantics and Lexical Selection\",\"url\":\"https://www.semanticscholar.org/paper/0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"venue\":\"ACL\",\"year\":1994},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2060684\",\"name\":\"Monica S. Castelhano\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1037/0033-295X.113.4.766\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"title\":\"Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.\",\"url\":\"https://www.semanticscholar.org/paper/b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"venue\":\"Psychological review\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-642-33715-4_54\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1994ba5946456fc70948c549daf62363f13fa2d\",\"title\":\"Indoor Segmentation and Support Inference from RGBD Images\",\"url\":\"https://www.semanticscholar.org/paper/c1994ba5946456fc70948c549daf62363f13fa2d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012}],\"title\":\"Answer-Type Prediction for Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Discriminative model\",\"topicId\":\"39987\",\"url\":\"https://www.semanticscholar.org/topic/39987\"},{\"topic\":\"Nonlinear gameplay\",\"topicId\":\"62171\",\"url\":\"https://www.semanticscholar.org/topic/62171\"},{\"topic\":\"Outline of object recognition\",\"topicId\":\"34569\",\"url\":\"https://www.semanticscholar.org/topic/34569\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Bayesian network\",\"topicId\":\"14005\",\"url\":\"https://www.semanticscholar.org/topic/14005\"},{\"topic\":\"Word embedding\",\"topicId\":\"286696\",\"url\":\"https://www.semanticscholar.org/topic/286696\"},{\"topic\":\"Text-based (computing)\",\"topicId\":\"75487\",\"url\":\"https://www.semanticscholar.org/topic/75487\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"