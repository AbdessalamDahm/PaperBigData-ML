"{\"abstract\":\"We propose a method for visual question answering which combines an internal representation of the content of an image with information extracted from a general knowledge base to answer a broad range of image-based questions. This allows more complex questions to be answered using the predominant neural network-based approach than has previously been possible. It particularly allows questions to be asked about the contents of an image, even when the image itself does not contain the whole answer. The method constructs a textual representation of the semantic content of an image, and merges it with textual information sourced from a knowledge base, to develop a deeper understanding of the scene viewed. Priming a recurrent neural network with this combined information, and the submitted question, leads to a very flexible visual question answering approach. We are specifically able to answer questions posed in natural language, that refer to information not contained in the image. We demonstrate the effectiveness of our model on two publicly available datasets, Toronto COCO-QA [23] and VQA [1] and show that it produces the best reported results in both cases.\",\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\",\"url\":\"https://www.semanticscholar.org/author/34902783\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\",\"url\":\"https://www.semanticscholar.org/author/48319305\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\",\"url\":\"https://www.semanticscholar.org/author/12459603\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\",\"url\":\"https://www.semanticscholar.org/author/2699095\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\",\"url\":\"https://www.semanticscholar.org/author/5546141\"}],\"citationVelocity\":57,\"citations\":[{\"arxivId\":\"1703.06246\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"title\":\"Towards Context-aware Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"40222634\",\"name\":\"K. Kulkarni\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"22a47c94c49e721e0afbf70ab10200403a1d2cf7\",\"title\":\"Compressive Visual Question Answering by Li-chi Huang A Thesis Presented in Partial Fulfillment of the Requirements for the Degree Master of Science Approved August 2017 by the Graduate Supervisory Committee: Pavan Turaga, Chair\",\"url\":\"https://www.semanticscholar.org/paper/22a47c94c49e721e0afbf70ab10200403a1d2cf7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9362d5ef2b01f7f6ca019409d3ab95e027160c0\",\"title\":\"Object Detection in Images using Knowledge Graphs Double Blind\",\"url\":\"https://www.semanticscholar.org/paper/c9362d5ef2b01f7f6ca019409d3ab95e027160c0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48831444\",\"name\":\"Shengdong Li\"},{\"authorId\":\"1759497\",\"name\":\"X. Lv\"}],\"doi\":\"10.1109/ICME.2019.00314\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2f22bd1a6dc157ec83a1f82c7ffa0887bef25a5\",\"title\":\"Momentum Based on Adaptive Bold Driver\",\"url\":\"https://www.semanticscholar.org/paper/c2f22bd1a6dc157ec83a1f82c7ffa0887bef25a5\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"2003.04679\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"144073922\",\"name\":\"Li Liu\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"}],\"doi\":\"10.1145/3366423.3380191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab771b7431f5d3dce4372a18555f4216528ace7\",\"title\":\"Learning to Respond with Stickers: A Framework of Unifying Multi-Modality in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/3ab771b7431f5d3dce4372a18555f4216528ace7\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1803.05263\",\"authors\":[{\"authorId\":\"100516201\",\"name\":\"K. Yi\"},{\"authorId\":\"27223428\",\"name\":\"Zhiqiang Jian\"},{\"authorId\":\"5369606\",\"name\":\"S. Chen\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc456f1bbce16dc37d1dd15e57ef7256e6786894\",\"title\":\"Feature Selective Small Object Detection via Knowledge-based Recurrent Attentive Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/bc456f1bbce16dc37d1dd15e57ef7256e6786894\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2110665\",\"name\":\"A. Padmakumar\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"title\":\"Visual Question Answering using Natural Language Object Retrieval and Saliency Cues\",\"url\":\"https://www.semanticscholar.org/paper/aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20600120\",\"name\":\"Mihael Cudic\"},{\"authorId\":\"40269075\",\"name\":\"R. Burt\"},{\"authorId\":\"145805087\",\"name\":\"Eder Santana\"},{\"authorId\":\"143961030\",\"name\":\"J. Pr\\u00edncipe\"}],\"doi\":\"10.1016/j.neucom.2018.02.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7d0325e3a012cae26b3d0861e878d60e97d0035\",\"title\":\"A flexible testing environment for visual question answering with performance evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7d0325e3a012cae26b3d0861e878d60e97d0035\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48205102\",\"name\":\"Wenhui Xing\"},{\"authorId\":\"50242824\",\"name\":\"X. Yuan\"},{\"authorId\":\"47681623\",\"name\":\"Lin Li\"},{\"authorId\":\"47918185\",\"name\":\"Jing Peng\"}],\"doi\":\"10.1109/BIBM.2017.8217694\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6297520c05cc80d60786f9380ceae82fa4de856\",\"title\":\"Cascade word embedding to sentence embedding: A class label enhanced approach to phenotype extraction\",\"url\":\"https://www.semanticscholar.org/paper/a6297520c05cc80d60786f9380ceae82fa4de856\",\"venue\":\"2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"144493052\",\"name\":\"Z. Zhao\"},{\"authorId\":\"2577617\",\"name\":\"Yueying He\"}],\"doi\":\"10.1016/j.knosys.2018.07.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"title\":\"From content to links: Social image embedding with deep multimodal model\",\"url\":\"https://www.semanticscholar.org/paper/31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"venue\":\"Knowl. Based Syst.\",\"year\":2018},{\"arxivId\":\"1712.00929\",\"authors\":[{\"authorId\":\"1693821\",\"name\":\"T. Nakamura\"},{\"authorId\":\"47734618\",\"name\":\"T. Nagai\"},{\"authorId\":\"1684099\",\"name\":\"T. Taniguchi\"}],\"doi\":\"10.3389/fnbot.2018.00025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e288fb34998ee3314648e2252c8412760511fbf\",\"title\":\"SERKET: An Architecture for Connecting Stochastic Models to Realize a Large-Scale Cognitive Model\",\"url\":\"https://www.semanticscholar.org/paper/2e288fb34998ee3314648e2252c8412760511fbf\",\"venue\":\"Front. Neurorobot.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"35742440\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2844789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46791594\",\"name\":\"Yangyang Guo\"}],\"doi\":\"10.1145/3338533.3372212\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5dcf0102f968510d4626a387affa74c008c470e0\",\"title\":\"Multimedia Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5dcf0102f968510d4626a387affa74c008c470e0\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":\"1708.03725\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc7a3573a464bca2cdca71f6f32e798464b85ee6\",\"title\":\"Exploiting Semantic Contextualization for Interpretation of Human Activity in Videos\",\"url\":\"https://www.semanticscholar.org/paper/bc7a3573a464bca2cdca71f6f32e798464b85ee6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"144118452\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1702.06700\",\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2385007824daaf9eac9476fccb1501b7ac166ceb\",\"title\":\"Task-driven Visual Saliency and Attention-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2385007824daaf9eac9476fccb1501b7ac166ceb\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"title\":\"Watch, Think and Attend: End-to-End Video Classification via Dynamic Knowledge Evolution Modeling\",\"url\":\"https://www.semanticscholar.org/paper/eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d423f37185a2210d5e47f24d4792e68d0088cd52\",\"title\":\"Apprentissage et exploitation de repr\\u00e9sentations s\\u00e9mantiques pour la classification et la recherche d'images. (Learning and exploiting semantic representations for image classification and retrieval)\",\"url\":\"https://www.semanticscholar.org/paper/d423f37185a2210d5e47f24d4792e68d0088cd52\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"61825a32a8cb28045ef4769e35a9fea6a372a1a1\",\"title\":\"Deep learning for semantic description of visual human traits. (Apprentissage profond pour la description s\\u00e9mantique des traits visuels humains)\",\"url\":\"https://www.semanticscholar.org/paper/61825a32a8cb28045ef4769e35a9fea6a372a1a1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112858943\",\"name\":\"Z. Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"title\":\"Representation Learning for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1511.02570\",\"authors\":[{\"authorId\":\"71984337\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.24963/ijcai.2017/179\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"title\":\"Explicit Knowledge-based Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"2012.03678\",\"authors\":[{\"authorId\":\"2935458\",\"name\":\"Alkesh Patel\"},{\"authorId\":\"71027035\",\"name\":\"Akanksha Bindal\"},{\"authorId\":\"3365389\",\"name\":\"Hadas Kotek\"},{\"authorId\":\"32192159\",\"name\":\"C. Klein\"},{\"authorId\":\"31868842\",\"name\":\"J. Williams\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1aae51526f8a9d27cc973d98223a909af0e82cd7\",\"title\":\"Generating Natural Questions from Images for Multimodal Assistants\",\"url\":\"https://www.semanticscholar.org/paper/1aae51526f8a9d27cc973d98223a909af0e82cd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/WACV.2019.00026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"183bf77d4f9b4eb227ba1d5a26eff5b6ab3d889d\",\"title\":\"Going Deeper With Semantics: Video Activity Interpretation Using Semantic Contextualization\",\"url\":\"https://www.semanticscholar.org/paper/183bf77d4f9b4eb227ba1d5a26eff5b6ab3d889d\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49268056\",\"name\":\"J. Hu\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"}],\"doi\":\"10.1145/3339363.3339389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"title\":\"Semantic BI-Embedded GRU for Fill-in-the-Blank Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"venue\":\"CSSE 2019\",\"year\":2019},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1707.03067\",\"authors\":[{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"3186356\",\"name\":\"X. Zhang\"},{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"67100504\",\"name\":\"C. Thomas\"},{\"authorId\":\"6004292\",\"name\":\"Zuha Agha\"},{\"authorId\":\"34493995\",\"name\":\"Nathan Ong\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2017.123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d173f80797b0e7984d2faf1bd609252a3b365f20\",\"title\":\"Automatic Understanding of Image and Video Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/d173f80797b0e7984d2faf1bd609252a3b365f20\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"2007.08751\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1007/978-3-030-58523-5_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"773e7d33411fc2cdd6829356b7ce8ed34e14cd65\",\"title\":\"Knowledge-Based Video Question Answering with Unsupervised Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/773e7d33411fc2cdd6829356b7ce8ed34e14cd65\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7361508\",\"name\":\"Zhiqiang Wan\"},{\"authorId\":\"144996615\",\"name\":\"Haibo He\"}],\"doi\":\"10.1109/TBDATA.2018.2884486\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"title\":\"AnswerNet: Learning to Answer Questions\",\"url\":\"https://www.semanticscholar.org/paper/8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"venue\":\"IEEE Transactions on Big Data\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.02516\",\"authors\":[{\"authorId\":\"21810992\",\"name\":\"Santhosh K. Ramakrishnan\"},{\"authorId\":\"2311107\",\"name\":\"Ambar Pal\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/CVPR.2017.773\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"title\":\"An Empirical Evaluation of Visual Question Answering for Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120178409\",\"name\":\"H. Xu\"},{\"authorId\":\"19217972\",\"name\":\"Chenhan Jiang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"97650833\",\"name\":\"Liang Lin\"},{\"authorId\":\"48458760\",\"name\":\"Zhenguo Li\"}],\"doi\":\"10.1109/CVPR.2019.00658\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"661f5c55d8d210e798abfd8ed1a640435f2a455d\",\"title\":\"Reasoning-RCNN: Unifying Adaptive Global Reasoning Into Large-Scale Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/661f5c55d8d210e798abfd8ed1a640435f2a455d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1708.01336\",\"authors\":[{\"authorId\":\"144811744\",\"name\":\"L. Jiang\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"3256430\",\"name\":\"Sachin Farfade\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ceac30061d8f7985987448f4712c49eeb98efad2\",\"title\":\"MemexQA: Visual Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ceac30061d8f7985987448f4712c49eeb98efad2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1906.09954\",\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":\"10.24963/ijcai.2019/873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2f02d8817a8fac2a2dda7359353712f8ff85aaa\",\"title\":\"Integrating Knowledge and Reasoning in Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a2f02d8817a8fac2a2dda7359353712f8ff85aaa\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1811.11903\",\"authors\":[{\"authorId\":\"46382824\",\"name\":\"Hui Li\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00648\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"title\":\"Visual Question Answering as Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.11528\",\"authors\":[{\"authorId\":\"46875376\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"9228892\",\"name\":\"P. Zhang\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.24963/ijcai.2020/151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0714f88deda344c87bf78569de68d9e1f0b377a7\",\"title\":\"Overcoming Language Priors with Self-supervised Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0714f88deda344c87bf78569de68d9e1f0b377a7\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1809.08697\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"51007384\",\"name\":\"Mary Arpita Pyreddy\"},{\"authorId\":\"40895015\",\"name\":\"Matthieu Felix\"},{\"authorId\":\"50745535\",\"name\":\"Narendra Nath Joshi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"title\":\"Textually Enriched Neural Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.02358\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"1837923\",\"name\":\"Taehoon Kim\"},{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b80f128830114896df94999b4104cb75408e657e\",\"title\":\"Transfer Learning via Unsupervised Task Discovery for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b80f128830114896df94999b4104cb75408e657e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/ICCV.2017.71\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"title\":\"Towards Context-Aware Interaction Recognition for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48205102\",\"name\":\"Wenhui Xing\"},{\"authorId\":\"50242824\",\"name\":\"X. Yuan\"},{\"authorId\":\"47681546\",\"name\":\"Lin Li\"},{\"authorId\":\"3065972\",\"name\":\"L. Hu\"},{\"authorId\":\"145615518\",\"name\":\"J. Peng\"}],\"doi\":\"10.1109/TNB.2018.2838137\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd6c208591ff45dbf3167f65ad6371bf2e37bcbc\",\"title\":\"Phenotype Extraction Based on Word Embedding to Sentence Embedding Cascaded Approach\",\"url\":\"https://www.semanticscholar.org/paper/fd6c208591ff45dbf3167f65ad6371bf2e37bcbc\",\"venue\":\"IEEE Transactions on NanoBioscience\",\"year\":2018},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1801.04334\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2018.00943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b2402dcd85b81381fde40d0b971b510471ef23\",\"title\":\"TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays\",\"url\":\"https://www.semanticscholar.org/paper/b1b2402dcd85b81381fde40d0b971b510471ef23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2006.01629\",\"authors\":[{\"authorId\":\"145498819\",\"name\":\"P. Wang\"},{\"authorId\":\"47417383\",\"name\":\"Dongyang Liu\"},{\"authorId\":\"144462039\",\"name\":\"H. Li\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1145/3394171.3413905\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a08274632296de2f98d11180ce3e2b06776a3a0\",\"title\":\"Give Me Something to Eat: Referring Expression Comprehension with Commonsense Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3a08274632296de2f98d11180ce3e2b06776a3a0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2002.12204\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":\"10.1109/cvpr42600.2020.01077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"title\":\"Visual Commonsense R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.01714\",\"authors\":[{\"authorId\":\"153474381\",\"name\":\"Fang Yuan\"},{\"authorId\":null,\"name\":\"Zhe Wang\"},{\"authorId\":\"66190968\",\"name\":\"Jie Lin\"},{\"authorId\":\"1405511901\",\"name\":\"Luis Fernando D'Haro\"},{\"authorId\":\"1413997113\",\"name\":\"Kim Jung Jae\"},{\"authorId\":\"3111797\",\"name\":\"Z. Zeng\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d81490b09cc99ab573d4ec73b43834a20c303244\",\"title\":\"End-to-End Video Classification with Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d81490b09cc99ab573d4ec73b43834a20c303244\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5301833\",\"name\":\"Sijia Chen\"},{\"authorId\":\"144977497\",\"name\":\"B. Song\"},{\"authorId\":\"51174778\",\"name\":\"L. Fan\"},{\"authorId\":\"144335971\",\"name\":\"Xiaojiang Du\"},{\"authorId\":\"145837053\",\"name\":\"M. Guizani\"}],\"doi\":\"10.1109/TCCN.2019.2893360\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bb220d21f029d786154ba61482c6f92ed8cbe29\",\"title\":\"Multi-Modal Data Semantic Localization With Relationship Dependencies for Efficient Signal Processing in EH CRNs\",\"url\":\"https://www.semanticscholar.org/paper/6bb220d21f029d786154ba61482c6f92ed8cbe29\",\"venue\":\"IEEE Transactions on Cognitive Communications and Networking\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3236503\",\"name\":\"Li-Chi Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5438445786db9f6181d9fabfc758663518ba28fd\",\"title\":\"Compressive Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5438445786db9f6181d9fabfc758663518ba28fd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2004.08385\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9b53307081ac7897fb84b646510907035be409\",\"title\":\"Knowledge-Based Visual Question Answering in Videos\",\"url\":\"https://www.semanticscholar.org/paper/ab9b53307081ac7897fb84b646510907035be409\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1612.01669\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"3386346\",\"name\":\"Ilchae Jung\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/ICCV.2017.312\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"title\":\"MarioQA: Answering Questions by Watching Gameplay Videos\",\"url\":\"https://www.semanticscholar.org/paper/00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134342162\",\"name\":\"Li Wen-jie\"},{\"authorId\":\"153697517\",\"name\":\"Y. Zheng\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"103245682\",\"name\":\"T. Zhang\"},{\"authorId\":\"1878750882\",\"name\":\"Weiguo Fan\"}],\"doi\":\"10.1002/asi.24373\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"title\":\"Cross\\u2010modal retrieval with dual multi\\u2010angle self\\u2010attention\",\"url\":\"https://www.semanticscholar.org/paper/fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.04306\",\"authors\":[{\"authorId\":\"31613801\",\"name\":\"Yi Wu\"},{\"authorId\":\"48608086\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"3025260\",\"name\":\"A. Tamar\"},{\"authorId\":\"153919677\",\"name\":\"S. Russell\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"}],\"doi\":\"10.1109/ICCV.2019.00286\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dffff97b8f37a5321550298494c9fa9199028ec\",\"title\":\"Bayesian Relational Memory for Semantic Visual Navigation\",\"url\":\"https://www.semanticscholar.org/paper/7dffff97b8f37a5321550298494c9fa9199028ec\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"2038685\",\"name\":\"Santosh Kumar Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144756076\",\"name\":\"Yong Jae Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"747d5fe667519acea1bee3df5cf94d9d6f874f20\",\"title\":\"Transferring Common-Sense Knowledge for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/747d5fe667519acea1bee3df5cf94d9d6f874f20\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1612.07411\",\"authors\":[{\"authorId\":\"2703486\",\"name\":\"Huayu Li\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"144143227\",\"name\":\"Y. Ge\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"}],\"doi\":\"10.1145/3097983.3098115\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"683f1d3bd6e4b3ee7b93ab76108d498ad41a3a6f\",\"title\":\"A Context-aware Attention Network for Interactive Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/683f1d3bd6e4b3ee7b93ab76108d498ad41a3a6f\",\"venue\":\"KDD\",\"year\":2017},{\"arxivId\":\"1704.03895\",\"authors\":[{\"authorId\":\"10730666\",\"name\":\"Siddha Ganju\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"title\":\"What's in a Question: Using Visual Questions as a Form of Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1802.00209\",\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b66dababebd800e95d23a1fde299d44a52e98ed\",\"title\":\"Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7b66dababebd800e95d23a1fde299d44a52e98ed\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528152\",\"name\":\"H. Wang\"},{\"authorId\":\"49468999\",\"name\":\"Xin Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2873570\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"title\":\"Multimodal Local Perception Bilinear Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2010.05406\",\"authors\":[{\"authorId\":\"4631835\",\"name\":\"Mingzhe Li\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"47357425\",\"name\":\"S. Gao\"},{\"authorId\":\"51177175\",\"name\":\"Zhangming Chan\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ed35a45f0d912afe37b915a30e2b254b946e10d\",\"title\":\"VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles\",\"url\":\"https://www.semanticscholar.org/paper/3ed35a45f0d912afe37b915a30e2b254b946e10d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144905355\",\"name\":\"Chao Ma\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"145950894\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"title\":\"Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/978-981-15-5788-0_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"title\":\"Optimal Image Feature Ranking and Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"venue\":\"FICTA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145478715\",\"name\":\"I. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.1109/ICIP.2017.8296600\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"title\":\"A cascaded long short-term memory (LSTM) driven generic visual question answering (VQA)\",\"url\":\"https://www.semanticscholar.org/paper/4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2486c41d1ec20dd53de912c77035743816638b6\",\"title\":\"An Active Information Seeking Model for Goal-oriented Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c2486c41d1ec20dd53de912c77035743816638b6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9653518\",\"name\":\"Yufei Ye\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"},{\"authorId\":\"153701831\",\"name\":\"G. Sigurdsson\"},{\"authorId\":\"32424449\",\"name\":\"A. Murali\"},{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"145456137\",\"name\":\"Tao Chen\"},{\"authorId\":\"144177386\",\"name\":\"N. Kulkarni\"},{\"authorId\":null,\"name\":\"Wenxuan Zhou\"},{\"authorId\":\"1391076188\",\"name\":\"Tian Ye\"},{\"authorId\":\"7463216\",\"name\":\"Gaurav Pathak\"},{\"authorId\":\"50465425\",\"name\":\"P. Sharma\"},{\"authorId\":\"3393217\",\"name\":\"Dhiraj Gandhi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a933264cc20eab7859fa6002f4aaecbf89d09395\",\"title\":\"Leveraging Structure for Generalization and Prediction in Visual System\",\"url\":\"https://www.semanticscholar.org/paper/a933264cc20eab7859fa6002f4aaecbf89d09395\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100516201\",\"name\":\"K. Yi\"},{\"authorId\":\"27223428\",\"name\":\"Zhiqiang Jian\"},{\"authorId\":\"9519140\",\"name\":\"Shi-tao Chen\"},{\"authorId\":null,\"name\":\"Yu Chen\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e45e74a3bdca430b66d9ecb4aab8c63c324f2f71\",\"title\":\"Knowledge-based Recurrent Attentive Neural Network for Traffic Sign Detection\",\"url\":\"https://www.semanticscholar.org/paper/e45e74a3bdca430b66d9ecb4aab8c63c324f2f71\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1705.02315\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"3774191\",\"name\":\"M. Bagheri\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2017.369\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05e882679d61f4c64a68ebe21826251a39f87e98\",\"title\":\"ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\",\"url\":\"https://www.semanticscholar.org/paper/05e882679d61f4c64a68ebe21826251a39f87e98\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.02071\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"49339267\",\"name\":\"Yanpeng Zhao\"},{\"authorId\":\"24027493\",\"name\":\"Shuaiyi Huang\"},{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1109/ICCV.2017.145\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5823d18cd378898b12de537862d996443ce9c9e8\",\"title\":\"Structured Attentions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5823d18cd378898b12de537862d996443ce9c9e8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82972947\",\"name\":\"Felipe Riquelme\"},{\"authorId\":\"1978662985\",\"name\":\"Alfredo De Goyeneche\"},{\"authorId\":\"49890233\",\"name\":\"Yundong Zhang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144949755\",\"name\":\"\\u00c1. Soto\"}],\"doi\":\"10.1016/j.imavis.2020.103968\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c956be94129de11a4deba6f1d34c5ae18b3fde\",\"title\":\"Explaining VQA predictions using visual grounding and a knowledge base\",\"url\":\"https://www.semanticscholar.org/paper/d2c956be94129de11a4deba6f1d34c5ae18b3fde\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1801.09718\",\"authors\":[{\"authorId\":\"35358246\",\"name\":\"Mikyas T. Desta\"},{\"authorId\":\"2230576\",\"name\":\"Larry Chen\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"}],\"doi\":\"10.1109/WACV.2018.00201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23d6bb8edcd86f8439072f932f414329b393473b\",\"title\":\"Object-Based Reasoning in VQA\",\"url\":\"https://www.semanticscholar.org/paper/23d6bb8edcd86f8439072f932f414329b393473b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"145863022\",\"name\":\"X. Zhang\"}],\"doi\":\"10.20944/PREPRINTS201804.0313.V1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.02234\",\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"},{\"authorId\":\"1924996\",\"name\":\"S. Herbin\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1007/978-3-030-20890-5_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"title\":\"Semantic bottleneck for computer vision tasks\",\"url\":\"https://www.semanticscholar.org/paper/ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1709.04625\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28853de59af8560dca5ff83f68f5af1cec0493d9\",\"title\":\"Robustness Analysis of Visual QA Models by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/28853de59af8560dca5ff83f68f5af1cec0493d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17817185\",\"name\":\"Sanae Achsas\"},{\"authorId\":\"3330938\",\"name\":\"E. Nfaoui\"}],\"doi\":\"10.11591/ijece.v10i4.pp3869-3882\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdb8dc43ef0c40791361db1c4f5e6ccce43a944c\",\"title\":\"Vertical intent prediction approach based on Doc2vec and convolutional neural networks for improving vertical selection in aggregated search\",\"url\":\"https://www.semanticscholar.org/paper/bdb8dc43ef0c40791361db1c4f5e6ccce43a944c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993611266\",\"name\":\"Guohao Li\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413943\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"title\":\"Boosting Visual Question Answering with Context-aware Knowledge Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66758719\",\"name\":\"Rahul Ambati\"},{\"authorId\":\"1574528555\",\"name\":\"Chakravardhan Reddy Dudyala\"}],\"doi\":\"10.1109/INDICON45594.2018.8987108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72379e4fbbc8a0bb52eac863188261f9951a9352\",\"title\":\"A Sequence-to-Sequence Model Approach for ImageCLEF 2018 Medical Domain Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72379e4fbbc8a0bb52eac863188261f9951a9352\",\"venue\":\"2018 15th IEEE India Council International Conference (INDICON)\",\"year\":2018},{\"arxivId\":\"1612.07833\",\"authors\":[{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"title\":\"Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task\",\"url\":\"https://www.semanticscholar.org/paper/6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.05546\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a8224266b8ab1483f6548307ab96227147f34da\",\"title\":\"Zero-Shot Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a8224266b8ab1483f6548307ab96227147f34da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36266636\",\"name\":\"J. Hahn\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c9c7f10f3d575e14eec3357440c88dfb287de3b\",\"title\":\"Hiding in plain sight: handwriting and applications to steganography\",\"url\":\"https://www.semanticscholar.org/paper/1c9c7f10f3d575e14eec3357440c88dfb287de3b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.11014\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a9015e511ec3da873f6114eeb542905a92d7d62\",\"title\":\"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA\",\"url\":\"https://www.semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1704.03162\",\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"2544590\",\"name\":\"Ali Elqursh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d674b540dcd968bc302ea4360df3f4e85e994b55\",\"title\":\"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d674b540dcd968bc302ea4360df3f4e85e994b55\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"46764518\",\"name\":\"Zhendong Niu\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"}],\"doi\":\"10.24963/ijcai.2019/720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad748d1772f893b3c8a3857a19292375be259daf\",\"title\":\"Knowledge Aware Semantic Concept Expansion for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/ad748d1772f893b3c8a3857a19292375be259daf\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"173a38768848cfe57a6b20b5ae019ce613e58781\",\"title\":\"Knowledge Acquisition for Visual Question Answering via Iterative Querying\",\"url\":\"https://www.semanticscholar.org/paper/173a38768848cfe57a6b20b5ae019ce613e58781\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.08105\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-01267-0_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a742c64f14b145b9e653ef30819520c5ce5e0123\",\"title\":\"Visual Question Answering as a Meta Learning Task\",\"url\":\"https://www.semanticscholar.org/paper/a742c64f14b145b9e653ef30819520c5ce5e0123\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034270322\",\"name\":\"Liyana Sahir Kallooriyakath\"},{\"authorId\":\"2034269084\",\"name\":\"Jithin M V\"},{\"authorId\":\"81431088\",\"name\":\"B. V\"},{\"authorId\":\"2034269088\",\"name\":\"Adith P P\"}],\"doi\":\"10.1109/ICSTCEE49637.2020.9277374\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea0ab46474037363b0a52b758538e61ccb90ecec\",\"title\":\"Visual Question Answering: Methodologies and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/ea0ab46474037363b0a52b758538e61ccb90ecec\",\"venue\":\"2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)\",\"year\":2020},{\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1109/CVPR42600.2020.01039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"title\":\"VQA With No Questions-Answers Training\",\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3269206.3271765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c67d62592ff24a25764e489a8a68672d40f50da7\",\"title\":\"Adversarial Learning of Answer-Related Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c67d62592ff24a25764e489a8a68672d40f50da7\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":\"1708.01956\",\"authors\":[{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"26538630\",\"name\":\"Z. Kyaw\"},{\"authorId\":\"46380822\",\"name\":\"Jinyang Yu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/ICCV.2017.454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65429789a95b3026457de76d46b5ec94158ce10e\",\"title\":\"PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel Pairwise R-FCN\",\"url\":\"https://www.semanticscholar.org/paper/65429789a95b3026457de76d46b5ec94158ce10e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1810.12681\",\"authors\":[{\"authorId\":\"19217972\",\"name\":\"Chenhan Jiang\"},{\"authorId\":\"35216010\",\"name\":\"H. Xu\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2979fdf4358f962593f33995e5dbc9714b0e4b73\",\"title\":\"Hybrid Knowledge Routed Modules for Large-scale Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2979fdf4358f962593f33995e5dbc9714b0e4b73\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1910.10706\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1609/AAAI.V34I07.6713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"title\":\"KnowIT VQA: Answering Knowledge-Based Questions about Videos\",\"url\":\"https://www.semanticscholar.org/paper/12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143844731\",\"name\":\"Yuan Fang\"},{\"authorId\":\"38513577\",\"name\":\"K. Kuan\"},{\"authorId\":\"144462791\",\"name\":\"Jie Lin\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.24963/IJCAI.2017/230\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74793980135737800c9d579f80605669d97cfcdb\",\"title\":\"Object Detection Meets Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/74793980135737800c9d579f80605669d97cfcdb\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3319373\",\"name\":\"Dirk Weissenborn\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a33e798c64d0cbf9015d5ad444c7f2cef3bce81\",\"title\":\"Reading Twice for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6a33e798c64d0cbf9015d5ad444c7f2cef3bce81\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143957784\",\"name\":\"M. Iqbal\"},{\"authorId\":\"119339025\",\"name\":\"H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.36227/techrxiv.12731948\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"182cff43865499c081c2ea9c441605ae6670ad5e\",\"title\":\"VISUAL QUESTION ANSWERING THROUGH ADVERSARIAL LEARNING OF MULTI-MODAL REPRESENTATION\",\"url\":\"https://www.semanticscholar.org/paper/182cff43865499c081c2ea9c441605ae6670ad5e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":\"1703.06492\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"title\":\"VQABQ: Visual Question Answering by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"92790579\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1007/978-3-030-13969-8_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d50d8da795bd50ebd14c4635116c159354409c9c\",\"title\":\"Automatic Classification and Reporting of Multiple Common Thorax Diseases Using Chest Radiographs\",\"url\":\"https://www.semanticscholar.org/paper/d50d8da795bd50ebd14c4635116c159354409c9c\",\"venue\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"144914662\",\"name\":\"F. Xiao\"},{\"authorId\":\"143728443\",\"name\":\"Le An\"},{\"authorId\":\"2989422\",\"name\":\"Xianzhong Long\"},{\"authorId\":\"48305363\",\"name\":\"Xiaochuan Sun\"}],\"doi\":\"10.1145/3300938\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"title\":\"Semantic Concept Network and Deep Walk-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.7282/T3-KA2Q-B984\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b198f5cb09446433a8d3a181107f408d26d5a34\",\"title\":\"Scene graph parsing and its application in cross-modal reasoning tasks\",\"url\":\"https://www.semanticscholar.org/paper/7b198f5cb09446433a8d3a181107f408d26d5a34\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.12520\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"82729121\",\"name\":\"Chentao Ye\"},{\"authorId\":\"9071958\",\"name\":\"Zihua Liu\"},{\"authorId\":\"32104754\",\"name\":\"Qingtao Hu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"title\":\"A Dataset and Baselines for Visual Question Answering on Art\",\"url\":\"https://www.semanticscholar.org/paper/fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1574421683\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":\"40282454\",\"name\":\"Y. Li\"},{\"authorId\":\"50218711\",\"name\":\"Z. Wang\"},{\"authorId\":\"15696552\",\"name\":\"Bin Wang\"}],\"doi\":\"10.1007/s11042-020-08790-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"title\":\"Object-difference drived graph convolutional networks for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1612.05386\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.416\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"title\":\"The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions\",\"url\":\"https://www.semanticscholar.org/paper/7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2007.02833\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"title\":\"Eliminating Catastrophic Interference with Biased Competition\",\"url\":\"https://www.semanticscholar.org/paper/07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1706.02596\",\"authors\":[{\"authorId\":\"3319373\",\"name\":\"Dirk Weissenborn\"},{\"authorId\":\"1389922915\",\"name\":\"Tom'avs Kovcisk'y\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f92b10acf7c405e55c74c1043dabd9ded1b1800\",\"title\":\"Dynamic Integration of Background Knowledge in Neural NLU Systems\",\"url\":\"https://www.semanticscholar.org/paper/2f92b10acf7c405e55c74c1043dabd9ded1b1800\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eeff23d6e0127cfbbd0374a83341173a418ba7f\",\"title\":\"Dual Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6eeff23d6e0127cfbbd0374a83341173a418ba7f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.24963/ijcai.2018/126\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"title\":\"From Pixels to Objects: Cubic Visual Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47817913\",\"name\":\"L. Chen\"},{\"authorId\":\"1397287686\",\"name\":\"Yifan Zhuo\"},{\"authorId\":\"48607932\",\"name\":\"Yingjie Wu\"},{\"authorId\":null,\"name\":\"Yilei Wang\"},{\"authorId\":\"1678585\",\"name\":\"Xianghan Zheng\"}],\"doi\":\"10.1007/978-3-030-31723-2_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bae56e688485148c1519ff8458ea2ba6b7fab3f2\",\"title\":\"Multi-modal Feature Fusion Based on Variational Autoencoder for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bae56e688485148c1519ff8458ea2ba6b7fab3f2\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1805.04247\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7605857f551d128e7c3babfc019950250f81bca9\",\"title\":\"Reciprocal Attention Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7605857f551d128e7c3babfc019950250f81bca9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1712.03316\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"title\":\"IQA: Visual Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"2010.16010\",\"authors\":[{\"authorId\":\"1390575046\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"title\":\"Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View\",\"url\":\"https://www.semanticscholar.org/paper/9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.11189\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"51230553\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2018.00756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57c36f13b188816051a27478e2f56bb284f4fb13\",\"title\":\"Iterative Visual Reasoning Beyond Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/57c36f13b188816051a27478e2f56bb284f4fb13\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"1716207091\",\"name\":\"Xuefeng Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3801644100f6f7e521b3f28c2785a2d151988f4\",\"title\":\"Joint Learning of Scene Graph Generation and Reasoning for Visual Question Answering Project Survey\",\"url\":\"https://www.semanticscholar.org/paper/c3801644100f6f7e521b3f28c2785a2d151988f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.08035\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"9653518\",\"name\":\"Yufei Ye\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2018.00717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff65e3bf34e892ef75d91c5e3d7294e0b64d867d\",\"title\":\"Zero-Shot Recognition via Semantic Embeddings and Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/ff65e3bf34e892ef75d91c5e3d7294e0b64d867d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267f3674d02ab3b53e0ac58e082380547b0bbf1c\",\"title\":\"Beyond Labels and Captions: Contextualizing Grounded Semantics for Explainable Visual Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/267f3674d02ab3b53e0ac58e082380547b0bbf1c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145382463\",\"name\":\"T. Zhao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01258-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"380d50f3ccc07fa4f41282395a78c51e33985c39\",\"title\":\"Deep Attention Neural Tensor Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/380d50f3ccc07fa4f41282395a78c51e33985c39\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1609.08124\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"title\":\"Learning Language-Visual Embedding for Movie Understanding with Natural-Language\",\"url\":\"https://www.semanticscholar.org/paper/2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51052405\",\"name\":\"H. Liu\"},{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"50356714\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.2991/CMSA-18.2018.80\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"483828a82b26db7761a3a47fadc971b561b53615\",\"title\":\"Multimodal Cross-guided Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/483828a82b26db7761a3a47fadc971b561b53615\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.03322\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"9072379\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"336cad600d15832243f4228b351c638630d64cb7\",\"title\":\"Learning to Respond with Your Favorite Stickers: A Framework of Unifying Multi-Modality and User Preference in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/336cad600d15832243f4228b351c638630d64cb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"title\":\"Research Statement Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"057b80e235b10799d03876ad25465208a4c64caf\",\"title\":\"Video Question Answering via Gradually Refined Attention over Appearance and Motion\",\"url\":\"https://www.semanticscholar.org/paper/057b80e235b10799d03876ad25465208a4c64caf\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144485908\",\"name\":\"Y. Long\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"47390553\",\"name\":\"Zhihua Wei\"},{\"authorId\":\"73723234\",\"name\":\"Jinjing Gu\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1016/j.ins.2020.04.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb8f7cb96782c422fdf67c48bcfef10b635cd6f0\",\"title\":\"RepeatPadding: Balancing words and sentence length for language comprehension in visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/eb8f7cb96782c422fdf67c48bcfef10b635cd6f0\",\"venue\":\"Inf. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"L. Wang\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1109/MIPR.2018.00038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"883800c16fd5250d43a195dfa8b4eeca0b7f7e0b\",\"title\":\"Affective Visual Question Answering Network\",\"url\":\"https://www.semanticscholar.org/paper/883800c16fd5250d43a195dfa8b4eeca0b7f7e0b\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":\"1902.09774\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"title\":\"Image-Question-Answer Synergistic Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/s11263-018-1096-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"title\":\"Combining Multiple Cues for Visual Madlibs Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/s11263-017-1033-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"828ac57f755db989e2886042a85278ae4823297c\",\"title\":\"Uncovering the Temporal Context for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/828ac57f755db989e2886042a85278ae4823297c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1806.04860\",\"authors\":[{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00807\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f08157b959070ba802afbb135f4336c5a426fd\",\"title\":\"Learning Visual Knowledge Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33f08157b959070ba802afbb135f4336c5a426fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"49298718\",\"name\":\"Jie Li\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3321505\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"title\":\"Video Question Answering via Knowledge-based Progressive Spatial-Temporal Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2006.15762\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"844e8fa1bb852cef5554c0033aa4e8ae7716b03e\",\"title\":\"Empirically Verifying Hypotheses Using Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/844e8fa1bb852cef5554c0033aa4e8ae7716b03e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.00713\",\"authors\":[{\"authorId\":\"49780826\",\"name\":\"Hao Zhou\"},{\"authorId\":\"1750897\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"144541695\",\"name\":\"Chuanping Hu\"}],\"doi\":\"10.1145/3343031.3351024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad4333224c77079da0aee6b2b4a31c7f14cbd886\",\"title\":\"Visual Relationship Detection with Relative Location Mining\",\"url\":\"https://www.semanticscholar.org/paper/ad4333224c77079da0aee6b2b4a31c7f14cbd886\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1801.07853\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"48032659\",\"name\":\"Xiaoyi Liu\"},{\"authorId\":\"49330599\",\"name\":\"Liangjian Chen\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"},{\"authorId\":\"100575838\",\"name\":\"Xiaohui Xie\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/WACV.2018.00209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"title\":\"Structured Triplet Learning with POS-Tag Guided Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a562e7c7da908ae9abde477a00bcc33921ee5e86\",\"title\":\"High-level Cues for Predicting Motivations\",\"url\":\"https://www.semanticscholar.org/paper/a562e7c7da908ae9abde477a00bcc33921ee5e86\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2004.10966\",\"authors\":[{\"authorId\":\"1389550960\",\"name\":\"Tasmia Tasrin\"},{\"authorId\":\"1381931976\",\"name\":\"Md Sultan Al Nahian\"},{\"authorId\":\"34442699\",\"name\":\"B. Harrison\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"title\":\"Visual Question Answering Using Semantic Information from Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2918814\",\"name\":\"Z. Bai\"},{\"authorId\":\"47002010\",\"name\":\"Y. Li\"},{\"authorId\":\"3309410\",\"name\":\"Meili Zhou\"},{\"authorId\":\"1409646866\",\"name\":\"Di Li\"},{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"1734496\",\"name\":\"Dawid Po\\u0142ap\"},{\"authorId\":\"144433006\",\"name\":\"M. Wo\\u017aniak\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206964\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07e8b56bc2f996c269d6550c8ff0195171cd7215\",\"title\":\"Bilinear Semi-Tensor Product Attention (BSTPA) model for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/07e8b56bc2f996c269d6550c8ff0195171cd7215\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453279481\",\"name\":\"Gonzalo Vaca Castano\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a851ad57feec3140b574c85851c436dacad8e70\",\"title\":\"Understanding images and videos using context\",\"url\":\"https://www.semanticscholar.org/paper/4a851ad57feec3140b574c85851c436dacad8e70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1807.00983\",\"authors\":[{\"authorId\":\"46246362\",\"name\":\"Ahmad Babaeian Jelodar\"},{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"144825829\",\"name\":\"Y. Sun\"}],\"doi\":\"10.1109/TMM.2018.2885228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85fd039557f8d623ada0b2eaf0819cb594689d7b\",\"title\":\"Long Activity Video Understanding Using Functional Object-Oriented Network\",\"url\":\"https://www.semanticscholar.org/paper/85fd039557f8d623ada0b2eaf0819cb594689d7b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1912.11861\",\"authors\":[{\"authorId\":\"1696018\",\"name\":\"Filippos Gouidis\"},{\"authorId\":\"1471858890\",\"name\":\"Alexandros Vassiliades\"},{\"authorId\":\"151470761\",\"name\":\"Theodore Patkos\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"},{\"authorId\":\"143804820\",\"name\":\"Nick Bassiliades\"},{\"authorId\":\"69853580\",\"name\":\"Dimitris Plexousakis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"487ca1670a7fd97ff33be6f7d85455d00cea63ea\",\"title\":\"A Review on Intelligent Object Perception Methods Combining Knowledge-based Reasoning and Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/487ca1670a7fd97ff33be6f7d85455d00cea63ea\",\"venue\":\"AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1145/3009906\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e60536c847ac25dba4c1c071e0355e5537fe061\",\"title\":\"Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/6e60536c847ac25dba4c1c071e0355e5537fe061\",\"venue\":\"ACM Comput. Surv.\",\"year\":2017},{\"arxivId\":\"1805.09701\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"50688017\",\"name\":\"L. Ji\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"29943965\",\"name\":\"Nan Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"}],\"doi\":\"10.1145/3219819.3220036\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"title\":\"R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":\"1903.05485\",\"authors\":[{\"authorId\":\"46398992\",\"name\":\"Y. Liu\"},{\"authorId\":\"40012524\",\"name\":\"Hui Li\"},{\"authorId\":\"1405061488\",\"name\":\"Alberto Garc\\u00eda-Dur\\u00e1n\"},{\"authorId\":\"2780262\",\"name\":\"Mathias Niepert\"},{\"authorId\":\"1403974204\",\"name\":\"Daniel O\\u00f1oro-Rubio\"},{\"authorId\":\"1889646\",\"name\":\"David S. Rosenblum\"}],\"doi\":\"10.1007/978-3-030-21348-0_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d593a5830a7e7d84443473c3912b59165056d45a\",\"title\":\"MMKG: Multi-Modal Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d593a5830a7e7d84443473c3912b59165056d45a\",\"venue\":\"ESWC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"title\":\"Preserved Knowledge Embedding Question : Why does the person have an umbrella ? Answer : It is raining . Knowledge Incorporated Open-Domain VQA Candidate Knowledge Retrieval Dynamic Memory Network Memory Updating Attention Machanisim Query\",\"url\":\"https://www.semanticscholar.org/paper/db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"86df3250b3c5218d76076e46662ac17a2650c611\",\"title\":\"3 Discussion : Knowledge Integration in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/86df3250b3c5218d76076e46662ac17a2650c611\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1145/3123266.3123335\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b44999bb2e23cf8ca0a413a2d006cc9800794650\",\"title\":\"More Than An Answer: Neural Pivot Network for Visual Qestion Answering\",\"url\":\"https://www.semanticscholar.org/paper/b44999bb2e23cf8ca0a413a2d006cc9800794650\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1811.12772\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":\"10.1016/j.imavis.2020.103985\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a678b68abd4047d5342f64725f57a04647a47711\",\"title\":\"From Known to the Unknown: Transferring Knowledge to Answer Questions about Novel Visual and Semantic Concepts\",\"url\":\"https://www.semanticscholar.org/paper/a678b68abd4047d5342f64725f57a04647a47711\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143607578\",\"name\":\"Daniel Ayala\"},{\"authorId\":\"120516594\",\"name\":\"A. Borrego\"},{\"authorId\":\"152781734\",\"name\":\"I. Hern\\u00e1ndez\"},{\"authorId\":\"145930857\",\"name\":\"D. Ruiz\"}],\"doi\":\"10.1016/j.eswa.2019.113053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9864350ec73e36627645d7c018b0b2a691820c7\",\"title\":\"A neural network for semantic labelling of structured information\",\"url\":\"https://www.semanticscholar.org/paper/f9864350ec73e36627645d7c018b0b2a691820c7\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1907.07863\",\"authors\":[{\"authorId\":\"49053414\",\"name\":\"S. Anwar\"},{\"authorId\":\"2698424\",\"name\":\"Chongyi Li\"}],\"doi\":\"10.1016/j.image.2020.115978\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f64b5c28465fc716ed838b4456589506af67e6d\",\"title\":\"Diving Deeper into Underwater Image Enhancement: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/9f64b5c28465fc716ed838b4456589506af67e6d\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"1400347434\",\"name\":\"Guanhong Zhou\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01163764edf888ded242e992845badaaf6c6ec6e\",\"title\":\"Residual Self-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01163764edf888ded242e992845badaaf6c6ec6e\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.10215\",\"authors\":[{\"authorId\":\"48631626\",\"name\":\"Xinyu Wang\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"46668045\",\"name\":\"Chun Chet Ng\"},{\"authorId\":\"30099960\",\"name\":\"Canjie Luo\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"46699480\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"35462302\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"title\":\"On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405709193\",\"name\":\"Gonzalo Vaca-Castano\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/J.CVIU.2019.02.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0efecabff90401ea60cc5bca791d00f5113fa73\",\"title\":\"Holistic object detection and image understanding\",\"url\":\"https://www.semanticscholar.org/paper/e0efecabff90401ea60cc5bca791d00f5113fa73\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152998639\",\"name\":\"Y. Li\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"47968029\",\"name\":\"Lingqiao Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f90b744cf3a4959689935416b9d40169b646e00\",\"title\":\"CNN joint embedding LSTM LSTM CNN joint embedding LSTM CNN joint embedding LSTM CNN joint embedding LSTM CNN joint embedding\",\"url\":\"https://www.semanticscholar.org/paper/2f90b744cf3a4959689935416b9d40169b646e00\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1611.09967\",\"authors\":[{\"authorId\":\"48513733\",\"name\":\"Y. Li\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.600\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d24b386d003bee176a942c26336dbe8f427aadd\",\"title\":\"Sequential Person Recognition in Photo Albums with a Recurrent Network\",\"url\":\"https://www.semanticscholar.org/paper/3d24b386d003bee176a942c26336dbe8f427aadd\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1910.14520\",\"authors\":[{\"authorId\":\"48016687\",\"name\":\"Haoyu Wang\"},{\"authorId\":\"50753116\",\"name\":\"M. Yu\"},{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"143863023\",\"name\":\"R. Das\"},{\"authorId\":\"22253126\",\"name\":\"Wenhan Xiong\"},{\"authorId\":\"143994460\",\"name\":\"Tian Gao\"}],\"doi\":\"10.18653/v1/D19-5813\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb86c76627d51d38e156ce15046513053f98f53b\",\"title\":\"Do Multi-hop Readers Dream of Reasoning Chains?\",\"url\":\"https://www.semanticscholar.org/paper/cb86c76627d51d38e156ce15046513053f98f53b\",\"venue\":\"MRQA@EMNLP\",\"year\":2019},{\"arxivId\":\"1712.00733\",\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23ed7f18100717ba814b2859196e10c5d4fed216\",\"title\":\"Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/23ed7f18100717ba814b2859196e10c5d4fed216\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1812.04239\",\"authors\":[{\"authorId\":\"2126047\",\"name\":\"Xiu-Shen Wei\"},{\"authorId\":\"31415725\",\"name\":\"Chen-Lin Zhang\"},{\"authorId\":\"47968029\",\"name\":\"Lingqiao Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"}],\"doi\":\"10.1007/978-3-030-20890-5_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01b94ffeef22187587a9d3b9aeefa6377f85baa7\",\"title\":\"Coarse-to-fine: A RNN-based hierarchical attention model for vehicle re-identification\",\"url\":\"https://www.semanticscholar.org/paper/01b94ffeef22187587a9d3b9aeefa6377f85baa7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1711.07613\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dde6ed569684356c46217fa53224272b668bae8\",\"title\":\"Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dde6ed569684356c46217fa53224272b668bae8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1380065125\",\"name\":\"Narges Honarvar Nazari\"},{\"authorId\":\"90323489\",\"name\":\"J. Hahn\"},{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/tpami.2019.2947440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86df22f8dbec3489432063ef569a4793dc232c70\",\"title\":\"Interpreting the Rhetoric of Visual Advertisements.\",\"url\":\"https://www.semanticscholar.org/paper/86df22f8dbec3489432063ef569a4793dc232c70\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1610.04062\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"title\":\"Video Fill in the Blank with Merging LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1709.08203\",\"authors\":[{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"2462516\",\"name\":\"Shagun Sodhani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e23229289b1fbea14bc425718bc0a227d100b8e\",\"title\":\"Survey of Recent Advances in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0e23229289b1fbea14bc425718bc0a227d100b8e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89813962\",\"name\":\"Shivangi Modi\"},{\"authorId\":\"153279050\",\"name\":\"Dhatri Pandya\"}],\"doi\":\"10.1109/ICCMC.2019.8819803\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c99654c738cf9a426fac40251e277282a8ee86a7\",\"title\":\"VQAR: Review on Information Retrieval Techniques based on Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/c99654c738cf9a426fac40251e277282a8ee86a7\",\"venue\":\"2019 3rd International Conference on Computing Methodologies and Communication (ICCMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145102294\",\"name\":\"Moreira de Souza\"},{\"authorId\":\"123900281\",\"name\":\"Fillipe Dias\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"title\":\"Semantic Description of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1705.03865\",\"authors\":[{\"authorId\":\"50178628\",\"name\":\"Akshay Kumar Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"637648198f9e91654ce27eaaa40512f2dc870fc1\",\"title\":\"Survey of Visual Question Answering: Datasets and Techniques\",\"url\":\"https://www.semanticscholar.org/paper/637648198f9e91654ce27eaaa40512f2dc870fc1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.04968\",\"authors\":[{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"title\":\"Visual Question Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1608.03410\",\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.5244/C.30.77\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"title\":\"Solving VIsual Madlibs with Multiple Cues\",\"url\":\"https://www.semanticscholar.org/paper/95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.18653/v1/P18-5004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"532837c431617d37c03361ba5a7d5fdb082c55f4\",\"title\":\"Connecting Language and Vision to Actions\",\"url\":\"https://www.semanticscholar.org/paper/532837c431617d37c03361ba5a7d5fdb082c55f4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ICASSP.2018.8461507\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54969341ec539ddaaf7537b7353e3cea84790eac\",\"title\":\"A Novel Semantic Attribute-Based Feature for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/54969341ec539ddaaf7537b7353e3cea84790eac\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924581\",\"name\":\"Jicheng Wang\"},{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1438588470\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"31048669\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11042-019-08439-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c48de74a40736498d6443f84ecdddc08275359f\",\"title\":\"Sequential image encoding for vision-to-language problems\",\"url\":\"https://www.semanticscholar.org/paper/0c48de74a40736498d6443f84ecdddc08275359f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25184078\",\"name\":\"M. Chevalier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b23981c8466e9a3b98f43b503d0dec0ac464bfa\",\"title\":\"R\\u00e9solution variable et information privil\\u00e9gi\\u00e9e pour la reconnaissance d'images. (Varying resolution and privileged information for image recognition)\",\"url\":\"https://www.semanticscholar.org/paper/1b23981c8466e9a3b98f43b503d0dec0ac464bfa\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1806.00857\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"31408089\",\"name\":\"Aron Szanto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a9135976912d4169a4490c641561ed0867a306c\",\"title\":\"On the Flip Side: Identifying Counterexamples in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2a9135976912d4169a4490c641561ed0867a306c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394415540\",\"name\":\"Xiankun Pei\"},{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"97522088\",\"name\":\"Ye Zhao\"}],\"doi\":\"10.1145/3347319.3356837\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91ef86ef55d7e70bdcc4e5ac20d798055f845736\",\"title\":\"Continuous Sign Language Recognition Based on Pseudo-supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/91ef86ef55d7e70bdcc4e5ac20d798055f845736\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50695255\",\"name\":\"S. Wang\"},{\"authorId\":\"144713153\",\"name\":\"Dan Guo\"},{\"authorId\":\"2779625\",\"name\":\"Wen-gang Zhou\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"}],\"doi\":\"10.1145/3240508.3240671\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33e309f993023a0384221733dd884e2b891c8311\",\"title\":\"Connectionist Temporal Fusion for Sign Language Translation\",\"url\":\"https://www.semanticscholar.org/paper/33e309f993023a0384221733dd884e2b891c8311\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100516201\",\"name\":\"K. Yi\"},{\"authorId\":\"27223428\",\"name\":\"Zhiqiang Jian\"},{\"authorId\":\"5369606\",\"name\":\"S. Chen\"},{\"authorId\":\"7607711\",\"name\":\"Yuedong Yang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30d38974207e5d43191b41906ed3200fde8660cd\",\"title\":\"Knowledge-based Recurrent Attentive Neural Network for Small Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/30d38974207e5d43191b41906ed3200fde8660cd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1909.07459\",\"authors\":[{\"authorId\":\"103393695\",\"name\":\"C. Jiang\"},{\"authorId\":\"3560734\",\"name\":\"Steven Weikai Lu\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3467c9977b875544221abbd8153facf2cb176759\",\"title\":\"Constructing Dynamic Knowledge Graph for Visual Semantic Understanding and Applications in Autonomous Robotics\",\"url\":\"https://www.semanticscholar.org/paper/3467c9977b875544221abbd8153facf2cb176759\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e464187b1cee23117a0b1b1b86a479bee011d991\",\"title\":\"Project on Visual Commonsense Reasoning Anonymous ACL submission\",\"url\":\"https://www.semanticscholar.org/paper/e464187b1cee23117a0b1b1b86a479bee011d991\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1612.01082\",\"authors\":[{\"authorId\":\"49050563\",\"name\":\"J. Zhang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"49051258\",\"name\":\"J. Zhang\"},{\"authorId\":\"145313246\",\"name\":\"Jianfeng Lu\"}],\"doi\":\"10.1109/TMM.2018.2812605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fc5465f3aa9c3efddd23cbaedf96399d9d40711\",\"title\":\"Multilabel Image Classification With Regional Latent Semantic Dependencies\",\"url\":\"https://www.semanticscholar.org/paper/1fc5465f3aa9c3efddd23cbaedf96399d9d40711\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1904.02865\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00204\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51932dc1148566040fdb0df6ed66d8d2a0712933\",\"title\":\"Actively Seeking and Learning From Live Data\",\"url\":\"https://www.semanticscholar.org/paper/51932dc1148566040fdb0df6ed66d8d2a0712933\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"1804.01077\",\"authors\":[{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1007/978-3-030-01261-8_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53e0ff629658f5a1b6d42be9a8892a0f16587ebc\",\"title\":\"DOCK: Detecting Objects by Transferring Common-Sense Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/53e0ff629658f5a1b6d42be9a8892a0f16587ebc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"1691826\",\"name\":\"Y. Li\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/ICIP.2016.7532764\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"940c42892bc5b012be2b2ac7421ccb15005781e6\",\"title\":\"Simple and effective visual question answering in a single modality\",\"url\":\"https://www.semanticscholar.org/paper/940c42892bc5b012be2b2ac7421ccb15005781e6\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121096333\",\"name\":\"Servio Palacios\"},{\"authorId\":\"120761366\",\"name\":\"K. M. Solaiman\"},{\"authorId\":\"1726391\",\"name\":\"Pelin Angin\"},{\"authorId\":\"84707434\",\"name\":\"A. Nesen\"},{\"authorId\":\"1712275\",\"name\":\"B. Bhargava\"},{\"authorId\":\"48426039\",\"name\":\"Zachary Collins\"},{\"authorId\":\"1390038553\",\"name\":\"Aaron Sipser\"},{\"authorId\":\"145345023\",\"name\":\"M. Stonebraker\"},{\"authorId\":\"46777936\",\"name\":\"J. Macdonald\"}],\"doi\":\"10.1007/978-3-030-33752-0_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b72d687d4b61796d47a21e56beb8657e47f01cdd\",\"title\":\"WIP - SKOD: A Framework for Situational Knowledge on Demand\",\"url\":\"https://www.semanticscholar.org/paper/b72d687d4b61796d47a21e56beb8657e47f01cdd\",\"venue\":\"Poly/DMAH@VLDB\",\"year\":2019},{\"arxivId\":\"1711.07614\",\"authors\":[{\"authorId\":\"39449550\",\"name\":\"J. Zhang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"31361101\",\"name\":\"J. Zhang\"},{\"authorId\":\"145313245\",\"name\":\"Jianfeng Lu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-01228-1_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d1ad43e4bde61534d6ddc5752151f1775c04d08\",\"title\":\"Asking the Difficult Questions: Goal-Oriented Visual Question Generation via Intermediate Rewards\",\"url\":\"https://www.semanticscholar.org/paper/3d1ad43e4bde61534d6ddc5752151f1775c04d08\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"}],\"doi\":\"10.1145/3313831.3376404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4501c700e6aefb261efa50a46e1b9091e175cad2\",\"title\":\"\\\"Person, Shoes, Tree. Is the Person Naked?\\\" What People with Vision Impairments Want in Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4501c700e6aefb261efa50a46e1b9091e175cad2\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":\"1810.10656\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86553974fabf38bbe022dc44794f345339b45c0b\",\"title\":\"Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures\",\"url\":\"https://www.semanticscholar.org/paper/86553974fabf38bbe022dc44794f345339b45c0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367790\",\"name\":\"Seong Jae Hwang\"},{\"authorId\":\"3023295\",\"name\":\"S. Ravi\"},{\"authorId\":\"46641029\",\"name\":\"Zirui Tao\"},{\"authorId\":\"40147719\",\"name\":\"H. Kim\"},{\"authorId\":\"31604982\",\"name\":\"Maxwell D. Collins\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2018.00112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b6d41795de1fd9a0da4227c83dc4dd038a229ec\",\"title\":\"Tensorize, Factorize and Regularize: Robust Visual Relationship Learning\",\"url\":\"https://www.semanticscholar.org/paper/1b6d41795de1fd9a0da4227c83dc4dd038a229ec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576781\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/JIOT.2017.2779865\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6cdf8dfa20d35af8714062d1ac203e80550ab6f\",\"title\":\"Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things\",\"url\":\"https://www.semanticscholar.org/paper/d6cdf8dfa20d35af8714062d1ac203e80550ab6f\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1016/j.cviu.2017.04.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"title\":\"Hierarchical & multimodal video captioning: Discovering and transferring multimodal knowledge for vision to language\",\"url\":\"https://www.semanticscholar.org/paper/96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2004.03755\",\"authors\":[{\"authorId\":\"27549522\",\"name\":\"Goonmeet Bajaj\"},{\"authorId\":\"153100367\",\"name\":\"B. Bandyopadhyay\"},{\"authorId\":\"144545992\",\"name\":\"D. Schmidt\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"32264523\",\"name\":\"Christopher W. Myers\"},{\"authorId\":\"143724543\",\"name\":\"S. Parthasarathy\"}],\"doi\":\"10.1109/CVPRW50498.2020.00201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"title\":\"Understanding Knowledge Gaps in Visual Question Answering: Implications for Gap Identification and Testing\",\"url\":\"https://www.semanticscholar.org/paper/e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020}],\"corpusId\":206594383,\"doi\":\"10.1109/CVPR.2016.500\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":12,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"references\":[{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1507.05670\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1776014\",\"name\":\"Ce Zhang\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"3216322\",\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9563d6fafb6ba09c082a57e8d9b31494029a45ac\",\"title\":\"Building a Large-scale Multimodal Knowledge Base for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9563d6fafb6ba09c082a57e8d9b31494029a45ac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"title\":\"What value high level concepts in vision to language problems\",\"url\":\"https://www.semanticscholar.org/paper/bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742448\",\"name\":\"K. Bollacker\"},{\"authorId\":\"144572178\",\"name\":\"C. Evans\"},{\"authorId\":\"2990264\",\"name\":\"Praveen Paritosh\"},{\"authorId\":\"1399112633\",\"name\":\"Tim Sturge\"},{\"authorId\":\"37715132\",\"name\":\"J. Taylor\"}],\"doi\":\"10.1145/1376616.1376746\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1976c9eeccc7115d18a04f1e7fb5145db6b96002\",\"title\":\"Freebase: a collaboratively created graph database for structuring human knowledge\",\"url\":\"https://www.semanticscholar.org/paper/1976c9eeccc7115d18a04f1e7fb5145db6b96002\",\"venue\":\"SIGMOD Conference\",\"year\":2008},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"cmp-lg/9406033\",\"authors\":[{\"authorId\":\"2459057\",\"name\":\"Z. Wu\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":\"10.3115/981732.981751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"title\":\"Verb Semantics and Lexical Selection\",\"url\":\"https://www.semanticscholar.org/paper/0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"venue\":\"ACL\",\"year\":1994},{\"arxivId\":\"1503.00848\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"},{\"authorId\":\"48509230\",\"name\":\"F. Marqu\\u00e9s\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/TPAMI.2016.2537320\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb2c4afc60b074d74a1cf5dd0b8b4f768a20626d\",\"title\":\"Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb2c4afc60b074d74a1cf5dd0b8b4f768a20626d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.5654\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"title\":\"Learning a Recurrent Visual Representation for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1502.06108\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7298917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"title\":\"Don't just listen, use your imagination: Leveraging visual common sense for non-visual tasks\",\"url\":\"https://www.semanticscholar.org/paper/e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Zhu\"},{\"authorId\":null,\"name\":\"C. Zhang\"},{\"authorId\":null,\"name\":\"C. R\\u00e9\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Building a Largescale Multimodal Knowledge Base for Visual Question Answering\",\"url\":\"\",\"venue\":\"arXiv:1507.05670\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"144529354\",\"name\":\"Wei Xia\"},{\"authorId\":\"143953684\",\"name\":\"M. Lin\"},{\"authorId\":\"1753492\",\"name\":\"Junshi Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145550812\",\"name\":\"J. Dong\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TPAMI.2015.2491929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32d850e556f39f6bbedcdef0e38f5cd295a6144f\",\"title\":\"HCP: A Flexible CNN Framework for Multi-Label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/32d850e556f39f6bbedcdef0e38f5cd295a6144f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1308.6628\",\"authors\":[{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"143764552\",\"name\":\"M. Meng\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"2194804\",\"name\":\"T. E. Choe\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/MMUL.2014.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2935d8071583e46c5a895730c65d2bd213757c07\",\"title\":\"Joint Video and Text Parsing for Understanding Events and Answering Queries\",\"url\":\"https://www.semanticscholar.org/paper/2935d8071583e46c5a895730c65d2bd213757c07\",\"venue\":\"IEEE MultiMedia\",\"year\":2014},{\"arxivId\":\"1506.00333\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"title\":\"Learning to Answer Questions from Image Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1410.8027\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"title\":\"Towards a Visual Turing Challenge\",\"url\":\"https://www.semanticscholar.org/paper/3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B. van Merrienboer\"},{\"authorId\":null,\"name\":\"C. Gulcehre\"},{\"authorId\":null,\"name\":\"F. Bougares\"},{\"authorId\":null,\"name\":\"H. Schwenk\"},{\"authorId\":null,\"name\":\"Y.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bengio . Learning phrase representations using rnn encoderdecoder for statistical machine translation\",\"url\":\"\",\"venue\":\"Proc . Conf . Empirical Methods in Natural Language Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3253737\",\"name\":\"F. Sadeghi\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2015.7298752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"495015d21c26eac9a6bd64c836ee3370283641ec\",\"title\":\"VisKE: Visual knowledge extraction and question answering by visual verification of relation phrases\",\"url\":\"https://www.semanticscholar.org/paper/495015d21c26eac9a6bd64c836ee3370283641ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1776014\",\"name\":\"Ce Zhang\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"131125a5aadb48ec3eceb404cedbff713c401feb\",\"title\":\"Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries\",\"url\":\"https://www.semanticscholar.org/paper/131125a5aadb48ec3eceb404cedbff713c401feb\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"48244232\",\"name\":\"A. Chou\"},{\"authorId\":\"34765463\",\"name\":\"Roy Frostig\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b29447ba499507a259ae9d8f685d60cc1597d7d3\",\"title\":\"Semantic Parsing on Freebase from Question-Answer Pairs\",\"url\":\"https://www.semanticscholar.org/paper/b29447ba499507a259ae9d8f685d60cc1597d7d3\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145044578\",\"name\":\"S. Auer\"},{\"authorId\":\"1729154\",\"name\":\"C. Bizer\"},{\"authorId\":\"2051816\",\"name\":\"Georgi Kobilarov\"},{\"authorId\":\"144568027\",\"name\":\"Jens Lehmann\"},{\"authorId\":\"1702661\",\"name\":\"Richard Cyganiak\"},{\"authorId\":\"1804315\",\"name\":\"Z. Ives\"}],\"doi\":\"10.1007/978-3-540-76298-0_52\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b2c30dfd3968c5d9418bb2c14b2382d3ccc64b2\",\"title\":\"DBpedia: A Nucleus for a Web of Open Data\",\"url\":\"https://www.semanticscholar.org/paper/2b2c30dfd3968c5d9418bb2c14b2382d3ccc64b2\",\"venue\":\"ISWC/ASWC\",\"year\":2007},{\"arxivId\":\"1405.4053\",\"authors\":[{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f527bcfb09f32e6a4a8afc0b37504941c1ba2cee\",\"title\":\"Distributed Representations of Sentences and Documents\",\"url\":\"https://www.semanticscholar.org/paper/f527bcfb09f32e6a4a8afc0b37504941c1ba2cee\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df4f851e3c37017822a683b1356c6c390b5b5487\",\"title\":\"Image Question Answering: A Visual Semantic Embedding Model and a New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/df4f851e3c37017822a683b1356c6c390b5b5487\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1648075979\",\"name\":\"B. A. R. Kernfach\"},{\"authorId\":\"1648268257\",\"name\":\"Nur IM Sommersemester\"},{\"authorId\":\"1648268256\",\"name\":\"\\u00dcbersicht Franz\\u00f6sisch\"},{\"authorId\":\"1648134774\",\"name\":\"\\u00dcbersicht Italienisch\"}],\"doi\":\"10.1515/9783111697888-004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fff1b293b45d06c8462021aa6c90c81e743e131b\",\"title\":\"B\",\"url\":\"https://www.semanticscholar.org/paper/fff1b293b45d06c8462021aa6c90c81e743e131b\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295799\",\"name\":\"D. Ferrucci\"},{\"authorId\":\"1793454\",\"name\":\"E. W. Brown\"},{\"authorId\":\"1684353\",\"name\":\"Jennifer Chu-Carroll\"},{\"authorId\":\"32653281\",\"name\":\"J. Fan\"},{\"authorId\":\"2771137\",\"name\":\"David Gondek\"},{\"authorId\":\"1973186\",\"name\":\"A. Kalyanpur\"},{\"authorId\":\"144071952\",\"name\":\"Adam Lally\"},{\"authorId\":\"145412011\",\"name\":\"J. William Murdock\"},{\"authorId\":\"144287919\",\"name\":\"Eric Nyberg\"},{\"authorId\":\"30210546\",\"name\":\"J. M. Prager\"},{\"authorId\":\"2807334\",\"name\":\"Nico Schlaefer\"},{\"authorId\":\"143778120\",\"name\":\"Chris Welty\"}],\"doi\":\"10.1609/AIMAG.V31I3.2303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ff2862a8121cc823a8eb72f3e0a97bbf25c82ec\",\"title\":\"Building Watson: An Overview of the DeepQA Project\",\"url\":\"https://www.semanticscholar.org/paper/3ff2862a8121cc823a8eb72f3e0a97bbf25c82ec\",\"venue\":\"AI Mag.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1406.5726\",\"authors\":[{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"144529354\",\"name\":\"Wei Xia\"},{\"authorId\":\"1753492\",\"name\":\"Junshi Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145550812\",\"name\":\"J. Dong\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TPAMI.2015.2491929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67bb920c40b161a543f29943e7d945789ef208cd\",\"title\":\"CNN: Single-label to Multi-label\",\"url\":\"https://www.semanticscholar.org/paper/67bb920c40b161a543f29943e7d945789ef208cd\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015}],\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Knowledge base\",\"topicId\":\"6201\",\"url\":\"https://www.semanticscholar.org/topic/6201\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Cyclic redundancy check\",\"topicId\":\"209863\",\"url\":\"https://www.semanticscholar.org/topic/209863\"},{\"topic\":\"Nonlinear gameplay\",\"topicId\":\"62171\",\"url\":\"https://www.semanticscholar.org/topic/62171\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Server (computing)\",\"topicId\":\"6042\",\"url\":\"https://www.semanticscholar.org/topic/6042\"},{\"topic\":\"Random neural network\",\"topicId\":\"136146\",\"url\":\"https://www.semanticscholar.org/topic/136146\"},{\"topic\":\"Software quality assurance\",\"topicId\":\"54373\",\"url\":\"https://www.semanticscholar.org/topic/54373\"}],\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"