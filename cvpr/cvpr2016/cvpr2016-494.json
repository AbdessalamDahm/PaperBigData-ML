"{\"abstract\":\"We introduce the MovieQA dataset which aims to evaluate automatic story comprehension from both video and text. The dataset consists of 14,944 questions about 408 movies with high semantic diversity. The questions range from simpler \\\"Who\\\" did \\\"What\\\" to \\\"Whom\\\", to \\\"Why\\\" and \\\"How\\\" certain events occurred. Each question comes with a set of five possible answers, a correct one and four deceiving answers provided by human annotators. Our dataset is unique in that it contains multiple sources of information - video clips, plots, subtitles, scripts, and DVS. We analyze our data through various statistics and methods. We further extend existing QA techniques to show that question-answering with such open-ended semantics is hard. We make this data set public along with an evaluation benchmark to encourage inspiring work in this challenging domain.\",\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\",\"url\":\"https://www.semanticscholar.org/author/2103464\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\",\"url\":\"https://www.semanticscholar.org/author/2214033\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\",\"url\":\"https://www.semanticscholar.org/author/1742325\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\",\"url\":\"https://www.semanticscholar.org/author/143805211\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\",\"url\":\"https://www.semanticscholar.org/author/2422559\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\",\"url\":\"https://www.semanticscholar.org/author/37895334\"}],\"citationVelocity\":87,\"citations\":[{\"arxivId\":\"1704.04689\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad2339c48ad4ffdd6100310dcbb1fb78e72fac98\",\"title\":\"Video Fill In the Blank Using LR/RL LSTMs with Spatial-Temporal Attentions\",\"url\":\"https://www.semanticscholar.org/paper/ad2339c48ad4ffdd6100310dcbb1fb78e72fac98\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"720efaa9dd0d63a81bf75246a18f79bd85172af0\",\"title\":\"Towards Traversing the Continuous Spectrum of Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/720efaa9dd0d63a81bf75246a18f79bd85172af0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"1478185914\",\"name\":\"Zehan Song\"},{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/TIP.2020.2963950\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"title\":\"Open-Ended Video Question Answering via Multi-Modal Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1707.00836\",\"authors\":[{\"authorId\":\"2593979\",\"name\":\"Kyung-Min Kim\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.24963/ijcai.2017/280\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e6cc717311c9c3dcf7279bc44e0c25b29650c15\",\"title\":\"DeepStory: Video Story QA by Deep Embedded Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/7e6cc717311c9c3dcf7279bc44e0c25b29650c15\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"2008.12520\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"82729121\",\"name\":\"Chentao Ye\"},{\"authorId\":\"9071958\",\"name\":\"Zihua Liu\"},{\"authorId\":\"32104754\",\"name\":\"Qingtao Hu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"title\":\"A Dataset and Baselines for Visual Question Answering on Art\",\"url\":\"https://www.semanticscholar.org/paper/fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f3da45ff0c3e1777c3a7830f79c10f5896bcc21\",\"title\":\"RIDING ROLE AGENT VEHICLE PLACE ROLE AGENT VEHICLE PLACE VALUE MAN HORSE OUTSIDE VALUE DOG SKATEBOARD\",\"url\":\"https://www.semanticscholar.org/paper/8f3da45ff0c3e1777c3a7830f79c10f5896bcc21\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"144738250\",\"name\":\"E. Erdem\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"79cba2b3d3b4289c19e324b0e833c3abeab0325e\",\"title\":\"2 RecipeQA Dataset The Recipe Question Answering ( RecipeQA ) dataset is a challenging multimodal dataset\",\"url\":\"https://www.semanticscholar.org/paper/79cba2b3d3b4289c19e324b0e833c3abeab0325e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.08385\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9b53307081ac7897fb84b646510907035be409\",\"title\":\"Knowledge-Based Visual Question Answering in Videos\",\"url\":\"https://www.semanticscholar.org/paper/ab9b53307081ac7897fb84b646510907035be409\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"46270526\",\"name\":\"Z. Liu\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053476\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dd133c6baed0b080687da0954754ea23abc8ba1\",\"title\":\"Video Question Generation via Semantic Rich Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dd133c6baed0b080687da0954754ea23abc8ba1\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1708.04923\",\"authors\":[{\"authorId\":\"34065547\",\"name\":\"Naveen Panwar\"},{\"authorId\":\"3064586\",\"name\":\"Shreya Khare\"},{\"authorId\":\"3350685\",\"name\":\"Neelamadhav Gantayat\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"40147882\",\"name\":\"Senthil Mani\"},{\"authorId\":\"2473935\",\"name\":\"A. Sankaran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"236dd39aa92c93b7114befcfc16c146ce809d52c\",\"title\":\"mAnI: Movie Amalgamation using Neural Imitation\",\"url\":\"https://www.semanticscholar.org/paper/236dd39aa92c93b7114befcfc16c146ce809d52c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"144136646\",\"name\":\"X. Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"144354055\",\"name\":\"Elizabeth Clark\"},{\"authorId\":\"144290719\",\"name\":\"D. Elson\"},{\"authorId\":\"2320509\",\"name\":\"Marjan Ghazvininejad\"},{\"authorId\":\"144380001\",\"name\":\"A. Gordon\"},{\"authorId\":null,\"name\":\"Gunhee Kim\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"50556697\",\"name\":\"S. Lukin\"},{\"authorId\":\"144431718\",\"name\":\"J. Magalh\\u00e3es\"},{\"authorId\":\"143945660\",\"name\":\"L. Martin\"},{\"authorId\":null,\"name\":\"Saif Mohammad\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"},{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"804e20b0e07157fb466999c6674c72c39de979e2\",\"title\":\"Event-centric Context Modeling : The Case of Story Comprehension and Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/804e20b0e07157fb466999c6674c72c39de979e2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48518113\",\"name\":\"Yang Lu\"},{\"authorId\":\"2042317896\",\"name\":\"Asri Rizki Yuliani\"},{\"authorId\":\"1381849055\",\"name\":\"K. Ishikawa\"},{\"authorId\":\"2042312191\",\"name\":\"Ronaldo Prata Amorim\"},{\"authorId\":\"1699604746\",\"name\":\"Roland Hartanto\"},{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"3318094\",\"name\":\"K. Uto\"},{\"authorId\":\"9280008\",\"name\":\"K. Shinoda\"}],\"doi\":\"10.1145/3395035.3425639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29f2e2b0b19d01fba40f9bb679af130a3b4a400b\",\"title\":\"Deep Video Understanding of Character Relationships in Movies\",\"url\":\"https://www.semanticscholar.org/paper/29f2e2b0b19d01fba40f9bb679af130a3b4a400b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1801.09036\",\"authors\":[{\"authorId\":\"2606846\",\"name\":\"W. Zadrozny\"},{\"authorId\":\"3147629\",\"name\":\"L. Garbayo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8578c3fc7900b33b47f0017dd527713a70b6aec\",\"title\":\"A Sheaf Model of Contradictions and Disagreements. Preliminary Report and Discussion\",\"url\":\"https://www.semanticscholar.org/paper/a8578c3fc7900b33b47f0017dd527713a70b6aec\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.04950\",\"authors\":[{\"authorId\":\"51906624\",\"name\":\"Catalina Cangea\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"},{\"authorId\":\"144269589\",\"name\":\"P. Li\\u00f2\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad732e16296b62ba1de9a22bd01452590b52a2fc\",\"title\":\"VideoNavQA: Bridging the Gap between Visual and Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad732e16296b62ba1de9a22bd01452590b52a2fc\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2002.10941\",\"authors\":[{\"authorId\":\"150319570\",\"name\":\"Tae Jun Ham\"},{\"authorId\":\"5079259\",\"name\":\"S. J. Jung\"},{\"authorId\":\"15319292\",\"name\":\"Seonghak Kim\"},{\"authorId\":\"3072985\",\"name\":\"Young H. Oh\"},{\"authorId\":\"1504704369\",\"name\":\"Yeonhong Park\"},{\"authorId\":\"11977680\",\"name\":\"Yongchan Song\"},{\"authorId\":\"2951798\",\"name\":\"Junghun Park\"},{\"authorId\":\"153311118\",\"name\":\"Sang-Hee Lee\"},{\"authorId\":\"144341935\",\"name\":\"K. Park\"},{\"authorId\":\"3091593\",\"name\":\"J. Lee\"},{\"authorId\":\"2850552\",\"name\":\"Deog-Kyoon Jeong\"}],\"doi\":\"10.1109/HPCA47549.2020.00035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3c6c635b9cfd8890c7244d3db4be53d45944963\",\"title\":\"A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation\",\"url\":\"https://www.semanticscholar.org/paper/d3c6c635b9cfd8890c7244d3db4be53d45944963\",\"venue\":\"2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2481662\",\"name\":\"Y. Zhou\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00775\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"title\":\"Now You Shake Me: Towards Automatic 4D Cinema\",\"url\":\"https://www.semanticscholar.org/paper/ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1912.01046\",\"authors\":[{\"authorId\":\"1441128975\",\"name\":\"Anthony Colas\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"1441127595\",\"name\":\"Siddhesh Gupte\"},{\"authorId\":\"1786275\",\"name\":\"D. Wang\"},{\"authorId\":\"2133420\",\"name\":\"Doo Soon Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1b32cb6be81f67bba12e40a6f5bb9eae9da0214e\",\"title\":\"TutorialVQA: Question Answering Dataset for Tutorial Videos\",\"url\":\"https://www.semanticscholar.org/paper/1b32cb6be81f67bba12e40a6f5bb9eae9da0214e\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1909.00142\",\"authors\":[{\"authorId\":\"46221498\",\"name\":\"Mingda Chen\"},{\"authorId\":\"2802149\",\"name\":\"Zewei Chu\"},{\"authorId\":\"1700980\",\"name\":\"Kevin Gimpel\"}],\"doi\":\"10.18653/v1/D19-1060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ce0747436d0673439cf5b827cde605501b27f80\",\"title\":\"Evaluation Benchmarks and Learning Criteriafor Discourse-Aware Sentence Representations\",\"url\":\"https://www.semanticscholar.org/paper/7ce0747436d0673439cf5b827cde605501b27f80\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49576171\",\"name\":\"Lingxiao Yang\"},{\"authorId\":\"46335319\",\"name\":\"D. Zhang\"},{\"authorId\":\"48571012\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V33I01.33019095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96fa23766fb070dadf33bd615a4d61c4831b3cea\",\"title\":\"Learning a Visual Tracker from a Single Movie without Annotation\",\"url\":\"https://www.semanticscholar.org/paper/96fa23766fb070dadf33bd615a4d61c4831b3cea\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2001.06206\",\"authors\":[{\"authorId\":\"9628638\",\"name\":\"Yun-Wei Chu\"},{\"authorId\":\"152923110\",\"name\":\"Kuan-Yen Lin\"},{\"authorId\":\"23608432\",\"name\":\"Chao-Chun Hsu\"},{\"authorId\":\"1746959\",\"name\":\"Lun-Wei Ku\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e885f1523349be48c884a4663d705487fde05b8a\",\"title\":\"Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/e885f1523349be48c884a4663d705487fde05b8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1608.07905\",\"authors\":[{\"authorId\":\"2992833\",\"name\":\"Shuohang Wang\"},{\"authorId\":\"144924150\",\"name\":\"Jing Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff1861b71eaedba46cb679bbe2c585dbe18f9b19\",\"title\":\"Machine Comprehension Using Match-LSTM and Answer Pointer\",\"url\":\"https://www.semanticscholar.org/paper/ff1861b71eaedba46cb679bbe2c585dbe18f9b19\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.02315\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"3774191\",\"name\":\"M. Bagheri\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2017.369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05e882679d61f4c64a68ebe21826251a39f87e98\",\"title\":\"ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\",\"url\":\"https://www.semanticscholar.org/paper/05e882679d61f4c64a68ebe21826251a39f87e98\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944274\",\"name\":\"Hongyin Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfe973d679b431276bc1dcb3a019a0272f14ffe9\",\"title\":\"Neural Attentions for Natural Language Understanding and Modeling by Hongyin Luo\",\"url\":\"https://www.semanticscholar.org/paper/bfe973d679b431276bc1dcb3a019a0272f14ffe9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2545727\",\"name\":\"T. S. Jayram\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"},{\"authorId\":\"88000484\",\"name\":\"V. Albouy\"},{\"authorId\":\"13177954\",\"name\":\"E. Sevgen\"},{\"authorId\":\"50192121\",\"name\":\"A. Ozcan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83530220b52280e857a81cc9f8774e92bb6817c3\",\"title\":\"Learning Multi-Step Spatio-Temporal Reasoning with Selective Attention Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/83530220b52280e857a81cc9f8774e92bb6817c3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.04938\",\"authors\":[{\"authorId\":\"8093340\",\"name\":\"Shuming Ma\"},{\"authorId\":\"145500855\",\"name\":\"Lei Cui\"},{\"authorId\":\"10780897\",\"name\":\"Damai Dai\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.1609/AAAI.V33I01.33016810\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09e39f4334417f92bddc20072f43efade9bd5b60\",\"title\":\"LiveBot: Generating Live Video Comments Based on Visual and Textual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/09e39f4334417f92bddc20072f43efade9bd5b60\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1812.02664\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"48985581\",\"name\":\"Manli Zhang\"},{\"authorId\":\"47538869\",\"name\":\"J. Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"2259699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":\"10.1109/CVPR.2019.00684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41db31c451cd819d22f9c0b90be110edc4424911\",\"title\":\"Recursive Visual Attention in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/41db31c451cd819d22f9c0b90be110edc4424911\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.04553\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207580\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a733dab9614611567209628a770b5fe19ad41f\",\"title\":\"Neural Reasoning, Fast and Slow, for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/45a733dab9614611567209628a770b5fe19ad41f\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2012.10210\",\"authors\":[{\"authorId\":\"108630954\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"2455565\",\"name\":\"S. Xiao\"},{\"authorId\":\"115718758\",\"name\":\"A. Mclean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"title\":\"On modality bias in the TVQA dataset.\",\"url\":\"https://www.semanticscholar.org/paper/6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144968846\",\"name\":\"Kun Xu\"},{\"authorId\":\"7827757\",\"name\":\"Yuxuan Lai\"},{\"authorId\":\"1717629\",\"name\":\"Yansong Feng\"},{\"authorId\":\"48708910\",\"name\":\"Zhongyu Wang\"}],\"doi\":\"10.18653/v1/N19-1301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bc33f2d6bb9e6100b720e09c44e6c3ebee5614f\",\"title\":\"Enhancing Key-Value Memory Neural Networks for Knowledge Based Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8bc33f2d6bb9e6100b720e09c44e6c3ebee5614f\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2005.00343\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1109/TPAMI.2020.2991965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1badccbe4a3cbf8662b924a97bbeea14fe2f1ac7\",\"title\":\"The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1badccbe4a3cbf8662b924a97bbeea14fe2f1ac7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1709.07992\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"title\":\"Visual Reference Resolution using Attention Memory for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"143761093\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68ea8690a6e55c00bdf6df50af6d14a0ad08914f\",\"title\":\"Input Clips CNN Features Clip Representation How many times eyes ?\",\"url\":\"https://www.semanticscholar.org/paper/68ea8690a6e55c00bdf6df50af6d14a0ad08914f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1007/978-3-030-01225-0_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"title\":\"Scaling Egocentric Vision: The Dataset\",\"url\":\"https://www.semanticscholar.org/paper/443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1801.01967\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-01261-8_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"title\":\"Visual Text Correction\",\"url\":\"https://www.semanticscholar.org/paper/ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2018.00008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/s11263-017-1033-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"828ac57f755db989e2886042a85278ae4823297c\",\"title\":\"Uncovering the Temporal Context for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/828ac57f755db989e2886042a85278ae4823297c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1711.07280\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"12139064\",\"name\":\"Jake Bruce\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd9642470ff8c2089427f7a6392cd17d213a334\",\"title\":\"Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments\",\"url\":\"https://www.semanticscholar.org/paper/6bd9642470ff8c2089427f7a6392cd17d213a334\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1609.08124\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"title\":\"Learning Language-Visual Embedding for Movie Understanding with Natural-Language\",\"url\":\"https://www.semanticscholar.org/paper/2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/WACV.2019.00026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"183bf77d4f9b4eb227ba1d5a26eff5b6ab3d889d\",\"title\":\"Going Deeper With Semantics: Video Activity Interpretation Using Semantic Contextualization\",\"url\":\"https://www.semanticscholar.org/paper/183bf77d4f9b4eb227ba1d5a26eff5b6ab3d889d\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35330701\",\"name\":\"K. Takanashi\"},{\"authorId\":\"71687093\",\"name\":\"T. Kawahara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88452dc70b263442c5da454fa801e80200a4d948\",\"title\":\"18th Annual Meeting of the Special Interest Group on Discourse and Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/88452dc70b263442c5da454fa801e80200a4d948\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1712.05558\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68773df340498768e88487abe8f7fbac5fcb52d\",\"title\":\"CoDraw: Visual Dialog for Collaborative Drawing\",\"url\":\"https://www.semanticscholar.org/paper/b68773df340498768e88487abe8f7fbac5fcb52d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48754879\",\"name\":\"F. Zeng\"},{\"authorId\":null,\"name\":\"Chen Wang\"},{\"authorId\":\"5136757\",\"name\":\"S. Ge\"}],\"doi\":\"10.1109/ACCESS.2020.3011438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d17362c79ff42760c70235fb377923f0caad1f3a\",\"title\":\"A Survey on Visual Navigation for Artificial Agents With Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d17362c79ff42760c70235fb377923f0caad1f3a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"49982480\",\"name\":\"Yuanyuan Ge\"},{\"authorId\":\"47909272\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s11042-018-5868-x\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"title\":\"Remember and forget: video and text fusion for video question answering\",\"url\":\"https://www.semanticscholar.org/paper/ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fernanda Mora Alba\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0b6d734f00ec06d7382cff070686f43e127a37c6\",\"title\":\"Recent efforts towards Machine Reading Comprehension : A Literature Review Mar\\u0131\\u0301a\",\"url\":\"https://www.semanticscholar.org/paper/0b6d734f00ec06d7382cff070686f43e127a37c6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15634170\",\"name\":\"S. Huang\"},{\"authorId\":\"3225210\",\"name\":\"Shaohan Hu\"},{\"authorId\":\"1466481870\",\"name\":\"Bencheng Yan\"}],\"doi\":\"10.1007/978-3-030-36718-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77465a0ae333a9ce4cf3969b93e756772714fc63\",\"title\":\"Watch and Ask: Video Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/77465a0ae333a9ce4cf3969b93e756772714fc63\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703411\",\"name\":\"T. Liu\"},{\"authorId\":\"15566220\",\"name\":\"Yu-Hsueh Wu\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a101ef97b358036a560b906581400549688535c0\",\"title\":\"Attention-based CNN Matching Net\",\"url\":\"https://www.semanticscholar.org/paper/a101ef97b358036a560b906581400549688535c0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.12043\",\"authors\":[{\"authorId\":\"49955730\",\"name\":\"Haibin Lin\"},{\"authorId\":\"144978189\",\"name\":\"Hang Zhang\"},{\"authorId\":\"50032176\",\"name\":\"Yifei Ma\"},{\"authorId\":\"145633170\",\"name\":\"Tong He\"},{\"authorId\":\"48805322\",\"name\":\"Zhi Zhang\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":null,\"name\":\"Mu Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64957205022593d904070a399a8d5675a08ffaf4\",\"title\":\"Dynamic Mini-batch SGD for Elastic Distributed Training: Learning in the Limbo of Resources\",\"url\":\"https://www.semanticscholar.org/paper/64957205022593d904070a399a8d5675a08ffaf4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.10092\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2019.00679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"title\":\"Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"2005221955\",\"name\":\"Ali Movaghar\"}],\"doi\":\"10.36227/techrxiv.12928544.v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b678835c5de86ebe2031da902957aead8de931aa\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/b678835c5de86ebe2031da902957aead8de931aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"4781463\",\"name\":\"Deniz Oktay\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.327\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03c48850373b40f32b2bc0b1fbf7c13ccf0c8063\",\"title\":\"Predicting Motivations of Actions by Leveraging Text\",\"url\":\"https://www.semanticscholar.org/paper/03c48850373b40f32b2bc0b1fbf7c13ccf0c8063\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yuta Kayatani\"},{\"authorId\":null,\"name\":\"Zekun Yang\"},{\"authorId\":null,\"name\":\"Mayu Otani\"},{\"authorId\":null,\"name\":\"Noa Garcia\"},{\"authorId\":null,\"name\":\"Chenhui Chu\"},{\"authorId\":null,\"name\":\"Yuta Nakashima\"},{\"authorId\":null,\"name\":\"Haruo Takemura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"168cb89383ae1d09c32f4c8f185a154f8b2c3754\",\"title\":\"The Laughing Machine: Predicting Humor in Video\",\"url\":\"https://www.semanticscholar.org/paper/168cb89383ae1d09c32f4c8f185a154f8b2c3754\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1608.07775\",\"authors\":[{\"authorId\":\"145359073\",\"name\":\"Wei Fang\"},{\"authorId\":\"3451540\",\"name\":\"Juei-Yang Hsu\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"145535692\",\"name\":\"L. Lee\"}],\"doi\":\"10.1109/SLT.2016.7846270\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70d9b39be1df90f7ea4807012117015ce5e5f1e9\",\"title\":\"Hierarchical attention model for improved machine comprehension of spoken content\",\"url\":\"https://www.semanticscholar.org/paper/70d9b39be1df90f7ea4807012117015ce5e5f1e9\",\"venue\":\"2016 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John R. Smith\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"},{\"authorId\":\"33334609\",\"name\":\"Jozef Cota\"}],\"doi\":\"10.1145/3123266.3127906\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7ebb463f1b50997ad28624bccf4397986ab7837d\",\"title\":\"Harnessing A.I. for Augmenting Creativity: Application to Movie Trailer Creation\",\"url\":\"https://www.semanticscholar.org/paper/7ebb463f1b50997ad28624bccf4397986ab7837d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"46867115\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"00b8cf945c995ea9ba6307f5dca308d22f4deab7\",\"title\":\"Jurassic World Hotel Rwanda One Day Toy Story Action Sci-Fi Adventure monster suspense escape murder violence death Drama History War Drama Romance love Animation Comedy Fantasy escape\",\"url\":\"https://www.semanticscholar.org/paper/00b8cf945c995ea9ba6307f5dca308d22f4deab7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9711610\",\"name\":\"Matthias Blohm\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cbf6f7f4df4b91830f77565592055c1eb993c2ab\",\"title\":\"Machine Question Answering with Attention-based Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cbf6f7f4df4b91830f77565592055c1eb993c2ab\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7675364\",\"name\":\"Tapan Chowdhury\"},{\"authorId\":\"9340604\",\"name\":\"Samya Muhuri\"},{\"authorId\":\"117839282\",\"name\":\"S. Chakraborty\"},{\"authorId\":\"46248871\",\"name\":\"Sabitri Nanda Chakraborty\"}],\"doi\":\"10.1109/TCSS.2019.2931721\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"818273a6445ffedfee0abcb9169cbec7f91b21c4\",\"title\":\"Analysis of Adapted Films and Stories Based on Social Network\",\"url\":\"https://www.semanticscholar.org/paper/818273a6445ffedfee0abcb9169cbec7f91b21c4\",\"venue\":\"IEEE Transactions on Computational Social Systems\",\"year\":2019},{\"arxivId\":\"1902.07285\",\"authors\":[{\"authorId\":\"49337126\",\"name\":\"Wenqi Wang\"},{\"authorId\":\"120692761\",\"name\":\"Lina Wang\"},{\"authorId\":\"108085540\",\"name\":\"Run Wang\"},{\"authorId\":\"3623271\",\"name\":\"Zhibo Wang\"},{\"authorId\":\"72069484\",\"name\":\"Aoshuang Ye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"45a06f184092522751d19f93f4297ff678ad1ba7\",\"title\":\"Towards a Robust Deep Neural Network in Texts: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/45a06f184092522751d19f93f4297ff678ad1ba7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144610224\",\"name\":\"Dan Su\"},{\"authorId\":\"40539650\",\"name\":\"Pascale Fung\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053979\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"976c781d35bd9b609c45b401b18e87164d4fc31f\",\"title\":\"Improving Spoken Question Answering Using Contextualized Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/976c781d35bd9b609c45b401b18e87164d4fc31f\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1903.01000\",\"authors\":[{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"4241648\",\"name\":\"M. S. Sarfraz\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/FG.2019.8756609\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bae0a603d88f47b0ebdb1e325031c36f63dba738\",\"title\":\"Self-Supervised Learning of Face Representations for Video Face Clustering\",\"url\":\"https://www.semanticscholar.org/paper/bae0a603d88f47b0ebdb1e325031c36f63dba738\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16726627\",\"name\":\"C. Liu\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1007/978-3-030-20876-9_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1687d0120e937d5efe2022cbeab19b38edba0608\",\"title\":\"A2A: Attention to Attention Reasoning for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1687d0120e937d5efe2022cbeab19b38edba0608\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1809.00812\",\"authors\":[{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.18653/v1/D18-1166\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c581686edbd7227e9eb4a0841cce16728ca27369\",\"title\":\"RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes\",\"url\":\"https://www.semanticscholar.org/paper/c581686edbd7227e9eb4a0841cce16728ca27369\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2005.06409\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"151270642\",\"name\":\"Zineng Tang\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"title\":\"Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1809.03707\",\"authors\":[{\"authorId\":\"51929143\",\"name\":\"M. Wagner\"},{\"authorId\":\"7005920\",\"name\":\"H. Basevi\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"1732672\",\"name\":\"A. Leonardis\"}],\"doi\":\"10.1007/978-3-030-11009-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"918f122b385c5de709d076063527e850c2666c78\",\"title\":\"Answering Visual What-If Questions: From Actions to Predicted Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/918f122b385c5de709d076063527e850c2666c78\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"}],\"doi\":\"10.1016/B978-0-12-809276-7.00014-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef42dd8253dc2de6be45af130d96348edd8b1313\",\"title\":\"Activity Forecasting: An Invitation to Predictive Perception\",\"url\":\"https://www.semanticscholar.org/paper/ef42dd8253dc2de6be45af130d96348edd8b1313\",\"venue\":\"Group and Crowd Behavior for Computer Vision\",\"year\":2017},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31942796\",\"name\":\"Weiping Pei\"},{\"authorId\":\"35296083\",\"name\":\"A. Mayer\"},{\"authorId\":\"1643955434\",\"name\":\"Kaylynn Tu\"},{\"authorId\":\"47746514\",\"name\":\"Chuan Yue\"}],\"doi\":\"10.1145/3366423.3380195\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6467e86d660b87fdad8554f51eaf56237231e2f\",\"title\":\"Attention Please: Your Attention Check Questions in Survey Studies Can Be Automatically Answered\",\"url\":\"https://www.semanticscholar.org/paper/a6467e86d660b87fdad8554f51eaf56237231e2f\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1705.01253\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1016/j.neucom.2018.06.069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"783e48629dfbb44697b15a3bc0cb2aa3eea490eb\",\"title\":\"The Forgettable-Watcher Model for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/783e48629dfbb44697b15a3bc0cb2aa3eea490eb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1612.03094\",\"authors\":[{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1145d3d5c96157a9b19c1bedb090a5157537ad97\",\"title\":\"Following Gaze Across Views\",\"url\":\"https://www.semanticscholar.org/paper/1145d3d5c96157a9b19c1bedb090a5157537ad97\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1806.08409\",\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICASSP.2019.8682583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"title\":\"End-to-end Audio Visual Scene-aware Dialog Using Multimodal Attention-based Video Features\",\"url\":\"https://www.semanticscholar.org/paper/85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"title\":\"Explore Multi-Step Reasoning in Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1904.00623\",\"authors\":[{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"7236400\",\"name\":\"S. Choi\"},{\"authorId\":\"70262116\",\"name\":\"Jaeseo Lim\"},{\"authorId\":\"7951400\",\"name\":\"J. Kim\"},{\"authorId\":\"89496405\",\"name\":\"Jeh-Kwang Ryu\"},{\"authorId\":\"39171461\",\"name\":\"B. Bae\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b27b6df500b4fc50092f22727a90111b2010a588\",\"title\":\"Constructing Hierarchical Q&A Datasets for Video Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b27b6df500b4fc50092f22727a90111b2010a588\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.01876\",\"authors\":[{\"authorId\":\"8780591\",\"name\":\"S. Mueller\"},{\"authorId\":\"1701142\",\"name\":\"R. Hoffman\"},{\"authorId\":\"1703064\",\"name\":\"W. Clancey\"},{\"authorId\":\"68975512\",\"name\":\"Abigail Emrey\"},{\"authorId\":\"145555383\",\"name\":\"G. Klein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c3a72f47ed8d58c0554210828af1ce4bbf2dbcd\",\"title\":\"Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI\",\"url\":\"https://www.semanticscholar.org/paper/5c3a72f47ed8d58c0554210828af1ce4bbf2dbcd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.03725\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc7a3573a464bca2cdca71f6f32e798464b85ee6\",\"title\":\"Exploiting Semantic Contextualization for Interpretation of Human Activity in Videos\",\"url\":\"https://www.semanticscholar.org/paper/bc7a3573a464bca2cdca71f6f32e798464b85ee6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134488190\",\"name\":\"M. V. van Gerven\"}],\"doi\":\"10.3389/fncom.2017.00112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2eecc3a6bed4c884f5100cb8b4c7c571710aeee9\",\"title\":\"Computational Foundations of Natural Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/2eecc3a6bed4c884f5100cb8b4c7c571710aeee9\",\"venue\":\"Front. Comput. Neurosci.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49046603\",\"name\":\"C. Liu\"},{\"authorId\":\"2887672\",\"name\":\"A. Shmilovici\"},{\"authorId\":\"3045152\",\"name\":\"Mark Last\"}],\"doi\":\"10.1371/journal.pone.0228579\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab4c7c12dd96b2e746666c6bdd9a59fdbd3c4f2f\",\"title\":\"Towards story-based classification of movie scenes\",\"url\":\"https://www.semanticscholar.org/paper/ab4c7c12dd96b2e746666c6bdd9a59fdbd3c4f2f\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":\"1906.09844\",\"authors\":[{\"authorId\":\"2052119\",\"name\":\"Zhaoquan Yuan\"},{\"authorId\":\"47393013\",\"name\":\"Siyuan Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"116155759\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48258806\",\"name\":\"Changsheng Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"title\":\"Adversarial Multimodal Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145222076\",\"name\":\"Tianyu Zhang\"},{\"authorId\":\"2366119\",\"name\":\"Weiqing Min\"},{\"authorId\":\"27730334\",\"name\":\"Ying Zhu\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3394171.3413964\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10066d89b96b8baac518c994f23278b817994a12\",\"title\":\"An Egocentric Action Anticipation Framework via Fusing Intuition and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/10066d89b96b8baac518c994f23278b817994a12\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1904.12368\",\"authors\":[{\"authorId\":\"144774026\",\"name\":\"Ting-Wu Chin\"},{\"authorId\":\"3306838\",\"name\":\"Ruizhou Ding\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"},{\"authorId\":\"1704073\",\"name\":\"Diana Marculescu\"}],\"doi\":\"10.1109/cvpr42600.2020.00159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"282eda4516e0d4d7e6a462814fae6d48126f9c8f\",\"title\":\"Towards Efficient Model Compression via Learned Global Ranking\",\"url\":\"https://www.semanticscholar.org/paper/282eda4516e0d4d7e6a462814fae6d48126f9c8f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1710.06917\",\"authors\":[{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"2302698\",\"name\":\"B. Cardier\"},{\"authorId\":\"48469819\",\"name\":\"Tong Wang\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f69fcd825437fa25bd2ad8b0bd4b74a2cd8a2f6\",\"title\":\"Annotating High-Level Structures of Short Stories and Personal Anecdotes\",\"url\":\"https://www.semanticscholar.org/paper/8f69fcd825437fa25bd2ad8b0bd4b74a2cd8a2f6\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2079753\",\"name\":\"Daria Dzendzik\"},{\"authorId\":\"144420027\",\"name\":\"C. Vogel\"},{\"authorId\":\"144116340\",\"name\":\"Jennifer Foster\"}],\"doi\":\"10.18653/v1/N19-3001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"45215662b51945793833b05231d831db4a09edd1\",\"title\":\"Is It Dish Washer Safe? Automatically Answering \\\"Yes/No\\\" Questions Using Customer Reviews\",\"url\":\"https://www.semanticscholar.org/paper/45215662b51945793833b05231d831db4a09edd1\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1710.11601\",\"authors\":[{\"authorId\":\"2875615\",\"name\":\"Lea Frermann\"},{\"authorId\":\"40146204\",\"name\":\"Shay B. Cohen\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1162/tacl_a_00001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6dd15b7e674755b01fe605efb42d03d920ebcde\",\"title\":\"Whodunnit? Crime Drama as a Case for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f6dd15b7e674755b01fe605efb42d03d920ebcde\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2018},{\"arxivId\":\"1809.08761\",\"authors\":[{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"2433617\",\"name\":\"Mingzhe Wang\"},{\"authorId\":\"32654429\",\"name\":\"M. Smith\"},{\"authorId\":\"31686229\",\"name\":\"Noriyuki Kojima\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":\"10.18653/v1/N18-1200\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8daab1e4f63051b78eb43e98ab723f6c425a6b5\",\"title\":\"Speaker Naming in Movies\",\"url\":\"https://www.semanticscholar.org/paper/f8daab1e4f63051b78eb43e98ab723f6c425a6b5\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1906.01874\",\"authors\":[{\"authorId\":\"9965236\",\"name\":\"Hamid Mirisaee\"},{\"authorId\":\"48819635\",\"name\":\"Eric Gaussier\"},{\"authorId\":\"1827845\",\"name\":\"C\\u00e9dric Lagnier\"},{\"authorId\":\"133602146\",\"name\":\"Agn\\u00e8s Guerraz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"406a0d31e1a714ee3ffd736034a4c6785a81ebd4\",\"title\":\"Terminology-based Text Embedding for Computing Document Similarities on Technical Content\",\"url\":\"https://www.semanticscholar.org/paper/406a0d31e1a714ee3ffd736034a4c6785a81ebd4\",\"venue\":\"PFIA\",\"year\":2019},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145691225\",\"name\":\"Santiago Castro\"},{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"1724416445\",\"name\":\"Cristina Noujaim\"},{\"authorId\":\"30646659\",\"name\":\"R. Wang\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"title\":\"LifeQA: A Real-life Dataset for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1809.07999\",\"authors\":[{\"authorId\":\"2593979\",\"name\":\"Kyung-Min Kim\"},{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1007/978-3-030-01267-0_41\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b01ed5c62abdc37c7318c155e12e366238bdc2f5\",\"title\":\"Multimodal Dual Attention Memory for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b01ed5c62abdc37c7318c155e12e366238bdc2f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2017.160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"241b86d3c71d14b8cc6044a425b047a0724cfdc9\",\"title\":\"Following Gaze in Video\",\"url\":\"https://www.semanticscholar.org/paper/241b86d3c71d14b8cc6044a425b047a0724cfdc9\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145952554\",\"name\":\"Michael Chan\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/CVPR.2019.00901\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"title\":\"Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.02036\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"48920375\",\"name\":\"T. Pham\"},{\"authorId\":\"97531942\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/cvpr42600.2020.01012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"title\":\"Modality Shifting Attention Network for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1907.13280\",\"authors\":[{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.18653/v1/W19-5926\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"title\":\"Learning Question-Guided Video Representation for Multi-Turn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"1908.03381\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143805303\",\"name\":\"M. Law\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2019.00513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40e24eb322d19d4f8aa6b2756e9babf88162869a\",\"title\":\"Video Face Clustering With Unknown Number of Clusters\",\"url\":\"https://www.semanticscholar.org/paper/40e24eb322d19d4f8aa6b2756e9babf88162869a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493849\",\"name\":\"Dejiang Kong\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1007/978-3-030-00776-8_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89e982f1a1cda786062f4044391a67d6739804cd\",\"title\":\"Visual Dialog with Multi-turn Attentional Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/89e982f1a1cda786062f4044391a67d6739804cd\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2011.06165\",\"authors\":[{\"authorId\":\"1379957693\",\"name\":\"Sean Segal\"},{\"authorId\":\"2219575\",\"name\":\"E. Kee\"},{\"authorId\":\"49756115\",\"name\":\"W. Luo\"},{\"authorId\":\"152948272\",\"name\":\"A. Sadat\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"781da932cceb0e69e5471e018c41fb95224e2e4c\",\"title\":\"Universal Embeddings for Spatio-Temporal Tagging of Self-Driving Logs\",\"url\":\"https://www.semanticscholar.org/paper/781da932cceb0e69e5471e018c41fb95224e2e4c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08502\",\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76e71fe84643b72ffb61afe54c9034be824604e3\",\"title\":\"Learning Trailer Moments in Full-Length Movies\",\"url\":\"https://www.semanticscholar.org/paper/76e71fe84643b72ffb61afe54c9034be824604e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.11880\",\"authors\":[{\"authorId\":\"1753591501\",\"name\":\"C. Zeng\"},{\"authorId\":\"47319200\",\"name\":\"Shaobo Li\"},{\"authorId\":\"50444485\",\"name\":\"Q. Li\"},{\"authorId\":\"50778787\",\"name\":\"J. Hu\"},{\"authorId\":\"49268315\",\"name\":\"J. Hu\"}],\"doi\":\"10.3390/app10217640\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"46c34e81a3f8d6dae946219c7277fd03af50738b\",\"title\":\"A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics, and Benchmark Datasets\",\"url\":\"https://www.semanticscholar.org/paper/46c34e81a3f8d6dae946219c7277fd03af50738b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5051820\",\"name\":\"X. Huang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPRW.2016.102\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"592f14f4b12225fc691477a180a2a3226a5ef4f0\",\"title\":\"Inferring Visual Persuasion via Body Language, Setting, and Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/592f14f4b12225fc691477a180a2a3226a5ef4f0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1809.10735\",\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"}],\"doi\":\"10.18653/v1/N19-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a5606f0d56c618aa610cb1677e2788a3bd678fa\",\"title\":\"A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC\",\"url\":\"https://www.semanticscholar.org/paper/0a5606f0d56c618aa610cb1677e2788a3bd678fa\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1912.13082\",\"authors\":[{\"authorId\":\"36964031\",\"name\":\"Atef Chaudhury\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2596437\",\"name\":\"Seung Wook Kim\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"285fc5903e6f23e6b659c896a09236908697a560\",\"title\":\"The Shmoop Corpus: A Dataset of Stories with Loosely Aligned Summaries\",\"url\":\"https://www.semanticscholar.org/paper/285fc5903e6f23e6b659c896a09236908697a560\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144175619\",\"name\":\"K. Curtis\"},{\"authorId\":\"145876242\",\"name\":\"G. Awad\"},{\"authorId\":\"145228525\",\"name\":\"S. Rajput\"},{\"authorId\":\"144526707\",\"name\":\"I. Soboroff\"}],\"doi\":\"10.1145/3382507.3419746\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"43587627608980a5a53b90dfea5b50012ab66947\",\"title\":\"International Workshop on Deep Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/43587627608980a5a53b90dfea5b50012ab66947\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"1807.11122\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"51150048\",\"name\":\"Kyle Buettner\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"title\":\"Story Understanding in Video Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"title\":\"Story Understanding through Semantic Analysis and Automatic Alignment of Text and Video\",\"url\":\"https://www.semanticscholar.org/paper/39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"4241648\",\"name\":\"M. S. Sarfraz\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/TBIOM.2019.2947264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"412f7b504244e0843226d0e626691d09f10b8ec6\",\"title\":\"Video Face Clustering With Self-Supervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/412f7b504244e0843226d0e626691d09f10b8ec6\",\"venue\":\"IEEE Transactions on Biometrics, Behavior, and Identity Science\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653799\",\"name\":\"W. Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":\"10.18653/v1/2020.alvr-1.2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30f86e15b4fd7936b9812d476976a6ff579b9036\",\"title\":\"Toward General Scene Graph: Integration of Visual Semantic Knowledge with Entity Synset Alignment\",\"url\":\"https://www.semanticscholar.org/paper/30f86e15b4fd7936b9812d476976a6ff579b9036\",\"venue\":\"ALVR\",\"year\":2020},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.00544\",\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.24963/ijcai.2020/148\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fda45368ef87c7ac1da12a7303dedab0e779fd20\",\"title\":\"Video Question Answering on Screencast Tutorials\",\"url\":\"https://www.semanticscholar.org/paper/fda45368ef87c7ac1da12a7303dedab0e779fd20\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"title\":\"End-to-End Multimodal Dialog Systems with Hierarchical Multimodal Attention on Video Features\",\"url\":\"https://www.semanticscholar.org/paper/fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2837477\",\"name\":\"A. Tozzo\"},{\"authorId\":\"144453657\",\"name\":\"D. Jovanovic\"},{\"authorId\":\"4599641\",\"name\":\"M. Amer\"}],\"doi\":\"10.18653/v1/W18-1507\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8b190728064747f58cc580c7771fe8f4ad8a220\",\"title\":\"Neural Event Extraction from Movies Description\",\"url\":\"https://www.semanticscholar.org/paper/e8b190728064747f58cc580c7771fe8f4ad8a220\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ad97e877f55f7ce631fbce30d194c1912c22362\",\"title\":\"IARY PROGRESS ESTIMATION\",\"url\":\"https://www.semanticscholar.org/paper/8ad97e877f55f7ce631fbce30d194c1912c22362\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1910.10706\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1609/AAAI.V34I07.6713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"title\":\"KnowIT VQA: Answering Knowledge-Based Questions about Videos\",\"url\":\"https://www.semanticscholar.org/paper/12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1809.04560\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D18-1012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"title\":\"Game-Based Video-Context Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1804.07927\",\"authors\":[{\"authorId\":\"2909575\",\"name\":\"Amrita Saha\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"},{\"authorId\":\"145590185\",\"name\":\"K. Sankaranarayanan\"}],\"doi\":\"10.18653/v1/P18-1156\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a7bbb084f5de4f318c811776afeba2b05439c234\",\"title\":\"DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/a7bbb084f5de4f318c811776afeba2b05439c234\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1909.08859\",\"authors\":[{\"authorId\":\"1388790625\",\"name\":\"Mustafa Sercan Amac\"},{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"152827782\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":\"10.18653/v1/K19-1041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfb92b8424c5e0f912f240b3bb9c746fe19e891e\",\"title\":\"Procedural Reasoning Networks for Understanding Multimodal Procedures\",\"url\":\"https://www.semanticscholar.org/paper/dfb92b8424c5e0f912f240b3bb9c746fe19e891e\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451396\",\"name\":\"Nikos Papasarantopoulos\"},{\"authorId\":\"2875615\",\"name\":\"Lea Frermann\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"},{\"authorId\":\"40146204\",\"name\":\"Shay B. Cohen\"}],\"doi\":\"10.18653/v1/D19-1212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"187e69900484453fda35d853cdc8c5a298ecbd24\",\"title\":\"Partners in Crime: Multi-view Sequential Inference for Movie Understanding\",\"url\":\"https://www.semanticscholar.org/paper/187e69900484453fda35d853cdc8c5a298ecbd24\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1905.13540\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"3549056\",\"name\":\"K. Kim\"},{\"authorId\":\"72108920\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/IJCNN.2019.8852087\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"title\":\"Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117133855\",\"name\":\"Hossein Rajaby Faghihi\"},{\"authorId\":\"1805995461\",\"name\":\"Roshanak Mirzaee\"},{\"authorId\":\"1805991829\",\"name\":\"Sudarshan Paliwal\"},{\"authorId\":\"2190934\",\"name\":\"Parisa Kordjamshidi\"}],\"doi\":\"10.18653/v1/2020.alvr-1.5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93614a127d125b0c3a4dca5be5c4af20539313d4\",\"title\":\"Latent Alignment of Procedural Concepts in Multimodal Recipes\",\"url\":\"https://www.semanticscholar.org/paper/93614a127d125b0c3a4dca5be5c4af20539313d4\",\"venue\":\"ALVR\",\"year\":2020},{\"arxivId\":\"2010.10839\",\"authors\":[{\"authorId\":\"7878341\",\"name\":\"Wubo Li\"},{\"authorId\":\"46197764\",\"name\":\"D. Jiang\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"1898780\",\"name\":\"Xiangang Li\"}],\"doi\":\"10.21437/interspeech.2020-2359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"title\":\"TMT: A Transformer-based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151238392\",\"name\":\"T. Tangiuchi\"},{\"authorId\":\"2619938\",\"name\":\"D. Mochihashi\"},{\"authorId\":\"47734618\",\"name\":\"T. Nagai\"},{\"authorId\":\"71893053\",\"name\":\"S. Uchida\"},{\"authorId\":\"32427616\",\"name\":\"Naoya Inoue\"},{\"authorId\":\"3236658\",\"name\":\"I. Kobayashi\"},{\"authorId\":\"1693821\",\"name\":\"T. Nakamura\"},{\"authorId\":\"2621346\",\"name\":\"Y. Hagiwara\"},{\"authorId\":\"1728425\",\"name\":\"N. Iwahashi\"},{\"authorId\":\"3116567\",\"name\":\"T. Inamura\"}],\"doi\":\"10.1080/01691864.2019.1632223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdd548be9f3368492247ff9b7d41ab33cee674ac\",\"title\":\"Survey on frontiers of language and robotics\",\"url\":\"https://www.semanticscholar.org/paper/cdd548be9f3368492247ff9b7d41ab33cee674ac\",\"venue\":\"Adv. Robotics\",\"year\":2019},{\"arxivId\":\"2012.10285\",\"authors\":[{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"7750732\",\"name\":\"S. Xiao\"},{\"authorId\":\"145147517\",\"name\":\"A. McLean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f06224d597451ce1d440ca0c8542dee4a5767afe\",\"title\":\"Trying Bilinear Pooling in Video-QA\",\"url\":\"https://www.semanticscholar.org/paper/f06224d597451ce1d440ca0c8542dee4a5767afe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144379221\",\"name\":\"Catherine Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f724a84647c5a70865509910070077962433dca\",\"title\":\"RECONSTRUCTIVE MEMORY FOR ABSTRACT SELECTIVE RECALL\",\"url\":\"https://www.semanticscholar.org/paper/5f724a84647c5a70865509910070077962433dca\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1611.09053\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/CVPR.2017.147\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"533d14e539ae5cdca0ece392487a2b19106d468a\",\"title\":\"Bidirectional Multirate Reconstruction for Temporal Modeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/533d14e539ae5cdca0ece392487a2b19106d468a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2017.2746267\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"title\":\"Unifying the Video and Question Attentions for Open-Ended Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1908.03180\",\"authors\":[{\"authorId\":\"1399431057\",\"name\":\"Paola Cascante-Bonilla\"},{\"authorId\":\"1416539256\",\"name\":\"Kalpathy Sitaraman\"},{\"authorId\":\"31143971\",\"name\":\"Mengjia Luo\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"title\":\"Moviescope: Large-scale Analysis of Movies using Multiple Modalities\",\"url\":\"https://www.semanticscholar.org/paper/e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.06164\",\"authors\":[{\"authorId\":\"48324018\",\"name\":\"Moonsu Han\"},{\"authorId\":\"120434407\",\"name\":\"Minki Kang\"},{\"authorId\":\"145043682\",\"name\":\"Hyunwoo Jung\"},{\"authorId\":\"35788904\",\"name\":\"Sung Ju Hwang\"}],\"doi\":\"10.18653/v1/P19-1434\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b47e7376666a87374b1254469723603039333fa\",\"title\":\"Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data\",\"url\":\"https://www.semanticscholar.org/paper/4b47e7376666a87374b1254469723603039333fa\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"9390267\",\"name\":\"Qifan Yang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2017/492\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"title\":\"Video Question Answering via Hierarchical Spatio-Temporal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"49969588\",\"name\":\"Ziyin Li\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1145/3240508.3240651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4218e08002ffa8c2988c3d96af232440591e724\",\"title\":\"Extractive Video Summarizer with Memory Augmented Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c4218e08002ffa8c2988c3d96af232440591e724\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1911.09655\",\"authors\":[{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":\"10.1109/TASLP.2020.3010650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfa437129daef8533708924c395c3fd0c5c3bf81\",\"title\":\"Temporal Reasoning via Audio Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bfa437129daef8533708924c395c3fd0c5c3bf81\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":\"2012.07536\",\"authors\":[{\"authorId\":\"22220222\",\"name\":\"Pinelopi Papalampidi\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"1412841514\",\"name\":\"M. Lapata\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d739bc3eafbac3304be528c706f127dda243dc9c\",\"title\":\"Movie Summarization via Sparse Graph Construction\",\"url\":\"https://www.semanticscholar.org/paper/d739bc3eafbac3304be528c706f127dda243dc9c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.11997\",\"authors\":[{\"authorId\":\"35481078\",\"name\":\"Zhanwen Chen\"},{\"authorId\":\"47319436\",\"name\":\"Shiyao Li\"},{\"authorId\":\"7348086\",\"name\":\"R. Rashedi\"},{\"authorId\":\"2001076431\",\"name\":\"Xiaoman Zi\"},{\"authorId\":\"2001076425\",\"name\":\"Morgan Elrod-Erickson\"},{\"authorId\":\"2001126495\",\"name\":\"Bryan Hollis\"},{\"authorId\":\"2001085414\",\"name\":\"Angela Maliakal\"},{\"authorId\":\"48946892\",\"name\":\"Xinyu Shen\"},{\"authorId\":\"49113037\",\"name\":\"Simeng Zhao\"},{\"authorId\":\"2333314\",\"name\":\"M. Kunda\"}],\"doi\":\"10.1109/ICDL-EpiRob48136.2020.9278057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27f09719c529d49bec2f4d776c5de53d425510bd\",\"title\":\"Characterizing Datasets for Social Visual Question Answering, and the New TinySocial Dataset\",\"url\":\"https://www.semanticscholar.org/paper/27f09719c529d49bec2f4d776c5de53d425510bd\",\"venue\":\"2020 Joint IEEE 10th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)\",\"year\":2020},{\"arxivId\":\"1909.02218\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"2061528\",\"name\":\"Wenqing Chu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2018.2859820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96f0908cc138aceb2d5e0180c440e5adc711d855\",\"title\":\"A Better Way to Attend: Attention With Trees for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/96f0908cc138aceb2d5e0180c440e5adc711d855\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112995179\",\"name\":\"L. Chen\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"50775044\",\"name\":\"Jiawei He\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCVW.2019.00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"347748443be69ffceb2fb345df9b41448f2974ad\",\"title\":\"Object Grounding via Iterative Context Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/347748443be69ffceb2fb345df9b41448f2974ad\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2009.03793\",\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1397911258\",\"name\":\"Ali Movaghar-Rahimabadi\"}],\"doi\":\"10.36227/techrxiv.12928544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f097e32ea304a14c8e26648b05f944d530b016\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/46f097e32ea304a14c8e26648b05f944d530b016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1612.04061\",\"authors\":[{\"authorId\":\"145310618\",\"name\":\"Aditya Singh\"},{\"authorId\":\"3448416\",\"name\":\"Saurabh Saini\"},{\"authorId\":\"1962817\",\"name\":\"Rajvi Shah\"},{\"authorId\":\"144422343\",\"name\":\"P. J. Narayanan\"}],\"doi\":\"10.1145/3009977.3010035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a260a623fd3dc72a4aa34c2b15639369f30b0fc8\",\"title\":\"Learning to hash-tag videos with Tag2Vec\",\"url\":\"https://www.semanticscholar.org/paper/a260a623fd3dc72a4aa34c2b15639369f30b0fc8\",\"venue\":\"ICVGIP '16\",\"year\":2016},{\"arxivId\":\"1711.05345\",\"authors\":[{\"authorId\":\"2815804\",\"name\":\"Yu-An Chung\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.18653/v1/N18-1143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb567cf793a6c4df1a652489c5ce866fe044f0e5\",\"title\":\"Supervised and Unsupervised Transfer Learning for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bb567cf793a6c4df1a652489c5ce866fe044f0e5\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1712.07040\",\"authors\":[{\"authorId\":\"2367821\",\"name\":\"Tom\\u00e1s Kocisk\\u00fd\"},{\"authorId\":\"144735987\",\"name\":\"Jonathan Schwarz\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"2910877\",\"name\":\"K. Hermann\"},{\"authorId\":\"94303026\",\"name\":\"G\\u00e1bor Melis\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"}],\"doi\":\"10.1162/tacl_a_00023\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a\",\"title\":\"The NarrativeQA Reading Comprehension Challenge\",\"url\":\"https://www.semanticscholar.org/paper/d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2018},{\"arxivId\":\"1907.08584\",\"authors\":[{\"authorId\":\"48417678\",\"name\":\"Jonathan Gray\"},{\"authorId\":\"27693639\",\"name\":\"Kavya Srinet\"},{\"authorId\":\"2262249\",\"name\":\"Yacine Jernite\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"2240134\",\"name\":\"Zhuoyuan Chen\"},{\"authorId\":\"35578711\",\"name\":\"Demi Guo\"},{\"authorId\":\"3322061\",\"name\":\"S. Goyal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d8d6278ad32acee4d649f32766de90cf4d787eb\",\"title\":\"CraftAssist: A Framework for Dialogue-enabled Interactive Agents\",\"url\":\"https://www.semanticscholar.org/paper/5d8d6278ad32acee4d649f32766de90cf4d787eb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1610.09996\",\"authors\":[{\"authorId\":\"48623415\",\"name\":\"Y. Yu\"},{\"authorId\":\"47527881\",\"name\":\"Wei Zhang\"},{\"authorId\":\"31412199\",\"name\":\"K. Hasan\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144028698\",\"name\":\"B. Xiang\"},{\"authorId\":\"145218984\",\"name\":\"Bowen Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0680f04750b1e257ffdd161e85382031dc73ea7f\",\"title\":\"End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/0680f04750b1e257ffdd161e85382031dc73ea7f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.11543\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPRW.2018.00279\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.24963/ijcai.2018/513\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"title\":\"Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network\",\"url\":\"https://www.semanticscholar.org/paper/396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.07891\",\"authors\":[{\"authorId\":\"51235014\",\"name\":\"Ekta Sood\"},{\"authorId\":\"87863676\",\"name\":\"Simon Tannert\"},{\"authorId\":\"1605986895\",\"name\":\"Philipp M\\u00fcller\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54d1079968596ea2ffe17ef3eeb854ef488b4882\",\"title\":\"Improving Natural Language Processing Tasks with Human Gaze-Guided Neural Attention\",\"url\":\"https://www.semanticscholar.org/paper/54d1079968596ea2ffe17ef3eeb854ef488b4882\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.00202\",\"authors\":[{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d30c5753cd41f6fb8d13717b85fbb46f2c5dcc8\",\"title\":\"Traversing the Continuous Spectrum of Image Retrieval with Deep Dynamic Models\",\"url\":\"https://www.semanticscholar.org/paper/3d30c5753cd41f6fb8d13717b85fbb46f2c5dcc8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1611.01747\",\"authors\":[{\"authorId\":\"2992833\",\"name\":\"Shuohang Wang\"},{\"authorId\":\"144924150\",\"name\":\"Jing Jiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3f567d3d4975359fadfa9d750e1e4c4722d666c8\",\"title\":\"A Compare-Aggregate Model for Matching Text Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3f567d3d4975359fadfa9d750e1e4c4722d666c8\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"2007.15781\",\"authors\":[{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58574-7_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"title\":\"LEMMA: A Multi-view Dataset for Learning Multi-agent Multi-task Activities\",\"url\":\"https://www.semanticscholar.org/paper/cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10937\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58548-8_41\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"0732df185bdfcb9c908ec30bb441252593f58875\",\"title\":\"MovieNet: A Holistic Dataset for Movie Understanding\",\"url\":\"https://www.semanticscholar.org/paper/0732df185bdfcb9c908ec30bb441252593f58875\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1808.02559\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"153188107\",\"name\":\"Jongseok Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/978-3-030-01234-2_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8befcd91c24038e5c26df0238d26e2311b21719a\",\"title\":\"A Joint Sequence Fusion Model for Video Question Answering and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8befcd91c24038e5c26df0238d26e2311b21719a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.07023\",\"authors\":[{\"authorId\":\"5298478\",\"name\":\"T. D. Nguyen\"},{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"1944614\",\"name\":\"Hannes Schulz\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d252759ea411343f274a92276bf7bd8f9d43db8c\",\"title\":\"From FiLM to Video: Multi-turn Question Answering with Multi-modal Context\",\"url\":\"https://www.semanticscholar.org/paper/d252759ea411343f274a92276bf7bd8f9d43db8c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1707.08559\",\"authors\":[{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"153231574\",\"name\":\"J. Lee\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.18653/v1/D17-1102\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18aa7b466953189d5bc98e88f2a1ab12182f8b88\",\"title\":\"Video Highlight Prediction Using Audience Chat Reactions\",\"url\":\"https://www.semanticscholar.org/paper/18aa7b466953189d5bc98e88f2a1ab12182f8b88\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1809.02922\",\"authors\":[{\"authorId\":\"81551000\",\"name\":\"Dorottya Demszky\"},{\"authorId\":\"2091768\",\"name\":\"Kelvin Guu\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8f1c9b656157b1d851563fb42129245701d83175\",\"title\":\"Transforming Question Answering Datasets Into Natural Language Inference Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8f1c9b656157b1d851563fb42129245701d83175\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145102294\",\"name\":\"Moreira de Souza\"},{\"authorId\":\"123900281\",\"name\":\"Fillipe Dias\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"title\":\"Semantic Description of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964003\",\"name\":\"C. Lee\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"2208161\",\"name\":\"Szu-Lin Wu\"},{\"authorId\":\"117660020\",\"name\":\"Chi-Liang Liu\"},{\"authorId\":\"145359071\",\"name\":\"Wei Fang\"},{\"authorId\":\"3451540\",\"name\":\"Juei-Yang Hsu\"},{\"authorId\":\"33870107\",\"name\":\"Bo-Hsiang Tseng\"}],\"doi\":\"10.1109/TASLP.2019.2913499\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"title\":\"Machine Comprehension of Spoken Content: TOEFL Listening Test and Spoken SQuAD\",\"url\":\"https://www.semanticscholar.org/paper/76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"48985581\",\"name\":\"Manli Zhang\"},{\"authorId\":\"1684276\",\"name\":\"Jianhong Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"2259699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"14644cc31aec3b9aa7d785e3c1a007bda0c7824d\",\"title\":\"Recursive Visual Attention Algorithm 1 Recursive Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/14644cc31aec3b9aa7d785e3c1a007bda0c7824d\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"4495301\",\"name\":\"Yuan-Fang Li\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1609/AAAI.V33I01.33016391\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"524879e9a072489110e9578cf2689e50c5531f05\",\"title\":\"Structured Two-Stream Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/524879e9a072489110e9578cf2689e50c5531f05\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2010.02795\",\"authors\":[{\"authorId\":\"32528506\",\"name\":\"Deepanway Ghosal\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"1747784\",\"name\":\"Alexander Gelbukh\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.224\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4236663e6416423fca02d5b058302adcb78f51f3\",\"title\":\"COSMIC: COmmonSense knowledge for eMotion Identification in Conversations\",\"url\":\"https://www.semanticscholar.org/paper/4236663e6416423fca02d5b058302adcb78f51f3\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1902.06468\",\"authors\":[{\"authorId\":\"46312037\",\"name\":\"Youngeun Kwon\"},{\"authorId\":\"1998820\",\"name\":\"Minsoo Rhu\"}],\"doi\":\"10.1109/MICRO.2018.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c841fcd728e7fe12af5f02c898e99859432f42ff\",\"title\":\"Beyond the Memory Wall: A Case for Memory-Centric HPC System for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/c841fcd728e7fe12af5f02c898e99859432f42ff\",\"venue\":\"2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":\"1911.03083\",\"authors\":[{\"authorId\":\"35923416\",\"name\":\"Bhavan Jasani\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCVW.2019.00235\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"31c5eb6d5cab2df914f54eab9f2db942193e1be4\",\"title\":\"Are we Asking the Right Questions in MovieQA?\",\"url\":\"https://www.semanticscholar.org/paper/31c5eb6d5cab2df914f54eab9f2db942193e1be4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1145/3009906\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e60536c847ac25dba4c1c071e0355e5537fe061\",\"title\":\"Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/6e60536c847ac25dba4c1c071e0355e5537fe061\",\"venue\":\"ACM Comput. Surv.\",\"year\":2017},{\"arxivId\":\"2010.06396\",\"authors\":[{\"authorId\":\"51235014\",\"name\":\"Ekta Sood\"},{\"authorId\":\"87863676\",\"name\":\"Simon Tannert\"},{\"authorId\":\"2752887\",\"name\":\"Diego Frassinelli\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"},{\"authorId\":\"4160376\",\"name\":\"Ngoc Thang Vu\"}],\"doi\":\"10.18653/v1/2020.conll-1.2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e6cbd4d8b91444e4704db7849596493882fa2d3f\",\"title\":\"Interpreting Attention Models with Human Visual Attention in Machine Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/e6cbd4d8b91444e4704db7849596493882fa2d3f\",\"venue\":\"CoNLL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1706.07960\",\"authors\":[{\"authorId\":\"19255603\",\"name\":\"Seil Na\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"49476855\",\"name\":\"Jisung Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76996250596ca0665192daf5d4c8588f75014096\",\"title\":\"Encoding Video and Label Priors for Multi-label Video Classification on YouTube-8M dataset\",\"url\":\"https://www.semanticscholar.org/paper/76996250596ca0665192daf5d4c8588f75014096\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31724961\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"31686229\",\"name\":\"Noriyuki Kojima\"},{\"authorId\":\"121806097\",\"name\":\"J. Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":\"10.18653/v1/K19-1010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a445b9c46458a81c277199e8a5912ab302308b0a\",\"title\":\"Representing Movie Characters in Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/a445b9c46458a81c277199e8a5912ab302308b0a\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51235014\",\"name\":\"Ekta Sood\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"de73a8a11b2ce3de40f5866ac6cabb66e0d2ea34\",\"title\":\"Predicting Gaze Patterns: Text Saliency for Integration into Machine Learning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/de73a8a11b2ce3de40f5866ac6cabb66e0d2ea34\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/512\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"title\":\"Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":\"10.3389/FNCOM.2017.00112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a81f478817e031e2389b6cda24854c1fa48ac3b\",\"title\":\"Computational Foundations of Natural Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/0a81f478817e031e2389b6cda24854c1fa48ac3b\",\"venue\":\"Frontiers Comput. Neurosci.\",\"year\":2017},{\"arxivId\":\"1907.01011\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"2987266\",\"name\":\"Zhun Liu\"},{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P19-1152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93deae7cfaba34066afa05a2b05162891b13e769\",\"title\":\"Learning Representations from Imperfect Time Series Data via Tensor Rank Regularization\",\"url\":\"https://www.semanticscholar.org/paper/93deae7cfaba34066afa05a2b05162891b13e769\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1610.02947\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3dc37dab102a0465098111b7ccf6f95b736397f2\",\"title\":\"End-to-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3dc37dab102a0465098111b7ccf6f95b736397f2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1909.01860\",\"authors\":[{\"authorId\":\"66275275\",\"name\":\"Yash Srivastava\"},{\"authorId\":\"152967610\",\"name\":\"Vaishnav Murali\"},{\"authorId\":\"34992579\",\"name\":\"S. Dubey\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"title\":\"Visual Question Answering using Deep Learning: A Survey and Performance Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32794831\",\"name\":\"W. Zhang\"},{\"authorId\":\"1713128\",\"name\":\"Quan Z. Sheng\"},{\"authorId\":\"65966956\",\"name\":\"A. Alhazmi\"},{\"authorId\":\"2829009\",\"name\":\"Chenliang Li\"}],\"doi\":\"10.1145/3374217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"652107ea8161f607e3bdabc89199e9ff2fdfd015\",\"title\":\"Adversarial Attacks on Deep-learning Models in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/652107ea8161f607e3bdabc89199e9ff2fdfd015\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2020},{\"arxivId\":\"2003.13158\",\"authors\":[{\"authorId\":\"146108424\",\"name\":\"A. Kukleva\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/cvpr42600.2020.00987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d57d0c8071378c26967fa428bf339193713b91a5\",\"title\":\"Learning Interactions and Relationships Between Movie Characters\",\"url\":\"https://www.semanticscholar.org/paper/d57d0c8071378c26967fa428bf339193713b91a5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1612.01669\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"3386346\",\"name\":\"Ilchae Jung\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/ICCV.2017.312\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"title\":\"MarioQA: Answering Questions by Watching Gameplay Videos\",\"url\":\"https://www.semanticscholar.org/paper/00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2007.03626\",\"authors\":[{\"authorId\":\"46477844\",\"name\":\"Jianing Yang\"},{\"authorId\":\"4375156\",\"name\":\"Yuying Zhu\"},{\"authorId\":null,\"name\":\"Yongxin Wang\"},{\"authorId\":\"1796308073\",\"name\":\"Ruitao Yi\"},{\"authorId\":\"2960619\",\"name\":\"A. Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cbe147910b53fbae66836e132024e70f0c988334\",\"title\":\"What Gives the Answer Away? Question Answering Bias Analysis on Video QA Datasets\",\"url\":\"https://www.semanticscholar.org/paper/cbe147910b53fbae66836e132024e70f0c988334\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.02280\",\"authors\":[{\"authorId\":\"2964003\",\"name\":\"C. Lee\"},{\"authorId\":\"1947838\",\"name\":\"Shang-Ming Wang\"},{\"authorId\":\"39908989\",\"name\":\"H. Chang\"},{\"authorId\":\"144300094\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.1109/SLT.2018.8639505\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de91454ff9fc82c68359360b661c25f52dd2c0cb\",\"title\":\"ODSQA: Open-Domain Spoken Question Answering Dataset\",\"url\":\"https://www.semanticscholar.org/paper/de91454ff9fc82c68359360b661c25f52dd2c0cb\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47897687\",\"name\":\"H. Tan\"},{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"1786343\",\"name\":\"Q. Xu\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"2998031\",\"name\":\"F. Fang\"},{\"authorId\":\"2000269838\",\"name\":\"Yi Cheng\"},{\"authorId\":\"152765071\",\"name\":\"N. Gauthier\"},{\"authorId\":\"2000311149\",\"name\":\"Ying Sun\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"}],\"doi\":\"10.1109/ICIP40778.2020.9190659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"title\":\"Task-Oriented Multi-Modal Question Answering For Collaborative Applications\",\"url\":\"https://www.semanticscholar.org/paper/cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787108\",\"name\":\"P. Chen\"},{\"authorId\":\"145428828\",\"name\":\"Wu Guo\"},{\"authorId\":\"1850125\",\"name\":\"Z. Chen\"},{\"authorId\":null,\"name\":\"Jian Sun\"},{\"authorId\":\"5472606\",\"name\":\"Lanhua You\"}],\"doi\":\"10.21437/Interspeech.2018-70\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdb42409d7888a82b2ffe48faf23031072c14e81\",\"title\":\"Gated Convolutional Neural Network for Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/fdb42409d7888a82b2ffe48faf23031072c14e81\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1608.06378\",\"authors\":[{\"authorId\":\"33870107\",\"name\":\"Bo-Hsiang Tseng\"},{\"authorId\":\"1988475\",\"name\":\"S. Shen\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"145535692\",\"name\":\"L. Lee\"}],\"doi\":\"10.21437/Interspeech.2016-876\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21633a4ef076e21ec116856a003efb1bb033a470\",\"title\":\"Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine\",\"url\":\"https://www.semanticscholar.org/paper/21633a4ef076e21ec116856a003efb1bb033a470\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2004.12238\",\"authors\":[{\"authorId\":\"1424748326\",\"name\":\"A. Kumar\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"title\":\"MCQA: Multimodal Co-attention Based Network for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00463\",\"authors\":[{\"authorId\":\"144175619\",\"name\":\"K. Curtis\"},{\"authorId\":\"145876242\",\"name\":\"G. Awad\"},{\"authorId\":\"145228525\",\"name\":\"S. Rajput\"},{\"authorId\":\"144526707\",\"name\":\"I. Soboroff\"}],\"doi\":\"10.1145/3372278.3390742\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7105d91c324e6118dbc5ec119ec93af6471638c6\",\"title\":\"HLVU: A New Challenge to Test Deep Understanding of Movies the Way Humans do\",\"url\":\"https://www.semanticscholar.org/paper/7105d91c324e6118dbc5ec119ec93af6471638c6\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1380065125\",\"name\":\"Narges Honarvar Nazari\"},{\"authorId\":\"90323489\",\"name\":\"J. Hahn\"},{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/tpami.2019.2947440\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86df22f8dbec3489432063ef569a4793dc232c70\",\"title\":\"Interpreting the Rhetoric of Visual Advertisements.\",\"url\":\"https://www.semanticscholar.org/paper/86df22f8dbec3489432063ef569a4793dc232c70\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134488190\",\"name\":\"M. V. van Gerven\"}],\"doi\":\"10.1101/166785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed6a08eac32e0129a8a324bc0876d3d479727d4d\",\"title\":\"Computational Foundations of Natural Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/ed6a08eac32e0129a8a324bc0876d3d479727d4d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.08751\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1007/978-3-030-58523-5_34\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"773e7d33411fc2cdd6829356b7ce8ed34e14cd65\",\"title\":\"Knowledge-Based Video Question Answering with Unsupervised Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/773e7d33411fc2cdd6829356b7ce8ed34e14cd65\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488897\",\"name\":\"Hongyin Luo\"},{\"authorId\":\"1754057\",\"name\":\"Mitra Mohtarami\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"},{\"authorId\":\"48180941\",\"name\":\"K. Krishnamurthy\"},{\"authorId\":\"46362798\",\"name\":\"Brigitte Richardson\"}],\"doi\":\"10.21437/interspeech.2019-1736\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58cd5975fe958e11642edfc63e479c9c066b57d\",\"title\":\"Integrating Video Retrieval and Moment Detection in a Unified Corpus for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58cd5975fe958e11642edfc63e479c9c066b57d\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"2002.10698\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/cvpr42600.2020.00999\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"53de96cf981c9d58a86697d812484808945b47f5\",\"title\":\"Hierarchical Conditional Relation Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/53de96cf981c9d58a86697d812484808945b47f5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1712.06761\",\"authors\":[{\"authorId\":\"2039154\",\"name\":\"Paul Vicol\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00895\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"523574aca71d8981b4122cce8d132f22391ef26e\",\"title\":\"MovieGraphs: Towards Understanding Human-Centric Situations from Videos\",\"url\":\"https://www.semanticscholar.org/paper/523574aca71d8981b4122cce8d132f22391ef26e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2009.01004\",\"authors\":[{\"authorId\":\"150254263\",\"name\":\"Omar Mossad\"},{\"authorId\":\"118331199\",\"name\":\"Amgad Ahmed\"},{\"authorId\":\"1931375075\",\"name\":\"Anandharaju Raju\"},{\"authorId\":\"1931377767\",\"name\":\"Hari Karthikeyan\"},{\"authorId\":\"33454763\",\"name\":\"Zayed Ahmed\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a67f49aad84abbdf4dc980709f6cd2c43ef495\",\"title\":\"FAT ALBERT: Finding Answers in Large Texts using Semantic Similarity Attention Layer based on BERT\",\"url\":\"https://www.semanticscholar.org/paper/f8a67f49aad84abbdf4dc980709f6cd2c43ef495\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1606.07373\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1732879\",\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c69040777e2b0e1d443e22f86e45e527381d79e7\",\"title\":\"ViCom: Benchmark and Methods for Video Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c69040777e2b0e1d443e22f86e45e527381d79e7\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145381969\",\"name\":\"T. Yu\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"}],\"doi\":\"10.1145/3292500.3330991\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78b25ca3f02d1abe1fa5440d02dd5fa82c8dfa3c\",\"title\":\"A Visual Dialog Augmented Interactive Recommender System\",\"url\":\"https://www.semanticscholar.org/paper/78b25ca3f02d1abe1fa5440d02dd5fa82c8dfa3c\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46822280\",\"name\":\"K. Jiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77c55d771bca41ee7361dba3a27fbc883bba65bf\",\"title\":\"Retrieval-Based Open-Domain Question Answering: Exploring The Impact on The Retrieval Component across Datasets\",\"url\":\"https://www.semanticscholar.org/paper/77c55d771bca41ee7361dba3a27fbc883bba65bf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3188342\",\"name\":\"Omkar M. Parkhi\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"46632720\",\"name\":\"Q. Cao\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/TPAMI.2018.2889831\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"967017fe15981d4ce8b755fd461b600f1aa38a2a\",\"title\":\"Automated Video Face Labelling for Films and TV Material\",\"url\":\"https://www.semanticscholar.org/paper/967017fe15981d4ce8b755fd461b600f1aa38a2a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1808.08744\",\"authors\":[{\"authorId\":\"9711610\",\"name\":\"Matthias Blohm\"},{\"authorId\":\"2322347\",\"name\":\"Glorianna Jagfeld\"},{\"authorId\":\"51235014\",\"name\":\"Ekta Sood\"},{\"authorId\":\"38438821\",\"name\":\"Xiang Yu\"},{\"authorId\":\"4160376\",\"name\":\"Ngoc Thang Vu\"}],\"doi\":\"10.18653/v1/K18-1011\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2ed61688f19c90bbde6e5652d05b776a3d9680a0\",\"title\":\"Comparing Attention-based Convolutional and Recurrent Neural Networks: Success and Limitations in Machine Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2ed61688f19c90bbde6e5652d05b776a3d9680a0\",\"venue\":\"CoNLL\",\"year\":2018},{\"arxivId\":\"2012.04293\",\"authors\":[{\"authorId\":\"32856839\",\"name\":\"T. Ates\"},{\"authorId\":\"2033380403\",\"name\":\"Muhammed Samil Atesoglu\"},{\"authorId\":\"2033381520\",\"name\":\"Cagatay Yigit\"},{\"authorId\":\"116865200\",\"name\":\"Ilker Kesen\"},{\"authorId\":\"2033382593\",\"name\":\"Mert Kobas\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"152827782\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"81703837\",\"name\":\"T. Goksun\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b2397185ef6315ce346180d505df00550d6b08d\",\"title\":\"CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions\",\"url\":\"https://www.semanticscholar.org/paper/9b2397185ef6315ce346180d505df00550d6b08d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-58523-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b26d5d20b073828898087f99b81736c0629c1798\",\"title\":\"Learning Trailer Moments in Full-Length Movies with Co-Contrastive Attention\",\"url\":\"https://www.semanticscholar.org/paper/b26d5d20b073828898087f99b81736c0629c1798\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.12861\",\"authors\":[{\"authorId\":\"13726384\",\"name\":\"Ritwick Chaudhry\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"},{\"authorId\":\"2681580\",\"name\":\"Utkarsh Gupta\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"153841978\",\"name\":\"Prann Bansal\"},{\"authorId\":\"33901930\",\"name\":\"A. Joshi\"}],\"doi\":\"10.1109/WACV45572.2020.9093269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d47f20de7195fea82e48315fea52ccf06dc301d3\",\"title\":\"LEAF-QA: Locate, Encode & Attend for Figure Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d47f20de7195fea82e48315fea52ccf06dc301d3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2003.05162\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1794bc353c94e8d708476132eb326fe3af51c2e6\",\"title\":\"Video2Commonsense: Generating Commonsense Descriptions to Enrich Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1794bc353c94e8d708476132eb326fe3af51c2e6\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582890834\",\"name\":\"Zekun Yang\"},{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1748743\",\"name\":\"H. Takemura\"}],\"doi\":\"10.1109/WACV45572.2020.9093596\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39b2d8b8233a53dc7eadb819c52213369dff8648\",\"title\":\"BERT Representations for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/39b2d8b8233a53dc7eadb819c52213369dff8648\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41a809153d43dadd285e587f9a166c6175b6db64\",\"title\":\"A Modular Interface for Multimodal Data Annotation and Visualization with Applications to Conversational AI and Commonsense Grounding\",\"url\":\"https://www.semanticscholar.org/paper/41a809153d43dadd285e587f9a166c6175b6db64\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7332901\",\"name\":\"Gan Sun\"},{\"authorId\":\"145702758\",\"name\":\"Yang Cong\"},{\"authorId\":\"49681152\",\"name\":\"L. Wang\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"152987474\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/ICCVW.2019.00126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c83c8a91b67768adcfa8cfc661e1093bc8a25fc8\",\"title\":\"Online Multi-Task Clustering for Human Motion Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c83c8a91b67768adcfa8cfc661e1093bc8a25fc8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1706.05028\",\"authors\":[{\"authorId\":\"3079079\",\"name\":\"Nelson Nauata\"},{\"authorId\":\"144915895\",\"name\":\"J. Smith\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2888084b375163f7c956adff102fdbc9fe7fb40\",\"title\":\"Hierarchical Label Inference for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e2888084b375163f7c956adff102fdbc9fe7fb40\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2606846\",\"name\":\"W. Zadrozny\"},{\"authorId\":\"3147629\",\"name\":\"L. Garbayo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff6f1bd4257067c80f097cb3d5778a14222534e8\",\"title\":\"A Sheaf Model of Contradictions and Disagreements. A (very) Preliminary Report\",\"url\":\"https://www.semanticscholar.org/paper/ff6f1bd4257067c80f097cb3d5778a14222534e8\",\"venue\":\"ISAIM\",\"year\":2018},{\"arxivId\":\"1811.10561\",\"authors\":[{\"authorId\":\"52004465\",\"name\":\"J. Abdelnour\"},{\"authorId\":\"38655449\",\"name\":\"G. Salvi\"},{\"authorId\":\"1680808\",\"name\":\"J. Rouat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6bb8fda39f104a95332b5dbca9b1a1c071de539\",\"title\":\"CLEAR: A Dataset for Compositional Language and Elementary Acoustic Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a6bb8fda39f104a95332b5dbca9b1a1c071de539\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1910.11009\",\"authors\":[{\"authorId\":\"47424372\",\"name\":\"Yu Xiong\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"10357054\",\"name\":\"L. Guo\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00469\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"87699cff38982712ddb0b2349313077779a5d0ff\",\"title\":\"A Graph-Based Framework to Bridge Movies and Synopses\",\"url\":\"https://www.semanticscholar.org/paper/87699cff38982712ddb0b2349313077779a5d0ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.01525\",\"authors\":[{\"authorId\":\"2372537\",\"name\":\"Hang Chu\"},{\"authorId\":\"51344879\",\"name\":\"D. Li\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00743\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b09a35b0ee3f1b51fa809ca6a1f70528d910b366\",\"title\":\"A Face-to-Face Neural Conversation Model\",\"url\":\"https://www.semanticscholar.org/paper/b09a35b0ee3f1b51fa809ca6a1f70528d910b366\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1901.06706\",\"authors\":[{\"authorId\":\"38907975\",\"name\":\"Ning Xie\"},{\"authorId\":\"1868193\",\"name\":\"Farley Lai\"},{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c54b796cc10cb530f77caa4d18e1c80ac863822\",\"title\":\"Visual Entailment: A Novel Task for Fine-Grained Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3c54b796cc10cb530f77caa4d18e1c80ac863822\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2706269\",\"name\":\"Chengxiang Yin\"},{\"authorId\":\"152949437\",\"name\":\"Jian Tang\"},{\"authorId\":\"48559420\",\"name\":\"Zhiyuan Xu\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"}],\"doi\":\"10.1109/TNNLS.2019.2938015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d796ff29f8798c418d5374a6632231f02233dbba\",\"title\":\"Memory Augmented Deep Recurrent Neural Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d796ff29f8798c418d5374a6632231f02233dbba\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Weiying Wang\"},{\"authorId\":null,\"name\":\"Yongcheng Wang\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.18653/v1/D19-1517\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34e7db6ffcdfeffc29eab0622384ed412d9b4558\",\"title\":\"YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/34e7db6ffcdfeffc29eab0622384ed412d9b4558\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"51043468\",\"name\":\"Maksim Bolonkin\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ba0bf9323c2d79300f1a433ff8b4fe0a00ad889\",\"title\":\"VideoMCC: a New Benchmark for Video Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7ba0bf9323c2d79300f1a433ff8b4fe0a00ad889\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2010.10095\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"title\":\"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48632281\",\"name\":\"X. Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/tpami.2020.2972281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"title\":\"Vision-Language Navigation Policy Learning and Adaptation.\",\"url\":\"https://www.semanticscholar.org/paper/2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042126156\",\"name\":\"Tasmiah Tahsin Mayeesha\"},{\"authorId\":\"108184590\",\"name\":\"A. Sarwar\"},{\"authorId\":\"1732925\",\"name\":\"Rashedur M. Rahman\"}],\"doi\":\"10.1080/24751839.2020.1833136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d616b408df04cdcbddcf5af423b4d915bd40c750\",\"title\":\"Deep learning based question answering system in Bengali\",\"url\":\"https://www.semanticscholar.org/paper/d616b408df04cdcbddcf5af423b4d915bd40c750\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1901.02539\",\"authors\":[{\"authorId\":\"145242558\",\"name\":\"T. Lai\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1793409\",\"name\":\"Nedim Lipka\"},{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"}],\"doi\":\"10.1109/ICMLA.2018.00180\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8f8102fb6e0d1f64486b0be3d63c86aa47237e4\",\"title\":\"Supervised Transfer Learning for Product Information Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d8f8102fb6e0d1f64486b0be3d63c86aa47237e4\",\"venue\":\"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"STANDING WITH\"},{\"authorId\":null,\"name\":\"PARAPHRASED READING COMPRE\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e02867c4e172778b543b7fcd17f4c0f1b7c8cb5\",\"title\":\"DUORC: TOWARDS COMPLEX LANGUAGE UNDER-\",\"url\":\"https://www.semanticscholar.org/paper/7e02867c4e172778b543b7fcd17f4c0f1b7c8cb5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.08607\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"4604969\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/CVPR.2019.00853\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"title\":\"Progressive Attention Memory Network for Movie Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151411658\",\"name\":\"Xutao Qu\"},{\"authorId\":\"2127844\",\"name\":\"Dongye Zhuang\"},{\"authorId\":\"152962135\",\"name\":\"Haibin Xie\"}],\"doi\":\"10.1007/978-3-030-27532-7_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02a582e88eff56adc643b4d5404ae78a06524470\",\"title\":\"Semantic Situation Extraction from Satellite Image Based on Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/02a582e88eff56adc643b4d5404ae78a06524470\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":\"1709.05036\",\"authors\":[{\"authorId\":\"1703411\",\"name\":\"T. Liu\"},{\"authorId\":\"15566220\",\"name\":\"Yu-Hsueh Wu\"},{\"authorId\":\"144300094\",\"name\":\"Hung-yi Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa634836c057a34a4b5eb94624757ab262837bc6\",\"title\":\"Query-based Attention CNN for Text Similarity Map\",\"url\":\"https://www.semanticscholar.org/paper/fa634836c057a34a4b5eb94624757ab262837bc6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"79927338\",\"name\":\"L. Wang\"},{\"authorId\":\"37233332\",\"name\":\"J. Gou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"title\":\"Affective question answering on video\",\"url\":\"https://www.semanticscholar.org/paper/1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145532503\",\"name\":\"Marco Leo\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"3463966\",\"name\":\"G. Medioni\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11024-6_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"title\":\"Deep Learning for Assistive Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2005.03356\",\"authors\":[{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1679974562\",\"name\":\"Ahjeong Seo\"},{\"authorId\":\"1680054988\",\"name\":\"Youwon Jang\"},{\"authorId\":\"153311117\",\"name\":\"Seungchan Lee\"},{\"authorId\":\"1491775096\",\"name\":\"Minsu Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d21241b930b005847cf4350294c61d6c29ccd9f\",\"title\":\"DramaQA: Character-Centered Video Story Understanding with Hierarchical QA\",\"url\":\"https://www.semanticscholar.org/paper/4d21241b930b005847cf4350294c61d6c29ccd9f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.10692\",\"authors\":[{\"authorId\":\"1693704\",\"name\":\"H. F. Tung\"},{\"authorId\":\"34939798\",\"name\":\"Adam W. Harley\"},{\"authorId\":\"9930869\",\"name\":\"Liang-Kang Huang\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"}],\"doi\":\"10.1109/CVPR.2018.00732\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2558c26915e834b60b06be7da1d9db5d0897343\",\"title\":\"Reward Learning from Narrated Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/d2558c26915e834b60b06be7da1d9db5d0897343\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.03316\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"title\":\"IQA: Visual Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2621359\",\"name\":\"Mohit Yadav\"},{\"authorId\":\"3213990\",\"name\":\"L. Vig\"},{\"authorId\":\"143725466\",\"name\":\"G. Shroff\"}],\"doi\":\"10.18653/V1/E17-1080\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ced76a7bf4c90b7dce83a44e99eb2d3947da48a8\",\"title\":\"Learning and Knowledge Transfer with Memory Networks for Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/ced76a7bf4c90b7dce83a44e99eb2d3947da48a8\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2011.07231\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"title\":\"ActBERT: Learning Global-Local Video-Text Representations\",\"url\":\"https://www.semanticscholar.org/paper/8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"49418159\",\"name\":\"Y. Wang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/TCSVT.2019.2894161\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c75881e226b5d57e1c5570bf8e51a93bdada9e8\",\"title\":\"stagNet: An Attentive Semantic RNN for Group Activity and Individual Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c75881e226b5d57e1c5570bf8e51a93bdada9e8\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1758085\",\"name\":\"Toryn Q. Klassen\"},{\"authorId\":\"143634377\",\"name\":\"H. Levesque\"},{\"authorId\":\"1683896\",\"name\":\"Sheila A. McIlraith\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e72fdbe456bf22b96dee9e6ee77308d204512a40\",\"title\":\"Towards Representing What Readers of Fiction Believe\",\"url\":\"https://www.semanticscholar.org/paper/e72fdbe456bf22b96dee9e6ee77308d204512a40\",\"venue\":\"COMMONSENSE\",\"year\":2017},{\"arxivId\":\"1803.10699\",\"authors\":[{\"authorId\":\"144529493\",\"name\":\"Li Ding\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/CVPR.2018.00681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c6ce420976f958e7582a2f452c3a541faa82074\",\"title\":\"Weakly-Supervised Action Segmentation with Iterative Soft Boundary Assignment\",\"url\":\"https://www.semanticscholar.org/paper/6c6ce420976f958e7582a2f452c3a541faa82074\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40895941\",\"name\":\"Ronan Riochet\"},{\"authorId\":\"40901792\",\"name\":\"Mario Ynocente Castro\"},{\"authorId\":\"37831451\",\"name\":\"M. Bernard\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"3158706\",\"name\":\"V\\u00e9ronique Izard\"},{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e04f086c60214ab0d0f7ec827c0d3b0e0794d13e\",\"title\":\"IntPhys: A Benchmark for Visual Intuitive Physics Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e04f086c60214ab0d0f7ec827c0d3b0e0794d13e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.10973\",\"authors\":[{\"authorId\":\"46760211\",\"name\":\"Taehyeong Kim\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"46235583\",\"name\":\"Seonil Son\"},{\"authorId\":\"46260876\",\"name\":\"Kyoung-Wha Park\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d054c08b056139858312bd1dcfb282d511773c64\",\"title\":\"GLAC Net: GLocal Attention Cascading Networks for Multi-image Cued Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/d054c08b056139858312bd1dcfb282d511773c64\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2079753\",\"name\":\"Daria Dzendzik\"},{\"authorId\":\"27731932\",\"name\":\"Alberto Poncelas\"},{\"authorId\":\"144420027\",\"name\":\"C. Vogel\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db2af60318abd6fd306711dca52760516e692814\",\"title\":\"ADAPT Centre Cone Team at IJCNLP-2017 Task 5: A Similarity-Based Logistic Regression Approach to Multi-choice Question Answering in an Examinations Shared Task\",\"url\":\"https://www.semanticscholar.org/paper/db2af60318abd6fd306711dca52760516e692814\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":\"1805.00145\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"47585344\",\"name\":\"Yu Cheng\"},{\"authorId\":\"30126647\",\"name\":\"Steven Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7158bd1635bf7bb87c557c429774d5236703e64\",\"title\":\"Dialog-based Interactive Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f7158bd1635bf7bb87c557c429774d5236703e64\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1806.05341\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"46867115\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b23f52bde0bfa9ec093a360962df07f188dc1962\",\"title\":\"From Trailers to Storylines: An Efficient Way to Learn from Movies\",\"url\":\"https://www.semanticscholar.org/paper/b23f52bde0bfa9ec093a360962df07f188dc1962\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5519ca5f5bd0b1dfcb736d235dd5b430adaee1f\",\"title\":\"Desired Item Relevance Feedback : Negative Relative Attribute : More open Candidate A Dialog Feedback :\",\"url\":\"https://www.semanticscholar.org/paper/f5519ca5f5bd0b1dfcb736d235dd5b430adaee1f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"143761093\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d89c0c6a1d5bc5cf06b0927976eaca350653301\",\"title\":\"Learning to Reason with Relational Video Representation for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5d89c0c6a1d5bc5cf06b0927976eaca350653301\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1612.01848\",\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":\"144142401\",\"name\":\"Siyuan Zhao\"},{\"authorId\":\"37187331\",\"name\":\"Sadid A. Hasan\"},{\"authorId\":\"1878942\",\"name\":\"V. Datla\"},{\"authorId\":\"1694037\",\"name\":\"Kathy Lee\"},{\"authorId\":\"2845895\",\"name\":\"Ashequl Qadir\"},{\"authorId\":\"2217579\",\"name\":\"J. Liu\"},{\"authorId\":\"2211973\",\"name\":\"Oladimeji Farri\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4a83c0dc747b768939a730f764a7fc7c1761b431\",\"title\":\"Condensed Memory Networks for Clinical Diagnostic Inferencing\",\"url\":\"https://www.semanticscholar.org/paper/4a83c0dc747b768939a730f764a7fc7c1761b431\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.1016/j.csl.2020.101095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"661f04ecc734ced906e16980a6143c814ce085ed\",\"title\":\"Hierarchical multimodal attention for end-to-end audio-visual scene-aware dialogue response generation\",\"url\":\"https://www.semanticscholar.org/paper/661f04ecc734ced906e16980a6143c814ce085ed\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66801160\",\"name\":\"Ge Yuan-yuan\"},{\"authorId\":\"1441325232\",\"name\":\"Xu Youjiang\"},{\"authorId\":\"1391375173\",\"name\":\"Han Ya-hong\"}],\"doi\":\"10.1007/978-981-10-7299-4_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"489baaf7ca4b6ed0ff3cef48a8b078ca09b4c080\",\"title\":\"Video Question Answering Using a Forget Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/489baaf7ca4b6ed0ff3cef48a8b078ca09b4c080\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.00344\",\"authors\":[{\"authorId\":\"1769749\",\"name\":\"S. Wang\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"16132631\",\"name\":\"Z. Kou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e7d1c2d4b4ca2bf3109757f181bc2cf15240fcc5\",\"title\":\"How to Make a BLT Sandwich? Learning to Reason towards Understanding Web Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/e7d1c2d4b4ca2bf3109757f181bc2cf15240fcc5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66935500\",\"name\":\"P. Deshmukh\"},{\"authorId\":\"51502239\",\"name\":\"Rani S. Lande\"}],\"doi\":\"10.1109/ICICT48043.2020.9112454\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"title\":\"Convolutional Neural Network based Review System for Automatic Past Event Search using Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"venue\":\"2020 International Conference on Inventive Computation Technologies (ICICT)\",\"year\":2020},{\"arxivId\":\"1810.13441\",\"authors\":[{\"authorId\":\"49871029\",\"name\":\"Kai Sun\"},{\"authorId\":\"41190054\",\"name\":\"Dian Yu\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1748501\",\"name\":\"Claire Cardie\"}],\"doi\":\"10.18653/v1/N19-1270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f346de21a13dacf5b65e2de81e84d54226a5b9f\",\"title\":\"Improving Machine Reading Comprehension with General Reading Strategies\",\"url\":\"https://www.semanticscholar.org/paper/8f346de21a13dacf5b65e2de81e84d54226a5b9f\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14156382\",\"name\":\"T. Yu\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"46413384\",\"name\":\"Xiangyu Zeng\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"}],\"doi\":\"10.1145/3343031.3350935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"276855eb1a4487be77de1c62947bd443bfe2da0f\",\"title\":\"Vision-Language Recommendation via Attribute Augmented Multimodal Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/276855eb1a4487be77de1c62947bd443bfe2da0f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1810.11954\",\"authors\":[{\"authorId\":\"144992211\",\"name\":\"Shubham Agarwal\"},{\"authorId\":\"2544049\",\"name\":\"Ondrej Dusek\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"1681799\",\"name\":\"Verena Rieser\"}],\"doi\":\"10.18653/v1/W18-5709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2b41790d33770ba43c45ed2da89c644840debf0\",\"title\":\"A Knowledge-Grounded Multimodal Search-Based Conversational Agent\",\"url\":\"https://www.semanticscholar.org/paper/b2b41790d33770ba43c45ed2da89c644840debf0\",\"venue\":\"SCAI@EMNLP\",\"year\":2018},{\"arxivId\":\"1901.03035\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29e13746fa5aed13e51558a521a39aaeaa99c1b1\",\"title\":\"Self-Monitoring Navigation Agent via Auxiliary Progress Estimation\",\"url\":\"https://www.semanticscholar.org/paper/29e13746fa5aed13e51558a521a39aaeaa99c1b1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":\"10.1101/166785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"353a8c48eba4a179d6274b822d50aad4faf52bbc\",\"title\":\"Computational Foundations of Natural Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/353a8c48eba4a179d6274b822d50aad4faf52bbc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1906.12158\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145510896\",\"name\":\"Z. Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"}],\"doi\":\"10.24963/ijcai.2019/609\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b2ae2e1f9148e6a05128773c16868cae7e99dc2\",\"title\":\"Open-Ended Long-Form Video Question Answering via Hierarchical Convolutional Self-Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/1b2ae2e1f9148e6a05128773c16868cae7e99dc2\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2011.05558\",\"authors\":[{\"authorId\":\"51502783\",\"name\":\"Menglin Jia\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1748501\",\"name\":\"Claire Cardie\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b683aa99befd87f0223d2835f1b4f975e9175f8b\",\"title\":\"Intentonomy: a Dataset and Study towards Human Intent Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b683aa99befd87f0223d2835f1b4f975e9175f8b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.02896\",\"authors\":[{\"authorId\":\"144652649\",\"name\":\"E. Chu\"},{\"authorId\":\"145364504\",\"name\":\"D. Roy\"}],\"doi\":\"10.1109/ICDM.2017.100\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"fd397f15c2f0ee75e040a08c36363ec4f75ffc51\",\"title\":\"Audio-Visual Sentiment Analysis for Learning Emotional Arcs in Movies\",\"url\":\"https://www.semanticscholar.org/paper/fd397f15c2f0ee75e040a08c36363ec4f75ffc51\",\"venue\":\"2017 IEEE International Conference on Data Mining (ICDM)\",\"year\":2017},{\"arxivId\":\"1907.05006\",\"authors\":[{\"authorId\":\"150065958\",\"name\":\"Chiwan Song\"},{\"authorId\":\"40506942\",\"name\":\"Woobin Im\"},{\"authorId\":\"144182454\",\"name\":\"Sung-eui Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"title\":\"Two-stream Spatiotemporal Feature for Video QA Task\",\"url\":\"https://www.semanticscholar.org/paper/b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"144675299\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"title\":\"The Fashion IQ Dataset: Retrieving Images by Combining Side Information and Relative Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2079753\",\"name\":\"Daria Dzendzik\"},{\"authorId\":\"144420027\",\"name\":\"C. Vogel\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e4b0ac8090e67fc425189da983e0719e2184e38b\",\"title\":\"Who framed Roger Rabbit? Multiple choice questions answering about movie plot\",\"url\":\"https://www.semanticscholar.org/paper/e4b0ac8090e67fc425189da983e0719e2184e38b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2012.09216\",\"authors\":[{\"authorId\":\"2015467\",\"name\":\"Te-Lin Wu\"},{\"authorId\":\"2018730539\",\"name\":\"Shikhar Singh\"},{\"authorId\":\"21409233\",\"name\":\"S. Paul\"},{\"authorId\":\"49581425\",\"name\":\"G. Burns\"},{\"authorId\":\"3157053\",\"name\":\"Nanyun Peng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9074d9719c5ce0dd3a7369dd0749cd08d7f67ed\",\"title\":\"MELINDA: A Multimodal Dataset for Biomedical Experiment Method Classification\",\"url\":\"https://www.semanticscholar.org/paper/c9074d9719c5ce0dd3a7369dd0749cd08d7f67ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1905.12794\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f472b819ce521337c01e4ebf91714f93413d9997\",\"title\":\"Fashion IQ: A New Dataset towards Retrieving Images by Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/f472b819ce521337c01e4ebf91714f93413d9997\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"26900125\",\"name\":\"Jinghao Lin\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2411270f111a160c9289d56132651c896a5738f6\",\"title\":\"Video Question Answering via Hierarchical Dual-Level Attention Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/2411270f111a160c9289d56132651c896a5738f6\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1901.06796\",\"authors\":[{\"authorId\":\"32794831\",\"name\":\"W. Zhang\"},{\"authorId\":\"1713128\",\"name\":\"Quan Z. Sheng\"},{\"authorId\":\"65966956\",\"name\":\"A. Alhazmi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42d6727d6db5440a87d223a474b3dc6ecc271aeb\",\"title\":\"Generating Textual Adversarial Examples for Deep Learning Models: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/42d6727d6db5440a87d223a474b3dc6ecc271aeb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.02880\",\"authors\":[{\"authorId\":\"1381942456\",\"name\":\"Prakamya Mishra\"},{\"authorId\":\"32018612\",\"name\":\"Pranav D Mathur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"737e77decce038c890f81583f72281f14adae563\",\"title\":\"Contextualized Spoken Word Representations from Convolutional Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/737e77decce038c890f81583f72281f14adae563\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10019\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"title\":\"Hierarchical Conditional Relation Networks for Multimodal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.02648\",\"authors\":[{\"authorId\":\"8442412\",\"name\":\"Xueya Zhang\"},{\"authorId\":\"50728655\",\"name\":\"Tong Zhang\"},{\"authorId\":\"49783660\",\"name\":\"X. Hong\"},{\"authorId\":\"1830568950\",\"name\":\"Zhen Cui\"},{\"authorId\":\"72086292\",\"name\":\"Jian Yang\"}],\"doi\":\"10.1007/978-3-030-58595-2_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cc97c0e2e2645a9f633aaf6b93232c1ad605498a\",\"title\":\"Graph Wasserstein Correlation Analysis for Movie Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/cc97c0e2e2645a9f633aaf6b93232c1ad605498a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82117909\",\"name\":\"Sanket Shah\"},{\"authorId\":\"39719398\",\"name\":\"Anand Mishra\"},{\"authorId\":\"46202814\",\"name\":\"N. Yadati\"},{\"authorId\":\"2408872\",\"name\":\"P. Talukdar\"}],\"doi\":\"10.1609/aaai.v33i01.33018876\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0818dac77eee5b970736e57a478bcedfb1b15fe\",\"title\":\"KVQA: Knowledge-Aware Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d0818dac77eee5b970736e57a478bcedfb1b15fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1611.04021\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1da2431a799f68888b7e035fe49fe47a4735b71b\",\"title\":\"Leveraging Video Descriptions to Learn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1da2431a799f68888b7e035fe49fe47a4735b71b\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1709.09345\",\"authors\":[{\"authorId\":\"19255603\",\"name\":\"Seil Na\"},{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"49476855\",\"name\":\"Jisung Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/ICCV.2017.80\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d66bf8b883b85e72b98b75a87773281d86fed25\",\"title\":\"A Read-Write Memory Network for Movie Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6d66bf8b883b85e72b98b75a87773281d86fed25\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.07810\",\"authors\":[{\"authorId\":\"3422058\",\"name\":\"Tegan Maharaj\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":\"10.1109/CVPR.2017.778\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"120ae4cbdcfeaf2604983b3bc3d9a8e1ec37e376\",\"title\":\"A Dataset and Exploration of Models for Understanding Video Data through Fill-in-the-Blank Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/120ae4cbdcfeaf2604983b3bc3d9a8e1ec37e376\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-319-75928-9_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51280870657c72400b5de46ba56ee18b9891ab40\",\"title\":\"Multimodal Attention Agents in Visual Conversation\",\"url\":\"https://www.semanticscholar.org/paper/51280870657c72400b5de46ba56ee18b9891ab40\",\"venue\":\"EIDWT\",\"year\":2018},{\"arxivId\":\"1611.02145\",\"authors\":[{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1561/0600000073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84c95a8db377c25d4280f188e9477569ab57281b\",\"title\":\"Crowdsourcing in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/84c95a8db377c25d4280f188e9477569ab57281b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1803.07616\",\"authors\":[{\"authorId\":\"40895941\",\"name\":\"Ronan Riochet\"},{\"authorId\":\"40901792\",\"name\":\"Mario Ynocente Castro\"},{\"authorId\":\"37831451\",\"name\":\"M. Bernard\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"3158706\",\"name\":\"V\\u00e9ronique Izard\"},{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"705ab4cd13ea26247fd537150708ee352e06b863\",\"title\":\"IntPhys: A Framework and Benchmark for Visual Intuitive Physics Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/705ab4cd13ea26247fd537150708ee352e06b863\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2545727\",\"name\":\"T. S. Jayram\"},{\"authorId\":\"88000484\",\"name\":\"V. Albouy\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"},{\"authorId\":\"13177954\",\"name\":\"E. Sevgen\"},{\"authorId\":\"50192121\",\"name\":\"A. Ozcan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73b5a24a033073142d895f81c4668d096a0896fb\",\"title\":\"Visually Grounded Video Reasoning in Selective Attention Memory\",\"url\":\"https://www.semanticscholar.org/paper/73b5a24a033073142d895f81c4668d096a0896fb\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491241424\",\"name\":\"Ao Liu\"},{\"authorId\":\"14564042\",\"name\":\"Lizhen Qu\"},{\"authorId\":\"152319891\",\"name\":\"Junyu Lu\"},{\"authorId\":\"2254851\",\"name\":\"Chenbin Zhang\"},{\"authorId\":\"1683510\",\"name\":\"Zenglin Xu\"}],\"doi\":\"10.1145/3357384.3358139\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b8d29605c017b5447379ccf0637679f6fdade88\",\"title\":\"Machine Reading Comprehension: Matching and Orders\",\"url\":\"https://www.semanticscholar.org/paper/5b8d29605c017b5447379ccf0637679f6fdade88\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":\"10.1109/CVPR.2017.571\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"title\":\"Are You Smarter Than a Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1908.10328\",\"authors\":[{\"authorId\":\"22220222\",\"name\":\"Pinelopi Papalampidi\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.18653/v1/D19-1180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"329dd1f97576416b60a19074c94726fc0faf8041\",\"title\":\"Movie Plot Analysis via Turning Point Identification\",\"url\":\"https://www.semanticscholar.org/paper/329dd1f97576416b60a19074c94726fc0faf8041\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1902.03570\",\"authors\":[{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"2781522\",\"name\":\"T. Singh\"},{\"authorId\":\"49148034\",\"name\":\"Akash Jain\"},{\"authorId\":\"8518719\",\"name\":\"S. Singh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d96ac48e92b6b42737276a319f48d9d27080fce\",\"title\":\"EvalAI: Towards Better Evaluation Systems for AI Agents\",\"url\":\"https://www.semanticscholar.org/paper/0d96ac48e92b6b42737276a319f48d9d27080fce\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.01166\",\"authors\":[{\"authorId\":\"143725625\",\"name\":\"Hung Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/P19-1564\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"title\":\"Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2002.11886\",\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5dff9ae50c0aadbd99ca59ff70425f63213243e\",\"title\":\"Hierarchical Memory Decoding for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a5dff9ae50c0aadbd99ca59ff70425f63213243e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.04320\",\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2017.448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8d52265649c16f95af71d6f548c15afc85ac905\",\"title\":\"Situation Recognition with Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8d52265649c16f95af71d6f548c15afc85ac905\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2001.09099\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1007/978-3-030-58589-1_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"title\":\"TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.04208\",\"authors\":[{\"authorId\":\"153000035\",\"name\":\"M. Bain\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"152853748\",\"name\":\"A. Brown\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"title\":\"Condensed Movies: Story Based Retrieval with Contextual Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.06612\",\"authors\":[{\"authorId\":\"1492180855\",\"name\":\"Zahra Abbasiyantaeb\"},{\"authorId\":\"2306648\",\"name\":\"S. Momtazi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6d391498d4161532b0ea158cc11280e1096dbe8f\",\"title\":\"Text-based Question Answering from Information Retrieval and Deep Neural Network Perspectives: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/6d391498d4161532b0ea158cc11280e1096dbe8f\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":1017389,\"doi\":\"10.1109/CVPR.2016.501\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":53,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"T. Mikolov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Show and Tell : A Neural Image Caption Generator chine Comprehension with Syntax , Frames , and Semantics\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"title\":\"Generating Natural-Language Video Descriptions Using Text-Mined Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52075048\",\"name\":\"P. Strevens\"}],\"doi\":\"10.1177/003368828501600204\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b7e3ba2d357552a5a605b79c5a29fc4d05f3698\",\"title\":\"Iii\",\"url\":\"https://www.semanticscholar.org/paper/5b7e3ba2d357552a5a605b79c5a29fc4d05f3698\",\"venue\":\"\",\"year\":1985},{\"arxivId\":\"1501.02530\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298940\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"title\":\"A dataset for Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145714602\",\"name\":\"E. Wilde\"}],\"doi\":\"10.1109/SCC.2007.135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1879caf0debda3e10c49780669422f12e54af000\",\"title\":\"What are you talking about?\",\"url\":\"https://www.semanticscholar.org/paper/1879caf0debda3e10c49780669422f12e54af000\",\"venue\":\"IEEE International Conference on Services Computing (SCC 2007)\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1506.03340\",\"authors\":[{\"authorId\":\"2910877\",\"name\":\"K. Hermann\"},{\"authorId\":\"2367821\",\"name\":\"Tom\\u00e1s Kocisk\\u00fd\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"2311318\",\"name\":\"Lasse Espeholt\"},{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d1505c6123c102e53eb19dff312cb25cea840b72\",\"title\":\"Teaching Machines to Read and Comprehend\",\"url\":\"https://www.semanticscholar.org/paper/d1505c6123c102e53eb19dff312cb25cea840b72\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2013.117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"092f57121e10dcb65a6c348dd8b529bb06ebfb89\",\"title\":\"Video Event Understanding Using Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/092f57121e10dcb65a6c348dd8b529bb06ebfb89\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144369161\",\"name\":\"Wei Qiu\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"title\":\"Translating Video Content to Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2014.455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"title\":\"What Are You Talking About? Text-to-Image Coreference\",\"url\":\"https://www.semanticscholar.org/paper/13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"40085065\",\"name\":\"Percy Liang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-10590-1_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0a083c7bb23db507a40a736953b1cca5a33b16d\",\"title\":\"Linking People in Videos with \\\"Their\\\" Names Using Coreference Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a0a083c7bb23db507a40a736953b1cca5a33b16d\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Wang\"},{\"authorId\":null,\"name\":\"M. Bansal\"},{\"authorId\":null,\"name\":\"K. Gimpel\"},{\"authorId\":null,\"name\":\"D. McAllester\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Machine Comprehension with Syntax\",\"url\":\"\",\"venue\":\"Frames, and Semantics. In ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T.-Y. Lin\"},{\"authorId\":null,\"name\":\"M. Maire\"},{\"authorId\":null,\"name\":\"S. Belongie\"},{\"authorId\":null,\"name\":\"J. Hays\"},{\"authorId\":null,\"name\":\"P. Perona\"},{\"authorId\":null,\"name\":\"P. Doll\\u00e1r\"},{\"authorId\":null,\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Com - mon Objects in Context\",\"url\":\"\",\"venue\":\"In ECCV .\",\"year\":2014},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2013.283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d766bb9364326fbca3d3b40606c6ed5db54f081\",\"title\":\"Finding Actors and Actions in Movies\",\"url\":\"https://www.semanticscholar.org/paper/4d766bb9364326fbca3d3b40606c6ed5db54f081\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"97711484\",\"name\":\"Xiao Lin\"},{\"authorId\":\"32519394\",\"name\":\"Tanmay Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.292\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b888196dda951287dddb60bd44798aab16d6fca\",\"title\":\"Learning Common Sense through Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/0b888196dda951287dddb60bd44798aab16d6fca\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145537764\",\"name\":\"K. P. Sankar\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.23.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6166950a0f4d33812ed6c5e48d951cf370c4e74c\",\"title\":\"Subtitle-free Movie to Script Alignment\",\"url\":\"https://www.semanticscholar.org/paper/6166950a0f4d33812ed6c5e48d951cf370c4e74c\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Kiros\"},{\"authorId\":null,\"name\":\"Y Zhu\"},{\"authorId\":null,\"name\":\"R Salakhutdinov\"},{\"authorId\":null,\"name\":\"R Zemel\"},{\"authorId\":null,\"name\":\"A Torralba\"},{\"authorId\":null,\"name\":\"R Urtasun\"},{\"authorId\":null,\"name\":\"S Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Skip-Thought Vectors. NIPS\",\"url\":\"\",\"venue\":\"Skip-Thought Vectors. NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1109.6841\",\"authors\":[{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1162/COLI_a_00127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ecd3e00bbbfd94446c3adc9c6878de27e250f7c\",\"title\":\"Learning Dependency-Based Compositional Semantics\",\"url\":\"https://www.semanticscholar.org/paper/3ecd3e00bbbfd94446c3adc9c6878de27e250f7c\",\"venue\":\"Computational Linguistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422314\",\"name\":\"M. Richardson\"},{\"authorId\":\"2676309\",\"name\":\"C. Burges\"},{\"authorId\":\"1859813\",\"name\":\"Erin Renshaw\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"564257469fa44cdb57e4272f85253efb9acfd69d\",\"title\":\"MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text\",\"url\":\"https://www.semanticscholar.org/paper/564257469fa44cdb57e4272f85253efb9acfd69d\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Barbu\"},{\"authorId\":null,\"name\":\"A Bridge\"},{\"authorId\":null,\"name\":\"Z Burchill\"},{\"authorId\":null,\"name\":\"D Coroian\"},{\"authorId\":null,\"name\":\"S Dickinson\"},{\"authorId\":null,\"name\":\"S Fidler\"},{\"authorId\":null,\"name\":\"A Michaux\"},{\"authorId\":null,\"name\":\"S Mussman\"},{\"authorId\":null,\"name\":\"S Narayanaswamy\"},{\"authorId\":null,\"name\":\"D Salvi\"},{\"authorId\":null,\"name\":\"L Schmidt\"},{\"authorId\":null,\"name\":\"J Shangguan\"},{\"authorId\":null,\"name\":\"J Siskind\"},{\"authorId\":null,\"name\":\"J Waggoner\"},{\"authorId\":null,\"name\":\"S Wang\"},{\"authorId\":null,\"name\":\"J Wei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Yin, and Z. Zhang. Video-In-sentences Out. In UAI\",\"url\":\"\",\"venue\":\"Yin, and Z. Zhang. Video-In-sentences Out. In UAI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2807482\",\"name\":\"Timoth\\u00e9e Cour\"},{\"authorId\":\"35137957\",\"name\":\"C. Jordan\"},{\"authorId\":\"1759302\",\"name\":\"Eleni Miltsakaki\"},{\"authorId\":\"1685978\",\"name\":\"B. Taskar\"}],\"doi\":\"10.1007/978-3-540-88693-8_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c980b058f98dc1904ad328c2341a47c31479d076\",\"title\":\"Movie/Script: Alignment and Parsing of Video and Text Transcription\",\"url\":\"https://www.semanticscholar.org/paper/c980b058f98dc1904ad328c2341a47c31479d076\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"1931707\",\"name\":\"M. B\\u00e4uml\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPR.2015.7298792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ca387a4080b6aee610783ed03d19bd1891503f\",\"title\":\"Book2Movie: Aligning video scenes with book chapters\",\"url\":\"https://www.semanticscholar.org/paper/45ca387a4080b6aee610783ed03d19bd1891503f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.5654\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"title\":\"Learning a Recurrent Visual Representation for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931707\",\"name\":\"M. B\\u00e4uml\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPR.2013.462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b743e9a1aa638f46f2842187136b0e32e3bc042\",\"title\":\"Semi-supervised Learning with Constraints for Person Identification in Multimedia Data\",\"url\":\"https://www.semanticscholar.org/paper/2b743e9a1aa638f46f2842187136b0e32e3bc042\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2014.340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"title\":\"Visual Semantic Search: Retrieving Videos via Complex Textual Queries\",\"url\":\"https://www.semanticscholar.org/paper/7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1204.2742\",\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"48540451\",\"name\":\"Alexander Bridge\"},{\"authorId\":\"3190146\",\"name\":\"Zachary Burchill\"},{\"authorId\":\"49081881\",\"name\":\"D. Coroian\"},{\"authorId\":\"1779136\",\"name\":\"S. Dickinson\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"38414598\",\"name\":\"A. Michaux\"},{\"authorId\":\"2587937\",\"name\":\"Sam Mussman\"},{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"2968009\",\"name\":\"D. Salvi\"},{\"authorId\":\"50269497\",\"name\":\"Lara Schmidt\"},{\"authorId\":\"2060623\",\"name\":\"Jiangnan Shangguan\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"},{\"authorId\":\"32655613\",\"name\":\"J. Waggoner\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"},{\"authorId\":\"2223764\",\"name\":\"Jinlian Wei\"},{\"authorId\":\"1813304\",\"name\":\"Yifan Yin\"},{\"authorId\":\"48806246\",\"name\":\"Zhiqi Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"793c1c908672ea71aef9e1b41a46272aa27598f7\",\"title\":\"Video In Sentences Out\",\"url\":\"https://www.semanticscholar.org/paper/793c1c908672ea71aef9e1b41a46272aa27598f7\",\"venue\":\"UAI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvprw.2009.5206513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03d1d0a665e358863ff4de9ee7d78f64edd7e756\",\"title\":\"\\u201cWho are you?\\u201d - Learning person specific classifiers from video\",\"url\":\"https://www.semanticscholar.org/paper/03d1d0a665e358863ff4de9ee7d78f64edd7e756\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"title\":\"End-To-End Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2363529\",\"name\":\"Pradipto Das\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"38972663\",\"name\":\"Richard F. Doell\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2013.340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"title\":\"A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching\",\"url\":\"https://www.semanticscholar.org/paper/a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Liang\"},{\"authorId\":null,\"name\":\"M. Jordan\"},{\"authorId\":null,\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning dependencybased compositional semantics\",\"url\":\"\",\"venue\":\"Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1406.5472\",\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.21236/ada612444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfe448d6297ea0a3d4deba21fbf1006bc35877d7\",\"title\":\"Inferring the Why in Images\",\"url\":\"https://www.semanticscholar.org/paper/dfe448d6297ea0a3d4deba21fbf1006bc35877d7\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1506.06724\",\"authors\":[{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2015.11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0e6824e137847be0599bb0032e37042ed2ef5045\",\"title\":\"Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\",\"url\":\"https://www.semanticscholar.org/paper/0e6824e137847be0599bb0032e37042ed2ef5045\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H Pirsiavash\"},{\"authorId\":null,\"name\":\"C Vondrick\"},{\"authorId\":null,\"name\":\"A Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Inferring the Why in Images. arXiv.org, jun 2014\",\"url\":\"\",\"venue\":\"Inferring the Why in Images. arXiv.org, jun 2014\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1502.05698\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"title\":\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\"url\":\"https://www.semanticscholar.org/paper/abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/TPAMI.2014.2366143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"title\":\"Adopting Abstract Images for Semantic Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49121996\",\"name\":\"William M. Marsden\"}],\"doi\":\"10.1017/CBO9781139207249.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d2218b17e7898a222e5fc2079a3f1531990708f\",\"title\":\"I and J\",\"url\":\"https://www.semanticscholar.org/paper/3d2218b17e7898a222e5fc2079a3f1531990708f\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48016277\",\"name\":\"Hai Wang\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1700980\",\"name\":\"Kevin Gimpel\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"}],\"doi\":\"10.3115/v1/P15-2115\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"999f0acfac28215db2e4c69ff42711fd4f56511d\",\"title\":\"Machine Comprehension with Syntax, Frames, and Semantics\",\"url\":\"https://www.semanticscholar.org/paper/999f0acfac28215db2e4c69ff42711fd4f56511d\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"1931707\",\"name\":\"M. B\\u00e4uml\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/s13735-014-0065-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74974f60cc6e5832d40115a443273d7970d1f410\",\"title\":\"Aligning plot synopses to videos for story-based retrieval\",\"url\":\"https://www.semanticscholar.org/paper/74974f60cc6e5832d40115a443273d7970d1f410\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2014}],\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"topics\":[{\"topic\":\"Descriptive Video Service\",\"topicId\":\"2010485\",\"url\":\"https://www.semanticscholar.org/topic/2010485\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Nonlinear gameplay\",\"topicId\":\"62171\",\"url\":\"https://www.semanticscholar.org/topic/62171\"},{\"topic\":\"Server (computing)\",\"topicId\":\"6042\",\"url\":\"https://www.semanticscholar.org/topic/6042\"},{\"topic\":\"Software quality assurance\",\"topicId\":\"54373\",\"url\":\"https://www.semanticscholar.org/topic/54373\"}],\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"