"{\"abstract\":\"The deep two-stream architecture [23] exhibited excellent performance on video based action recognition. The most computationally expensive step in this approach comes from the calculation of optical flow which prevents it to be real-time. This paper accelerates this architecture by replacing optical flow with motion vector which can be obtained directly from compressed videos without extra calculation. However, motion vector lacks fine structures, and contains noisy and inaccurate motion patterns, leading to the evident degradation of recognition performance. Our key insight for relieving this problem is that optical flow and motion vector are inherent correlated. Transferring the knowledge learned with optical flow CNN to motion vector CNN can significantly boost the performance of the latter. Specifically, we introduce three strategies for this, initialization transfer, supervision transfer and their combination. Experimental results show that our method achieves comparable recognition performance to the state-of-the-art, while our method can process 390.7 frames per second, which is 27 times faster than the original two-stream method.\",\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\",\"url\":\"https://www.semanticscholar.org/author/3047890\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\",\"url\":\"https://www.semanticscholar.org/author/33345248\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\",\"url\":\"https://www.semanticscholar.org/author/1915826\"},{\"authorId\":null,\"name\":\"Yu Qiao\",\"url\":null},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\",\"url\":\"https://www.semanticscholar.org/author/2774427\"}],\"citationVelocity\":68,\"citations\":[{\"arxivId\":\"1708.09083\",\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCVW.2017.313\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b0e017a277cc6108d1b0785c49274579d0a26ae\",\"title\":\"Adaptive SVM+: Learning with Privileged Information for Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/3b0e017a277cc6108d1b0785c49274579d0a26ae\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51228744\",\"name\":\"Girmaw Abebe Tadesse\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1145/3211960.3211978\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d531875e928ae0e64df8a1618f47c111c9306b11\",\"title\":\"Visual features for ego-centric activity recognition: a survey\",\"url\":\"https://www.semanticscholar.org/paper/d531875e928ae0e64df8a1618f47c111c9306b11\",\"venue\":\"WearSys@MobiSys\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41185832\",\"name\":\"Xiaochun Luo\"},{\"authorId\":\"49404404\",\"name\":\"Heng Li\"},{\"authorId\":\"46690737\",\"name\":\"Dongping Cao\"},{\"authorId\":\"2740879\",\"name\":\"Y. Yu\"},{\"authorId\":\"30963734\",\"name\":\"Xincong Yang\"},{\"authorId\":\"51029695\",\"name\":\"Ting Huang\"}],\"doi\":\"10.1016/J.AUTCON.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9384eb2b25b939d83b81a618abfc9de686fe5ec5\",\"title\":\"Towards efficient and objective work sampling: Recognizing workers' activities in site surveillance videos with two-stream convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/9384eb2b25b939d83b81a618abfc9de686fe5ec5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"}],\"doi\":\"10.32657/10356/70099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"title\":\"Pose-invariant action recognition for automated behaviour analysis\",\"url\":\"https://www.semanticscholar.org/paper/fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"102868457\",\"name\":\"W. Li\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"144410724\",\"name\":\"K. Jin\"}],\"doi\":\"10.1145/3234804.3234821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"title\":\"Local Feature Analysis for real-time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"venue\":\"ICDLT '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21244644\",\"name\":\"Ichraf Lahouli\"},{\"authorId\":\"2796328\",\"name\":\"R. Haelterman\"},{\"authorId\":\"2410085\",\"name\":\"Zied Chtourou\"},{\"authorId\":\"3249667\",\"name\":\"G. D. Cubber\"},{\"authorId\":\"145162642\",\"name\":\"R. Attia\"}],\"doi\":\"10.1007/978-3-030-19816-9_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d914c53cdf26acc64259d381fbd45c4e150633ee\",\"title\":\"Pedestrian Tracking in the Compressed Domain Using Thermal Images\",\"url\":\"https://www.semanticscholar.org/paper/d914c53cdf26acc64259d381fbd45c4e150633ee\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410507241\",\"name\":\"Joseph Cahill-Lane\"},{\"authorId\":\"1754999\",\"name\":\"S. Mills\"}],\"doi\":\"10.1109/IVCNZ.2017.8402453\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cdec7e1a0f3dab0e70a80aacb4a89085fab3f4\",\"title\":\"Of mice, men, and machines: Real and artificial deep networks for vision\",\"url\":\"https://www.semanticscholar.org/paper/43cdec7e1a0f3dab0e70a80aacb4a89085fab3f4\",\"venue\":\"2017 International Conference on Image and Vision Computing New Zealand (IVCNZ)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.sigpro.2017.10.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"778e6aee04548ec06a52fd3f6aff32074132abdd\",\"title\":\"Distinctive action sketch for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/778e6aee04548ec06a52fd3f6aff32074132abdd\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2797504\",\"name\":\"Honghui Fan\"},{\"authorId\":\"50319375\",\"name\":\"Hongjin Zhu\"}],\"doi\":\"10.1007/s10586-017-1428-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4d1baeb43415381c39d8c2279faad78f0461389\",\"title\":\"Motion vector detection based on local autocorrelation coefficient\",\"url\":\"https://www.semanticscholar.org/paper/a4d1baeb43415381c39d8c2279faad78f0461389\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":\"1708.05465\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f257300b2b4141aab73f93c146bf94846aef5fa1\",\"title\":\"Eigen Evolution Pooling for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f257300b2b4141aab73f93c146bf94846aef5fa1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.00823\",\"authors\":[{\"authorId\":\"79993273\",\"name\":\"Jian Liu\"},{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/s11263-019-01192-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57ba391f7462d2f6b7957d30682670c7f833009d\",\"title\":\"Learning Human Pose Models from Synthesized Data for Robust RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57ba391f7462d2f6b7957d30682670c7f833009d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICIP.2017.8296598\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df2899462e04559c024a773d91f6e06c262e136b\",\"title\":\"Compressed-domain video classification with deep neural networks: \\u201cThere's way too much information to decode the matrix\\u201d\",\"url\":\"https://www.semanticscholar.org/paper/df2899462e04559c024a773d91f6e06c262e136b\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47978407\",\"name\":\"Peilin Chen\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"1476719517\",\"name\":\"Long Sun\"},{\"authorId\":\"51257183\",\"name\":\"Shiqi Wang\"}],\"doi\":\"10.1145/3394171.3413504\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f35d2eeeb86e99f7254819e614e012acba4e535\",\"title\":\"When Bitstream Prior Meets Deep Prior: Compressed Video Super-resolution with Learning from Decoding\",\"url\":\"https://www.semanticscholar.org/paper/1f35d2eeeb86e99f7254819e614e012acba4e535\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1809.03258\",\"authors\":[{\"authorId\":\"9179750\",\"name\":\"Omar Hommos\"},{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-030-11024-6_51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"23dbada22825613e7c616eb60af0c8a812372f3b\",\"title\":\"Using phase instead of optical flow for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/23dbada22825613e7c616eb60af0c8a812372f3b\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1709.06664\",\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"41225110\",\"name\":\"Theodore Giannakopoulos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1016/j.patcog.2018.02.028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b42a8325d5cabefd11cee59f4b2b5901eb7f18c6\",\"title\":\"Curriculum Learning of Visual Attribute Clusters for Multi-Task Classification\",\"url\":\"https://www.semanticscholar.org/paper/b42a8325d5cabefd11cee59f4b2b5901eb7f18c6\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/3078971.3078988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"title\":\"Simple, Efficient and Effective Encodings of Local Deep Features for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1811.11057\",\"authors\":[{\"authorId\":\"49183840\",\"name\":\"S. Wang\"},{\"authorId\":\"46386380\",\"name\":\"Hongchao Lu\"},{\"authorId\":\"144690532\",\"name\":\"P. Dmitriev\"},{\"authorId\":\"144165738\",\"name\":\"Z. Deng\"}],\"doi\":\"10.1109/ICCV.2019.00720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6be40f3f375066e02ab53a7967b8d651a680097d\",\"title\":\"Fast Object Detection in Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/6be40f3f375066e02ab53a7967b8d651a680097d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145023992\",\"name\":\"Liang Xie\"},{\"authorId\":\"3108696\",\"name\":\"Jili Tao\"},{\"authorId\":\"35172990\",\"name\":\"Q. Zhang\"},{\"authorId\":\"46544755\",\"name\":\"Huiyu Zhou\"}],\"doi\":\"10.1109/ACCESS.2019.2938768\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64730b9b4b33b434be862449b6c2d97b10d1351a\",\"title\":\"CNN and KPCA-Based Automated Feature Extraction for Real Time Driving Pattern Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64730b9b4b33b434be862449b6c2d97b10d1351a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400906506\",\"name\":\"Quang-Do Ha\"},{\"authorId\":\"1780348\",\"name\":\"Minh-Triet Tran\"}],\"doi\":\"10.1007/978-3-319-70004-5_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3c337c6efe1d80c0ab0a3637a1e65c45e1769e7\",\"title\":\"Activity Recognition from Inertial Sensors with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b3c337c6efe1d80c0ab0a3637a1e65c45e1769e7\",\"venue\":\"FDSE\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/CAC.2017.8243438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"title\":\"Deep learning based human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2041540405\",\"name\":\"Fatemeh Mohammadi Amin\"},{\"authorId\":\"2008796666\",\"name\":\"Maryam Rezayati\"},{\"authorId\":\"2041540399\",\"name\":\"Hans Wernher van de Venn\"},{\"authorId\":\"2306299\",\"name\":\"H. Karimpour\"}],\"doi\":\"10.3390/s20216347\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ebf5debfc670033006b8f1ab8a67db9004c5bae\",\"title\":\"A Mixed-Perception Approach for Safe Human\\u2013Robot Collaboration in Industrial Automation\",\"url\":\"https://www.semanticscholar.org/paper/2ebf5debfc670033006b8f1ab8a67db9004c5bae\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2006.07743\",\"authors\":[{\"authorId\":\"1749326359\",\"name\":\"Adrian Sanchez-Caballero\"},{\"authorId\":\"143645592\",\"name\":\"S. Diz\"},{\"authorId\":\"1406742079\",\"name\":\"David Fuentes-Jim\\u00e9nez\"},{\"authorId\":\"1637432258\",\"name\":\"Cristina Losada-Guti\\u00e9rrez\"},{\"authorId\":\"39343700\",\"name\":\"Marta Marr\\u00f3n Romera\"},{\"authorId\":\"1415064936\",\"name\":\"David Casillas-P\\u00e9rez\"},{\"authorId\":\"134470377\",\"name\":\"Mohammad Ibrahim Sarker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f613f166ec26e3e01e996f7f04ed1d747081d9c\",\"title\":\"3DFCNN: Real-Time Action Recognition using 3D Deep Neural Networks with Raw Depth Information\",\"url\":\"https://www.semanticscholar.org/paper/6f613f166ec26e3e01e996f7f04ed1d747081d9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"1416525307\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"49673319\",\"name\":\"Changsheng Li\"}],\"doi\":\"10.1007/978-3-030-31654-9_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"342a035046125153abdfc0c684c5c9b189146ddf\",\"title\":\"Weakly-Supervised Action Recognition and Localization via Knowledge Transfer\",\"url\":\"https://www.semanticscholar.org/paper/342a035046125153abdfc0c684c5c9b189146ddf\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2017.236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1710.07455\",\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"27619673\",\"name\":\"Xiongxiong Dong\"}],\"doi\":\"10.1007/s11280-018-0642-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"title\":\"Generalized zero-shot learning for action recognition with web-scale video data\",\"url\":\"https://www.semanticscholar.org/paper/c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21244644\",\"name\":\"Ichraf Lahouli\"},{\"authorId\":\"2410085\",\"name\":\"Zied Chtourou\"},{\"authorId\":\"48302637\",\"name\":\"M. Ayed\"},{\"authorId\":\"2594521\",\"name\":\"R. Haelterman\"},{\"authorId\":\"3249667\",\"name\":\"G. D. Cubber\"},{\"authorId\":\"145162642\",\"name\":\"R. Attia\"}],\"doi\":\"10.1007/978-3-030-26756-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"082d8ce642317c80f973f4452f1cd7f645499099\",\"title\":\"Pedestrian Detection and Trajectory Estimation in the Compressed Domain Using Thermal Images\",\"url\":\"https://www.semanticscholar.org/paper/082d8ce642317c80f973f4452f1cd7f645499099\",\"venue\":\"VISIGRAPP\",\"year\":2018},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":\"1911.04469\",\"authors\":[{\"authorId\":\"48212782\",\"name\":\"A. Hammam\"},{\"authorId\":\"1782978\",\"name\":\"M. Soliman\"},{\"authorId\":\"1697259\",\"name\":\"A. Hassanien\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fe6f034179cfe95317abf579d8b7f0b5bfd328e\",\"title\":\"A Proposed Artificial intelligence Model for Real-Time Human Action Localization and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/7fe6f034179cfe95317abf579d8b7f0b5bfd328e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1710.03383\",\"authors\":[{\"authorId\":\"2682151\",\"name\":\"Cheng-Bin Jin\"},{\"authorId\":\"2707231\",\"name\":\"Shengzhe Li\"},{\"authorId\":\"1697362\",\"name\":\"H. Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"208e903211ddc62b997afb5a1bd3c2c43e0e69ee\",\"title\":\"Real-Time Action Detection in Video Surveillance using Sub-Action Descriptor with Multi-CNN\",\"url\":\"https://www.semanticscholar.org/paper/208e903211ddc62b997afb5a1bd3c2c43e0e69ee\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"},{\"authorId\":\"113011036\",\"name\":\"Kun-Hsuan Wu\"}],\"doi\":\"10.1109/ICASSP.2019.8682450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"title\":\"Multi-teacher Knowledge Distillation for Compressed Video Action Recognition on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2944007\",\"name\":\"Guanghua Tan\"},{\"authorId\":\"1883252\",\"name\":\"Rui Miao\"},{\"authorId\":\"151471091\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1007/978-3-030-30508-6_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"title\":\"Action Recognition Based on Divide-and-Conquer\",\"url\":\"https://www.semanticscholar.org/paper/53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1901.07474\",\"authors\":[{\"authorId\":\"50141653\",\"name\":\"Xiao Wang\"},{\"authorId\":\"66119284\",\"name\":\"Shaofei Zheng\"},{\"authorId\":\"145653641\",\"name\":\"R. Yang\"},{\"authorId\":\"144625999\",\"name\":\"B. Luo\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"96fece067ba203eb32c4884ce66031bf7c4a8f78\",\"title\":\"Pedestrian Attribute Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/96fece067ba203eb32c4884ce66031bf7c4a8f78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28908518\",\"name\":\"Takayuki Ujiie\"},{\"authorId\":\"3172422\",\"name\":\"Masayuki Hiromoto\"},{\"authorId\":\"144798056\",\"name\":\"Takashi Sato\"}],\"doi\":\"10.1109/CVPRW.2018.00104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"489ef25ef51b2a2e660f8085d482fa5801d59058\",\"title\":\"Interpolation-Based Object Detection Using Motion Vectors for Embedded Real-time Tracking Systems\",\"url\":\"https://www.semanticscholar.org/paper/489ef25ef51b2a2e660f8085d482fa5801d59058\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145344525\",\"name\":\"H. Fang\"},{\"authorId\":\"2180137\",\"name\":\"Jeyarajan Thiyagalingam\"},{\"authorId\":\"1711673\",\"name\":\"N. Bessis\"},{\"authorId\":\"145537714\",\"name\":\"E. Edirisinghe\"}],\"doi\":\"10.1109/ICIP.2017.8297028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef7b8f73e95faa7a747e0b04363fced0a38d33b0\",\"title\":\"Fast and reliable human action recognition in video sequences by sequential analysis\",\"url\":\"https://www.semanticscholar.org/paper/ef7b8f73e95faa7a747e0b04363fced0a38d33b0\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1812.10071\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"Kui Jia\"},{\"authorId\":\"48234805\",\"name\":\"Yuejia Shen\"},{\"authorId\":\"1702137\",\"name\":\"Silvio Savarese\"},{\"authorId\":\"1739816\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"2131088\",\"name\":\"Bertram Emil Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"073fabecf18f1421321f1961872b9842d913e4ee\",\"title\":\"Coupled Recurrent Network (CRN)\",\"url\":\"https://www.semanticscholar.org/paper/073fabecf18f1421321f1961872b9842d913e4ee\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.03099\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7598ad186218f5d43fde37acd3d17f897283c3b7\",\"title\":\"Abductive Reasoning as Self-Supervision for Common Sense Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7598ad186218f5d43fde37acd3d17f897283c3b7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081925\",\"name\":\"L. Zhang\"},{\"authorId\":\"2032648\",\"name\":\"J. Varadarajan\"},{\"authorId\":\"47332572\",\"name\":\"Yong Pei\"}],\"doi\":\"10.1007/978-3-030-56150-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"title\":\"Action Recognition Using Co-trained Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"title\":\"T-C3D: Temporal Convolutional 3D Network for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"47628927\",\"name\":\"Mingyang Li\"},{\"authorId\":null,\"name\":\"He Bai\"},{\"authorId\":\"88502672\",\"name\":\"L. Ma\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"}],\"doi\":\"10.1007/s00521-019-04030-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"title\":\"DKD\\u2013DAD: a novel framework with discriminative kinematic descriptor and deep attention-pooled descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"1709.00657\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"},{\"authorId\":\"144370717\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"92e47ef1665bb15acf8eb50cfb6bbd007d226e33\",\"title\":\"Detection of Moving Object in Dynamic Background Using Gaussian Max-Pooling and Segmentation Constrained RPCA\",\"url\":\"https://www.semanticscholar.org/paper/92e47ef1665bb15acf8eb50cfb6bbd007d226e33\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41189343\",\"name\":\"A. E. Seghrouchni\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-56150-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"title\":\"Artificial Intelligence. IJCAI 2019 International Workshops: Macao, China, August 10\\u201312, 2019, Revised Selected Best Papers\",\"url\":\"https://www.semanticscholar.org/paper/ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"144978989\",\"name\":\"Y. Tian\"},{\"authorId\":\"1379758006\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/s11263-020-01328-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"title\":\"Towards Image-to-Video Translation: A Structure-Aware Approach via Multi-stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50599175\",\"name\":\"N. Li\"},{\"authorId\":\"3958124\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145121142\",\"name\":\"N. Guo\"}],\"doi\":\"10.1016/j.neucom.2017.05.045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3874543cfc320a3b24b294d54d3213e6e6ec48d\",\"title\":\"Instant coherent group motion filtering by group motion representations\",\"url\":\"https://www.semanticscholar.org/paper/b3874543cfc320a3b24b294d54d3213e6e6ec48d\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ICCVW.2017.371\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a2801b968c889a8625d4ab62e03323bd14d6eda\",\"title\":\"Large-Scale Multimodal Gesture Segmentation and Recognition Based on Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9a2801b968c889a8625d4ab62e03323bd14d6eda\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727978\",\"name\":\"J. Jiang\"},{\"authorId\":\"2481662\",\"name\":\"Y. Zhou\"},{\"authorId\":\"2849491\",\"name\":\"Ganesh Ananthanarayanan\"},{\"authorId\":\"39596641\",\"name\":\"Y. Shu\"},{\"authorId\":\"1695232\",\"name\":\"A. Chien\"}],\"doi\":\"10.1145/3349614.3356026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52e8c7d95a33069d11304de7c01692cae0e06ba2\",\"title\":\"Networked Cameras Are the New Big Data Clusters\",\"url\":\"https://www.semanticscholar.org/paper/52e8c7d95a33069d11304de7c01692cae0e06ba2\",\"venue\":\"HotEdgeVideo@MOBICOM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153727620\",\"name\":\"Slim Hamdi\"},{\"authorId\":\"73270188\",\"name\":\"Samir Bouindour\"},{\"authorId\":\"3228239\",\"name\":\"K. Loukil\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"153057492\",\"name\":\"M. Abid\"}],\"doi\":\"10.5220/0008949405140521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaee2f55b1aba55f064057c02fa3a926f7592df4\",\"title\":\"Two-streams Fully Convolutional Networks for Abnormal Event Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/eaee2f55b1aba55f064057c02fa3a926f7592df4\",\"venue\":\"ICAART\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145929374\",\"name\":\"Xue Bai\"},{\"authorId\":\"3150525\",\"name\":\"Enqing Chen\"},{\"authorId\":\"74806144\",\"name\":\"Haron Chweya Tinega\"}],\"doi\":\"10.1117/12.2540268\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"title\":\"Real-time action recognition based on enhanced motion vector temporal segment network\",\"url\":\"https://www.semanticscholar.org/paper/678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/TIP.2019.2922826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"title\":\"Compact and Low-Complexity Binary Feature Descriptor and Fisher Vectors for Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1908.04680\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"49270464\",\"name\":\"Jing Liu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"143999502\",\"name\":\"I. Reid\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f039a499df54321d84b8b214534df6c0b9a9394b\",\"title\":\"Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations\",\"url\":\"https://www.semanticscholar.org/paper/f039a499df54321d84b8b214534df6c0b9a9394b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.12.040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0adddb83eb89da8ecd14a296fa016773dc774646\",\"title\":\"Video summarization via spatio-temporal deep architecture\",\"url\":\"https://www.semanticscholar.org/paper/0adddb83eb89da8ecd14a296fa016773dc774646\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2003.07848\",\"authors\":[{\"authorId\":\"80447592\",\"name\":\"Yunzhong Hou\"},{\"authorId\":\"144436089\",\"name\":\"L. Zheng\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/cvpr42600.2020.01013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94889c780749b6c86a7be8defbb1fc4e915ccbd4\",\"title\":\"Learning to Structure an Image With Few Colors\",\"url\":\"https://www.semanticscholar.org/paper/94889c780749b6c86a7be8defbb1fc4e915ccbd4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22808998\",\"name\":\"F. Amin\"},{\"authorId\":\"49770302\",\"name\":\"Maryam Rezayati\"},{\"authorId\":\"98681611\",\"name\":\"H. W. V. D. Venn\"},{\"authorId\":null,\"name\":\"Hossein Karimpour\"}],\"doi\":\"10.20944/preprints202009.0119.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d29570f72bfa95d44987465dee1ffe959db30fce\",\"title\":\"A Mixed-Perception Approach for Safe Human-Robot Collaboration in Industrial Automation\",\"url\":\"https://www.semanticscholar.org/paper/d29570f72bfa95d44987465dee1ffe959db30fce\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2003.00951\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1515606862\",\"name\":\"Thomas Ledwon\"},{\"authorId\":\"1683451\",\"name\":\"Y. Rong\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f631ee7113032de2c6ee0b39b352af040b0c995f\",\"title\":\"DriverMHG: A Multi-Modal Dataset for Dynamic Recognition of Driver Micro Hand Gestures and a Real-Time Recognition Framework\",\"url\":\"https://www.semanticscholar.org/paper/f631ee7113032de2c6ee0b39b352af040b0c995f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31802065\",\"name\":\"Zhaoxuan Fan\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"47896893\",\"name\":\"W. Jiang\"},{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-319-71607-7_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0471a93e6bf5435fad106da97fcbbed7dbab4006\",\"title\":\"An Online Approach for Gesture Recognition Toward Real-World Applications\",\"url\":\"https://www.semanticscholar.org/paper/0471a93e6bf5435fad106da97fcbbed7dbab4006\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46433230\",\"name\":\"Y. Zhou\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"46275945\",\"name\":\"Jingyu Li\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1725421\",\"name\":\"Shi Qiu\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"}],\"doi\":\"10.1145/3134263.3134265\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"title\":\"Video Classification via Relational Feature Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"3444345\",\"name\":\"Erkun Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/s11042-017-4514-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2faaebd17d10e2919bd69492787e7565546a63f\",\"title\":\"Exploring hybrid spatio-temporal convolutional networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2faaebd17d10e2919bd69492787e7565546a63f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"52217578\",\"name\":\"S. Alavi\"}],\"doi\":\"10.1109/ICWR49608.2020.9122304\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"title\":\"Human Action Recognition in Video Using DB-LSTM and ResNet\",\"url\":\"https://www.semanticscholar.org/paper/e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"venue\":\"2020 6th International Conference on Web Research (ICWR)\",\"year\":2020},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.13726\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI51738.2020.00017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"title\":\"Faster and Accurate Compressed Video Action Recognition Straight from the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"venue\":\"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005105\",\"name\":\"Youngkyoon Jang\"},{\"authorId\":\"49300666\",\"name\":\"Brian T. Sullivan\"},{\"authorId\":\"40626572\",\"name\":\"Casimir J H Ludwig\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1109/ICCVW.2019.00547\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"title\":\"EPIC-Tent: An Egocentric Video Dataset for Camping Tent Assembly\",\"url\":\"https://www.semanticscholar.org/paper/e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.07742\",\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":\"10.1007/978-3-030-11018-5_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4aac6f2dddf0f068f664b666a21a304275ebe0c\",\"title\":\"Fast Semantic Segmentation on Video Using Block Motion-Based Feature Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e4aac6f2dddf0f068f664b666a21a304275ebe0c\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144277662\",\"name\":\"Chao Huang\"},{\"authorId\":\"48571613\",\"name\":\"Like Zhang\"},{\"authorId\":\"70049109\",\"name\":\"Yanqing Jing\"},{\"authorId\":\"3437345\",\"name\":\"D. Zhou\"}],\"doi\":\"10.1145/3305275.3305309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe8bc7c565865a482c4f7c20df103de68ee1f\",\"title\":\"RGVCD: A New Real-time Game Video Clip Detection System\",\"url\":\"https://www.semanticscholar.org/paper/8acbe8bc7c565865a482c4f7c20df103de68ee1f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.13085\",\"authors\":[{\"authorId\":\"144766725\",\"name\":\"D. Wang\"},{\"authorId\":\"49521346\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2904857\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"title\":\"Early Action Prediction With Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2006.09675\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/tcsvt.2020.2984569\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"046f98d55c557d574ef84631cae8d65d709585ed\",\"title\":\"A Real-time Action Representation with Temporal Encoding and Deep Compression\",\"url\":\"https://www.semanticscholar.org/paper/046f98d55c557d574ef84631cae8d65d709585ed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35258643\",\"name\":\"S. Jothi\"},{\"authorId\":null,\"name\":\"Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.35940/ijitee.i7914.078919\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"611dc0fa4b0beb0ac8fa0bf3bbf24f089adf3fe5\",\"title\":\"Anomaly Detection in Video Events using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/611dc0fa4b0beb0ac8fa0bf3bbf24f089adf3fe5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"134883142\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2018.2887408\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification With Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2017.341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"title\":\"Spatio-Temporal Vector of Locally Max Pooled Features for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1903.01038\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2017.226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f66207713871da193af24e19a5d8855bfe7f5a\",\"title\":\"Spatiotemporal Pyramid Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1f66207713871da193af24e19a5d8855bfe7f5a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.08249\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/WACV45572.2020.9093274\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2766379db5d9907766dab034a52867d7394a265e\",\"title\":\"D3D: Distilled 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2766379db5d9907766dab034a52867d7394a265e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31379738\",\"name\":\"H. Chao\"},{\"authorId\":\"79929919\",\"name\":\"Zhang Li-ke\"},{\"authorId\":\"73106786\",\"name\":\"Jing Yan-qing\"},{\"authorId\":\"71423750\",\"name\":\"Zhou Da-jun\"}],\"doi\":\"10.1145/3305275.3305309\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e8cd863aabe4976c25ae65c43556a6386259a73\",\"title\":\"RGVCD: A New Real-time Game Video Clip Detection System\",\"url\":\"https://www.semanticscholar.org/paper/3e8cd863aabe4976c25ae65c43556a6386259a73\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"49605422\",\"name\":\"Jing Wang\"},{\"authorId\":\"4869835\",\"name\":\"T. Hassan\"},{\"authorId\":\"144506604\",\"name\":\"Z. Fei\"}],\"doi\":\"10.3390/fi11020042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"title\":\"3D-CNN-Based Fused Feature Maps with LSTM Applied to Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150223\",\"name\":\"K. Yang\"},{\"authorId\":\"47196642\",\"name\":\"Z. Wang\"},{\"authorId\":\"7944784\",\"name\":\"H. Dai\"},{\"authorId\":\"15785036\",\"name\":\"Tianlong Shen\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"},{\"authorId\":\"47911285\",\"name\":\"J. Jiang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053394\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"651bbfced764c3e8039adf8598def1bd1d69506d\",\"title\":\"Attentional Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/651bbfced764c3e8039adf8598def1bd1d69506d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144861485\",\"name\":\"Z. Ma\"},{\"authorId\":\"3261741\",\"name\":\"Z. Sun\"}],\"doi\":\"10.1007/s11042-018-6260-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8613fef2738325a5697e253276b160099100528d\",\"title\":\"Time-varying LSTM networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8613fef2738325a5697e253276b160099100528d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/TIP.2018.2791180\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"title\":\"Real-Time Action Recognition With Deeply Transferred Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"49527719\",\"name\":\"Houyi Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"title\":\"D3-LND: A two-stream framework with discriminant deep descriptor, linear CMDT and nonlinear KCMDT descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49865142\",\"name\":\"P. Zhou\"},{\"authorId\":\"31355406\",\"name\":\"Qing-hai Ding\"},{\"authorId\":\"47030228\",\"name\":\"H. Luo\"},{\"authorId\":\"30983656\",\"name\":\"X. Hou\"}],\"doi\":\"10.1088/1742-6596/844/1/012044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cd55e3a6c3b73ac76e5552625d3cf3ccf1d9ced\",\"title\":\"Violent Interaction Detection in Video Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8cd55e3a6c3b73ac76e5552625d3cf3ccf1d9ced\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/978-3-030-00767-6_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c9222c188866351c994fee3ac2a2beaa843cc8\",\"title\":\"Gaze Aware Deep Learning Model for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/09c9222c188866351c994fee3ac2a2beaa843cc8\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50816965\",\"name\":\"F. Camarena\"},{\"authorId\":\"3129149\",\"name\":\"Leonardo Chang\"},{\"authorId\":\"1390007889\",\"name\":\"M. Gonz\\u00e1lez-Mendoza\"}],\"doi\":\"10.1109/IWBF.2019.8739244\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaad84f586e09bff5420ef20c18f9f13045b1a89\",\"title\":\"Improving the Dense Trajectories Approach Towards Efficient Recognition of Simple Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/aaad84f586e09bff5420ef20c18f9f13045b1a89\",\"venue\":\"2019 7th International Workshop on Biometrics and Forensics (IWBF)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144195544\",\"name\":\"S. Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.1016/J.COMCOM.2019.07.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"476d10ce66a13a6e2d270329f47aae1761cf4389\",\"title\":\"Crowd Video Event Classification using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/476d10ce66a13a6e2d270329f47aae1761cf4389\",\"venue\":\"Comput. Commun.\",\"year\":2019},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4158401\",\"name\":\"Yeguang Li\"},{\"authorId\":\"48985434\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"1384843518\",\"name\":\"L. Hu\"},{\"authorId\":\"49298479\",\"name\":\"J. Li\"},{\"authorId\":\"1792722\",\"name\":\"Deqing Wang\"}],\"doi\":\"10.1016/j.jvcir.2020.102818\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5392fc56f99ab7f9fc01ca2bca94a13acd8cf280\",\"title\":\"Candidate region correlation for video action detection\",\"url\":\"https://www.semanticscholar.org/paper/5392fc56f99ab7f9fc01ca2bca94a13acd8cf280\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70147929\",\"name\":\"H. Yang\"},{\"authorId\":\"18997752\",\"name\":\"Jun Zhang\"},{\"authorId\":\"2721485\",\"name\":\"Shuohao Li\"},{\"authorId\":\"3249639\",\"name\":\"Tingjin Luo\"}],\"doi\":\"10.3233/JIFS-18209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"title\":\"Bi-direction hierarchical LSTM with spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1703.02716\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"title\":\"A Pursuit of Temporal Accuracy in General Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2949626\",\"name\":\"Debanga Raj Neog\"}],\"doi\":\"10.14288/1.0368664\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18ae71496eb883d62a6a934a485fef88cf9bc7c6\",\"title\":\"Measurement and animation of the eye region of the human face in reduced coordinates\",\"url\":\"https://www.semanticscholar.org/paper/18ae71496eb883d62a6a934a485fef88cf9bc7c6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3794315\",\"name\":\"Yutong Cai\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":\"10.1109/VCIP.2018.8698676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e51635fe9554db3b10a262cc113c237ffcb759bf\",\"title\":\"Multi-scale Spatiotemporal Information Fusion Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e51635fe9554db3b10a262cc113c237ffcb759bf\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":\"1912.01601\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"title\":\"LiteEval: A Coarse-to-Fine Framework for Resource Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978582908\",\"name\":\"Divina Govender\"},{\"authorId\":\"66491832\",\"name\":\"Jules-Raymond Tapamo\"}],\"doi\":\"10.1007/978-3-030-58799-4_58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3c05361e249d6ec8e68f2d9c9d33ed71cfce89\",\"title\":\"Factors Affecting the Cost to Accuracy Balance for Real-Time Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a3c05361e249d6ec8e68f2d9c9d33ed71cfce89\",\"venue\":\"ICCSA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471424585\",\"name\":\"Deepika Roselind Johnson\"},{\"authorId\":\"69493918\",\"name\":\"V. R. Uthariaraj\"}],\"doi\":\"10.1155/2020/8852404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"title\":\"A Novel Parameter Initialization Technique Using RBM-NN for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1708.08728\",\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"1911727\",\"name\":\"Theodoros Giannakopoulos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCVW.2017.306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f775be87ca71180d1cf97d81678f4fd713343e01\",\"title\":\"Curriculum Learning for Multi-task Classification of Visual Attributes\",\"url\":\"https://www.semanticscholar.org/paper/f775be87ca71180d1cf97d81678f4fd713343e01\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48321132\",\"name\":\"Y. Zou\"},{\"authorId\":\"9641665\",\"name\":\"X. Ren\"}],\"doi\":\"10.1007/978-981-15-8458-9_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"title\":\"An Efficient Action Recognition Framework Based on ELM and 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.5244/C.31.72\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b61fdc47b5eeae6bc0a52523f519eaeaadbc8c8\",\"title\":\"Temporal Perceptive Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b61fdc47b5eeae6bc0a52523f519eaeaadbc8c8\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1610.01119\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"143921503\",\"name\":\"S. Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2675339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c5ba685c319915711677743b31250c622fd47c4\",\"title\":\"Knowledge Guided Disambiguation for Large-Scale Scene Classification With Multi-Resolution CNNs\",\"url\":\"https://www.semanticscholar.org/paper/6c5ba685c319915711677743b31250c622fd47c4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"48730399\",\"name\":\"Sihui Luo\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TSMC.2016.2625840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"title\":\"Group Sparse-Based Mid-Level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"},{\"authorId\":\"143657565\",\"name\":\"P. Jiang\"}],\"doi\":\"10.1007/s10489-018-1347-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57bb032953f09168953f1cc03102b9269eeee7f5\",\"title\":\"Learning multi-temporal-scale deep information for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/57bb032953f09168953f1cc03102b9269eeee7f5\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2123106\",\"name\":\"H. Xia\"},{\"authorId\":\"50858019\",\"name\":\"T. Li\"},{\"authorId\":\"48152212\",\"name\":\"W. Liu\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"7998512\",\"name\":\"Jingling Yuan\"}],\"doi\":\"10.1145/3330530.3330538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5a7351519efb11d3a5bf750aac9158edbf2ee48\",\"title\":\"Abnormal Event Detection Method in Surveillance Video Based on Temporal CNN and Sparse Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/d5a7351519efb11d3a5bf750aac9158edbf2ee48\",\"venue\":\"ICCDE' 19\",\"year\":2019},{\"arxivId\":\"1802.06724\",\"authors\":[{\"authorId\":\"32082024\",\"name\":\"Ali Javidani\"},{\"authorId\":\"2757076\",\"name\":\"Ahmad Mahmoudi Aznaveh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"075ec6ce86828da112558e4c73e7135e0a7a269f\",\"title\":\"Learning Representative Temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/075ec6ce86828da112558e4c73e7135e0a7a269f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8897402\",\"name\":\"Feng-Ping An\"}],\"doi\":\"10.1109/ACCESS.2018.2874022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f1ef5156eccee6c845bb9f0a99a3943218e145a3\",\"title\":\"Human Action Recognition Algorithm Based on Adaptive Initialization of Deep Learning Model Parameters and Support Vector Machine\",\"url\":\"https://www.semanticscholar.org/paper/f1ef5156eccee6c845bb9f0a99a3943218e145a3\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1911.11961\",\"authors\":[{\"authorId\":\"1391221756\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"49673319\",\"name\":\"Changsheng Li\"},{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"1698347\",\"name\":\"Xiaobin Zhu\"},{\"authorId\":\"145924255\",\"name\":\"Peng Li\"},{\"authorId\":\"143689318\",\"name\":\"Jing Dong\"}],\"doi\":\"10.1109/tnnls.2019.2962815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77e48bc788edc9870dd7c1bdfe7283a909a25b2f\",\"title\":\"AdapNet: Adaptability Decomposing Encoder-Decoder Network for Weakly Supervised Action Recognition and Localization\",\"url\":\"https://www.semanticscholar.org/paper/77e48bc788edc9870dd7c1bdfe7283a909a25b2f\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"Shiwen Zhang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a19185b1cbb6588682318bb9ce649a611e889162\",\"title\":\"VIDEO-LEVEL REPRESENTATION LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/a19185b1cbb6588682318bb9ce649a611e889162\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578886\",\"name\":\"Mohamed R. Ibrahim\"},{\"authorId\":\"38973565\",\"name\":\"J. Haworth\"},{\"authorId\":\"145561918\",\"name\":\"N. Christie\"},{\"authorId\":\"49829302\",\"name\":\"T. Cheng\"},{\"authorId\":\"1718391\",\"name\":\"S. Hailes\"}],\"doi\":\"10.1080/01441647.2020.1840456\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46b89e059bbec06777dbba1d26464700c423b1fa\",\"title\":\"Cycling near misses: a review of the current methods, challenges and the potential of an AI-embedded system\",\"url\":\"https://www.semanticscholar.org/paper/46b89e059bbec06777dbba1d26464700c423b1fa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.14426\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"title\":\"Deep Learning Towards Edge Computing: Neural Networks Straight from Compressed Data\",\"url\":\"https://www.semanticscholar.org/paper/1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ACPR.2017.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08acfa0920abbac5c5046edcff01e41b12c98be7\",\"title\":\"Learning Principal Orientations Descriptor for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08acfa0920abbac5c5046edcff01e41b12c98be7\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":\"2002.07442\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df2f2591054080d069e563cb9ca4e0592bc6df08\",\"title\":\"V4D: 4D Convolutional Neural Networks for Video-level Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/df2f2591054080d069e563cb9ca4e0592bc6df08\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51931034\",\"name\":\"Khari Jarrett\"},{\"authorId\":\"1411317532\",\"name\":\"Joachim Lohn-Jaramillo\"},{\"authorId\":\"39517986\",\"name\":\"Elijah F. W. Bowen\"},{\"authorId\":\"144089674\",\"name\":\"L. Ray\"},{\"authorId\":\"144297712\",\"name\":\"Richard Granger\"}],\"doi\":\"10.5220/0007313603770387\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e90813779746afae2112eb58f5fe3e4d83fdef6b\",\"title\":\"Feedforward and Feedback Processing of Spatiotemporal Tubes for Efficient Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/e90813779746afae2112eb58f5fe3e4d83fdef6b\",\"venue\":\"ICPRAM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144925873\",\"name\":\"N. Kumaran\"},{\"authorId\":\"3846423\",\"name\":\"U. S. Reddy\"},{\"authorId\":\"46574794\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"title\":\"Multiple Action Recognition for Human Object with Motion Video Sequence using the Properties of HSV Color Space Applying with Region of Interest\",\"url\":\"https://www.semanticscholar.org/paper/80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410106115\",\"name\":\"Tieu Binh Hoang\"},{\"authorId\":\"29543391\",\"name\":\"T. C. Ma\"},{\"authorId\":\"71752568\",\"name\":\"Sugimoto Akihiro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"title\":\"Selecting active frames for action recognition with 3D convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1803.11232\",\"authors\":[{\"authorId\":\"2124167\",\"name\":\"Yuhao Zhu\"},{\"authorId\":\"41096175\",\"name\":\"Anand Samajdar\"},{\"authorId\":\"39045061\",\"name\":\"Matthew Mattina\"},{\"authorId\":\"3313708\",\"name\":\"P. Whatmough\"}],\"doi\":\"10.1109/ISCA.2018.00052\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1f041594fa37d407c80b28a13680a9ddc081c49\",\"title\":\"Euphrates: Algorithm-SoC Co-Design for Low-Power Mobile Continuous Vision\",\"url\":\"https://www.semanticscholar.org/paper/e1f041594fa37d407c80b28a13680a9ddc081c49\",\"venue\":\"2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)\",\"year\":2018},{\"arxivId\":\"1811.07598\",\"authors\":[{\"authorId\":\"143866730\",\"name\":\"X. Lan\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":\"10.1007/978-3-030-20890-5_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dcda812bc1cd62c4f930b2a01293d9a232d2c76\",\"title\":\"Self-Referenced Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/1dcda812bc1cd62c4f930b2a01293d9a232d2c76\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1810.04047\",\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d94395882da6da17cee0a6ea6f1058314f091f05\",\"title\":\"Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video\",\"url\":\"https://www.semanticscholar.org/paper/d94395882da6da17cee0a6ea6f1058314f091f05\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1912.04462\",\"authors\":[{\"authorId\":\"3264239\",\"name\":\"Shi-Yuan Huang\"},{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"title\":\"Flow-Distilled IP Two-Stream Networks for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14078265\",\"name\":\"Y. Liao\"},{\"authorId\":\"144383740\",\"name\":\"X. Lu\"},{\"authorId\":\"1736783\",\"name\":\"C. Zhang\"},{\"authorId\":\"47904794\",\"name\":\"Yongtao Wang\"},{\"authorId\":null,\"name\":\"Zhi Tang\"}],\"doi\":\"10.1109/ICCV.2017.519\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ab36c9506b8ece6443898be0c29a72857033f83\",\"title\":\"Mutual Enhancement for Detection of Multiple Logos in Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/5ab36c9506b8ece6443898be0c29a72857033f83\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1518683403\",\"name\":\"S. El-Bana\"},{\"authorId\":\"1410429737\",\"name\":\"A. Al-Kabbany\"},{\"authorId\":\"145844806\",\"name\":\"M. Sharkas\"}],\"doi\":\"10.1101/2020.06.24.20139238\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"179430e915adefab1f1c425319e8c30f6687df05\",\"title\":\"A Multi-Task Pipeline with Specialized Streams forClassification and Segmentation of InfectionManifestations in COVID-19 Scans\",\"url\":\"https://www.semanticscholar.org/paper/179430e915adefab1f1c425319e8c30f6687df05\",\"venue\":\"medRxiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145742542\",\"name\":\"W. Li\"},{\"authorId\":\"144536247\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/ACCESS.2018.2863943\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd22e6532211f679ba6057d15a801ba448b9915c\",\"title\":\"Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/cd22e6532211f679ba6057d15a801ba448b9915c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2007.00843\",\"authors\":[{\"authorId\":\"47061966\",\"name\":\"M. Potter\"},{\"authorId\":\"1785364061\",\"name\":\"Henry Gridley\"},{\"authorId\":\"1785339126\",\"name\":\"Noah Lichtenstein\"},{\"authorId\":\"47128606\",\"name\":\"Kevin Hines\"},{\"authorId\":\"50004462\",\"name\":\"John Nguyen\"},{\"authorId\":\"151494580\",\"name\":\"Jacob Walsh\"}],\"doi\":\"10.1109/MLSP49062.2020.9231894\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"216e819a500c2d5ba2dfc993ddf4c161d72d34bb\",\"title\":\"Low-Light Environment Neural Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/216e819a500c2d5ba2dfc993ddf4c161d72d34bb\",\"venue\":\"2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108808263\",\"name\":\"Jian He\"},{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"98197525\",\"name\":\"Xinlin He\"},{\"authorId\":\"1786267\",\"name\":\"Ruihai Dong\"}],\"doi\":\"10.1016/j.neucom.2019.07.103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6fd8edaa5f7da9c9e2d8547a4d8381ea6a7a4e0\",\"title\":\"Visual Recognition of traffic police gestures with convolutional pose machine and handcrafted features\",\"url\":\"https://www.semanticscholar.org/paper/e6fd8edaa5f7da9c9e2d8547a4d8381ea6a7a4e0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"47002225\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1177/1729881418825093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"title\":\"Hierarchical dynamic depth projected difference images\\u2013based action recognition in videos with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145783730\",\"name\":\"X. Xiao\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"},{\"authorId\":\"145524181\",\"name\":\"W. Wan\"}],\"doi\":\"10.1109/ICALIP.2016.7846652\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"861a51e66553979535df2b41971150453ab26372\",\"title\":\"Overview: Video recognition from handcrafted method to deep learning method\",\"url\":\"https://www.semanticscholar.org/paper/861a51e66553979535df2b41971150453ab26372\",\"venue\":\"2016 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2016},{\"arxivId\":\"1911.08206\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"1420126809\",\"name\":\"Haim Barad\"},{\"authorId\":\"39278465\",\"name\":\"Hanlin Tang\"},{\"authorId\":\"3243137\",\"name\":\"Amit Bleiweiss\"}],\"doi\":\"10.1109/CVPRW50498.2020.00350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da2934c24a9de690ff399736711b754cc10ae1ec\",\"title\":\"Mimic The Raw Domain: Accelerating Action Recognition in the Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/da2934c24a9de690ff399736711b754cc10ae1ec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70346423\",\"name\":\"Jeongseop Yun\"},{\"authorId\":\"39924323\",\"name\":\"Junyeop Lee\"},{\"authorId\":\"2538237\",\"name\":\"Seongkyu Mun\"},{\"authorId\":\"70327574\",\"name\":\"Chul Jin Cho\"},{\"authorId\":\"2757702\",\"name\":\"David K. Han\"},{\"authorId\":\"144878703\",\"name\":\"H. Ko\"}],\"doi\":\"10.1109/AVSS.2018.8639091\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b040b3b4475ca5f9a6938dfd34fca059aa6ed6e\",\"title\":\"Image fusion and influence function for performance improvement of ATM vandalism action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b040b3b4475ca5f9a6938dfd34fca059aa6ed6e\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2408106\",\"name\":\"Mokhtar B. Abdullah\"},{\"authorId\":\"34911220\",\"name\":\"Mobeen Ahmad\"},{\"authorId\":\"52271749\",\"name\":\"D. Han\"}],\"doi\":\"10.1109/ICEIC49074.2020.9051332\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9e74c827a29e5fb8bca1fd4451ec23aaa6713bc\",\"title\":\"Facial Expression Recognition in Videos: An CNN-LSTM based Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f9e74c827a29e5fb8bca1fd4451ec23aaa6713bc\",\"venue\":\"2020 International Conference on Electronics, Information, and Communication (ICEIC)\",\"year\":2020},{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726914\",\"name\":\"Shuren Zhou\"},{\"authorId\":\"49435489\",\"name\":\"X. Zeng\"}],\"doi\":\"10.1007/978-981-15-8083-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"title\":\"Spatial-Temporal Co-attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"title\":\"V4D: 4D Covolutional Neural Networks for Video-level Representations Learning\",\"url\":\"https://www.semanticscholar.org/paper/60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"15223978\",\"name\":\"Xingming Sun\"},{\"authorId\":\"46583977\",\"name\":\"J. Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-981-15-8083-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"title\":\"Artificial Intelligence and Security: 6th International Conference, ICAIS 2020, Hohhot, China, July 17\\u201320, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41c21f12f6896c458004f26b1fd704f4058aaac1\",\"title\":\"CV-C3D: Action Recognition on Compressed Videos with Convolutional 3D Networks\",\"url\":\"https://www.semanticscholar.org/paper/41c21f12f6896c458004f26b1fd704f4058aaac1\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"41225110\",\"name\":\"Theodore Giannakopoulos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab1a5e9b7a71569e87d2480498788260db0ba64d\",\"title\":\"Learning of Visual Attribute Clusters for MultiTask Classification\",\"url\":\"https://www.semanticscholar.org/paper/ab1a5e9b7a71569e87d2480498788260db0ba64d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1706.00384\",\"authors\":[{\"authorId\":\"46868596\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2018.00454\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f06a12928307e17b1aff2b9f4a6c11791f19b6a7\",\"title\":\"Deep Mutual Learning\",\"url\":\"https://www.semanticscholar.org/paper/f06a12928307e17b1aff2b9f4a6c11791f19b6a7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"title\":\"Efficient and Effective Solutions for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642847\",\"name\":\"Yongbin Gao\"},{\"authorId\":\"79890978\",\"name\":\"Xuehao Xiang\"},{\"authorId\":\"145826495\",\"name\":\"N. Xiong\"},{\"authorId\":\"144230953\",\"name\":\"Bo Huang\"},{\"authorId\":\"4292934\",\"name\":\"H. J. Lee\"},{\"authorId\":\"52240872\",\"name\":\"Rad Alrifai\"},{\"authorId\":\"48324819\",\"name\":\"Xiaoyan Jiang\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"}],\"doi\":\"10.1109/ACCESS.2018.2869790\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11c67d6fedc3dd95b752ade4e46ee143ac494259\",\"title\":\"Human Action Monitoring for Healthcare Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/11c67d6fedc3dd95b752ade4e46ee143ac494259\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14516821\",\"name\":\"Ganesh Yaparla\"},{\"authorId\":\"32339189\",\"name\":\"Allaparthi Sriteja\"},{\"authorId\":\"9585601\",\"name\":\"Sai Krishna Munnangi\"},{\"authorId\":\"143674379\",\"name\":\"G. R. Murthy\"}],\"doi\":\"10.1007/978-3-030-20518-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1899d96326b67dc222500b0d8689ebad7c8dafd\",\"title\":\"A Novel Framework for Fine Grained Action Recognition in Soccer\",\"url\":\"https://www.semanticscholar.org/paper/b1899d96326b67dc222500b0d8689ebad7c8dafd\",\"venue\":\"IWANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380231577\",\"name\":\"Ching-Kai Tseng\"},{\"authorId\":\"38603660\",\"name\":\"Chien-Chih Liao\"},{\"authorId\":\"2651451\",\"name\":\"Po-Chun Shen\"},{\"authorId\":\"36027402\",\"name\":\"Jiun-In Guo\"}],\"doi\":\"10.1109/ICIP.2019.8802963\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"663dc035804a45460972a9d7fe372dbb6e2ed415\",\"title\":\"Using C3D to Detect Rear Overtaking Behavior\",\"url\":\"https://www.semanticscholar.org/paper/663dc035804a45460972a9d7fe372dbb6e2ed415\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038399\",\"name\":\"Reza Fuad Rachmadi\"},{\"authorId\":\"35249215\",\"name\":\"K. Uchimura\"},{\"authorId\":\"1953986\",\"name\":\"G. Koutaki\"}],\"doi\":\"10.1109/TENCON.2016.7848130\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0446d14d25a178702c10752b803966a54b539e4\",\"title\":\"Video classification using compacted dataset based on selected keyframe\",\"url\":\"https://www.semanticscholar.org/paper/e0446d14d25a178702c10752b803966a54b539e4\",\"venue\":\"2016 IEEE Region 10 Conference (TENCON)\",\"year\":2016},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557606546\",\"name\":\"Jose M. Rodriguez-Borbon\"},{\"authorId\":\"72445820\",\"name\":\"X. Ma\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"1778860\",\"name\":\"W. Najjar\"}],\"doi\":\"10.1109/TCSVT.2019.2895304\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"title\":\"Heterogeneous Acceleration of HAR Applications\",\"url\":\"https://www.semanticscholar.org/paper/62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930831020\",\"name\":\"Lorxayxang Kai\"},{\"authorId\":\"50741340\",\"name\":\"Yang Wu\"},{\"authorId\":\"3017565\",\"name\":\"Xiaodong Dai\"},{\"authorId\":\"81498564\",\"name\":\"M. Ma\"}],\"doi\":\"10.1007/978-3-030-57884-8_71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"title\":\"Fast Video Classification with CNNs in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":\"2010.10637\",\"authors\":[{\"authorId\":\"120281172\",\"name\":\"Xiaofeng Liu\"},{\"authorId\":\"2000231390\",\"name\":\"Linghao Jin\"},{\"authorId\":\"145343933\",\"name\":\"X. Han\"},{\"authorId\":\"144329386\",\"name\":\"J. You\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07bc6dd2a128e0a433b928faba484c5831227690\",\"title\":\"Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/07bc6dd2a128e0a433b928faba484c5831227690\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02182\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2019.2921539\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95138f276b34cc84695b64ee5fc00c1e27091497\",\"title\":\"Two-Stream Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/95138f276b34cc84695b64ee5fc00c1e27091497\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/s11042-018-5953-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"title\":\"Foveated convolutional neural networks for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"title\":\"From pixels to spikes : efficient multimodal learning in the presence of domain shift\",\"url\":\"https://www.semanticscholar.org/paper/02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83145882\",\"name\":\"J. You\"},{\"authorId\":\"144388019\",\"name\":\"P. Shi\"},{\"authorId\":\"29348697\",\"name\":\"Xiaojie Bao\"}],\"doi\":\"10.1109/ITOEC.2018.8740606\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f41e30a97b7ea505de56630755fde312d3752c5\",\"title\":\"Multi-stream I3D Network for Fine-grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f41e30a97b7ea505de56630755fde312d3752c5\",\"venue\":\"2018 IEEE 4th Information Technology and Mechatronics Engineering Conference (ITOEC)\",\"year\":2018},{\"arxivId\":\"1909.12929\",\"authors\":[{\"authorId\":\"46868059\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"48985485\",\"name\":\"Mingrui Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3010141db561594cad7325554fbc6d41f88c8eba\",\"title\":\"Self-Paced Video Data Augmentation with Dynamic Images Generated by Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/3010141db561594cad7325554fbc6d41f88c8eba\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1690844\",\"name\":\"F. Silva\"},{\"authorId\":\"3087384\",\"name\":\"S. Gul\"},{\"authorId\":\"46493237\",\"name\":\"Daniel Becker\"},{\"authorId\":\"46624407\",\"name\":\"M. Schmidt\"},{\"authorId\":\"1691172\",\"name\":\"C. Hellge\"}],\"doi\":\"10.1109/MMSP.2018.8547120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43ca75ff98e43937ca4292e9974246d042cc9d00\",\"title\":\"Efficient Object Tracking in Compressed Video Streams with Graph Cuts\",\"url\":\"https://www.semanticscholar.org/paper/43ca75ff98e43937ca4292e9974246d042cc9d00\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51427986\",\"name\":\"A. Jacoby\"},{\"authorId\":\"47293698\",\"name\":\"M. Pattichis\"},{\"authorId\":\"1403924583\",\"name\":\"Sylvia Celedon-Pattichis\"},{\"authorId\":\"9623767\",\"name\":\"Carlos LopezLeiva\"}],\"doi\":\"10.1109/SSIAI.2018.8470331\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"510eea270068988276f04933142b403a799ba592\",\"title\":\"Context-Sensitive Human Activity Classification in Collaborative Learning Environments\",\"url\":\"https://www.semanticscholar.org/paper/510eea270068988276f04933142b403a799ba592\",\"venue\":\"2018 IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"76944706\",\"name\":\"Y. Yang\"},{\"authorId\":\"145760952\",\"name\":\"C. Hou\"},{\"authorId\":\"48484256\",\"name\":\"Yue Lang\"},{\"authorId\":\"73070687\",\"name\":\"Dai Guan\"},{\"authorId\":\"8675597\",\"name\":\"D. Huang\"},{\"authorId\":\"2369390\",\"name\":\"Jinchen Xu\"}],\"doi\":\"10.1016/j.patcog.2018.07.030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"213e0c2d10427b569f5d35cb1ecf27068ab2a8cc\",\"title\":\"Open-set human activity recognition based on micro-Doppler signatures\",\"url\":\"https://www.semanticscholar.org/paper/213e0c2d10427b569f5d35cb1ecf27068ab2a8cc\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3432961\",\"name\":\"Wukui Yang\"},{\"authorId\":\"145468103\",\"name\":\"S. Gao\"},{\"authorId\":\"38836749\",\"name\":\"Wenran Liu\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/MMSP.2018.8547088\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c4761b47c3f259559740c90bd42ed8442249499d\",\"title\":\"3-Stream Convolutional Networks for Video Action Recognition with Hybrid Motion Field\",\"url\":\"https://www.semanticscholar.org/paper/c4761b47c3f259559740c90bd42ed8442249499d\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":\"1602.00224\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2019.03.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"title\":\"Order-aware Convolutional Pooling for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1652110241\",\"name\":\"M. Lee\"},{\"authorId\":\"2167197\",\"name\":\"B. Mudassar\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"144192724\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":\"10.1109/DAC18072.2020.9218502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"541ecd9eef7c7bf0b69f47584678a031d5b5c500\",\"title\":\"WarningNet: A Deep Learning Platform for Early Warning of Task Failures under Input Perturbation for Reliable Autonomous Platforms\",\"url\":\"https://www.semanticscholar.org/paper/541ecd9eef7c7bf0b69f47584678a031d5b5c500\",\"venue\":\"2020 57th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICASSP.2019.8683606\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"750c885ee644cb19d89f52ab31639f56254273a2\",\"title\":\"Neuromorphic Vision Sensing for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/750c885ee644cb19d89f52ab31639f56254273a2\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50762746\",\"name\":\"Jun Chen\"},{\"authorId\":\"13849852\",\"name\":\"Yuan-ping Xu\"},{\"authorId\":\"9372837\",\"name\":\"Chao-long Zhang\"},{\"authorId\":\"50070258\",\"name\":\"Zhijie Xu\"},{\"authorId\":\"89978385\",\"name\":\"Xiangxiang Meng\"},{\"authorId\":\"97773646\",\"name\":\"J. Wang\"}],\"doi\":\"10.23919/IConAC.2019.8894962\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841ae506fbd745273cd3498c923088a5736f42d1\",\"title\":\"An Improved Two-stream 3D Convolutional Neural Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/841ae506fbd745273cd3498c923088a5736f42d1\",\"venue\":\"2019 25th International Conference on Automation and Computing (ICAC)\",\"year\":2019},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908694\",\"name\":\"Y. Liu\"},{\"authorId\":\"50535300\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143863243\",\"name\":\"X. Hua\"}],\"doi\":\"10.1145/3126686.3126705\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce11b2d7905d2955c4282db5b68482edb846f29f\",\"title\":\"Spatiotemporal Multi-Task Network for Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ce11b2d7905d2955c4282db5b68482edb846f29f\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1810.07212\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1007/978-3-030-01261-8_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"title\":\"Cross-Modal and Hierarchical Modeling of Video and Text\",\"url\":\"https://www.semanticscholar.org/paper/ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392816360\",\"name\":\"Xiaohui Fanhe\"},{\"authorId\":\"144665929\",\"name\":\"Jie Guo\"},{\"authorId\":\"122473359\",\"name\":\"Zheng Huang\"},{\"authorId\":\"47846658\",\"name\":\"Weidong Qiu\"},{\"authorId\":\"38091504\",\"name\":\"Yuele Zhang\"}],\"doi\":\"10.1109/ICIT.2019.8755180\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96960fc55de526ef37e6f91de49d7627f7459163\",\"title\":\"Multi-Task Learning with Knowledge Transfer for Facial Attribute Classification\",\"url\":\"https://www.semanticscholar.org/paper/96960fc55de526ef37e6f91de49d7627f7459163\",\"venue\":\"2019 IEEE International Conference on Industrial Technology (ICIT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24964059\",\"name\":\"Radhakrishna Dasari\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/MIPR.2018.00069\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"31486c9342901ccdcef5a37c501ca9c56a1e3bc0\",\"title\":\"MPEG CDVS Feature Trajectories for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/31486c9342901ccdcef5a37c501ca9c56a1e3bc0\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"153817519\",\"name\":\"S. E. Alavi\"}],\"doi\":\"10.22133/IJWR.2020.242723.1063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9064d8220c7fb8fde958d700b825bf03a757dc46\",\"title\":\"CoReHAR: A Hybrid Deep Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9064d8220c7fb8fde958d700b825bf03a757dc46\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144350339\",\"name\":\"Chirag I. Patel\"},{\"authorId\":\"2042647646\",\"name\":\"Dileep Labana\"},{\"authorId\":\"47706103\",\"name\":\"S. Pandya\"},{\"authorId\":\"3438822\",\"name\":\"Kirit Modi\"},{\"authorId\":\"3424424\",\"name\":\"H. Ghayvat\"},{\"authorId\":\"1622021877\",\"name\":\"Muhammad Awais\"}],\"doi\":\"10.3390/s20247299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"title\":\"Histogram of Oriented Gradient-Based Fusion of Features for Human Action Recognition in Action Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1710.05112\",\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2017.2786999\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"title\":\"Video Classification With CNNs: Using the Codec as a Spatio-Temporal Activity Sensor\",\"url\":\"https://www.semanticscholar.org/paper/ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1608.00797\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"48596202\",\"name\":\"Hang Song\"},{\"authorId\":\"144838223\",\"name\":\"Wei Li\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8d3b24cd4e6477e9dc7979580449db962d50e19\",\"title\":\"CUHK & ETHZ & SIAT Submission to ActivityNet Challenge 2016\",\"url\":\"https://www.semanticscholar.org/paper/b8d3b24cd4e6477e9dc7979580449db962d50e19\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49537438\",\"name\":\"Xing Fan\"},{\"authorId\":\"3181908\",\"name\":\"Huijune Luo\"},{\"authorId\":\"1391222888\",\"name\":\"Xuan Zhang\"},{\"authorId\":\"144486617\",\"name\":\"Lingxiao He\"},{\"authorId\":\"47897373\",\"name\":\"Wei Jiang\"}],\"doi\":\"10.1007/978-3-030-20890-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d336e2e536de51c287e04d95737ff62eeebb536\",\"title\":\"Computer Vision \\u2013 ACCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/2d336e2e536de51c287e04d95737ff62eeebb536\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ICCVW.2017.370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f865770fa62204783c475186fdb92d496362c2b9\",\"title\":\"Large-Scale Multimodal Gesture Recognition Using Heterogeneous Networks\",\"url\":\"https://www.semanticscholar.org/paper/f865770fa62204783c475186fdb92d496362c2b9\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TIP.2019.2922108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff4f13d4973cfe74f8ac7ef8384548c22284011e\",\"title\":\"Breaking Winner-Takes-All: Iterative-Winners-Out Networks for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/ff4f13d4973cfe74f8ac7ef8384548c22284011e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740612\",\"name\":\"C. Wu\"},{\"authorId\":\"50171534\",\"name\":\"Xiaojun Wu\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/ICCVW.2019.00216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"title\":\"Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gangireddy Prabhakar Reddy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdcdc33b4bf2381fa5e48a6f715f453b31bf8140\",\"title\":\"Review Of Improving Healthcare Services Through Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdcdc33b4bf2381fa5e48a6f715f453b31bf8140\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"68974941\",\"name\":\"Kanishk Lohumi\"},{\"authorId\":\"38542228\",\"name\":\"S. Roy\"}],\"doi\":\"10.1109/ICT-DM.2018.8636373\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02b6d01ca1f5f11b3ab6c92e35b934dd58fd0a5b\",\"title\":\"Automatic Detection of Flood Severity Level from Flood Videos using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/02b6d01ca1f5f11b3ab6c92e35b934dd58fd0a5b\",\"venue\":\"2018 5th International Conference on Information and Communication Technologies for Disaster Management (ICT-DM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7886733\",\"name\":\"A. Angeleas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"232426243970bbc718a57cc2b0bf02bfc7801008\",\"title\":\"A Multi-Formal Languages Collaborative Scheme for Complex Human Activity Recognition and Behavioral Patterns Extraction\",\"url\":\"https://www.semanticscholar.org/paper/232426243970bbc718a57cc2b0bf02bfc7801008\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7550195\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"47474011\",\"name\":\"M. Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":\"10.1145/3394171.3414003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"title\":\"Self-Paced Video Data Augmentation by Generative Adversarial Networks with Insufficient Samples\",\"url\":\"https://www.semanticscholar.org/paper/1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1804.08254\",\"authors\":[{\"authorId\":\"1394243625\",\"name\":\"Chunyu Xie\"},{\"authorId\":\"49672556\",\"name\":\"Ce Li\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"},{\"authorId\":\"151481622\",\"name\":\"Jungong Han\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":\"7137861\",\"name\":\"Jianzhuang Liu\"}],\"doi\":\"10.24963/ijcai.2018/227\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae36037c5142ab1ec108fb94d4b665cfe33480ce\",\"title\":\"Memory Attention Networks for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae36037c5142ab1ec108fb94d4b665cfe33480ce\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1810.03964\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"},{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"}],\"doi\":\"10.1109/ICIP.2018.8451666\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification with Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40896248\",\"name\":\"Samvit Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd070be9327291e229d3149ec60388dd4dbf74b1\",\"title\":\"Fast Semantic Segmentation on Video Using Motion Vector-Based Feature Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/fd070be9327291e229d3149ec60388dd4dbf74b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.02543\",\"authors\":[{\"authorId\":\"30621486\",\"name\":\"Stepan Alekseevich Komkov\"},{\"authorId\":\"2007675511\",\"name\":\"Maksim Dzabraev\"},{\"authorId\":\"1380315305\",\"name\":\"Aleksandr Petiushko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"title\":\"Mutual Modality Learning for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578886\",\"name\":\"Mohamed R. Ibrahim\"},{\"authorId\":\"38973565\",\"name\":\"J. Haworth\"},{\"authorId\":\"144944046\",\"name\":\"T. Cheng\"}],\"doi\":\"10.1016/j.cities.2019.102481\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2213e058a897cb790070b53e53c765f09b6c44d8\",\"title\":\"Understanding cities with machine eyes: A review of deep computer vision in urban analytics\",\"url\":\"https://www.semanticscholar.org/paper/2213e058a897cb790070b53e53c765f09b6c44d8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.10418\",\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/978-3-030-01225-0_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"title\":\"W-TALC: Weakly-supervised Temporal Activity Localization and Classification\",\"url\":\"https://www.semanticscholar.org/paper/b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37614515\",\"name\":\"J. Duan\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"145182505\",\"name\":\"Shuai Zhou\"},{\"authorId\":\"3315491\",\"name\":\"Xiaoyuan Guo\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1145/3131343\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"6f5461679e7caa7841a5e1d369f5c2aa86ff83af\",\"title\":\"A Unified Framework for Multi-Modal Isolated Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f5461679e7caa7841a5e1d369f5c2aa86ff83af\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52224898\",\"name\":\"Patrick Weyers\"},{\"authorId\":\"1778586\",\"name\":\"David Schiebener\"},{\"authorId\":\"31335306\",\"name\":\"A. Kummert\"}],\"doi\":\"10.1109/ITSC.2019.8917139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aabe0e2ee00a25754f1549eeea0cfc2e2339f8a4\",\"title\":\"Action and Object Interaction Recognition for Driver Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/aabe0e2ee00a25754f1549eeea0cfc2e2339f8a4\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/S12652-019-01239-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca3d26b3139d8f3db2e7f37c64d18e3cde27f322\",\"title\":\"Evaluating fusion of RGB-D and inertial sensors for multimodal human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ca3d26b3139d8f3db2e7f37c64d18e3cde27f322\",\"venue\":\"J. Ambient Intell. Humaniz. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2682151\",\"name\":\"Cheng-Bin Jin\"},{\"authorId\":\"2772929\",\"name\":\"T. D. Do\"},{\"authorId\":\"47842167\",\"name\":\"M. Liu\"},{\"authorId\":\"1697362\",\"name\":\"H. Kim\"}],\"doi\":\"10.5772/INTECHOPEN.76086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d017d99aba5a39a6e70d96155bec849fed1311b\",\"title\":\"Real-Time Action Recognition Using Multi-level Action Descriptor and DNN\",\"url\":\"https://www.semanticscholar.org/paper/2d017d99aba5a39a6e70d96155bec849fed1311b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1611.06689\",\"authors\":[{\"authorId\":\"37614515\",\"name\":\"J. Duan\"},{\"authorId\":\"145182505\",\"name\":\"Shuai Zhou\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"3315491\",\"name\":\"Xiaoyuan Guo\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee6cf6d7e5b034d1220518a3c9bcd0b08617cd65\",\"title\":\"Multi-Modality Fusion based on Consensus-Voting and 3D Convolution for Isolated Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee6cf6d7e5b034d1220518a3c9bcd0b08617cd65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"1410115257\",\"name\":\"Ge Li\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"}],\"doi\":\"10.1007/978-3-319-64698-5_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20828d021b5987bebc3ce495e44eb9e48eb9be3e\",\"title\":\"A Violence Detection Approach Based on Spatio-temporal Hypergraph Transition\",\"url\":\"https://www.semanticscholar.org/paper/20828d021b5987bebc3ce495e44eb9e48eb9be3e\",\"venue\":\"CAIP\",\"year\":2017},{\"arxivId\":\"1703.06246\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"title\":\"Towards Context-aware Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.13072\",\"authors\":[{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ICASSP.2018.8461792\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"title\":\"Cross-Modal Message Passing for Two-Stream Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1924057490\",\"name\":\"Jinkue Lee\"},{\"authorId\":\"150123608\",\"name\":\"Hoeryong Jung\"}],\"doi\":\"10.3390/s20174871\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"696f993294597ba4657733d12a5f783ac58d1b80\",\"title\":\"TUHAD: Taekwondo Unit Technique Human Action Dataset with Key Frame-Based CNN Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/696f993294597ba4657733d12a5f783ac58d1b80\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2555418\",\"name\":\"J. Tan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6dfcca8c1b08b769ec3e8659de9a9f445d6e689\",\"title\":\"Human pose stream for multi-stream convolutional network in video action classification\",\"url\":\"https://www.semanticscholar.org/paper/b6dfcca8c1b08b769ec3e8659de9a9f445d6e689\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"93233966\",\"name\":\"Chunping Hou\"},{\"authorId\":\"145874777\",\"name\":\"Y. Lang\"},{\"authorId\":\"144902595\",\"name\":\"T. Sakamoto\"},{\"authorId\":\"143605211\",\"name\":\"Yuan He\"},{\"authorId\":\"144455669\",\"name\":\"Wei Xiang\"}],\"doi\":\"10.1109/TGRS.2019.2958178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3b126f91b1a3f1f0c4664e2850f37419bb1121d\",\"title\":\"Omnidirectional Motion Classification With Monostatic Radar System Using Micro-Doppler Signatures\",\"url\":\"https://www.semanticscholar.org/paper/f3b126f91b1a3f1f0c4664e2850f37419bb1121d\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46528640\",\"name\":\"H. T. Binh\"},{\"authorId\":\"9283769\",\"name\":\"Ma Thi Chau\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"9349062\",\"name\":\"B. Duy\"}],\"doi\":\"10.1109/ICCCE.2018.8539313\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3901f177642912be3fd132807a1e7d16796d1011\",\"title\":\"Selecting active frames for action recognition with vote fusion method\",\"url\":\"https://www.semanticscholar.org/paper/3901f177642912be3fd132807a1e7d16796d1011\",\"venue\":\"2018 7th International Conference on Computer and Communication Engineering (ICCCE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73270188\",\"name\":\"Samir Bouindour\"},{\"authorId\":\"50365406\",\"name\":\"Ronghua Hu\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"}],\"doi\":\"10.1109/AIKE.2019.00039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01a91efd651870f78f62b7398e9f1a9e583d250e\",\"title\":\"Enhanced Convolutional Neural Network for Abnormal Event Detection in Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/01a91efd651870f78f62b7398e9f1a9e583d250e\",\"venue\":\"2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/ICCV.2017.71\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"title\":\"Towards Context-Aware Interaction Recognition for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b217f438697476c3fbffd3f1595c17fd05ee89\",\"title\":\"Adapting computer vision models to limitations on input dimensionality and model complexity\",\"url\":\"https://www.semanticscholar.org/paper/38b217f438697476c3fbffd3f1595c17fd05ee89\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49b911544ebfca12bed8cbf09b4f48679a8a8ae2\",\"title\":\"Efficient Inference on Video, In Real-Time and At Scale\",\"url\":\"https://www.semanticscholar.org/paper/49b911544ebfca12bed8cbf09b4f48679a8a8ae2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48625207\",\"name\":\"W. Li\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2690741\",\"name\":\"Shengbei Wang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1007/978-3-319-97289-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"473c74782b0120aa0a8b0e94f49fea6542a6d7da\",\"title\":\"Get the Whole Action Event by Action Stage Classification\",\"url\":\"https://www.semanticscholar.org/paper/473c74782b0120aa0a8b0e94f49fea6542a6d7da\",\"venue\":\"PKAW\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/SMC.2018.00675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"title\":\"TSNet: Deep Network for Human Action Recognition in Hazy Videos\",\"url\":\"https://www.semanticscholar.org/paper/634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":\"1902.10640\",\"authors\":[{\"authorId\":\"34971636\",\"name\":\"Shweta Bhardwaj\"},{\"authorId\":\"34658653\",\"name\":\"M. Srinivasan\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.1109/CVPR.2019.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58f32f1e294569f88d20892c11b389105da9c615\",\"title\":\"Efficient Video Classification Using Fewer Frames\",\"url\":\"https://www.semanticscholar.org/paper/58f32f1e294569f88d20892c11b389105da9c615\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"Vittorio Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"Martial Hebert\"},{\"authorId\":\"1781120\",\"name\":\"Cristian Sminchisescu\"},{\"authorId\":\"144538257\",\"name\":\"Yair Weiss\"}],\"doi\":\"10.1007/978-3-030-01225-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64d5bc73de9113ef6fa564eb44636c8d3e99d890\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/64d5bc73de9113ef6fa564eb44636c8d3e99d890\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2079038\",\"name\":\"Jiayu Sun\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"2838253\",\"name\":\"C. He\"}],\"doi\":\"10.1007/s11042-017-5244-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86114a87c1a5f34a1c2e3e4fb08e38468f94fea4\",\"title\":\"Abnormal event detection for video surveillance using deep one-class learning\",\"url\":\"https://www.semanticscholar.org/paper/86114a87c1a5f34a1c2e3e4fb08e38468f94fea4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144785131\",\"name\":\"Ping Li\"},{\"authorId\":\"1749395\",\"name\":\"Xianghua Xu\"}],\"doi\":\"10.1109/ACCESS.2020.3003939\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f99d0990c255c635f731cefa434912b09598e8cd\",\"title\":\"Recurrent Compressed Convolutional Networks for Short Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/f99d0990c255c635f731cefa434912b09598e8cd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21244644\",\"name\":\"Ichraf Lahouli\"},{\"authorId\":\"2594521\",\"name\":\"R. Haelterman\"},{\"authorId\":\"2410085\",\"name\":\"Zied Chtourou\"},{\"authorId\":\"3249667\",\"name\":\"G. D. Cubber\"},{\"authorId\":\"145162642\",\"name\":\"R. Attia\"}],\"doi\":\"10.5220/0006723704870495\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21262e01039e5994114b4c102fc80e9afa3f1bde\",\"title\":\"Pedestrian Detection and Tracking in Thermal Images from Aerial MPEG Videos\",\"url\":\"https://www.semanticscholar.org/paper/21262e01039e5994114b4c102fc80e9afa3f1bde\",\"venue\":\"VISIGRAPP\",\"year\":2018},{\"arxivId\":\"1811.12432\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00137\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a98ef88bae12639d8770e5680564b8f9a188bec\",\"title\":\"AdaFrame: Adaptive Frame Selection for Fast Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0a98ef88bae12639d8770e5680564b8f9a188bec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31739490\",\"name\":\"E. Fu\"},{\"authorId\":\"143965164\",\"name\":\"Michael Xuelin Huang\"},{\"authorId\":\"1714454\",\"name\":\"H. Leong\"},{\"authorId\":\"1706729\",\"name\":\"G. Ngai\"}],\"doi\":\"10.1145/3240508.3240710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866f70b2b3d91d15e235712378952d942c9c7478\",\"title\":\"Cross-Species Learning: A Low-Cost Approach to Learning Human Fight from Animal Fight\",\"url\":\"https://www.semanticscholar.org/paper/866f70b2b3d91d15e235712378952d942c9c7478\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":\"7296530\",\"name\":\"Hongyu Zhu\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"title\":\"Reversing Two-Stream Networks with Decoding Discrepancy Penalty for Robust Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3130030\",\"name\":\"M. Farrajota\"},{\"authorId\":\"143955056\",\"name\":\"J. Rodrigues\"},{\"authorId\":\"1394604631\",\"name\":\"J. M. H. du Buf\"}],\"doi\":\"10.1007/s10044-018-0727-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b999364980e4c21d9c22cc5a9f14501432999ca4\",\"title\":\"Human action recognition in videos with articulated pose information by deep networks\",\"url\":\"https://www.semanticscholar.org/paper/b999364980e4c21d9c22cc5a9f14501432999ca4\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2004.08861\",\"authors\":[{\"authorId\":\"145016614\",\"name\":\"Jie Fu\"},{\"authorId\":\"145604424\",\"name\":\"X. Geng\"},{\"authorId\":\"49909152\",\"name\":\"Zhijian Duan\"},{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"144462789\",\"name\":\"J. Lin\"},{\"authorId\":\"93572676\",\"name\":\"C. Pal\"},{\"authorId\":\"47866123\",\"name\":\"H. Dong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75af404d6e4279541aafb8d5b330c44039bd437d\",\"title\":\"Role-Wise Data Augmentation for Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/75af404d6e4279541aafb8d5b330c44039bd437d\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":6234666,\"doi\":\"10.1109/CVPR.2016.297\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":28,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"references\":[{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1503.02531\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c908739fbff75f03469d13d4a1a07de3414ee19\",\"title\":\"Distilling the Knowledge in a Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G Jiang\"},{\"authorId\":null,\"name\":\"J Liu\"},{\"authorId\":null,\"name\":\"A Roshan Zamir\"},{\"authorId\":null,\"name\":\"G Toderici\"},{\"authorId\":null,\"name\":\"I Laptev\"},{\"authorId\":null,\"name\":\"M Shah\"},{\"authorId\":null,\"name\":\"R Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"THUMOS challenge: Action recognition with a large number of classes\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2013.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2633f6a4bb683aafecd86e9484258c0767196422\",\"title\":\"Motionlets: Mid-level 3D Parts for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2633f6a4bb683aafecd86e9484258c0767196422\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390562671\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"}],\"doi\":\"10.1007/s11263-013-0636-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4cede3acfd94fccc927519e04384a8debfec705\",\"title\":\"Image Classification with the Fisher Vector: Theory and Practice\",\"url\":\"https://www.semanticscholar.org/paper/d4cede3acfd94fccc927519e04384a8debfec705\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2695601\",\"name\":\"Vadim Kantorov\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2014.332\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"482f7471c708f371cbd7658aa4a48187dc830e17\",\"title\":\"Efficient Feature Extraction, Encoding, and Classification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/482f7471c708f371cbd7658aa4a48187dc830e17\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2003.1238663\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"642e328cae81c5adb30069b680cf60ba6b475153\",\"title\":\"Video Google: a text retrieval approach to object matching in videos\",\"url\":\"https://www.semanticscholar.org/paper/642e328cae81c5adb30069b680cf60ba6b475153\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143757530\",\"name\":\"J. P\\u00e9rez\"},{\"authorId\":\"7805981\",\"name\":\"E. Meinhardt\"},{\"authorId\":\"1724244\",\"name\":\"G. Facciolo\"}],\"doi\":\"10.5201/ipol.2013.26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43009b83d691ff6cc8973e701081176b388c355f\",\"title\":\"TV-L1 Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43009b83d691ff6cc8973e701081176b388c355f\",\"venue\":\"Image Process. Line\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b42f83a720bd4156113ba5350add2df2673daf0\",\"title\":\"Action Recognition and Detection by Combining Motion and Appearance Features\",\"url\":\"https://www.semanticscholar.org/paper/2b42f83a720bd4156113ba5350add2df2673daf0\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866310\",\"name\":\"I. Kviatkovsky\"},{\"authorId\":\"1747801\",\"name\":\"E. Rivlin\"},{\"authorId\":\"1782918\",\"name\":\"I. Shimshoni\"}],\"doi\":\"10.1016/j.cviu.2014.08.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce3f3088d0c0bf236638014a299a28e492069753\",\"title\":\"Online action recognition using covariance of shape and motion\",\"url\":\"https://www.semanticscholar.org/paper/ce3f3088d0c0bf236638014a299a28e492069753\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1504.01561\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2733373.2806222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fd06a73e7970181bfd87fa4d6c340bc99373069\",\"title\":\"Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/2fd06a73e7970181bfd87fa4d6c340bc99373069\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"1502.01852\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/ICCV.2015.123\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"title\":\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Simonyan\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"age classification with the fisher vector : Theory and practice\",\"url\":\"\",\"venue\":\"IJCV\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"F. Perronnin\"},{\"authorId\":null,\"name\":\"T. Mensink\"},{\"authorId\":null,\"name\":\"J. Verbeek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"age classification with the fisher vector : Theory and practice\",\"url\":\"\",\"venue\":\"IJCV\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":null,\"name\":\"F. Perronnin\"},{\"authorId\":null,\"name\":\"T. Mensink\"},{\"authorId\":null,\"name\":\"J. Verbeek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"age classification with the fisher vector : Theory and practice\",\"url\":\"\",\"venue\":\"IJCV\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298872\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3de050d1707524512eeab99780df3cbdee09670c\",\"title\":\"DevNet: A Deep Event Network for multimedia event detection and evidence recounting\",\"url\":\"https://www.semanticscholar.org/paper/3de050d1707524512eeab99780df3cbdee09670c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"48620041\",\"name\":\"Yun Yi\"},{\"authorId\":\"38928373\",\"name\":\"J. Wu\"}],\"doi\":\"10.1145/2733373.2806310\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f60ba4ba12a1072e5c7fd67d5cc7acab9a595a2\",\"title\":\"Human Action Recognition With Trajectory Based Covariance Descriptor In Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/1f60ba4ba12a1072e5c7fd67d5cc7acab9a595a2\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"1412.0767\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd243d77076b3b8fe046bd3dc6e8a02aa9b38d62\",\"title\":\"C3D: Generic Features for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/bd243d77076b3b8fe046bd3dc6e8a02aa9b38d62\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1109/CVPR.2010.5540039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"400e09ceca374f0621335f84a4daf2049d5902be\",\"title\":\"Aggregating local descriptors into a compact image representation\",\"url\":\"https://www.semanticscholar.org/paper/400e09ceca374f0621335f84a4daf2049d5902be\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2015.7298599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90d44ce126b1ca7107f555db4d546d0e1843d075\",\"title\":\"What do 15,000 object categories tell us about classifying and localizing actions?\",\"url\":\"https://www.semanticscholar.org/paper/90d44ce126b1ca7107f555db4d546d0e1843d075\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779050\",\"name\":\"Gunnar Farneb\\u00e4ck\"}],\"doi\":\"10.1007/3-540-45103-X_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"534805683c27accb27d66d9425f759b798df380a\",\"title\":\"Two-Frame Motion Estimation Based on Polynomial Expansion\",\"url\":\"https://www.semanticscholar.org/paper/534805683c27accb27d66d9425f759b798df380a\",\"venue\":\"SCIA\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"563e821bb5ea825efb56b77484f5287f08cf3753\",\"title\":\"Convolutional networks for images, speech, and time series\",\"url\":\"https://www.semanticscholar.org/paper/563e821bb5ea825efb56b77484f5287f08cf3753\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":null,\"name\":\"Jun Wang\"},{\"authorId\":\"143698722\",\"name\":\"Jian Pu\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2647868.2654931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef2eb1050629d3ab111a7d1b01873e06087245be\",\"title\":\"Exploring Inter-feature and Inter-class Relationships with Deep Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ef2eb1050629d3ab111a7d1b01873e06087245be\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/s11263-015-0859-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16eaa26a84468b27e559215db01c53286808ec2a\",\"title\":\"MoFAP: A Multi-level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16eaa26a84468b27e559215db01c53286808ec2a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2014.220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"title\":\"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\",\"url\":\"https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/ICCV.2013.333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b11228f6ce7d681a2a065b4ba191a51456671d29\",\"title\":\"Mining Motion Atoms and Phrases for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b11228f6ce7d681a2a065b4ba191a51456671d29\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013}],\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"topics\":[{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Analysis of algorithms\",\"topicId\":\"13372\",\"url\":\"https://www.semanticscholar.org/topic/13372\"},{\"topic\":\"Video decoder\",\"topicId\":\"374986\",\"url\":\"https://www.semanticscholar.org/topic/374986\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Elegant degradation\",\"topicId\":\"5091\",\"url\":\"https://www.semanticscholar.org/topic/5091\"},{\"topic\":\"Real-time clock\",\"topicId\":\"121831\",\"url\":\"https://www.semanticscholar.org/topic/121831\"},{\"topic\":\"Real-time transcription\",\"topicId\":\"763488\",\"url\":\"https://www.semanticscholar.org/topic/763488\"}],\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"