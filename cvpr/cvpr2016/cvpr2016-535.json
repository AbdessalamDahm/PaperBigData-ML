"{\"abstract\":\"The complex compositional structure of language makes problems at the intersection of vision and language challenging. But language also provides a strong prior that can result in good superficial performance, without the underlying models truly understanding the visual content. This can hinder progress in pushing state of art in the computer vision aspects of multi-modal AI. In this paper, we address binary Visual Question Answering (VQA) on abstract scenes. We formulate this problem as visual verification of concepts inquired in the questions. Specifically, we convert the question to a tuple that concisely summarizes the visual concept to be detected in the image. If the concept can be found in the image, the answer to the question is \\\"yes\\\", and otherwise \\\"no\\\". Abstract scenes play two roles (1) They allow us to focus on the highlevel semantics of the VQA task as opposed to the low-level recognition problems, and perhaps more importantly, (2) They provide us the modality to balance the dataset such that language priors are controlled, and the role of vision is essential. In particular, we collect fine-grained pairs of scenes for every question, such that the answer to the question is \\\"yes\\\" for one scene, and \\\"no\\\" for the other for the exact same question. Indeed, language priors alone do not perform better than chance on our balanced dataset. Moreover, our proposed approach matches the performance of a state-of-the-art VQA approach on the unbalanced dataset, and outperforms it on the balanced dataset.\",\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\",\"url\":\"https://www.semanticscholar.org/author/40409467\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\",\"url\":\"https://www.semanticscholar.org/author/37226164\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\",\"url\":\"https://www.semanticscholar.org/author/1403432120\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\",\"url\":\"https://www.semanticscholar.org/author/145054147\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"}],\"citationVelocity\":49,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412806873\",\"name\":\"Mandar Bhalerao\"},{\"authorId\":\"1491238382\",\"name\":\"Shlok Gujar\"},{\"authorId\":\"144555055\",\"name\":\"A. Bhave\"},{\"authorId\":\"2702152\",\"name\":\"Anant V. Nimkar\"}],\"doi\":\"10.1109/IBSSC47189.2019.8973090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"title\":\"Visual Question Answering Using Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"venue\":\"2019 IEEE Bombay Section Signature Conference (IBSSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144128023\",\"name\":\"Youcai Zhang\"},{\"authorId\":\"47470404\",\"name\":\"Jiayan Cao\"},{\"authorId\":null,\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1109/ACCESS.2018.2881997\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"152bb56b4d7f78fefd4e20c50c5aedc48a5fc78b\",\"title\":\"Learning Cross-Modal Aligned Representation With Graph Embedding\",\"url\":\"https://www.semanticscholar.org/paper/152bb56b4d7f78fefd4e20c50c5aedc48a5fc78b\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dce6fa7a13cc94954cbc6be9a709a4ce696ead3\",\"title\":\"Vision and Language Integration: Moving beyond Objects\",\"url\":\"https://www.semanticscholar.org/paper/8dce6fa7a13cc94954cbc6be9a709a4ce696ead3\",\"venue\":\"IWCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1705.01359\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"13597291\",\"name\":\"Yauhen Klimovich\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/P17-1024\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"title\":\"FOIL it! Find One mismatch between Image and Language caption\",\"url\":\"https://www.semanticscholar.org/paper/c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1907.04380\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"48926630\",\"name\":\"Adam Poliak\"},{\"authorId\":\"1692491\",\"name\":\"S. Shieber\"},{\"authorId\":\"7536576\",\"name\":\"Benjamin Van Durme\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":\"10.18653/v1/P19-1084\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6540ee01a87c3b3435da73f4e3297489d525c151\",\"title\":\"Don't Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/6540ee01a87c3b3435da73f4e3297489d525c151\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1905.11533\",\"authors\":[{\"authorId\":\"3457252\",\"name\":\"Xiaocong Du\"},{\"authorId\":\"48459178\",\"name\":\"Z. Li\"},{\"authorId\":\"144149886\",\"name\":\"Yu Cao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"438b3860ee945fb47984ab417249f1d19a65f9c3\",\"title\":\"CGaP: Continuous Growth and Pruning for Efficient Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/438b3860ee945fb47984ab417249f1d19a65f9c3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.02923\",\"authors\":[{\"authorId\":\"1947259\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"145040726\",\"name\":\"Raffaella Bernardi\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"49af582b8e96cd69986ff21223e3fa331081d7d5\",\"title\":\"Pay Attention to Those Sets! Learning Quantification from Images\",\"url\":\"https://www.semanticscholar.org/paper/49af582b8e96cd69986ff21223e3fa331081d7d5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1908.02660\",\"authors\":[{\"authorId\":\"150180131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"145124903\",\"name\":\"J. Deng\"}],\"doi\":\"10.1109/ICCV.2019.00214\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"title\":\"SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1611.05546\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a8224266b8ab1483f6548307ab96227147f34da\",\"title\":\"Zero-Shot Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a8224266b8ab1483f6548307ab96227147f34da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1909.03683\",\"authors\":[{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/D19-1418\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ba783d92d0eaf6a7bff6ced7660150ce38016bbc\",\"title\":\"Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases\",\"url\":\"https://www.semanticscholar.org/paper/ba783d92d0eaf6a7bff6ced7660150ce38016bbc\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":\"2010.10038\",\"authors\":[{\"authorId\":\"31340289\",\"name\":\"Sameer Dharur\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"title\":\"SOrT-ing VQA Models : Contrastive Gradient Learning for Improved Consistency\",\"url\":\"https://www.semanticscholar.org/paper/997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.15015\",\"authors\":[{\"authorId\":\"65844131\",\"name\":\"Yuxian Meng\"},{\"authorId\":\"1845298604\",\"name\":\"Shuhe Wang\"},{\"authorId\":\"5439717\",\"name\":\"Qinghong Han\"},{\"authorId\":\"48304805\",\"name\":\"Xiaofei Sun\"},{\"authorId\":\"93192602\",\"name\":\"Fei Wu\"},{\"authorId\":null,\"name\":\"Rui Yan\"},{\"authorId\":\"5183779\",\"name\":\"J. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3470e15ae52baae8b8560dd59c616da9820cf43a\",\"title\":\"OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/3470e15ae52baae8b8560dd59c616da9820cf43a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1806.00857\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"31408089\",\"name\":\"Aron Szanto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a9135976912d4169a4490c641561ed0867a306c\",\"title\":\"On the Flip Side: Identifying Counterexamples in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2a9135976912d4169a4490c641561ed0867a306c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.11029\",\"authors\":[{\"authorId\":\"88739004\",\"name\":\"Noel Mizzi\"},{\"authorId\":\"35347012\",\"name\":\"Adrian Muscat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56a43d2e5005c390a7afc4136cdbaa377468379c\",\"title\":\"Optimising the Input Image to Improve Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/56a43d2e5005c390a7afc4136cdbaa377468379c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145654605\",\"name\":\"Correia Ribeiro\"},{\"authorId\":\"51281748\",\"name\":\"M. T\\u00falio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ade1cb5278876e2ee6cf4adf1adadabf8ca40ca\",\"title\":\"Model-Agnostic Explanations and Evaluation of Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ade1cb5278876e2ee6cf4adf1adadabf8ca40ca\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.05054\",\"authors\":[{\"authorId\":\"114577307\",\"name\":\"C. Alberti\"},{\"authorId\":\"50602231\",\"name\":\"Jeffrey Ling\"},{\"authorId\":\"123052390\",\"name\":\"Michael Collins\"},{\"authorId\":\"1781409\",\"name\":\"D. Reitter\"}],\"doi\":\"10.18653/v1/D19-1219\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"title\":\"Fusion of Detected Objects in Text for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1612.01175\",\"authors\":[{\"authorId\":\"8140754\",\"name\":\"Benjamin Eysenbach\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fac17d4bb7268bbf33290de2915c33e6e57647da\",\"title\":\"Who is Mistaken?\",\"url\":\"https://www.semanticscholar.org/paper/fac17d4bb7268bbf33290de2915c33e6e57647da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395925001\",\"name\":\"Bj\\u00f6rn Wahle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"title\":\"Grounding semantics in robots for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.01944\",\"authors\":[{\"authorId\":\"1417453674\",\"name\":\"Mikolaj Malki'nski\"},{\"authorId\":\"1681735\",\"name\":\"J. Ma\\u0144dziuk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d69712a9e1d13317fe8f32ad3ff19c73663b97d\",\"title\":\"Multi-Label Contrastive Learning for Abstract Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/3d69712a9e1d13317fe8f32ad3ff19c73663b97d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.11280\",\"authors\":[{\"authorId\":\"52004465\",\"name\":\"J. Abdelnour\"},{\"authorId\":\"38655449\",\"name\":\"G. Salvi\"},{\"authorId\":\"1680808\",\"name\":\"J. Rouat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b90f978dae910f0662041ca44fdad7009d2a006\",\"title\":\"From Visual to Acoustic Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b90f978dae910f0662041ca44fdad7009d2a006\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.04689\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.157\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ad2339c48ad4ffdd6100310dcbb1fb78e72fac98\",\"title\":\"Video Fill In the Blank Using LR/RL LSTMs with Spatial-Temporal Attentions\",\"url\":\"https://www.semanticscholar.org/paper/ad2339c48ad4ffdd6100310dcbb1fb78e72fac98\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32102885\",\"name\":\"Rachel Gardner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad707fc8b36a8f3daf8742cf92fcf099de434cec\",\"title\":\"A Deep Learning Approach for Identification of Confusion in Unstructured Crowdsourced Annotations\",\"url\":\"https://www.semanticscholar.org/paper/ad707fc8b36a8f3daf8742cf92fcf099de434cec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"48567083\",\"name\":\"Zheng Yu\"},{\"authorId\":\"3116943\",\"name\":\"Jiange Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190828\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"316f057e36cf432ece4ba4e2d167a84aef700aee\",\"title\":\"VC-VQA: Visual Calibration Mechanism For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/316f057e36cf432ece4ba4e2d167a84aef700aee\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.01238\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/CVPR.2018.00009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83f355634fac2b445a475ee81b8d16bf768188ec\",\"title\":\"Learning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/83f355634fac2b445a475ee81b8d16bf768188ec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.10561\",\"authors\":[{\"authorId\":\"52004465\",\"name\":\"J. Abdelnour\"},{\"authorId\":\"38655449\",\"name\":\"G. Salvi\"},{\"authorId\":\"1680808\",\"name\":\"J. Rouat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6bb8fda39f104a95332b5dbca9b1a1c071de539\",\"title\":\"CLEAR: A Dataset for Compositional Language and Elementary Acoustic Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a6bb8fda39f104a95332b5dbca9b1a1c071de539\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1902.09506\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c122fa378a774ba202d418cf71c5c356cf2f902f\",\"title\":\"GQA: a new dataset for compositional question answering over real-world images\",\"url\":\"https://www.semanticscholar.org/paper/c122fa378a774ba202d418cf71c5c356cf2f902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2003.06576\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/cvpr42600.2020.01081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc08d90005b12f66a12798fd79959a8f7f8c4885\",\"title\":\"Counterfactual Samples Synthesizing for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/dc08d90005b12f66a12798fd79959a8f7f8c4885\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39986707\",\"name\":\"C. H. Lin\"},{\"authorId\":\"2674444\",\"name\":\"Mausam\"},{\"authorId\":\"1780531\",\"name\":\"Daniel S. Weld\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baeb8344ce623f692151b8c9dc0c5d3869dd1ab4\",\"title\":\"Active Learning with Unbalanced Classes and Example-Generation Queries\",\"url\":\"https://www.semanticscholar.org/paper/baeb8344ce623f692151b8c9dc0c5d3869dd1ab4\",\"venue\":\"HCOMP\",\"year\":2018},{\"arxivId\":\"2003.13962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"title\":\"Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text\",\"url\":\"https://www.semanticscholar.org/paper/c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2363901\",\"name\":\"Rabeeh Karimi Mahabadi\"},{\"authorId\":\"144915758\",\"name\":\"James Henderson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82923dbd7eca1b22de222eb8766cb48f8d25a89e\",\"title\":\"Simple but effective techniques to reduce biases\",\"url\":\"https://www.semanticscholar.org/paper/82923dbd7eca1b22de222eb8766cb48f8d25a89e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.04293\",\"authors\":[{\"authorId\":\"32856839\",\"name\":\"T. Ates\"},{\"authorId\":\"2033380403\",\"name\":\"Muhammed Samil Atesoglu\"},{\"authorId\":\"2033381520\",\"name\":\"Cagatay Yigit\"},{\"authorId\":\"116865200\",\"name\":\"Ilker Kesen\"},{\"authorId\":\"2033382593\",\"name\":\"Mert Kobas\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"152827782\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"81703837\",\"name\":\"T. Goksun\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b2397185ef6315ce346180d505df00550d6b08d\",\"title\":\"CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions\",\"url\":\"https://www.semanticscholar.org/paper/9b2397185ef6315ce346180d505df00550d6b08d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07790\",\"authors\":[{\"authorId\":\"1637185408\",\"name\":\"Joe Stacey\"},{\"authorId\":\"3051815\",\"name\":\"Pasquale Minervini\"},{\"authorId\":\"2026652\",\"name\":\"Haim Dubossarsky\"},{\"authorId\":\"48662861\",\"name\":\"Sebastian Riedel\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1def7b029df7d37962fd684ea5ae7a7d7e99491\",\"title\":\"There is Strength in Numbers: Avoiding the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/a1def7b029df7d37962fd684ea5ae7a7d7e99491\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2001.06927\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"title\":\"SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04422\",\"authors\":[{\"authorId\":\"1802508687\",\"name\":\"Vatsal Goel\"},{\"authorId\":\"1802505447\",\"name\":\"Mohit Chandak\"},{\"authorId\":\"47583481\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"title\":\"IQ-VQA: Intelligent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.05492\",\"authors\":[{\"authorId\":\"2235894\",\"name\":\"Pramod Kaushik Mudrakarta\"},{\"authorId\":\"40511120\",\"name\":\"Ankur Taly\"},{\"authorId\":\"30740726\",\"name\":\"M. Sundararajan\"},{\"authorId\":\"1696833\",\"name\":\"K. Dhamdhere\"}],\"doi\":\"10.18653/v1/P18-1176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a9831e5fec549edee454709048a51997ef60fb7\",\"title\":\"Did the Model Understand the Question?\",\"url\":\"https://www.semanticscholar.org/paper/4a9831e5fec549edee454709048a51997ef60fb7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9330502\",\"name\":\"Navneet Sinha\"},{\"authorId\":\"1841118\",\"name\":\"Ifeoma Nwogu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20289282fedfd60d9d4a7153f460f5c8e0a502b8\",\"title\":\"Goal Driven Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/20289282fedfd60d9d4a7153f460f5c8e0a502b8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f55deed4fa5d6d806790610dad9cf7505c1adde8\",\"title\":\"Goal Driven Detection in Natural Scenes Anonymous\",\"url\":\"https://www.semanticscholar.org/paper/f55deed4fa5d6d806790610dad9cf7505c1adde8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1109/CVPR.2019.00686\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"title\":\"Explore Multi-Step Reasoning in Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2376695\",\"name\":\"A. Patil\"},{\"authorId\":\"52225414\",\"name\":\"Amrita Behera\"},{\"authorId\":\"144515161\",\"name\":\"P. Anusha\"},{\"authorId\":\"1455644032\",\"name\":\"Mitali Seth\"},{\"authorId\":\"1455386475\",\"name\":\"Prabhuling\"}],\"doi\":\"10.1109/TENCON.2019.8929263\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73156fde14fdaa27de466a8f39b92a41a4b876cc\",\"title\":\"Speech Enabled Visual Question Answering using LSTM and CNN with Real Time Image Capturing for assisting the Visually Impaired\",\"url\":\"https://www.semanticscholar.org/paper/73156fde14fdaa27de466a8f39b92a41a4b876cc\",\"venue\":\"TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)\",\"year\":2019},{\"arxivId\":\"1810.12440\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1609/aaai.v33i01.33018076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"634161e4759616dbe06f0b1465999d3df122f366\",\"title\":\"TallyQA: Answering Complex Counting Questions\",\"url\":\"https://www.semanticscholar.org/paper/634161e4759616dbe06f0b1465999d3df122f366\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2003.11844\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"145491338\",\"name\":\"S. Palacio\"},{\"authorId\":\"144553243\",\"name\":\"J. Folz\"},{\"authorId\":\"48258541\",\"name\":\"Federico Raue\"},{\"authorId\":\"120996558\",\"name\":\"J. Hees\"},{\"authorId\":\"1384499125\",\"name\":\"Andreas Dengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"title\":\"P $\\\\approx$ NP, at least in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"3055431\",\"name\":\"Marco T\\u00falio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":\"10.1109/CVPR42600.2020.01002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cea494961a45d6a0687c75248fd078999d9a43\",\"title\":\"SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/27cea494961a45d6a0687c75248fd078999d9a43\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4009206\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"33201965\",\"name\":\"Satyananda Kashyap\"},{\"authorId\":\"1410148565\",\"name\":\"Karina Kanjaria\"},{\"authorId\":\"40346984\",\"name\":\"Joy T. Wu\"},{\"authorId\":\"13403287\",\"name\":\"D. Ballah\"},{\"authorId\":\"1388126424\",\"name\":\"Adam Coy\"},{\"authorId\":\"2308391\",\"name\":\"Alexandros Karargyris\"},{\"authorId\":\"2230103\",\"name\":\"Yufan Guo\"},{\"authorId\":\"1768272818\",\"name\":\"David James Beymer\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"},{\"authorId\":\"80257800\",\"name\":\"Vandana Mukherjee\"}],\"doi\":\"10.18653/v1/2020.bionlp-1.6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"title\":\"Towards Visual Dialog for Radiology\",\"url\":\"https://www.semanticscholar.org/paper/6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"venue\":\"BioNLP\",\"year\":2020},{\"arxivId\":\"1606.06108\",\"authors\":[{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICME.2017.8019436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"121a9a160f1f2819a01edbe522024b58dbfee798\",\"title\":\"DualNet: Domain-invariant network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/121a9a160f1f2819a01edbe522024b58dbfee798\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782578\",\"name\":\"Chun-Ju Yang\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"title\":\"Visual Question Answer Diversity\",\"url\":\"https://www.semanticscholar.org/paper/91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"venue\":\"HCOMP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39986707\",\"name\":\"C. H. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ad8bd882d69e1e48b1e1b508a88eadb88efb76b\",\"title\":\"The Intelligent Management of Crowd-Powered Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/0ad8bd882d69e1e48b1e1b508a88eadb88efb76b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.03821\",\"authors\":[{\"authorId\":\"36251013\",\"name\":\"Wei Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09bb33837609afd9f90a9ba418ca3550926e8495\",\"title\":\"Knowing Where to Look? Analysis on Attention of Visual Question Answering System\",\"url\":\"https://www.semanticscholar.org/paper/09bb33837609afd9f90a9ba418ca3550926e8495\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1905.12681\",\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b434904230cd2c09f349cc69b72baa670b5d815\",\"title\":\"What Makes Training Multi-Modal Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/4b434904230cd2c09f349cc69b72baa670b5d815\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1609.05600\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.344\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7d007ba376faddf0046930ea7375ed59600cee9\",\"title\":\"Graph-Structured Representations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c7d007ba376faddf0046930ea7375ed59600cee9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48071615\",\"name\":\"Huda Alamri\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"title\":\"Audio Visual Scene-aware dialog (AVSD) Track for Natural Language Generation in DSTC7\",\"url\":\"https://www.semanticscholar.org/paper/aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317148\",\"name\":\"Z. Zhang\"},{\"authorId\":null,\"name\":\"Lizi Liao\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"145213537\",\"name\":\"X. Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7937ad963f18675d2dc802d94f672180c037fde\",\"title\":\"Color dark Taxonomy nightdress Length short Material cotton Type casual Color beige Taxonomy nightdress Length mini Material silk Type patchwork Color dark Taxonomy nightdress Length\",\"url\":\"https://www.semanticscholar.org/paper/a7937ad963f18675d2dc802d94f672180c037fde\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47111044\",\"name\":\"Mingqin Chen\"},{\"authorId\":null,\"name\":\"Yilei Wang\"},{\"authorId\":\"145675052\",\"name\":\"Shan Chen\"},{\"authorId\":\"48607932\",\"name\":\"Yingjie Wu\"}],\"doi\":\"10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"title\":\"Counting Attention Based on Classification Confidence for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"venue\":\"2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"title\":\"Mind Your Language: Learning Visually Grounded Dialog in a Multi-Agent Setting\",\"url\":\"https://www.semanticscholar.org/paper/bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.06087\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"32587693\",\"name\":\"A. Moudgil\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ead5088bc1922526be9a503dd42b15d467b962\",\"title\":\"Contrast and Classify: Alternate Training for Robust VQA\",\"url\":\"https://www.semanticscholar.org/paper/35ead5088bc1922526be9a503dd42b15d467b962\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.5244/C.31.131\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d814981606fe5954148e45c737f1debe7b5b36c4\",\"title\":\"Visual Textbook Network: Watch Carefully before Answering Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/d814981606fe5954148e45c737f1debe7b5b36c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145280977\",\"name\":\"Cheng Shi\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"24545031\",\"name\":\"Jiayin Cai\"},{\"authorId\":\"41017837\",\"name\":\"Zhuobin Zheng\"},{\"authorId\":\"16129585\",\"name\":\"Yangyang Cheng\"},{\"authorId\":\"1754924\",\"name\":\"Zhihui Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42152899eecae52cbf2f3f3459a7d4eaefda6978\",\"title\":\"Conditional Kronecker Batch Normalization for Compositional Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/42152899eecae52cbf2f3f3459a7d4eaefda6978\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1804.02088\",\"authors\":[{\"authorId\":\"145659406\",\"name\":\"Y. Shi\"},{\"authorId\":\"2426872\",\"name\":\"T. Furlanello\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":\"10.1007/978-3-030-01225-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"title\":\"Question Type Guided Attention in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1912.00578\",\"authors\":[{\"authorId\":\"50424875\",\"name\":\"Shruti Bhargava\"},{\"authorId\":\"144016260\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d1735a875eb2b3dfd0f281492c9b28b16f72bc9\",\"title\":\"Exposing and Correcting the Gender Bias in Image Captioning Datasets and Models\",\"url\":\"https://www.semanticscholar.org/paper/5d1735a875eb2b3dfd0f281492c9b28b16f72bc9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112858943\",\"name\":\"Z. Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"title\":\"Representation Learning for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"292d6cbab27ba35c825d75130311a4b27f291af2\",\"title\":\"Visual Question Answering with Annotation-Efficient Zero Shot Learning under Linguistic Domain Shift\",\"url\":\"https://www.semanticscholar.org/paper/292d6cbab27ba35c825d75130311a4b27f291af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1801.07853\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"48032659\",\"name\":\"Xiaoyi Liu\"},{\"authorId\":\"49330599\",\"name\":\"Liangjian Chen\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"},{\"authorId\":\"100575838\",\"name\":\"Xiaohui Xie\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/WACV.2018.00209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"title\":\"Structured Triplet Learning with POS-Tag Guided Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52004465\",\"name\":\"J. Abdelnour\"},{\"authorId\":\"145709285\",\"name\":\"Giampiero Salvi\"},{\"authorId\":\"1680808\",\"name\":\"J. Rouat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1df4414f38e524db344d868938fdd8ddecde23b1\",\"title\":\"L G ] 2 8 Fe b 20 19 FROM VISUAL TO ACOUSTIC QUESTION ANSWERING\",\"url\":\"https://www.semanticscholar.org/paper/1df4414f38e524db344d868938fdd8ddecde23b1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"title\":\"Removing the i\\u2019s from i.i.d : Testing generalization on hard datasets\",\"url\":\"https://www.semanticscholar.org/paper/41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.01780\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1b8ffe938f706a9416c319a34793a2389866773\",\"title\":\"Visual Question Answering as a Multi-Task Problem\",\"url\":\"https://www.semanticscholar.org/paper/b1b8ffe938f706a9416c319a34793a2389866773\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.11530\",\"authors\":[{\"authorId\":\"3457252\",\"name\":\"Xiaocong Du\"},{\"authorId\":\"48459178\",\"name\":\"Z. Li\"},{\"authorId\":\"50032226\",\"name\":\"Y. Ma\"},{\"authorId\":\"144149886\",\"name\":\"Yu Cao\"}],\"doi\":\"10.1109/JETCAS.2019.2933233\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3f2ca7b60d432fa5f44289ecae4de843ae95b9a\",\"title\":\"Efficient Network Construction Through Structural Plasticity\",\"url\":\"https://www.semanticscholar.org/paper/b3f2ca7b60d432fa5f44289ecae4de843ae95b9a\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":\"1901.00850\",\"authors\":[{\"authorId\":\"9326827\",\"name\":\"Runtao Liu\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"48442730\",\"name\":\"Y. Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00431\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9695676deace8c05d4e95274b92f20ed1e97470c\",\"title\":\"CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9695676deace8c05d4e95274b92f20ed1e97470c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1608.08974\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"title\":\"Towards Transparent AI Systems: Interpreting Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1910.11033\",\"authors\":[{\"authorId\":\"73659073\",\"name\":\"T. Hascoet\"},{\"authorId\":\"12658654\",\"name\":\"Xue-jiao Deng\"},{\"authorId\":\"46932377\",\"name\":\"K. Tai\"},{\"authorId\":\"14425978\",\"name\":\"M. Sugiyama\"},{\"authorId\":\"48715900\",\"name\":\"Y. Adachi\"},{\"authorId\":\"47046257\",\"name\":\"S. Nakamura\"},{\"authorId\":\"1678564\",\"name\":\"Y. Ariki\"},{\"authorId\":\"49604548\",\"name\":\"T. Hayashi\"},{\"authorId\":\"1388661285\",\"name\":\"Tetusya Takiguchi\"}],\"doi\":\"10.1109/ICCVW.2019.00519\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"94705d9bc8580c3d0c64000689c3389dae6e2755\",\"title\":\"Assisting human experts in the interpretation of their visual process: A case study on assessing copper surface adhesive potency\",\"url\":\"https://www.semanticscholar.org/paper/94705d9bc8580c3d0c64000689c3389dae6e2755\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1806.08409\",\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICASSP.2019.8682583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"title\":\"End-to-end Audio Visual Scene-aware Dialog Using Multimodal Attention-based Video Features\",\"url\":\"https://www.semanticscholar.org/paper/85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"title\":\"Research Statement Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947259\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1017/S1351324918000128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e7533da3833a1e89c14f6c7d948c44331d9f815\",\"title\":\"Learning quantification from images: A structured neural architecture\",\"url\":\"https://www.semanticscholar.org/paper/4e7533da3833a1e89c14f6c7d948c44331d9f815\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1709.07992\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"title\":\"Visual Reference Resolution using Attention Memory for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2012.01634\",\"authors\":[{\"authorId\":\"47989608\",\"name\":\"Ankit Goyal\"},{\"authorId\":\"150180131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"150084688\",\"name\":\"Dawei Yang\"},{\"authorId\":\"2026954992\",\"name\":\"Jia Deng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4d3f7ee5ccfefe8e132d5f394a683034b2eeec7\",\"title\":\"Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations in 3D\",\"url\":\"https://www.semanticscholar.org/paper/c4d3f7ee5ccfefe8e132d5f394a683034b2eeec7\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2006.09437\",\"authors\":[{\"authorId\":\"2652016\",\"name\":\"Tim Klinger\"},{\"authorId\":\"21493167\",\"name\":\"D. Adjodah\"},{\"authorId\":\"79805467\",\"name\":\"Vincent Marois\"},{\"authorId\":\"47263059\",\"name\":\"J. Joseph\"},{\"authorId\":\"40497459\",\"name\":\"M. Riemer\"},{\"authorId\":\"144994681\",\"name\":\"Alex 'Sandy' Pentland\"},{\"authorId\":\"143903370\",\"name\":\"Murray Campbell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c103f1903e6cb9904729e65fb167a18dbfe3b129\",\"title\":\"A Study of Compositional Generalization in Neural Models\",\"url\":\"https://www.semanticscholar.org/paper/c103f1903e6cb9904729e65fb167a18dbfe3b129\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08325\",\"authors\":[{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1007/978-3-030-58589-1_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558984f821c4b9fb9aacf7441cf9ca6d303be836\",\"title\":\"VQA-LOL: Visual Question Answering under the Lens of Logic\",\"url\":\"https://www.semanticscholar.org/paper/558984f821c4b9fb9aacf7441cf9ca6d303be836\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.04289\",\"authors\":[{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2019.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"title\":\"Multi-Modality Latent Interaction Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1809.01816\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01267-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"782bc02684de81f98c92475957501801bf91e023\",\"title\":\"Visual Coreference Resolution in Visual Dialog using Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/782bc02684de81f98c92475957501801bf91e023\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2010.16010\",\"authors\":[{\"authorId\":\"1390575046\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"title\":\"Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View\",\"url\":\"https://www.semanticscholar.org/paper/9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1711.11543\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPRW.2018.00279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.03127\",\"authors\":[{\"authorId\":\"40116153\",\"name\":\"Gabriel Schwartz\"},{\"authorId\":\"153162213\",\"name\":\"Ko Nishino\"}],\"doi\":\"10.1109/TPAMI.2019.2907850\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"729a9d35bc291cc7117b924219bef89a864ce62c\",\"title\":\"Recognizing Material Properties from Images\",\"url\":\"https://www.semanticscholar.org/paper/729a9d35bc291cc7117b924219bef89a864ce62c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39214752\",\"name\":\"Z. Zhang\"},{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"145213540\",\"name\":\"Xiaoyan Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3308558.3313598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"title\":\"Neural Multimodal Belief Tracker with Adaptive Attention for Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"49761595\",\"name\":\"A. Kalra\"},{\"authorId\":\"3374607\",\"name\":\"Vaibhav\"},{\"authorId\":\"1764061\",\"name\":\"Sumedha Chaudhary\"},{\"authorId\":\"22267101\",\"name\":\"L. Patel\"},{\"authorId\":\"69948163\",\"name\":\"Louis-Phillippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e975bbb6cbd8216cfb920e0a1861079d0ac3535c\",\"title\":\"Attend and Attack : Attention Guided Adversarial Attacks on Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/e975bbb6cbd8216cfb920e0a1861079d0ac3535c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1803.07616\",\"authors\":[{\"authorId\":\"40895941\",\"name\":\"Ronan Riochet\"},{\"authorId\":\"40901792\",\"name\":\"Mario Ynocente Castro\"},{\"authorId\":\"37831451\",\"name\":\"M. Bernard\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"3158706\",\"name\":\"V\\u00e9ronique Izard\"},{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"705ab4cd13ea26247fd537150708ee352e06b863\",\"title\":\"IntPhys: A Framework and Benchmark for Visual Intuitive Physics Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/705ab4cd13ea26247fd537150708ee352e06b863\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"51487414\",\"name\":\"Yunshan Ma\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8384387a3739280b15d38f39429aadb7c9bd620f\",\"title\":\"Knowledge-aware Multimodal Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/8384387a3739280b15d38f39429aadb7c9bd620f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1708.08874\",\"authors\":[{\"authorId\":\"3393384\",\"name\":\"Jong-Chyi Su\"},{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2017.53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"title\":\"Reasoning About Fine-Grained Attribute Phrases Using Reference Games\",\"url\":\"https://www.semanticscholar.org/paper/956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.11587\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"title\":\"Object-Centric Diagnosis of Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/978-981-15-5788-0_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"title\":\"Optimal Image Feature Ranking and Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"venue\":\"FICTA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fa9c5af78b3ca04476f4ee6910684dc19008f5e\",\"title\":\"Supplementary Material : Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1fa9c5af78b3ca04476f4ee6910684dc19008f5e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a212be7ec1ff75ecfee52c7c49c73d7244a87eb7\",\"title\":\"Video Scene-Aware Dialog Track in DSTC 7\",\"url\":\"https://www.semanticscholar.org/paper/a212be7ec1ff75ecfee52c7c49c73d7244a87eb7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447789\",\"name\":\"Jens Nevens\"},{\"authorId\":\"150266649\",\"name\":\"Paul Van Eecke\"},{\"authorId\":\"2972424\",\"name\":\"Katrien Beuls\"}],\"doi\":\"10.1515/lingvan-2018-0070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f388721a2b76e18f5515e599509d4504729f847e\",\"title\":\"Computational construction grammar for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/f388721a2b76e18f5515e599509d4504729f847e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.14602\",\"authors\":[{\"authorId\":\"22670284\",\"name\":\"Miyoung Ko\"},{\"authorId\":\"65798870\",\"name\":\"Jinhyuk Lee\"},{\"authorId\":\"153761147\",\"name\":\"Hyunjae Kim\"},{\"authorId\":\"1390543205\",\"name\":\"Gangwoo Kim\"},{\"authorId\":\"144323862\",\"name\":\"Jaewoo Kang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.84\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e14aad3423e454254c4d90c5de0ad7d965f328ee\",\"title\":\"Look at the First Sentence: Position Bias in Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e14aad3423e454254c4d90c5de0ad7d965f328ee\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.279\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150112916\",\"name\":\"Gabino Luis\"},{\"authorId\":\"47756806\",\"name\":\"D. Suarez\"},{\"authorId\":\"145940020\",\"name\":\"A. Mateos\"}],\"doi\":\"10.14201/ADCAIJ2018741726\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0dcf93dde3488d42e244999f6be62a1bb9732521\",\"title\":\"Multi-Agent Word Guessing Game\",\"url\":\"https://www.semanticscholar.org/paper/0dcf93dde3488d42e244999f6be62a1bb9732521\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1603.07396\",\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"153778850\",\"name\":\"M. Salvato\"},{\"authorId\":\"3386570\",\"name\":\"Eric Kolve\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1007/978-3-319-46493-0_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"title\":\"A Diagram is Worth a Dozen Images\",\"url\":\"https://www.semanticscholar.org/paper/e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Elizabeth Coppock\"},{\"authorId\":null,\"name\":\"Danielle Dionne\"},{\"authorId\":\"1994754478\",\"name\":\"Nathanial Graham\"},{\"authorId\":\"1994755542\",\"name\":\"Elias Ganem\"},{\"authorId\":\"1957250044\",\"name\":\"Shijie Zhao\"},{\"authorId\":\"35025843\",\"name\":\"S. Lin\"},{\"authorId\":\"49663231\",\"name\":\"Wenxing Liu\"},{\"authorId\":null,\"name\":\"Derry Wijaya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4769896d37963f4609c394736184e92b6d82fcb\",\"title\":\"Informativity in Image Captions vs. Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/d4769896d37963f4609c394736184e92b6d82fcb\",\"venue\":\"PAM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1801.01967\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-01261-8_10\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"title\":\"Visual Text Correction\",\"url\":\"https://www.semanticscholar.org/paper/ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"2004.09034\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-58607-2_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29121a31e4d684839cfd0bb358f33ea1266cece5\",\"title\":\"Learning What Makes a Difference from Counterfactual Examples and Gradient Supervision\",\"url\":\"https://www.semanticscholar.org/paper/29121a31e4d684839cfd0bb358f33ea1266cece5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8536519\",\"name\":\"Eunsol Kim\"},{\"authorId\":\"21152168\",\"name\":\"Woo Young Kang\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01459\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1888f86aa78a2a538ad68a8bba1dd6b01492c77\",\"title\":\"Hypergraph Attention Networks for Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/d1888f86aa78a2a538ad68a8bba1dd6b01492c77\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.08105\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-01267-0_14\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"a742c64f14b145b9e653ef30819520c5ce5e0123\",\"title\":\"Visual Question Answering as a Meta Learning Task\",\"url\":\"https://www.semanticscholar.org/paper/a742c64f14b145b9e653ef30819520c5ce5e0123\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1902.05660\",\"authors\":[{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2019.00681\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"title\":\"Cycle-Consistency for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"}],\"doi\":\"10.18653/v1/P19-1621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2723f54b4f5ed2d3f3a47c1b6749bbf5d8c660fd\",\"title\":\"Are Red Roses Red? Evaluating Consistency of Question-Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/2723f54b4f5ed2d3f3a47c1b6749bbf5d8c660fd\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669004\",\"name\":\"P. Hawkins\"},{\"authorId\":\"1737645\",\"name\":\"F. Maire\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"3019028\",\"name\":\"M. Baktash\"}],\"doi\":\"10.1109/DICTA47822.2019.8946101\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b842f2d3979662ef236cbf4e5c46b707ed7052c4\",\"title\":\"Object Graph Networks for Spatial Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b842f2d3979662ef236cbf4e5c46b707ed7052c4\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"title\":\"Story Understanding through Semantic Analysis and Automatic Alignment of Text and Video\",\"url\":\"https://www.semanticscholar.org/paper/39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1906.09635\",\"authors\":[{\"authorId\":\"145511547\",\"name\":\"Shawn Tan\"},{\"authorId\":\"2305979\",\"name\":\"Yikang Shen\"},{\"authorId\":\"48908331\",\"name\":\"C. Huang\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a7a21d9359a4e1e4e9ce6063f6110c00593bcad3\",\"title\":\"Investigating Biases in Textual Entailment Datasets\",\"url\":\"https://www.semanticscholar.org/paper/a7a21d9359a4e1e4e9ce6063f6110c00593bcad3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.04359\",\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"title\":\"Community Regularization of Visually-Grounded Dialog\",\"url\":\"https://www.semanticscholar.org/paper/79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"1906.08430\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"}],\"doi\":\"10.18653/v1/W19-1801\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"title\":\"Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects\",\"url\":\"https://www.semanticscholar.org/paper/a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"1716207091\",\"name\":\"Xuefeng Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3801644100f6f7e521b3f28c2785a2d151988f4\",\"title\":\"Joint Learning of Scene Graph Generation and Reasoning for Visual Question Answering Project Survey\",\"url\":\"https://www.semanticscholar.org/paper/c3801644100f6f7e521b3f28c2785a2d151988f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.07538\",\"authors\":[{\"authorId\":\"48189355\",\"name\":\"V. Agarwal\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/cvpr42600.2020.00971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"title\":\"Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing\",\"url\":\"https://www.semanticscholar.org/paper/d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.00403\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"97992296\",\"name\":\"P. Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"title\":\"Cops-Ref: A New Dataset and Task on Compositional Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1712.05558\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b68773df340498768e88487abe8f7fbac5fcb52d\",\"title\":\"CoDraw: Visual Dialog for Collaborative Drawing\",\"url\":\"https://www.semanticscholar.org/paper/b68773df340498768e88487abe8f7fbac5fcb52d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068677\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2b745ccfc7403dfed60380d3cd8bece9c99de11\",\"title\":\"Incorporating visual information into neural machine translation\",\"url\":\"https://www.semanticscholar.org/paper/d2b745ccfc7403dfed60380d3cd8bece9c99de11\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2011.03856\",\"authors\":[{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.272\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55188532ea9ea4d4a4872ebe79fc3add14cd34dd\",\"title\":\"Learning to Model and Ignore Dataset Bias with Mixed Capacity Ensembles\",\"url\":\"https://www.semanticscholar.org/paper/55188532ea9ea4d4a4872ebe79fc3add14cd34dd\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150272855\",\"name\":\"Rishi Bommasani\"},{\"authorId\":\"1748501\",\"name\":\"Claire Cardie\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc8b5dc80c45855c594f3f2b7906a9d2f52bc50f\",\"title\":\"Intrinsic Evaluation of Summarization Datasets\",\"url\":\"https://www.semanticscholar.org/paper/fc8b5dc80c45855c594f3f2b7906a9d2f52bc50f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2739186\",\"name\":\"Michael Maynord\"},{\"authorId\":\"1969847\",\"name\":\"D. Aha\"},{\"authorId\":\"49530191\",\"name\":\"S. Bhattacharya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f33a5fcc5db4625c66972f0e6f06540b64d4f1e\",\"title\":\"Image Surveillance Assistant Architecture : Status and Planned Extensions\",\"url\":\"https://www.semanticscholar.org/paper/7f33a5fcc5db4625c66972f0e6f06540b64d4f1e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068677\",\"name\":\"Iacer Calixto\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"}],\"doi\":\"10.26615/978-954-452-049-6_020\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c61b11b3949ccfe9b7d5fcbb5fcf072226d29314\",\"title\":\"Sentence-Level Multilingual Multi-modal Embedding for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/c61b11b3949ccfe9b7d5fcbb5fcf072226d29314\",\"venue\":\"RANLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2006.04315\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"112957699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"title\":\"Counterfactual VQA: A Cause-Effect Look at Language Bias\",\"url\":\"https://www.semanticscholar.org/paper/3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2006.02174\",\"authors\":[{\"authorId\":\"3444866\",\"name\":\"Alessandro Suglia\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"34742006\",\"name\":\"Andrea Vanzo\"},{\"authorId\":\"2972920\",\"name\":\"E. Bastianelli\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143873430\",\"name\":\"S. Frank\"},{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"}],\"doi\":\"10.18653/V1/2020.ACL-MAIN.682\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"title\":\"CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.02865\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00204\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51932dc1148566040fdb0df6ed66d8d2a0712933\",\"title\":\"Actively Seeking and Learning From Live Data\",\"url\":\"https://www.semanticscholar.org/paper/51932dc1148566040fdb0df6ed66d8d2a0712933\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1109/ICCV.2019.00757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2011.13160\",\"authors\":[{\"authorId\":\"145251354\",\"name\":\"Xin Hong\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"48537499\",\"name\":\"Liang Pang\"},{\"authorId\":\"70414094\",\"name\":\"J. Guo\"},{\"authorId\":\"30857876\",\"name\":\"Xueqi Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"825363a518902f3e44d61bd9a10262d0e527be60\",\"title\":\"Transformation Driven Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/825363a518902f3e44d61bd9a10262d0e527be60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1704.04517\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02218fcd3aece5a7bd19255d74b12f63dfa5c1a7\",\"title\":\"ShapeWorld - A new test methodology for multimodal language understanding\",\"url\":\"https://www.semanticscholar.org/paper/02218fcd3aece5a7bd19255d74b12f63dfa5c1a7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1908.01931\",\"authors\":[{\"authorId\":\"50770333\",\"name\":\"Qian Guo\"},{\"authorId\":\"1771193\",\"name\":\"Yuhua Qian\"},{\"authorId\":\"9540574\",\"name\":\"Xinyan Liang\"},{\"authorId\":\"11518256\",\"name\":\"Yanhong She\"},{\"authorId\":\"93209814\",\"name\":\"Deyu Li\"},{\"authorId\":\"3155883\",\"name\":\"Ji-Ye Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fa10a9f900c78c52e7e614e6af72ee981092400\",\"title\":\"Logic could be learned from images\",\"url\":\"https://www.semanticscholar.org/paper/6fa10a9f900c78c52e7e614e6af72ee981092400\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2018.00008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.01300\",\"authors\":[{\"authorId\":\"51918868\",\"name\":\"Victor Sanh\"},{\"authorId\":\"1407538116\",\"name\":\"Thomas Wolf\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"734f85727161f27bc7b295f0140a905363202d3f\",\"title\":\"Learning from others' mistakes: Avoiding dataset biases without modeling them\",\"url\":\"https://www.semanticscholar.org/paper/734f85727161f27bc7b295f0140a905363202d3f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"2002.11894\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"title\":\"Unshuffling Data for Improved Generalization\",\"url\":\"https://www.semanticscholar.org/paper/fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":6733279,\"doi\":\"10.1109/CVPR.2016.542\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":22,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"references\":[{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422314\",\"name\":\"M. Richardson\"},{\"authorId\":\"2676309\",\"name\":\"C. Burges\"},{\"authorId\":\"1859813\",\"name\":\"Erin Renshaw\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"564257469fa44cdb57e4272f85253efb9acfd69d\",\"title\":\"MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text\",\"url\":\"https://www.semanticscholar.org/paper/564257469fa44cdb57e4272f85253efb9acfd69d\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3253737\",\"name\":\"F. Sadeghi\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2015.7298752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"495015d21c26eac9a6bd64c836ee3370283641ec\",\"title\":\"VisKE: Visual knowledge extraction and question answering by visual verification of relation phrases\",\"url\":\"https://www.semanticscholar.org/paper/495015d21c26eac9a6bd64c836ee3370283641ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46371164\",\"name\":\"L. Ortiz\"},{\"authorId\":\"23472148\",\"name\":\"C. Wolff\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.3115/v1/N15-1174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c34e7af8283a94655e85cfde4d55dc52239e33d\",\"title\":\"Learning to Interpret and Describe Abstract Scenes\",\"url\":\"https://www.semanticscholar.org/paper/4c34e7af8283a94655e85cfde4d55dc52239e33d\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2622985\",\"name\":\"P\\u00e9ter Hal\\u00e1csy\"},{\"authorId\":\"2979211\",\"name\":\"Andr\\u00e1s Kornai\"},{\"authorId\":\"3211404\",\"name\":\"Csaba Oravecz\"}],\"doi\":\"10.3115/1557769.1557830\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd3f73da1d3c1d007c8e4c7ff1a711653e068d6e\",\"title\":\"HunPos: an open source trigram tagger\",\"url\":\"https://www.semanticscholar.org/paper/fd3f73da1d3c1d007c8e4c7ff1a711653e068d6e\",\"venue\":\"ACL 2007\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"},{\"authorId\":\"145606490\",\"name\":\"E. Klein\"},{\"authorId\":\"3213150\",\"name\":\"E. Loper\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a65f23d990231d461418067c808b09d84c19b2c\",\"title\":\"Natural Language Processing with Python\",\"url\":\"https://www.semanticscholar.org/paper/7a65f23d990231d461418067c808b09d84c19b2c\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Bird\"},{\"authorId\":null,\"name\":\"E Klein\"},{\"authorId\":null,\"name\":\"E Loper\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Natural Language Processing with Python. O'Reilly Media\",\"url\":\"\",\"venue\":\"Natural Language Processing with Python. O'Reilly Media\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"97711484\",\"name\":\"Xiao Lin\"},{\"authorId\":\"32519394\",\"name\":\"Tanmay Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.292\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b888196dda951287dddb60bd44798aab16d6fca\",\"title\":\"Learning Common Sense through Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/0b888196dda951287dddb60bd44798aab16d6fca\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"153472666\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1805986.1806020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0c668d1da866617ccfeee910d13eb14fa340bea\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/e0c668d1da866617ccfeee910d13eb14fa340bea\",\"venue\":\"W4A\",\"year\":2010},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38087946\",\"name\":\"Anthony Fader\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"1741101\",\"name\":\"Oren Etzioni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0be2ac2f45681f1852fc1d298af5dceb85834f4\",\"title\":\"Paraphrase-Driven Learning for Open Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c0be2ac2f45681f1852fc1d298af5dceb85834f4\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.05698\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"title\":\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\"url\":\"https://www.semanticscholar.org/paper/abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/978-3-319-10593-2_27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3ab56d83a616dba391a3373037aceb662bcda9d\",\"title\":\"Zero-Shot Learning via Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/d3ab56d83a616dba391a3373037aceb662bcda9d\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1308.6628\",\"authors\":[{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"143764552\",\"name\":\"M. Meng\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"2194804\",\"name\":\"T. E. Choe\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/MMUL.2014.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2935d8071583e46c5a895730c65d2bd213757c07\",\"title\":\"Joint Video and Text Parsing for Understanding Events and Answering Queries\",\"url\":\"https://www.semanticscholar.org/paper/2935d8071583e46c5a895730c65d2bd213757c07\",\"venue\":\"IEEE MultiMedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1936277\",\"name\":\"Omar Zaidan\"},{\"authorId\":\"145043214\",\"name\":\"Jason Eisner\"},{\"authorId\":\"1718753\",\"name\":\"C. Piatko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"99fe982dce046869f60e4552c7f91c3627304780\",\"title\":\"Using \\\"Annotator Rationales\\\" to Improve Machine Learning for Text Categorization\",\"url\":\"https://www.semanticscholar.org/paper/99fe982dce046869f60e4552c7f91c3627304780\",\"venue\":\"HLT-NAACL\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.1109/ICCV.2013.211\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"title\":\"Learning the Visual Interpretation of Sentences\",\"url\":\"https://www.semanticscholar.org/paper/6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2011.6126394\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2b779ad15c6f73011673105dcaf02d243c6d2ae\",\"title\":\"Annotator rationales for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2b779ad15c6f73011673105dcaf02d243c6d2ae\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Keras: Theano-based deep learning library\",\"url\":\"\",\"venue\":\"Keras: Theano-based deep learning library\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Common Objects in Context\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38087946\",\"name\":\"Anthony Fader\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"1741101\",\"name\":\"Oren Etzioni\"}],\"doi\":\"10.1145/2623330.2623677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f86ec155cce6259e5230aaad3b762343757feb1d\",\"title\":\"Open question answering over curated and extracted knowledge bases\",\"url\":\"https://www.semanticscholar.org/paper/f86ec155cce6259e5230aaad3b762343757feb1d\",\"venue\":\"KDD\",\"year\":2014},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2076800\",\"name\":\"Amar Parkash\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/978-3-642-33712-3_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6750185e26df5085570d23c1ab92c63e9ebb63bc\",\"title\":\"Attributes for Classifier Feedback\",\"url\":\"https://www.semanticscholar.org/paper/6750185e26df5085570d23c1ab92c63e9ebb63bc\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1502.06108\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7298917\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"title\":\"Don't just listen, use your imagination: Leveraging visual common sense for non-visual tasks\",\"url\":\"https://www.semanticscholar.org/paper/e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812486\",\"name\":\"P. Simard\"},{\"authorId\":\"38767254\",\"name\":\"David Steinkraus\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"}],\"doi\":\"10.1109/ICDAR.2003.1227801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5562a56da3a96dae82add7de705e2bd841eb00fc\",\"title\":\"Best practices for convolutional neural networks applied to visual document analysis\",\"url\":\"https://www.semanticscholar.org/paper/5562a56da3a96dae82add7de705e2bd841eb00fc\",\"venue\":\"Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Lin\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Don\\u2019t just listen\",\"url\":\"\",\"venue\":\"use your imagination: Leveraging visual common sense for non-visual tasks. In CVPR\",\"year\":2015},{\"arxivId\":\"1312.5402\",\"authors\":[{\"authorId\":\"144727050\",\"name\":\"A. Howard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d67175d17c450ab0ac9c256103828f9e9a0acb85\",\"title\":\"Some Improvements on Deep Convolutional Neural Network Based Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/d67175d17c450ab0ac9c256103828f9e9a0acb85\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"144360239\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"2925245\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1866029.1866080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"venue\":\"UIST '10\",\"year\":2010},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Torralba\"},{\"authorId\":null,\"name\":\"A. Efros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unbiased look at the bias\",\"url\":\"\",\"venue\":\"CVPR,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38087946\",\"name\":\"Anthony Fader\"},{\"authorId\":\"144295318\",\"name\":\"S. Soderland\"},{\"authorId\":\"1741101\",\"name\":\"Oren Etzioni\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b651d6a904f69f8fa1dcad4ebe972296af3a9a\",\"title\":\"Identifying Relations for Open Information Extraction\",\"url\":\"https://www.semanticscholar.org/paper/d4b651d6a904f69f8fa1dcad4ebe972296af3a9a\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2014.260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c99798fce885b41ab1de66bbacf04b7de7274f85\",\"title\":\"Predicting Object Dynamics in Scenes\",\"url\":\"https://www.semanticscholar.org/paper/c99798fce885b41ab1de66bbacf04b7de7274f85\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2013.387\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"051830b0ea58d1568f19ec3297e301d9789c9a76\",\"title\":\"Bringing Semantics into Focus Using Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/051830b0ea58d1568f19ec3297e301d9789c9a76\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/TPAMI.2014.2366143\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"title\":\"Adopting Abstract Images for Semantic Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47606073\",\"name\":\"A. Biswas\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2013.89\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01e12be4097fa8c94cabeef0ad61498c8e7762f2\",\"title\":\"Simultaneous Active Learning of Classifiers &amp; Attributes via Relative Feedback\",\"url\":\"https://www.semanticscholar.org/paper/01e12be4097fa8c94cabeef0ad61498c8e7762f2\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Weston\"},{\"authorId\":null,\"name\":\"A Bordes\"},{\"authorId\":null,\"name\":\"S Chopra\"},{\"authorId\":null,\"name\":\"T Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Towards aicomplete question answering: A set of prerequisite toy tasks. CoRR, abs/1502\",\"url\":\"\",\"venue\":\"Towards aicomplete question answering: A set of prerequisite toy tasks. CoRR, abs/1502\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2748591\",\"name\":\"Martin Sundermeyer\"},{\"authorId\":\"144490010\",\"name\":\"R. Schl\\u00fcter\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9a1b3850dfd837793743565a8af95973d395a4e\",\"title\":\"LSTM Neural Networks for Language Modeling\",\"url\":\"https://www.semanticscholar.org/paper/f9a1b3850dfd837793743565a8af95973d395a4e\",\"venue\":\"INTERSPEECH\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50536468\",\"name\":\"Danqi Chen\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a14045a751f5d8ed387c8630a86a3a2861b90643\",\"title\":\"A Fast and Accurate Dependency Parser using Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a14045a751f5d8ed387c8630a86a3a2861b90643\",\"venue\":\"EMNLP\",\"year\":2014}],\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"topics\":[{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"YANG\",\"topicId\":\"811002\",\"url\":\"https://www.semanticscholar.org/topic/811002\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"The Superficial\",\"topicId\":\"708686\",\"url\":\"https://www.semanticscholar.org/topic/708686\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Unbalanced circuit\",\"topicId\":\"4990362\",\"url\":\"https://www.semanticscholar.org/topic/4990362\"}],\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"