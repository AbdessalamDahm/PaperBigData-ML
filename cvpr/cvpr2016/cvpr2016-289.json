"{\"abstract\":\"Actionness was introduced to quantify the likelihood of containing a generic action instance at a specific location. Accurate and efficient estimation of actionness is important in video analysis and may benefit other relevant tasks such as action recognition and action detection. This paper presents a new deep architecture for actionness estimation, called hybrid fully convolutional network (HFCN), which is composed of appearance FCN (A-FCN) and motion FCN (M-FCN). These two FCNs leverage the strong capacity of deep models to estimate actionness maps from the perspectives of static appearance and dynamic motion, respectively. In addition, the fully convolutional nature of H-FCN allows it to efficiently process videos with arbitrary sizes. Experiments are conducted on the challenging datasets of Stanford40, UCF Sports, and JHMDB to verify the effectiveness of H-FCN on actionness estimation, which demonstrate that our method achieves superior performance to previous ones. Moreover, we apply the estimated actionness maps on action proposal generation and action detection. Our actionness maps advance the current state-of-the-art performance of these tasks substantially.\",\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\",\"url\":\"https://www.semanticscholar.org/author/33345248\"},{\"authorId\":null,\"name\":\"Yu Qiao\",\"url\":null},{\"authorId\":\"50295995\",\"name\":\"X. Tang\",\"url\":\"https://www.semanticscholar.org/author/50295995\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\",\"url\":\"https://www.semanticscholar.org/author/1681236\"}],\"citationVelocity\":13,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/ICIP.2017.8296639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d933b789e4822b4d77976936ca6c82026b7e280c\",\"title\":\"Search video action proposal with recurrent and static YOLO\",\"url\":\"https://www.semanticscholar.org/paper/d933b789e4822b4d77976936ca6c82026b7e280c\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1708.00042\",\"authors\":[{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.95\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae6fc9fa6dba7a20567671b9f1b0815b343bc152\",\"title\":\"Spatio-Temporal Action Detection with Cascade Proposal and Location Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/ae6fc9fa6dba7a20567671b9f1b0815b343bc152\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22197107\",\"name\":\"Huidi Fang\"},{\"authorId\":\"35099667\",\"name\":\"C. Cui\"},{\"authorId\":\"5586734\",\"name\":\"X. Deng\"},{\"authorId\":\"3082612\",\"name\":\"Xiushan Nie\"},{\"authorId\":\"1783889\",\"name\":\"M. Jian\"},{\"authorId\":\"102446355\",\"name\":\"Y. Yin\"}],\"doi\":\"10.1007/978-3-319-73603-7_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b574086f86de5e50f7b81f2e77610417894e9bd7\",\"title\":\"Image Aesthetic Distribution Prediction with Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/b574086f86de5e50f7b81f2e77610417894e9bd7\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":\"1703.10664\",\"authors\":[{\"authorId\":\"151185786\",\"name\":\"R. Hou\"},{\"authorId\":\"145430739\",\"name\":\"C. Chen\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065f55d40d473b63becccc890fe8a57c2f840548\",\"title\":\"Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065f55d40d473b63becccc890fe8a57c2f840548\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1905.11575\",\"authors\":[{\"authorId\":\"144045444\",\"name\":\"R. Su\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"6578587\",\"name\":\"L. Zhou\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1109/CVPR.2019.01229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3d445c883a396501acf3b5f2cd7680b2b953903\",\"title\":\"Improving Action Localization by Progressive Cross-Stream Cooperation\",\"url\":\"https://www.semanticscholar.org/paper/c3d445c883a396501acf3b5f2cd7680b2b953903\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9102201\",\"name\":\"Yaxiang Fan\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"},{\"authorId\":\"144334479\",\"name\":\"Gongjian Wen\"},{\"authorId\":\"3437649\",\"name\":\"Shaohua Qiu\"}],\"doi\":\"10.1016/j.neucom.2017.02.082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fe7239546e34ede6579fad5d7f36317c850fefd\",\"title\":\"A deep neural network for real-time detection of falling humans in naturally occurring scenes\",\"url\":\"https://www.semanticscholar.org/paper/9fe7239546e34ede6579fad5d7f36317c850fefd\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16278524\",\"name\":\"J. Jin\"},{\"authorId\":\"2620809\",\"name\":\"Z. Liu\"},{\"authorId\":\"1697202\",\"name\":\"C. Chen\"}],\"doi\":\"10.1007/s11432-017-9421-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"942fd0b406fe1d24b50d745cd31fd31220c78f0c\",\"title\":\"Discriminative graph regularized broad learning system for image recognition\",\"url\":\"https://www.semanticscholar.org/paper/942fd0b406fe1d24b50d745cd31fd31220c78f0c\",\"venue\":\"Science China Information Sciences\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35099667\",\"name\":\"C. Cui\"},{\"authorId\":\"145246510\",\"name\":\"H. Liu\"},{\"authorId\":\"144889776\",\"name\":\"Tao Lian\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"145081305\",\"name\":\"L. Zhu\"},{\"authorId\":\"102446355\",\"name\":\"Y. Yin\"}],\"doi\":\"10.1109/TMM.2018.2875357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91ea403dc58819b1f010bf0eadb7c7c5cf4da9e8\",\"title\":\"Distribution-Oriented Aesthetics Assessment With Semantic-Aware Hybrid Network\",\"url\":\"https://www.semanticscholar.org/paper/91ea403dc58819b1f010bf0eadb7c7c5cf4da9e8\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.04608\",\"authors\":[{\"authorId\":\"1527103472\",\"name\":\"Yixuan Li\"},{\"authorId\":\"50218816\",\"name\":\"Zixu Wang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58517-4_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6e3034cd8855616533d091dc1d70e969c20a42b\",\"title\":\"Actions as Moving Points\",\"url\":\"https://www.semanticscholar.org/paper/e6e3034cd8855616533d091dc1d70e969c20a42b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35723063\",\"name\":\"Md. Jamil-Ur Rahman\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CRV50864.2020.00035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"title\":\"Single-Stage End-to-End Temporal Activity Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"venue\":\"2020 17th Conference on Computer and Robot Vision (CRV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9385562\",\"name\":\"Minwen Zhang\"},{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"48934185\",\"name\":\"Q. Li\"},{\"authorId\":\"48169955\",\"name\":\"L. Wang\"},{\"authorId\":\"49050577\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11042-017-5116-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"954ce390c9e762b2c34b0c6cc8d8829bc6932d4c\",\"title\":\"Action detection based on tracklets with the two-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/954ce390c9e762b2c34b0c6cc8d8829bc6932d4c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7527803\",\"name\":\"Guangyu Nie\"},{\"authorId\":\"8280187\",\"name\":\"Yinan Guo\"},{\"authorId\":\"49420505\",\"name\":\"Y. Liu\"},{\"authorId\":\"1692621\",\"name\":\"Yongtian Wang\"}],\"doi\":\"10.1007/978-981-10-7389-2_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cf2ba0bf334dce9fea7f47aec079628a44f01c8\",\"title\":\"Real-Time Salient Object Detection Based on Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3cf2ba0bf334dce9fea7f47aec079628a44f01c8\",\"venue\":\"IGTA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09926ed62511c340f4540b5bc53cf2480e8063f8\",\"title\":\"Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/09926ed62511c340f4540b5bc53cf2480e8063f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"35223779\",\"name\":\"Daniel Sawyer\"},{\"authorId\":\"1801614\",\"name\":\"Michal Balazia\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d891ebddb3f378774255cfb91aa06f45d211fca7\",\"title\":\"An Examination of Proposal-based Approaches to Fine-grained Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d891ebddb3f378774255cfb91aa06f45d211fca7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1609.00153\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2666739\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c45ce0e5b795765d14b801b6b8ece2ee9bb641fb\",\"title\":\"Weakly Supervised PatchNets: Describing and Aggregating Local Patches for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c45ce0e5b795765d14b801b6b8ece2ee9bb641fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2871170\",\"name\":\"Huifen Xia\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/ACCESS.2020.2986861\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"title\":\"A Survey on Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145783730\",\"name\":\"X. Xiao\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"},{\"authorId\":\"145524181\",\"name\":\"W. Wan\"}],\"doi\":\"10.1109/ICALIP.2016.7846652\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"861a51e66553979535df2b41971150453ab26372\",\"title\":\"Overview: Video recognition from handcrafted method to deep learning method\",\"url\":\"https://www.semanticscholar.org/paper/861a51e66553979535df2b41971150453ab26372\",\"venue\":\"2016 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145182602\",\"name\":\"Dong Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01231-1_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"title\":\"Recurrent Tubelet Proposal and Recognition Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.01861\",\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.472\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"title\":\"Action Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798691\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144323097\",\"name\":\"W. Yu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9695232daa85651937569d1b7b2541faf2633dc\",\"title\":\"Actionness-pooled Deep-convolutional Descriptor for fine-grained action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9695232daa85651937569d1b7b2541faf2633dc\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1049/iet-cvi.2017.0005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"title\":\"Fully convolutional networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8548d5a93869a5a4c808f5e81742f59f848c718c\",\"title\":\"Semantic Proposal for Activity Localization in Videos via Sentence Query\",\"url\":\"https://www.semanticscholar.org/paper/8548d5a93869a5a4c808f5e81742f59f848c718c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48018055\",\"name\":\"P. Duan\"},{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"138223027\",\"name\":\"Maowei Cui\"},{\"authorId\":\"7851018\",\"name\":\"Hong-yan Sang\"},{\"authorId\":\"47632907\",\"name\":\"Q. Sun\"}],\"doi\":\"10.1016/J.JVCIR.2019.05.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f458913ad5d54de034537931946cf907e587d166\",\"title\":\"Multi-person pose estimation based on a deep convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/f458913ad5d54de034537931946cf907e587d166\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1710.08011\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"35163655\",\"name\":\"K. Hata\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba11083602568bbc2514c0905e0d831a65c2af6e\",\"title\":\"ActivityNet Challenge 2017 Summary\",\"url\":\"https://www.semanticscholar.org/paper/ba11083602568bbc2514c0905e0d831a65c2af6e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007998\",\"name\":\"Lars Andersson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51262903\",\"name\":\"Changbo Zhai\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-37731-1_45\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81d34d88f10b347091a03c6bbde6e770d30839e2\",\"title\":\"Action Co-localization in an Untrimmed Video by Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/81d34d88f10b347091a03c6bbde6e770d30839e2\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3288214\",\"name\":\"Rao Muhammad Anwer\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-59126-1_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81ede08b36f3abd423424804da8ff240606b3a5d\",\"title\":\"Top-Down Deep Appearance Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/81ede08b36f3abd423424804da8ff240606b3a5d\",\"venue\":\"SCIA\",\"year\":2017},{\"arxivId\":\"1906.06521\",\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfdd73269882b6d512786f64118a305aea18e43b\",\"title\":\"Delving into 3D Action Anticipation from Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/bfdd73269882b6d512786f64118a305aea18e43b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867157\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47364599\",\"name\":\"Mingli Ding\"},{\"authorId\":\"2860057\",\"name\":\"Yancheng Bai\"},{\"authorId\":\"48928816\",\"name\":\"Dandan Liu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1016/j.patrec.2019.10.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d277ff82da3cb6bdfe9987f1be12998cccbf3c37\",\"title\":\"Learning a strong detector for action localization in videos\",\"url\":\"https://www.semanticscholar.org/paper/d277ff82da3cb6bdfe9987f1be12998cccbf3c37\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.04952\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.473\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f91a5b09b50a9118d75ffea672a785a703cd604a\",\"title\":\"AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/f91a5b09b50a9118d75ffea672a785a703cd604a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1007/978-3-030-58526-6_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"title\":\"Learning Actionness via Long-Range Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.09961\",\"authors\":[{\"authorId\":\"144865353\",\"name\":\"B. Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"3166067\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"145716219\",\"name\":\"C. Shi\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/CVPR.2019.00051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"title\":\"Deep RNN Framework for Visual Sequential Applications\",\"url\":\"https://www.semanticscholar.org/paper/5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.00110\",\"authors\":[{\"authorId\":\"46419391\",\"name\":\"M. Elfeki\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2019.00085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be447eedf6c50096cc6a85b47ae7afa203c511b6\",\"title\":\"Video Summarization Via Actionness Ranking\",\"url\":\"https://www.semanticscholar.org/paper/be447eedf6c50096cc6a85b47ae7afa203c511b6\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15841516\",\"name\":\"Shuo Chen\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144436744\",\"name\":\"Tao Hu\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1145/3372278.3390680\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed38ab8511cd7f6a202730bfd3de566c3622562f\",\"title\":\"Interactivity Proposals for Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/ed38ab8511cd7f6a202730bfd3de566c3622562f\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121405052\",\"name\":\"S. V. Kiran\"},{\"authorId\":\"116372419\",\"name\":\"Raj Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09275e4157969c0606efc4c085fd3db43c2186a5\",\"title\":\"Contextual Action Recognition using Tube Convolutional Neural Network (T-CNN)\",\"url\":\"https://www.semanticscholar.org/paper/09275e4157969c0606efc4c085fd3db43c2186a5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1704.01358\",\"authors\":[{\"authorId\":\"145560551\",\"name\":\"Harkirat Singh Behl\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"961fd8da3102e9c8696f70375507eee89d37ef61\",\"title\":\"Incremental Tube Construction for Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/961fd8da3102e9c8696f70375507eee89d37ef61\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2006.00212\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"50753313\",\"name\":\"Minghui Yu\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1038/s42256-020-0168-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"title\":\"Complex sequential understanding through the awareness of spatial and temporal concepts\",\"url\":\"https://www.semanticscholar.org/paper/86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35286235\",\"name\":\"Erick Hendra Putra Alwando\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/TCSVT.2018.2887283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"title\":\"CNN-Based Multiple Path Search for Action Tube Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"40546560\",\"name\":\"Qingquan Sun\"}],\"doi\":\"10.1016/j.neucom.2016.09.106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"title\":\"Action recognition by saliency-based dense sampling\",\"url\":\"https://www.semanticscholar.org/paper/6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1807.08069\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"207a1766a942be3f22534980f47916f6dc683095\",\"title\":\"S3D: Single Shot multi-Span Detector via Fully 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/207a1766a942be3f22534980f47916f6dc683095\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145547128\",\"name\":\"D. Sawyer\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/WACVW.2019.00014\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56eddb8ecbcf5090b0a03daa703e0824700a0d22\",\"title\":\"Fine-grained Action Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/56eddb8ecbcf5090b0a03daa703e0824700a0d22\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"40dd2b9aace337467c6e1e269d0cb813442313d7\",\"title\":\"Localizing spatially and temporally objects and actions in videos. (Localiser spatio-temporallement des objets et des actions dans des vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/40dd2b9aace337467c6e1e269d0cb813442313d7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138115\",\"name\":\"F. Negin\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.3390/s19194237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"title\":\"An Unsupervised Framework for Online Spatiotemporal Detection of Activities of Daily Living by Hierarchical Activity Models\",\"url\":\"https://www.semanticscholar.org/paper/4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40286484\",\"name\":\"Xi Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2017.2740160\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd056ecfdcc8ce89a550e56887f1df1a66f5cbff\",\"title\":\"Body Structure Aware Deep Crowd Counting\",\"url\":\"https://www.semanticscholar.org/paper/dd056ecfdcc8ce89a550e56887f1df1a66f5cbff\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812342\",\"name\":\"Yeongtaek Song\"},{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.3390/s19051085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"title\":\"Spatio-Temporal Action Detection in Untrimmed Videos by Using Multimodal Features and Region Proposals\",\"url\":\"https://www.semanticscholar.org/paper/be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1501.06993\",\"authors\":[{\"authorId\":\"1746008\",\"name\":\"Youjie Zhou\"},{\"authorId\":\"1730682\",\"name\":\"Hongkai Yu\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICIP.2017.8297027\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0be0dcbd7284994145d072f7a24db52a210f22ed\",\"title\":\"Feature sampling strategies for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/0be0dcbd7284994145d072f7a24db52a210f22ed\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1016/j.neucom.2018.05.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2cda38655d3f216430969b5b864b96c1b011c1\",\"title\":\"Detecting action tubes via spatial action estimation and temporal path inference\",\"url\":\"https://www.semanticscholar.org/paper/de2cda38655d3f216430969b5b864b96c1b011c1\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1704.00758\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2017.06.001\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"079ca5438664c8fc529bfbf2749747515c098e8a\",\"title\":\"Unsupervised action proposal ranking through proposal recombination\",\"url\":\"https://www.semanticscholar.org/paper/079ca5438664c8fc529bfbf2749747515c098e8a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016}],\"corpusId\":17071670,\"doi\":\"10.1109/CVPR.2016.296\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"references\":[{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10578-9_48\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"title\":\"Spatio-temporal Object Detection Proposals\",\"url\":\"https://www.semanticscholar.org/paper/5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"144813540\",\"name\":\"K. Kang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2015.7299097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8215adca01bc207147085c6091ff7901fab26a5\",\"title\":\"Deeply learned attributes for crowded scene understanding\",\"url\":\"https://www.semanticscholar.org/paper/f8215adca01bc207147085c6091ff7901fab26a5\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2015.7298735\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"title\":\"Fast action proposals for human action detection and search\",\"url\":\"https://www.semanticscholar.org/paper/22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2014.101\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"title\":\"Actionness Ranking with Lattice Conditional Ordinal Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/s11263-015-0859-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16eaa26a84468b27e559215db01c53286808ec2a\",\"title\":\"MoFAP: A Multi-level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16eaa26a84468b27e559215db01c53286808ec2a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"144813540\",\"name\":\"K. Kang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2016.606\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cbc729fdf29f78c42c5a04c331d753ee915f102\",\"title\":\"Slicing Convolutional Neural Network for Crowd Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5cbc729fdf29f78c42c5a04c331d753ee915f102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1678783\",\"name\":\"D. Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1007/s11263-016-0893-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca7b4bbc20d81b15a8c592d0d5c7ae4851085c99\",\"title\":\"Recognizing an Action Using Its Name: A Knowledge-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/ca7b4bbc20d81b15a8c592d0d5c7ae4851085c99\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2013.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2633f6a4bb683aafecd86e9484258c0767196422\",\"title\":\"Motionlets: Mid-level 3D Parts for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2633f6a4bb683aafecd86e9484258c0767196422\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I Laptev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"On space-time interest points. IJCV\",\"url\":\"\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298872\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3de050d1707524512eeab99780df3cbdee09670c\",\"title\":\"DevNet: A Deep Event Network for multimedia event detection and evidence recounting\",\"url\":\"https://www.semanticscholar.org/paper/3de050d1707524512eeab99780df3cbdee09670c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TIP.2013.2295753\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca137df68953b803d2a8e224ed22be3cbcccf819\",\"title\":\"Latent Hierarchical Model of Temporal Structure for Complex Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/ca137df68953b803d2a8e224ed22be3cbcccf819\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCV.2011.6126472\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"title\":\"Discriminative figure-centric models for joint action localization and recognition\",\"url\":\"https://www.semanticscholar.org/paper/40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1680188\",\"name\":\"T. Joachims\"}],\"doi\":\"10.17877/DE290R-14262\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7550a05bf00f7b24aed9c1ac3ef000575388d21c\",\"title\":\"Making large scale SVM learning practical\",\"url\":\"https://www.semanticscholar.org/paper/7550a05bf00f7b24aed9c1ac3ef000575388d21c\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620865361\",\"name\":\"Seguin Hen\"}],\"doi\":\"10.1515/9783111576855-015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"title\":\"J\",\"url\":\"https://www.semanticscholar.org/paper/048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55a7260f9da39d778d1622c036b6c0ad3b42b6a6\",\"title\":\"Exploring Semantic Inter-Class Relationships (SIR) for Zero-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/55a7260f9da39d778d1622c036b6c0ad3b42b6a6\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1719780\",\"name\":\"Yan Ke\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2007.4409011\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"53964e0ccc0412e2fbb2cdf3483e1f383208febe\",\"title\":\"Event Detection in Crowded Videos\",\"url\":\"https://www.semanticscholar.org/paper/53964e0ccc0412e2fbb2cdf3483e1f383208febe\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c0f44d60b485da34112161536f294ef9d12dac5\",\"title\":\"Evaluation of super-voxel methods for early video processing\",\"url\":\"https://www.semanticscholar.org/paper/6c0f44d60b485da34112161536f294ef9d12dac5\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2014.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"title\":\"Action Localization with Tubelets from Motion\",\"url\":\"https://www.semanticscholar.org/paper/377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1406.6962\",\"authors\":[{\"authorId\":\"2536361\",\"name\":\"J. Hosang\"},{\"authorId\":\"1798000\",\"name\":\"Rodrigo Benenson\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.5244/C.28.24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b1e6ed85dae91843f3d986a001fb59439adbc39\",\"title\":\"How good are detection proposals, really?\",\"url\":\"https://www.semanticscholar.org/paper/7b1e6ed85dae91843f3d986a001fb59439adbc39\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10602-1_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"title\":\"Video Action Detection with Relational Dynamic-Poselets\",\"url\":\"https://www.semanticscholar.org/paper/d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2365442\",\"name\":\"B. Alexe\"},{\"authorId\":\"1879646\",\"name\":\"Thomas Deselaers\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1109/TPAMI.2012.28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eb6caace8296fd4dfd4947efa4fe911c8e133b2\",\"title\":\"Measuring the Objectness of Image Windows\",\"url\":\"https://www.semanticscholar.org/paper/2eb6caace8296fd4dfd4947efa4fe911c8e133b2\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8193421\",\"name\":\"Yicong Tian\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2013.341\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eea7842025dad6b4cf53445c161538536020b412\",\"title\":\"Spatiotemporal Deformable Part Models for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/eea7842025dad6b4cf53445c161538536020b412\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"},{\"authorId\":\"2805147\",\"name\":\"O. Javed\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"}],\"doi\":\"10.1109/ICCV.2009.5459334\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b322b3ecb1b8d2264641388ebcf1d64fb1aa0cb2\",\"title\":\"Background Subtraction for Freely Moving Cameras\",\"url\":\"https://www.semanticscholar.org/paper/b322b3ecb1b8d2264641388ebcf1d64fb1aa0cb2\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2015.7299000\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"17ea3c06ac00ad1a909c41a25b6c0f0c4a890d24\",\"title\":\"Human action segmentation with hierarchical supervoxel consistency\",\"url\":\"https://www.semanticscholar.org/paper/17ea3c06ac00ad1a909c41a25b6c0f0c4a890d24\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. H. Hosang\"},{\"authorId\":null,\"name\":\"R. Benenson\"},{\"authorId\":null,\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"How good are detection proposals\",\"url\":\"\",\"venue\":\"really? In BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685089\",\"name\":\"Pedro F. Felzenszwalb\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/TPAMI.2009.167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e79272fe3d65197100eae8be9fec6469107969ae\",\"title\":\"Object Detection with Discriminatively Trained Part Based Models\",\"url\":\"https://www.semanticscholar.org/paper/e79272fe3d65197100eae8be9fec6469107969ae\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"2195129\",\"name\":\"X. Jiang\"},{\"authorId\":\"120643531\",\"name\":\"A. Khosla\"},{\"authorId\":\"32157394\",\"name\":\"A. L. Lin\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2011.6126386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e15dc51de6da2bc5cabbb733cf2adf5a2c1f72c\",\"title\":\"Human action recognition by learning bases of action attributes and parts\",\"url\":\"https://www.semanticscholar.org/paper/8e15dc51de6da2bc5cabbb733cf2adf5a2c1f72c\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1405.3531\",\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.28.6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"title\":\"Return of the Devil in the Details: Delving Deep into Convolutional Nets\",\"url\":\"https://www.semanticscholar.org/paper/14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1756979\",\"name\":\"K. V. D. Sande\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1007/s11263-013-0620-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b6540ddd5beebffd05047c78183f7575559fb2\",\"title\":\"Selective Search for Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/38b6540ddd5beebffd05047c78183f7575559fb2\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678553621\",\"name\":\"Martin P. Catherwood\"}],\"doi\":\"10.1515/9783111576855-016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"725cd02f9ab4e5e4f7db6ef0d2ff5b13819a6fc1\",\"title\":\"K\",\"url\":\"https://www.semanticscholar.org/paper/725cd02f9ab4e5e4f7db6ef0d2ff5b13819a6fc1\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"48442503\",\"name\":\"K. Zhu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7298768\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce70db86c508d9c956951bdc6d210b3ce4e90249\",\"title\":\"Recognize complex events from static images by fusing deep channels\",\"url\":\"https://www.semanticscholar.org/paper/ce70db86c508d9c956951bdc6d210b3ce4e90249\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/cvprw.2009.5206671\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c24176d8f3a25eb96aa874f663680970602b77b\",\"title\":\"Discriminative subvolume search for efficient action detection\",\"url\":\"https://www.semanticscholar.org/paper/4c24176d8f3a25eb96aa874f663680970602b77b\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34702203\",\"name\":\"M. Bergh\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"2414059\",\"name\":\"S. Manen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICCV.2013.54\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4404a99e2f6db3e703609168a3595e0fbdeabc38\",\"title\":\"Online Video SEEDS for Temporal Window Objectness\",\"url\":\"https://www.semanticscholar.org/paper/4404a99e2f6db3e703609168a3595e0fbdeabc38\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"topics\":[{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"}],\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"