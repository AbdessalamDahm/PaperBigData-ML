"{\"abstract\":\"A practical lipreading system can be considered either as subject dependent (SD) or subject-independent (SI). An SD system is user-specific, i.e., customized for some particular user while an SI system has to cope with a large number of users. These two types of systems pose variant challenges and have to be treated differently. In this paper, we propose a simple deterministic model to tackle the problem. The model first seeks a low-dimensional manifold where visual features extracted from the frames of a video can be projected onto a continuous deterministic curve embedded in a path graph. Moreover, it can map arbitrary points on the curve back into the image space, making it suitable for temporal interpolation. Based on the model, we develop two separate strategies for SD and SI lipreading. The former is turned into a simple curve-matching problem while for the latter, we propose a video-normalization scheme to improve the system developed by Zhao et al. We evaluated our system on the OuluVS database and achieved recognition rates more than 20% higher than the ones reported by Zhao et al. in both SD and SI testing scenarios.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"34849838\",\"name\":\"Ziheng Zhou\",\"url\":\"https://www.semanticscholar.org/author/34849838\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\",\"url\":\"https://www.semanticscholar.org/author/1757287\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\",\"url\":\"https://www.semanticscholar.org/author/145962204\"}],\"citationVelocity\":12,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"7489436\",\"name\":\"S. Wang\"},{\"authorId\":\"9185305\",\"name\":\"W. Yan\"},{\"authorId\":\"2464999\",\"name\":\"Tingkai Sun\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"144054357\",\"name\":\"X. Fu\"}],\"doi\":\"10.1016/j.neucom.2016.05.083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf83ce4fb5884691989c8eccfcb6000515f538ff\",\"title\":\"Sparse tensor canonical correlation analysis for micro-expression recognition\",\"url\":\"https://www.semanticscholar.org/paper/bf83ce4fb5884691989c8eccfcb6000515f538ff\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715826\",\"name\":\"Y. Liu\"},{\"authorId\":\"8214258\",\"name\":\"J. Zhang\"},{\"authorId\":\"9185305\",\"name\":\"W. Yan\"},{\"authorId\":\"7489436\",\"name\":\"S. Wang\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"144054357\",\"name\":\"X. Fu\"}],\"doi\":\"10.1109/TAFFC.2015.2485205\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc6e844fbc30fdbcb8163768ffe2886c4cb0283e\",\"title\":\"A Main Directional Mean Optical Flow Feature for Spontaneous Micro-Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc6e844fbc30fdbcb8163768ffe2886c4cb0283e\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1844956391\",\"name\":\"Ling Zhou\"},{\"authorId\":\"47403609\",\"name\":\"Xiuyan Shao\"},{\"authorId\":\"151423308\",\"name\":\"Qirong Mao\"}],\"doi\":\"10.1016/j.imavis.2020.104043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5decc82a4122f2258256cceeeb4b9211e3ad4e0\",\"title\":\"A survey of micro-expression recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5decc82a4122f2258256cceeeb4b9211e3ad4e0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"46469663\",\"name\":\"Mayank Aggarwal\"},{\"authorId\":\"51118910\",\"name\":\"Pratham Nawal\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7115db883183510122e2485dd9063d31a25dabdb\",\"title\":\"Speech Reconstitution using Multi-view Silent Videos\",\"url\":\"https://www.semanticscholar.org/paper/7115db883183510122e2485dd9063d31a25dabdb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849838\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"1734663\",\"name\":\"Yimo Guo\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/TCSVT.2012.2199399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6dfc83619543c3c4165a66034c6d81956e7ebcb\",\"title\":\"An Image-Based Visual Speech Animation System\",\"url\":\"https://www.semanticscholar.org/paper/e6dfc83619543c3c4165a66034c6d81956e7ebcb\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2012},{\"arxivId\":\"1907.00193\",\"authors\":[{\"authorId\":\"79402595\",\"name\":\"Debin Meng\"},{\"authorId\":\"51003139\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"47373181\",\"name\":\"K. Wang\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/ICIP.2019.8803603\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddb2aecf8777007414b1eb341c6c19ec799280d3\",\"title\":\"Frame Attention Networks for Facial Expression Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/ddb2aecf8777007414b1eb341c6c19ec799280d3\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2783666\",\"name\":\"H. Jian\"}],\"doi\":\"10.1007/978-3-319-20684-4_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9273a379928c48e04adcbbd276e645ad7cd885ce\",\"title\":\"Speech Driven by Artificial Larynx: Potential Advancement Using Synthetic Pitch Contours\",\"url\":\"https://www.semanticscholar.org/paper/9273a379928c48e04adcbbd276e645ad7cd885ce\",\"venue\":\"HCI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1402564695\",\"name\":\"John A. Ruiz-Hernandez\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/FG.2013.6553709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dffe35473225111edaf60123946df8faf7f54247\",\"title\":\"Encoding Local Binary Patterns using the re-parametrization of the second order Gaussian jet\",\"url\":\"https://www.semanticscholar.org/paper/dffe35473225111edaf60123946df8faf7f54247\",\"venue\":\"2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23677993\",\"name\":\"Wenkai Dong\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":null,\"name\":\"Shu Zhang\"}],\"doi\":\"10.1109/ICDSP.2016.7868603\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0ba06ca457672c5de0c254c52b853d304412967\",\"title\":\"Digital recognition from lip texture analysis\",\"url\":\"https://www.semanticscholar.org/paper/e0ba06ca457672c5de0c254c52b853d304412967\",\"venue\":\"2016 IEEE International Conference on Digital Signal Processing (DSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2298773\",\"name\":\"Tofigh Naghibi\"}],\"doi\":\"10.3929/ETHZ-A-010492674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9358cc8e229102064b817a8c346d8bfe28d170ca\",\"title\":\"Towards Robust Audio-Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9358cc8e229102064b817a8c346d8bfe28d170ca\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9267486\",\"name\":\"Si Miao\"},{\"authorId\":\"1724825\",\"name\":\"Haoyu Xu\"},{\"authorId\":\"2005462\",\"name\":\"Zhenqi Han\"},{\"authorId\":\"35884242\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1109/ACCESS.2019.2921220\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"729b76715c5665643058045de178a0b91262dfdb\",\"title\":\"Recognizing Facial Expressions Using a Shallow Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/729b76715c5665643058045de178a0b91262dfdb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46326993\",\"name\":\"Hang Pan\"},{\"authorId\":\"143971861\",\"name\":\"Lun Xie\"},{\"authorId\":\"144906809\",\"name\":\"Zeping Lv\"},{\"authorId\":\"47786705\",\"name\":\"J. Li\"},{\"authorId\":\"50218218\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/s11042-020-09475-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cad006b7e5110a76537f10cc5ebe217ab67edb35\",\"title\":\"Hierarchical support vector machine for facial micro-expression recognition\",\"url\":\"https://www.semanticscholar.org/paper/cad006b7e5110a76537f10cc5ebe217ab67edb35\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1907.10087\",\"authors\":[{\"authorId\":\"26997269\",\"name\":\"Naima Otberdout\"},{\"authorId\":\"2909056\",\"name\":\"M. Daoudi\"},{\"authorId\":\"46243487\",\"name\":\"A. Kacem\"},{\"authorId\":\"2062946\",\"name\":\"Lahoucine Ballihi\"},{\"authorId\":\"2507859\",\"name\":\"S. Berretti\"}],\"doi\":\"10.1109/TPAMI.2020.3002500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4ea07e4cf344ed5fbc2aa833eec5b6bf2f6b759\",\"title\":\"Dynamic Facial Expression Generation on Hilbert Hypersphere with Conditional Wasserstein Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/b4ea07e4cf344ed5fbc2aa833eec5b6bf2f6b759\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849838\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/TPAMI.2013.173\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8bbbf3ff7757e2c963997ab07229518b04a1db6\",\"title\":\"A Compact Representation of Visual Speech Data Using Latent Variables\",\"url\":\"https://www.semanticscholar.org/paper/a8bbbf3ff7757e2c963997ab07229518b04a1db6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7917586\",\"name\":\"Thuong-Khanh Tran\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1007/978-3-319-70353-4_46\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70aa7e17f01c1897b89a0493801715256a85a84e\",\"title\":\"Sliding Window Based Micro-expression Spotting: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/70aa7e17f01c1897b89a0493801715256a85a84e\",\"venue\":\"ACIVS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7489436\",\"name\":\"S. Wang\"},{\"authorId\":\"9185305\",\"name\":\"W. Yan\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"144054357\",\"name\":\"X. Fu\"},{\"authorId\":\"8239114\",\"name\":\"Chunguang Zhou\"}],\"doi\":\"10.1007/978-3-319-16178-5_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96573574fdaf3550af4f4c6ac19a9cb2f43adc7f\",\"title\":\"Micro-Expression Recognition Using Robust Principal Component Analysis and Local Spatiotemporal Directional Features\",\"url\":\"https://www.semanticscholar.org/paper/96573574fdaf3550af4f4c6ac19a9cb2f43adc7f\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7489436\",\"name\":\"S. Wang\"},{\"authorId\":\"9185305\",\"name\":\"W. Yan\"},{\"authorId\":\"50079101\",\"name\":\"Xiaobai Li\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"144054357\",\"name\":\"X. Fu\"}],\"doi\":\"10.1109/ICPR.2014.800\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d63d3f07e0243cc10df5dd6005564ac3eb361265\",\"title\":\"Micro-expression Recognition Using Dynamic Textures on Tensor Independent Color Space\",\"url\":\"https://www.semanticscholar.org/paper/d63d3f07e0243cc10df5dd6005564ac3eb361265\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46935678\",\"name\":\"H. Liu\"},{\"authorId\":\"2866844\",\"name\":\"Ting Fan\"},{\"authorId\":\"47561464\",\"name\":\"Pingping Wu\"}],\"doi\":\"10.1109/ICPR.2014.145\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae487d8075e4dd214d2ceb1974daddd543d6b26c\",\"title\":\"Audio-visual Keyword Spotting for Mandarin Based on Discriminative Local Spatial-Temporal Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/ae487d8075e4dd214d2ceb1974daddd543d6b26c\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2565775\",\"name\":\"X. Li\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"50623422\",\"name\":\"S. Zhan\"}],\"doi\":\"10.1109/ICSP.2016.7878004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab540c5be9f7ef688d3cd76765fcb794b92531fb\",\"title\":\"Spontaneous facial micro-expression detection based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/ab540c5be9f7ef688d3cd76765fcb794b92531fb\",\"venue\":\"2016 IEEE 13th International Conference on Signal Processing (ICSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39532631\",\"name\":\"Bihan Jiang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7d18a20280fcdc0fc5eca223a8fe8d7f81436b6\",\"title\":\"Spatial and temporal analysis of facial actions\",\"url\":\"https://www.semanticscholar.org/paper/d7d18a20280fcdc0fc5eca223a8fe8d7f81436b6\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34199365\",\"name\":\"J. D. Boeck\"},{\"authorId\":\"17819917\",\"name\":\"Jo Daems\"},{\"authorId\":\"3350608\",\"name\":\"J. Dekelver\"}],\"doi\":\"10.1007/978-3-642-31522-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b479911bf11c3258755690aacdfa9e499cf5d98\",\"title\":\"Computers Helping People with Special Needs\",\"url\":\"https://www.semanticscholar.org/paper/8b479911bf11c3258755690aacdfa9e499cf5d98\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144340651\",\"name\":\"D. G\\u00f3mez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff0810f0b3ac90a06e36a7a6ffd19b7b42be60a5\",\"title\":\"Lectura de labios en im\\u00e1genes de v\\u00eddeo\",\"url\":\"https://www.semanticscholar.org/paper/ff0810f0b3ac90a06e36a7a6ffd19b7b42be60a5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1382648588\",\"name\":\"Wei Peng\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"104117062\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1145/3342227\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd37895f5adfe8d4dc5276cee543eaf5a1f58a2c\",\"title\":\"Characterizing Subtle Facial Movements via Riemannian Manifold\",\"url\":\"https://www.semanticscholar.org/paper/cd37895f5adfe8d4dc5276cee543eaf5a1f58a2c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"34604467\",\"name\":\"Rohit Jain\"},{\"authorId\":\"66287688\",\"name\":\"Khwaja Mohd. Salik\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"},{\"authorId\":\"144221742\",\"name\":\"Yifang Yin\"}],\"doi\":\"10.1109/ISM.2018.00-19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfad754db0d4f0a57c73a931ce86da714793885d\",\"title\":\"MyLipper: A Personalized System for Speech Reconstruction using Multi-view Visual Feeds\",\"url\":\"https://www.semanticscholar.org/paper/dfad754db0d4f0a57c73a931ce86da714793885d\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1391546994\",\"name\":\"Hirokazu Kobori\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"3178184\",\"name\":\"Noriko Takemura\"},{\"authorId\":\"145800886\",\"name\":\"H. Nagahara\"}],\"doi\":\"10.1109/ICIP.2019.8803396\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acd7007dbbeeb1a597a9b342cc22a552a83ab96f\",\"title\":\"Facial Expression Recognition with Skip-Connection to Leverage Low-Level Features\",\"url\":\"https://www.semanticscholar.org/paper/acd7007dbbeeb1a597a9b342cc22a552a83ab96f\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31697809\",\"name\":\"C. Duque\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05ff6a21260d35687937d5209532e5bfd3af9b1b\",\"title\":\"Analysis of Micro-Expressions based on the Riesz Pyramid : Application to Spotting and Recognition. (Analyse des micro-expressions exploitant la pyramide de Riesz : application \\u00e0 la d\\u00e9tection et \\u00e0 la reconnaissance)\",\"url\":\"https://www.semanticscholar.org/paper/05ff6a21260d35687937d5209532e5bfd3af9b1b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800903\",\"name\":\"Heechul Jung\"},{\"authorId\":\"1800572\",\"name\":\"Sihaeng Lee\"},{\"authorId\":\"3249661\",\"name\":\"Junho Yim\"},{\"authorId\":\"1751648\",\"name\":\"Sunjeong Park\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/ICCV.2015.341\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2911e7f0fb6803851b0eddf8067a6fc06e8eadd6\",\"title\":\"Joint Fine-Tuning in Deep Neural Networks for Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2911e7f0fb6803851b0eddf8067a6fc06e8eadd6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1907.05023\",\"authors\":[{\"authorId\":\"3381691\",\"name\":\"Yante Li\"},{\"authorId\":\"46423139\",\"name\":\"Xiaohua Huang\"},{\"authorId\":\"1757287\",\"name\":\"Guoying Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2dba6123c278ab7be92cc21cd18b74bb9db97eb3\",\"title\":\"Micro-expression Action Unit Detection withSpatio-temporal Adaptive Pooling\",\"url\":\"https://www.semanticscholar.org/paper/2dba6123c278ab7be92cc21cd18b74bb9db97eb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732040\",\"name\":\"Ram P. Krish\"},{\"authorId\":\"7838430\",\"name\":\"P. Whelan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c03163511ea11e5c1d5de1b10e7058cf6f6149dc\",\"title\":\"Visual speech encoding based on facial landmark registration\",\"url\":\"https://www.semanticscholar.org/paper/c03163511ea11e5c1d5de1b10e7058cf6f6149dc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1904.07647\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPRW.2019.00030\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3b01e84a43a9ca9389b6e05fbc59922d8b485d9\",\"title\":\"LBVCNN: Local Binary Volume Convolutional Neural Network for Facial Expression Recognition From Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/a3b01e84a43a9ca9389b6e05fbc59922d8b485d9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31138514\",\"name\":\"Devangini Patel\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/ICPR.2016.7899972\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"745d49a2ff70450113f07124c2c5263105125f58\",\"title\":\"Selective deep features for micro-expression recognition\",\"url\":\"https://www.semanticscholar.org/paper/745d49a2ff70450113f07124c2c5263105125f58\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410464604\",\"name\":\"A. Fernandez-Lopez\"},{\"authorId\":\"2012978\",\"name\":\"F. Sukno\"}],\"doi\":\"10.1016/j.imavis.2018.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"938717d66533d900abac7451e15c1f322e78db81\",\"title\":\"Survey on automatic lip-reading in the era of deep learning\",\"url\":\"https://www.semanticscholar.org/paper/938717d66533d900abac7451e15c1f322e78db81\",\"venue\":\"Image Vis. Comput.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087579\",\"name\":\"X. Chen\"},{\"authorId\":\"1683416\",\"name\":\"Chunheng Wang\"},{\"authorId\":\"2658590\",\"name\":\"B. Xiao\"},{\"authorId\":\"40413482\",\"name\":\"Xinyuan Cai\"}],\"doi\":\"10.1109/ICIP.2014.7025382\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ed74ee80c7be140bc19085e5cdd96e2fcb1982e2\",\"title\":\"Learning associate appearance manifolds for cross-pose face recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed74ee80c7be140bc19085e5cdd96e2fcb1982e2\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"50079101\",\"name\":\"Xiaobai Li\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/ICCVW.2011.6130343\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7fec7ad4988a7b6812fafb5a32ef9d50d1e8791\",\"title\":\"Differentiating spontaneous from posed facial expressions within a generic facial expression recognition framework\",\"url\":\"https://www.semanticscholar.org/paper/f7fec7ad4988a7b6812fafb5a32ef9d50d1e8791\",\"venue\":\"2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)\",\"year\":2011},{\"arxivId\":\"1812.07742\",\"authors\":[{\"authorId\":\"145887139\",\"name\":\"Yuan Zong\"},{\"authorId\":\"40608983\",\"name\":\"W. Zheng\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"2397257\",\"name\":\"Chuangao Tang\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1145/3323873.3326590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cd7664e23b4099434a23889eba179a6134e1b78\",\"title\":\"Cross-Database Micro-Expression Recognition: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/2cd7664e23b4099434a23889eba179a6134e1b78\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1007/978-3-319-10590-1_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f7f0b5f15ac3fb9d2f1c1f90a5cb672e9e95a87\",\"title\":\"Read My Lips: Continuous Signer Independent Weakly Supervised Viseme Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0f7f0b5f15ac3fb9d2f1c1f90a5cb672e9e95a87\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1907.09160\",\"authors\":[{\"authorId\":\"3031515\",\"name\":\"C. Guo\"},{\"authorId\":\"145270228\",\"name\":\"J. Liang\"},{\"authorId\":\"145736603\",\"name\":\"G. Zhan\"},{\"authorId\":\"9830829\",\"name\":\"Z. Liu\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2942358\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77b692f9797ab1d562019ddb6d0ab40a39a8956f\",\"title\":\"Extended Local Binary Patterns for Efficient and Robust Spontaneous Facial Micro-Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/77b692f9797ab1d562019ddb6d0ab40a39a8956f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1805.01963\",\"authors\":[{\"authorId\":\"145692126\",\"name\":\"Xin Liu\"},{\"authorId\":\"30416451\",\"name\":\"Zhikai Hu\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"143840540\",\"name\":\"Yiu-ming Cheung\"}],\"doi\":\"10.1109/TPAMI.2019.2940446\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2206bae6be59c402e8e1de0f5d211ab442b85a6b\",\"title\":\"MTFH: A Matrix Tri-Factorization Hashing Framework for Efficient Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2206bae6be59c402e8e1de0f5d211ab442b85a6b\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1904.01748\",\"authors\":[{\"authorId\":\"39888137\",\"name\":\"Sze-Teng Liong\"},{\"authorId\":\"145274714\",\"name\":\"Y. S. Gan\"},{\"authorId\":\"96539681\",\"name\":\"Danna Zheng\"},{\"authorId\":\"93772751\",\"name\":\"S. Lic\"},{\"authorId\":\"95755749\",\"name\":\"Hao-Xuan Xua\"},{\"authorId\":\"7214027\",\"name\":\"Han-Zhe Zhang\"},{\"authorId\":\"96661596\",\"name\":\"R. Lyu\"},{\"authorId\":\"3052518\",\"name\":\"K. Liu\"}],\"doi\":\"10.1007/s11265-020-01523-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93aa8265bae5b7d1edf1c97f58a9cc47c1ac155d\",\"title\":\"Evaluation of the Spatio-Temporal Features and GAN for Micro-Expression Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/93aa8265bae5b7d1edf1c97f58a9cc47c1ac155d\",\"venue\":\"J. Signal Process. Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa127e6b2dc0aaccfb85e93e8b557f83ebee816b\",\"title\":\"Advancing human pose and gesture recognition\",\"url\":\"https://www.semanticscholar.org/paper/aa127e6b2dc0aaccfb85e93e8b557f83ebee816b\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1601.04805\",\"authors\":[{\"authorId\":\"35256518\",\"name\":\"A. L. Ngo\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"145016295\",\"name\":\"R. Phan\"}],\"doi\":\"10.1109/TAFFC.2016.2523996\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0952efc8df107142fd80fddc2549219dcc23afef\",\"title\":\"Sparsity in Dynamics of Spontaneous Subtle Emotions: Analysis and Application\",\"url\":\"https://www.semanticscholar.org/paper/0952efc8df107142fd80fddc2549219dcc23afef\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2017},{\"arxivId\":\"1907.01367\",\"authors\":[{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"34604467\",\"name\":\"Rohit Jain\"},{\"authorId\":\"66287688\",\"name\":\"Khwaja Mohd. Salik\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144221742\",\"name\":\"Yifang Yin\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":\"10.1609/aaai.v33i01.33012588\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"174812d636fdb17c1cbe24b8d9888d340a5dbf56\",\"title\":\"Lipper: Synthesizing Thy Speech using Multi-View Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/174812d636fdb17c1cbe24b8d9888d340a5dbf56\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827436\",\"name\":\"Y. Zhao\"},{\"authorId\":\"49395110\",\"name\":\"J. Xu\"}],\"doi\":\"10.3390/SYM11040497\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c23f87f079bd93807e3567fee6476f0e2db9e091\",\"title\":\"An Improved Micro-Expression Recognition Method Based on Necessary Morphological Patches\",\"url\":\"https://www.semanticscholar.org/paper/c23f87f079bd93807e3567fee6476f0e2db9e091\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9278275\",\"name\":\"Jiayao Tan\"},{\"authorId\":\"145000416\",\"name\":\"C. Nguyen\"},{\"authorId\":\"12142512\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/INFOCOM.2017.8057099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4832c0b4ba8f89a30368af837dd81330c0900f2\",\"title\":\"SilentTalk: Lip reading through ultrasonic sensing on mobile phones\",\"url\":\"https://www.semanticscholar.org/paper/d4832c0b4ba8f89a30368af837dd81330c0900f2\",\"venue\":\"IEEE INFOCOM 2017 - IEEE Conference on Computer Communications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2553739\",\"name\":\"A. Rekik\"},{\"authorId\":\"1403815663\",\"name\":\"Achraf Ben-Hamadou\"},{\"authorId\":\"1979087\",\"name\":\"W. Mahdi\"}],\"doi\":\"10.1007/978-3-319-11755-3_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba18c6439bf7a1f7e3534ea03e89393c7a372a8f\",\"title\":\"A New Visual Speech Recognition Approach for RGB-D Cameras\",\"url\":\"https://www.semanticscholar.org/paper/ba18c6439bf7a1f7e3534ea03e89393c7a372a8f\",\"venue\":\"ICIAR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1697978\",\"name\":\"M. Li\"},{\"authorId\":\"143640801\",\"name\":\"S. Chen\"},{\"authorId\":\"144222395\",\"name\":\"K. Ren\"}],\"doi\":\"10.1109/INFCOMW.2014.6849220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1272f973f5dcc86b28caeb145e16bec383dddd97\",\"title\":\"Enabling private and non-intrusive smartphone calls with LipTalk\",\"url\":\"https://www.semanticscholar.org/paper/1272f973f5dcc86b28caeb145e16bec383dddd97\",\"venue\":\"2014 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39329886\",\"name\":\"Veena Mayya\"},{\"authorId\":\"1837904\",\"name\":\"Radhika M. Pai\"},{\"authorId\":\"48752606\",\"name\":\"M. M. Pai\"}],\"doi\":\"10.1109/ICACCI.2016.7732128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a05b1a06863879f46dac8d0228a36fff8807c83\",\"title\":\"Combining temporal interpolation and DCNN for faster recognition of micro-expressions in video sequences\",\"url\":\"https://www.semanticscholar.org/paper/9a05b1a06863879f46dac8d0228a36fff8807c83\",\"venue\":\"2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46935678\",\"name\":\"H. Liu\"},{\"authorId\":\"47957488\",\"name\":\"X. Zhang\"},{\"authorId\":\"47561464\",\"name\":\"Pingping Wu\"}],\"doi\":\"10.1109/ICIP.2015.7351304\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f5346a169c9784ca79aca5d95ae8bf2ebab58e3\",\"title\":\"Two-level multi-task metric learning with application to multi-classification\",\"url\":\"https://www.semanticscholar.org/paper/7f5346a169c9784ca79aca5d95ae8bf2ebab58e3\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"144360884\",\"name\":\"H. Xiao\"},{\"authorId\":\"48730267\",\"name\":\"S. Luo\"},{\"authorId\":\"39232684\",\"name\":\"J. Zhang\"},{\"authorId\":\"40466073\",\"name\":\"X. Liu\"}],\"doi\":\"10.1016/J.IMAGE.2019.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b167b778eb9507956b6764dc11eedbaffa3449e4\",\"title\":\"A weighted feature extraction method based on temporal accumulation of optical flow for micro-expression recognition\",\"url\":\"https://www.semanticscholar.org/paper/b167b778eb9507956b6764dc11eedbaffa3449e4\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1904.01954\",\"authors\":[{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"2563750\",\"name\":\"Yujiang Wang\"},{\"authorId\":\"144933397\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"8798628\",\"name\":\"Z. Li\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1016/j.patrec.2020.01.022\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c785dcf80ae0f8d5fab1960ef2afc6cefcebd8a\",\"title\":\"End-to-End Visual Speech Recognition for Small-Scale Datasets\",\"url\":\"https://www.semanticscholar.org/paper/4c785dcf80ae0f8d5fab1960ef2afc6cefcebd8a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1503.01532\",\"authors\":[{\"authorId\":\"1800903\",\"name\":\"Heechul Jung\"},{\"authorId\":\"1800572\",\"name\":\"Sihaeng Lee\"},{\"authorId\":\"1751648\",\"name\":\"Sunjeong Park\"},{\"authorId\":\"8271137\",\"name\":\"I. Lee\"},{\"authorId\":\"36636015\",\"name\":\"Chunghyun Ahn\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4a0cff84c35f75bcdb7aec3a0b1395edd15189b\",\"title\":\"Deep Temporal Appearance-Geometry Network for Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4a0cff84c35f75bcdb7aec3a0b1395edd15189b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"2008.05924\",\"authors\":[{\"authorId\":\"1387822126\",\"name\":\"Xingxun Jiang\"},{\"authorId\":\"48115912\",\"name\":\"Yuan Zong\"},{\"authorId\":\"153811981\",\"name\":\"Wenming Zheng\"},{\"authorId\":\"2397257\",\"name\":\"Chuangao Tang\"},{\"authorId\":\"1382744618\",\"name\":\"Wanchuang Xia\"},{\"authorId\":\"102517285\",\"name\":\"Cheng Lu\"},{\"authorId\":\"1390977843\",\"name\":\"Jiateng Liu\"}],\"doi\":\"10.1145/3394171.3413620\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"title\":\"DFEW: A Large-Scale Database for Recognizing Dynamic Facial Expressions in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47561464\",\"name\":\"Pingping Wu\"},{\"authorId\":\"46935678\",\"name\":\"H. Liu\"},{\"authorId\":\"1757356\",\"name\":\"X. Li\"},{\"authorId\":\"2866844\",\"name\":\"Ting Fan\"},{\"authorId\":\"47957488\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/TMM.2016.2520091\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5df17c81c266cf2ebb0778e48e825905e161a8d9\",\"title\":\"A Novel Lip Descriptor for Audio-Visual Keyword Spotting Based on Adaptive Decision Fusion\",\"url\":\"https://www.semanticscholar.org/paper/5df17c81c266cf2ebb0778e48e825905e161a8d9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2016},{\"arxivId\":\"1810.11392\",\"authors\":[{\"authorId\":\"26997269\",\"name\":\"Naima Otberdout\"},{\"authorId\":\"46243486\",\"name\":\"A. Kacem\"},{\"authorId\":\"2909056\",\"name\":\"M. Daoudi\"},{\"authorId\":\"2062946\",\"name\":\"Lahoucine Ballihi\"},{\"authorId\":\"2507859\",\"name\":\"S. Berretti\"}],\"doi\":\"10.1109/TNNLS.2019.2947244\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09d6351cf4ce5b85e7f277e6fbe5aaa044cba168\",\"title\":\"Automatic Analysis of Facial Expressions Based on Deep Covariance Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/09d6351cf4ce5b85e7f277e6fbe5aaa044cba168\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35256518\",\"name\":\"A. L. Ngo\"},{\"authorId\":\"145016295\",\"name\":\"R. Phan\"},{\"authorId\":\"143937986\",\"name\":\"John See\"}],\"doi\":\"10.1007/978-3-319-16817-3_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e78af9bd0f9a0ce4ceb5f09f24bc4e4823bd698\",\"title\":\"Spontaneous Subtle Expression Recognition: Imbalanced Databases and Solutions\",\"url\":\"https://www.semanticscholar.org/paper/0e78af9bd0f9a0ce4ceb5f09f24bc4e4823bd698\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653504\",\"name\":\"Y. Pei\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"},{\"authorId\":\"1687248\",\"name\":\"H. Zha\"}],\"doi\":\"10.1109/ICCV.2013.23\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d2c61faa5350bce08725d2a301f393499feb734\",\"title\":\"Unsupervised Random Forest Manifold Alignment for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/7d2c61faa5350bce08725d2a301f393499feb734\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52625508\",\"name\":\"Dong Xiao-chen\"},{\"authorId\":\"47642846\",\"name\":\"Zhao Zhi-gang\"},{\"authorId\":\"145324727\",\"name\":\"L. Qiang\"}],\"doi\":\"10.1145/3290420.3290421\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5667a2b7e4917b9001d3f2adcc3ba8f77234408c\",\"title\":\"Microexpression recognition based on improved robust principal component analysis and texture feature extraction\",\"url\":\"https://www.semanticscholar.org/paper/5667a2b7e4917b9001d3f2adcc3ba8f77234408c\",\"venue\":\"ICCIP '18\",\"year\":2018},{\"arxivId\":\"1806.05781\",\"authors\":[{\"authorId\":\"2154760\",\"name\":\"Yee-Hui Oh\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"35256518\",\"name\":\"A. L. Ngo\"},{\"authorId\":\"145016295\",\"name\":\"R. Phan\"},{\"authorId\":\"34287833\",\"name\":\"V. M. Baskaran\"}],\"doi\":\"10.3389/fpsyg.2018.01128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb13e29fb8af6cfca568c6dc523da04d1db1fff5\",\"title\":\"A Survey of Automatic Facial Micro-Expression Analysis: Databases, Methods, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/cb13e29fb8af6cfca568c6dc523da04d1db1fff5\",\"venue\":\"Front. Psychol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145823936\",\"name\":\"Amr Bakry\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":\"10.1109/CVPR.2013.94\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a226c1252385e36abb0ac38117fd8dd7f37dbfac\",\"title\":\"MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification\",\"url\":\"https://www.semanticscholar.org/paper/a226c1252385e36abb0ac38117fd8dd7f37dbfac\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2630005\",\"name\":\"Shizhi Chen\"},{\"authorId\":\"2419350\",\"name\":\"D. M. Quintian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1007/978-3-642-31522-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13e5d4756e8276770e916aa63027e246829047e2\",\"title\":\"Towards a Visual Speech Learning System for the Deaf by Matching Dynamic Lip Shapes\",\"url\":\"https://www.semanticscholar.org/paper/13e5d4756e8276770e916aa63027e246829047e2\",\"venue\":\"ICCHP\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4359148\",\"name\":\"G. Li\"},{\"authorId\":\"2473859\",\"name\":\"J. Shi\"},{\"authorId\":\"2035290\",\"name\":\"Jinye Peng\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.5220/0007373604270434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d79f60d0ac70e6e4bc4a1e49d34a453eabfc5be\",\"title\":\"Micro-expression Recognition Under Low-resolution Cases\",\"url\":\"https://www.semanticscholar.org/paper/1d79f60d0ac70e6e4bc4a1e49d34a453eabfc5be\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71509054\",\"name\":\"L. Barbieri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9ca5778f661fe7bd5c5c5090516a76961f09618\",\"title\":\"Facial microexpression recognition based on descriptor and classifier combinations = Reconhecimento de microexpress\\u00f5es faciais baseado em combina\\u00e7\\u00f5es de descritores e classificadores\",\"url\":\"https://www.semanticscholar.org/paper/e9ca5778f661fe7bd5c5c5090516a76961f09618\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3034487\",\"name\":\"K. Thangthai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9f19c1fbf50f3a54d6227383c8b43b2d7fce75c\",\"title\":\"Computer lipreading via hybrid deep neural network hidden Markov models\",\"url\":\"https://www.semanticscholar.org/paper/a9f19c1fbf50f3a54d6227383c8b43b2d7fce75c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2560252\",\"name\":\"K. Palecek\"}],\"doi\":\"10.1007/s12193-018-0266-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0aa189ab443844f62a7aa973666556ceb9cd79b\",\"title\":\"Experimenting with lipreading for large vocabulary continuous speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0aa189ab443844f62a7aa973666556ceb9cd79b\",\"venue\":\"Journal on Multimodal User Interfaces\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39532631\",\"name\":\"Bihan Jiang\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.5244/C.28.102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e2e2e74f691ff96395f107e0debfe213c2d72e5\",\"title\":\"Parametric temporal alignment for the detection of facial action temporal segments\",\"url\":\"https://www.semanticscholar.org/paper/9e2e2e74f691ff96395f107e0debfe213c2d72e5\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":\"1601.05861\",\"authors\":[{\"authorId\":\"145823936\",\"name\":\"Amr Bakry\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a660639a1ca5e3f1bc97c80be9d753c0d48e85ce\",\"title\":\"Manifold-Kernels Comparison in MKPLS for Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a660639a1ca5e3f1bc97c80be9d753c0d48e85ce\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1503.06699\",\"authors\":[{\"authorId\":\"2047671\",\"name\":\"Zhengwu Zhang\"},{\"authorId\":\"2422388\",\"name\":\"Jingyong Su\"},{\"authorId\":\"144984764\",\"name\":\"E. Klassen\"},{\"authorId\":\"47890876\",\"name\":\"H. Le\"},{\"authorId\":\"143868576\",\"name\":\"A. Srivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2f02dce81c03063698c3b7d3cc91b266b11275e\",\"title\":\"Video-Based Action Recognition Using Rate-Invariant Analysis of Covariance Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d2f02dce81c03063698c3b7d3cc91b266b11275e\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"50079101\",\"name\":\"Xiaobai Li\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/ICCV.2011.6126401\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64fe14cb57889f95b770b088dc846671ea644769\",\"title\":\"Recognising spontaneous facial micro-expressions\",\"url\":\"https://www.semanticscholar.org/paper/64fe14cb57889f95b770b088dc846671ea644769\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7312196\",\"name\":\"E. Benhaim\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"},{\"authorId\":\"49837708\",\"name\":\"Guillaume Vitte\"}],\"doi\":\"10.1109/ICASSP.2015.7178370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"794417e6b17ac2532ff786b3af4747c8b0f9c91c\",\"title\":\"Continuous visual speech recognition for audio speech enhancement\",\"url\":\"https://www.semanticscholar.org/paper/794417e6b17ac2532ff786b3af4747c8b0f9c91c\",\"venue\":\"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027003826\",\"name\":\"Mingfeng Hao\"},{\"authorId\":\"26957200\",\"name\":\"Mutallip Mamut\"},{\"authorId\":\"2027003608\",\"name\":\"Nurbiya Yadikar\"},{\"authorId\":\"2119595\",\"name\":\"A. Aysa\"},{\"authorId\":\"1869945\",\"name\":\"K. Ubul\"}],\"doi\":\"10.1109/ACCESS.2020.3036865\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3014cc7546ad2c35d47fd6627233d92d7ae40a85\",\"title\":\"A Survey of Research on Lipreading Technology\",\"url\":\"https://www.semanticscholar.org/paper/3014cc7546ad2c35d47fd6627233d92d7ae40a85\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46935678\",\"name\":\"H. Liu\"},{\"authorId\":\"47957488\",\"name\":\"X. Zhang\"},{\"authorId\":\"47561464\",\"name\":\"Pingping Wu\"}],\"doi\":\"10.1109/ICIP.2015.7350911\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"11ba01ce7d606bab5c2d7e998c6d94325521b8a0\",\"title\":\"Regression based landmark estimation and multi-feature fusion for visual speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/11ba01ce7d606bab5c2d7e998c6d94325521b8a0\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827436\",\"name\":\"Y. Zhao\"},{\"authorId\":\"49395110\",\"name\":\"J. Xu\"}],\"doi\":\"10.3390/APP8101811\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdf781c08128b66f3700d17ccc38eec5743395e7\",\"title\":\"Necessary Morphological Patches Extraction for Automatic Micro-Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdf781c08128b66f3700d17ccc38eec5743395e7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1807.00619\",\"authors\":[{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"46469663\",\"name\":\"Mayank Aggarwal\"},{\"authorId\":\"51118910\",\"name\":\"Pratham Nawal\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":\"10.1145/3240508.3241911\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b978e6034842395b3e9202cec26a257594da8f76\",\"title\":\"Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed\",\"url\":\"https://www.semanticscholar.org/paper/b978e6034842395b3e9202cec26a257594da8f76\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143979425\",\"name\":\"F. Xu\"},{\"authorId\":\"2247926\",\"name\":\"Junping Zhang\"},{\"authorId\":\"1699550\",\"name\":\"J. Z. Wang\"}],\"doi\":\"10.1109/TAFFC.2016.2518162\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b52886610eda6265a2c1aaf04ce209c047432b6d\",\"title\":\"Microexpression Identification and Categorization Using a Facial Dynamics Map\",\"url\":\"https://www.semanticscholar.org/paper/b52886610eda6265a2c1aaf04ce209c047432b6d\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2017},{\"arxivId\":\"1901.07765\",\"authors\":[{\"authorId\":\"145439284\",\"name\":\"Wei Peng\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/FG.2019.8756541\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5266a95c80ca658b6beff8e8f093c2fc2e4c8672\",\"title\":\"A Boost in Revealing Subtle Facial Expressions: A Consolidated Eulerian Framework\",\"url\":\"https://www.semanticscholar.org/paper/5266a95c80ca658b6beff8e8f093c2fc2e4c8672\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/ICCVW.2015.69\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39cf849f5af8dbc7fca81c6f16cbe482b38ab329\",\"title\":\"Deep Learning of Mouth Shapes for Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/39cf849f5af8dbc7fca81c6f16cbe482b38ab329\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2227025\",\"name\":\"Carol Mazuera\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/BIBM.2013.6732556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52698f413853266706ca0ba9c84ae0e16269d6d5\",\"title\":\"Visual speech learning from an e-tutor via dynamic lip movement-based video segmentation and comparison\",\"url\":\"https://www.semanticscholar.org/paper/52698f413853266706ca0ba9c84ae0e16269d6d5\",\"venue\":\"2013 IEEE International Conference on Bioinformatics and Biomedicine\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36369206\",\"name\":\"Iryna Anina\"},{\"authorId\":\"34849838\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/FG.2015.7163155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"653b957d4c70d6cbf8de443df497e47edcab77b4\",\"title\":\"OuluVS2: A multi-view audiovisual database for non-rigid mouth motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/653b957d4c70d6cbf8de443df497e47edcab77b4\",\"venue\":\"2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2015},{\"arxivId\":\"1710.02820\",\"authors\":[{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"7917586\",\"name\":\"Thuong-Khanh Tran\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"44c4aca17f74c76dbbb14af75a6ba89d6b4fb703\",\"title\":\"Micro-Expression Spotting: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/44c4aca17f74c76dbbb14af75a6ba89d6b4fb703\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"48345000\",\"name\":\"T. Ahonen\"}],\"doi\":\"10.1007/978-0-85729-748-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3304f46422f47f8218a38ab2e033b02445a0b59\",\"title\":\"Visual Recognition of Spoken Phrases\",\"url\":\"https://www.semanticscholar.org/paper/b3304f46422f47f8218a38ab2e033b02445a0b59\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41037279\",\"name\":\"Zun-Ci Lee\"},{\"authorId\":\"145016295\",\"name\":\"R. Phan\"},{\"authorId\":\"37809010\",\"name\":\"Su-Wei Tan\"},{\"authorId\":\"35602940\",\"name\":\"Kuan-Heng Lee\"}],\"doi\":\"10.1109/APSIPA.2017.8282117\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ba12937dc8063150ea254d13b02d822bd7d4691\",\"title\":\"Multimodal decomposition for enhanced subtle emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ba12937dc8063150ea254d13b02d822bd7d4691\",\"venue\":\"2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144213476\",\"name\":\"Chao Sui\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"}],\"doi\":\"10.1109/ICCV.2015.26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad036ad46fc14212d6b9ffdb1a823c4a9e89195b\",\"title\":\"Listening with Your Eyes: Towards a Practical Visual Speech Recognition System Using Deep Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/ad036ad46fc14212d6b9ffdb1a823c4a9e89195b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46935678\",\"name\":\"H. Liu\"},{\"authorId\":\"2866844\",\"name\":\"Ting Fan\"},{\"authorId\":\"47561464\",\"name\":\"Pingping Wu\"}],\"doi\":\"10.1109/ICRA.2014.6907840\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63f1a37500762c84f03418cbc2df6eff862cd1a9\",\"title\":\"Audio-visual keyword spotting based on adaptive decision fusion under noisy conditions for human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/63f1a37500762c84f03418cbc2df6eff862cd1a9\",\"venue\":\"2014 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50079101\",\"name\":\"Xiaobai Li\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"39056318\",\"name\":\"Antti Moilanen\"},{\"authorId\":\"47932625\",\"name\":\"Xiaohua Huang\"},{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbb2f81fc00ee0f257d4aa79bbef8cad5000ac59\",\"title\":\"Reading Hidden Emotions: Spontaneous Micro-expression Spotting and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fbb2f81fc00ee0f257d4aa79bbef8cad5000ac59\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3670839\",\"name\":\"Carlos A. Arango\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2d3c01ab6c5e0761ffb035425cc7a8ee6ef0012\",\"title\":\"Analysis of Micro-Expressions based on the Riesz Pyramid: Application to Spotting and Recognition. (Analyse des micro-expressions utilisant la pyramide de Riesz: application \\u00e0 la d\\u00e9tection et \\u00e0 la reconnaissance)\",\"url\":\"https://www.semanticscholar.org/paper/a2d3c01ab6c5e0761ffb035425cc7a8ee6ef0012\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144213476\",\"name\":\"Chao Sui\"},{\"authorId\":\"102561200\",\"name\":\"Roberto Togneri\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1016/j.specom.2017.01.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa8edf7dac61cefe66ae1d039001d7a990a3b050\",\"title\":\"A cascade gray-stereo visual feature extraction method for visual and audio-visual speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa8edf7dac61cefe66ae1d039001d7a990a3b050\",\"venue\":\"Speech Commun.\",\"year\":2017},{\"arxivId\":\"1701.05847\",\"authors\":[{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"8798628\",\"name\":\"Z. Li\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/ICASSP.2017.7952625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1e214cf61b9f6be6a67ebe129e6d34584e783d4\",\"title\":\"End-to-end visual speech recognition with LSTMS\",\"url\":\"https://www.semanticscholar.org/paper/f1e214cf61b9f6be6a67ebe129e6d34584e783d4\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104117062\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1016/j.imavis.2014.06.004\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c842fbd4c032dd4d931eb6ff1eaa2a13450b7af\",\"title\":\"A review of recent advances in visual speech decoding\",\"url\":\"https://www.semanticscholar.org/paper/4c842fbd4c032dd4d931eb6ff1eaa2a13450b7af\",\"venue\":\"Image Vis. Comput.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2553739\",\"name\":\"A. Rekik\"},{\"authorId\":\"1403815663\",\"name\":\"Achraf Ben-Hamadou\"},{\"authorId\":\"1979087\",\"name\":\"W. Mahdi\"}],\"doi\":\"10.1007/978-3-319-25903-1_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72f2aa44ea2b3e68a69bc030fbdb488f6c07fe14\",\"title\":\"Unified System for Visual Speech Recognition and Speaker Identification\",\"url\":\"https://www.semanticscholar.org/paper/72f2aa44ea2b3e68a69bc030fbdb488f6c07fe14\",\"venue\":\"ACIVS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2560252\",\"name\":\"K. Palecek\"}],\"doi\":\"10.1109/EUSIPCO.2016.7760575\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de37d9b0926441c27e14a57a30c50f0ad5b218aa\",\"title\":\"Lipreading using spatiotemporal histogram of oriented gradients\",\"url\":\"https://www.semanticscholar.org/paper/de37d9b0926441c27e14a57a30c50f0ad5b218aa\",\"venue\":\"2016 24th European Signal Processing Conference (EUSIPCO)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1016/j.neucom.2015.07.134\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f2dc51d607f491dbe6338711c073620c85351ac\",\"title\":\"Capturing correlations of local features for image representation\",\"url\":\"https://www.semanticscholar.org/paper/6f2dc51d607f491dbe6338711c073620c85351ac\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2553739\",\"name\":\"A. Rekik\"},{\"authorId\":\"1403815663\",\"name\":\"Achraf Ben-Hamadou\"},{\"authorId\":\"1979087\",\"name\":\"W. Mahdi\"}],\"doi\":\"10.1007/s11042-015-2774-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88284228406f7690772d8a86a7c7a14c1c019d9a\",\"title\":\"An adaptive approach for lip-reading using image and depth data\",\"url\":\"https://www.semanticscholar.org/paper/88284228406f7690772d8a86a7c7a14c1c019d9a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":\"1511.00423\",\"authors\":[{\"authorId\":\"33672691\",\"name\":\"X. Li\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"39056318\",\"name\":\"Antti Moilanen\"},{\"authorId\":\"47932625\",\"name\":\"Xiaohua Huang\"},{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/TAFFC.2017.2667642\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29cb1e90d1e08f0990925c8d4e8d00fa5fa49100\",\"title\":\"Towards Reading Hidden Emotions: A Comparative Study of Spontaneous Micro-Expression Spotting and Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/29cb1e90d1e08f0990925c8d4e8d00fa5fa49100\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31113456\",\"name\":\"Nai-Ming Yao\"},{\"authorId\":\"47666606\",\"name\":\"Hui Chen\"},{\"authorId\":\"147862313\",\"name\":\"Qing-Pei Guo\"},{\"authorId\":\"9133020\",\"name\":\"H. Wang\"}],\"doi\":\"10.1007/s11390-017-1792-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28093e46fbf89c3d9c59d0a011738e3c5709164c\",\"title\":\"Non-Frontal Facial Expression Recognition Using a Depth-Patch Based Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/28093e46fbf89c3d9c59d0a011738e3c5709164c\",\"venue\":\"Journal of Computer Science and Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2241348\",\"name\":\"Longbin Lu\"},{\"authorId\":\"2510349\",\"name\":\"X. Zhang\"},{\"authorId\":\"48670199\",\"name\":\"X. Xu\"},{\"authorId\":\"3216953\",\"name\":\"Dongpeng Shang\"}],\"doi\":\"10.1117/1.JEI.24.5.053023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b59093a96d64353812cf6595abeffae196b24bba\",\"title\":\"Video analysis using spatiotemporal descriptor and kernel extreme learning machine for lip reading\",\"url\":\"https://www.semanticscholar.org/paper/b59093a96d64353812cf6595abeffae196b24bba\",\"venue\":\"J. Electronic Imaging\",\"year\":2015}],\"corpusId\":1296476,\"doi\":\"10.1109/CVPR.2011.5995345\",\"fieldsOfStudy\":[\"Mathematics\",\"Computer Science\"],\"influentialCitationCount\":9,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"56b506a95cb63afd1e359babe1fdf3f0138ff7a4\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849838\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/ICPR.2010.133\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c77c72a071acf607bf210155b79eec530bec9f23\",\"title\":\"Lipreading: A Graph Embedding Approach\",\"url\":\"https://www.semanticscholar.org/paper/c77c72a071acf607bf210155b79eec530bec9f23\",\"venue\":\"2010 20th International Conference on Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"2158301\",\"name\":\"B. Zhang\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"},{\"authorId\":\"152290618\",\"name\":\"Qiang Yang\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"}],\"doi\":\"10.1109/TPAMI.2007.250598\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69381b5efd97e7c55f51c2730caccab3d632d4d2\",\"title\":\"Graph Embedding and Extensions: A General Framework for Dimensionality Reduction\",\"url\":\"https://www.semanticscholar.org/paper/69381b5efd97e7c55f51c2730caccab3d632d4d2\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Zhao\"},{\"authorId\":null,\"name\":\"M. Barnard\"},{\"authorId\":null,\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Lipreading with local spatialtemporal\",\"url\":\"\",\"venue\":\"descriptors. TMM,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2054241\",\"name\":\"H. McGurk\"},{\"authorId\":\"143965550\",\"name\":\"J. Macdonald\"}],\"doi\":\"10.1038/264746A0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eef41ae597a20ea377461d522fd5100da6a7a9b7\",\"title\":\"Hearing lips and seeing voices\",\"url\":\"https://www.semanticscholar.org/paper/eef41ae597a20ea377461d522fd5100da6a7a9b7\",\"venue\":\"Nature\",\"year\":1976},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3029782\",\"name\":\"S. Sonnenburg\"},{\"authorId\":\"152597562\",\"name\":\"Gunnar R\\u00e4tsch\"},{\"authorId\":\"1754319\",\"name\":\"C. Sch\\u00e4fer\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d26a48aff2abc3460c1018d5b410766f698d696c\",\"title\":\"Large Scale Multiple Kernel Learning\",\"url\":\"https://www.semanticscholar.org/paper/d26a48aff2abc3460c1018d5b410766f698d696c\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G Potamianos\"},{\"authorId\":null,\"name\":\"C Neti\"},{\"authorId\":null,\"name\":\"G Gravier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Recent advances in the automatic recognition of audio-visual speech. Proceedings of the IEEE\",\"url\":\"\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2173900\",\"name\":\"K. Messer\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"},{\"authorId\":\"1678373\",\"name\":\"J. Luettin\"},{\"authorId\":\"2488626\",\"name\":\"G. Ma\\u00eetre\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b62628ac06bbac998a3ab825324a41a11bc3a988\",\"title\":\"XM2VTSDB: The Extended M2VTS Database\",\"url\":\"https://www.semanticscholar.org/paper/b62628ac06bbac998a3ab825324a41a11bc3a988\",\"venue\":\"\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"},{\"authorId\":\"2264160\",\"name\":\"C. Neti\"},{\"authorId\":\"1708671\",\"name\":\"G. Gravier\"},{\"authorId\":\"1729828\",\"name\":\"A. Garg\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"}],\"doi\":\"10.1109/JPROC.2003.817150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3326838b53788bdb79d3b37b3ddad6a619ce53b1\",\"title\":\"Recent advances in the automatic recognition of audiovisual speech\",\"url\":\"https://www.semanticscholar.org/paper/3326838b53788bdb79d3b37b3ddad6a619ce53b1\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878872\",\"name\":\"G. I. Chiou\"},{\"authorId\":\"145159381\",\"name\":\"J. Hwang\"}],\"doi\":\"10.1109/83.605417\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2235f6a289ce22823858703651257b07b60eb8ec\",\"title\":\"Lipreading from color video\",\"url\":\"https://www.semanticscholar.org/paper/2235f6a289ce22823858703651257b07b60eb8ec\",\"venue\":\"IEEE Trans. Image Process.\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"},{\"authorId\":\"7205190\",\"name\":\"T. Cootes\"},{\"authorId\":\"144427091\",\"name\":\"J. Bangham\"},{\"authorId\":\"35132323\",\"name\":\"S. Cox\"},{\"authorId\":\"144439756\",\"name\":\"R. Harvey\"}],\"doi\":\"10.1109/34.982900\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f78867834f7f6797ca6396f98edb10aad2a864fb\",\"title\":\"Extraction of Visual Features for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/f78867834f7f6797ca6396f98edb10aad2a864fb\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"144302675\",\"name\":\"M. Barnard\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/TMM.2009.2030637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c4a6a915a7fbb9af5beeff55bf7d8cef18bf93a\",\"title\":\"Lipreading With Local Spatiotemporal Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/8c4a6a915a7fbb9af5beeff55bf7d8cef18bf93a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Chou\"},{\"authorId\":null,\"name\":\"J. Hwang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Lipreading from color\",\"url\":\"\",\"venue\":\"video. TIP,\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1109/ICCV.2005.167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff9efce2c082d9e164065b8d6455e8c8a7233a26\",\"title\":\"Neighborhood preserving embedding\",\"url\":\"https://www.semanticscholar.org/paper/ff9efce2c082d9e164065b8d6455e8c8a7233a26\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1798550\",\"name\":\"Timothy J. Hazen\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"3079356\",\"name\":\"C. La\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1145/1027933.1027972\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8365df47be3313e86be96d0f8f96d070c2d51128\",\"title\":\"A segment-based audio-visual speech recognizer: data collection, development, and initial experiments\",\"url\":\"https://www.semanticscholar.org/paper/8365df47be3313e86be96d0f8f96d070c2d51128\",\"venue\":\"ICMI '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"},{\"authorId\":\"39851640\",\"name\":\"X. Zhou\"},{\"authorId\":\"153699253\",\"name\":\"M. Liu\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICIP.2007.4379312\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba80ef508507341228f449884ee5171470d3a484\",\"title\":\"Lipreading by Locality Discriminant Graph\",\"url\":\"https://www.semanticscholar.org/paper/ba80ef508507341228f449884ee5171470d3a484\",\"venue\":\"2007 IEEE International Conference on Image Processing\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"},{\"authorId\":\"145668986\",\"name\":\"Michael Siracusa\"},{\"authorId\":\"12812321\",\"name\":\"K. Wilson\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2005.251\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c53f18c4c30d1d97f720493ec918ee60fa8dea02\",\"title\":\"Visual speech recognition with loosely synchronized feature streams\",\"url\":\"https://www.semanticscholar.org/paper/c53f18c4c30d1d97f720493ec918ee60fa8dea02\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120015576\",\"name\":\"U. Feige\"}],\"doi\":\"10.1090/cbms/129/05\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9de3f1ed6352262b24c63c3dad62e15a3ef5a653\",\"title\":\"Spectral graph theory\",\"url\":\"https://www.semanticscholar.org/paper/9de3f1ed6352262b24c63c3dad62e15a3ef5a653\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. McGurk\"},{\"authorId\":null,\"name\":\"J. MacDonald\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hearing lips and seeing\",\"url\":\"\",\"venue\":\"voices. Nature,\",\"year\":1976},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749663\",\"name\":\"Bowon Lee\"},{\"authorId\":\"1744418\",\"name\":\"Mark Hasegawa-Johnson\"},{\"authorId\":\"2867733\",\"name\":\"Camille Goudeseune\"},{\"authorId\":\"71668275\",\"name\":\"Suketu Kamdar\"},{\"authorId\":\"2759962\",\"name\":\"S. Borys\"},{\"authorId\":\"100520046\",\"name\":\"M. Liu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76541dc3140196e34202792a728c29ab7fb334da\",\"title\":\"AVICAR: audio-visual speech corpus in a car environment\",\"url\":\"https://www.semanticscholar.org/paper/76541dc3140196e34202792a728c29ab7fb334da\",\"venue\":\"INTERSPEECH\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145520115\",\"name\":\"M. Belkin\"},{\"authorId\":\"1770745\",\"name\":\"P. Niyogi\"}],\"doi\":\"10.7551/mitpress/1120.003.0080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d16c547d15a08091e68c86a99731b14366e3f0d\",\"title\":\"Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering\",\"url\":\"https://www.semanticscholar.org/paper/9d16c547d15a08091e68c86a99731b14366e3f0d\",\"venue\":\"NIPS\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144228552\",\"name\":\"C. Sanderson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9f606ad99406bd17eddc016203c6610e6315e4d\",\"title\":\"The VidTIMIT Database\",\"url\":\"https://www.semanticscholar.org/paper/f9f606ad99406bd17eddc016203c6610e6315e4d\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65739159\",\"name\":\"A. Chrz\\u0229szczyk\"},{\"authorId\":\"49730763\",\"name\":\"J. Kochanowski\"}],\"doi\":\"10.1007/978-0-387-09766-4_2219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"444d70e3331b5083b40ef32e49390ef683a65e67\",\"title\":\"Matrix Computations\",\"url\":\"https://www.semanticscholar.org/paper/444d70e3331b5083b40ef32e49390ef683a65e67\",\"venue\":\"Encyclopedia of Parallel Computing\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G Zhao\"},{\"authorId\":null,\"name\":\"M Barnard\"},{\"authorId\":null,\"name\":\"M Pietik\\u00e4inen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Lipreading with local spatialtemporal descriptors\",\"url\":\"\",\"venue\":\"TMM\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1705045\",\"name\":\"J. Junqua\"},{\"authorId\":\"144678172\",\"name\":\"B. K. Mak\"},{\"authorId\":\"15463221\",\"name\":\"B. Reaves\"}],\"doi\":\"10.1109/89.294354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f20241889fb729a22d624aa18f8ac299969e6b9\",\"title\":\"A robust algorithm for word boundary detection in the presence of noise\",\"url\":\"https://www.semanticscholar.org/paper/6f20241889fb729a22d624aa18f8ac299969e6b9\",\"venue\":\"IEEE Trans. Speech Audio Process.\",\"year\":1994}],\"title\":\"Towards a practical lipreading system\",\"topics\":[{\"topic\":\"Interpolation\",\"topicId\":\"1131\",\"url\":\"https://www.semanticscholar.org/topic/1131\"},{\"topic\":\"Academy\",\"topicId\":\"2609\",\"url\":\"https://www.semanticscholar.org/topic/2609\"},{\"topic\":\"Embedded system\",\"topicId\":\"4423\",\"url\":\"https://www.semanticscholar.org/topic/4423\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"}],\"url\":\"https://www.semanticscholar.org/paper/56b506a95cb63afd1e359babe1fdf3f0138ff7a4\",\"venue\":\"CVPR 2011\",\"year\":2011}\n"