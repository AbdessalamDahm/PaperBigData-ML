"{\"abstract\":\"This paper presents a method to synthesize a realistic facial animation of a target person, driven by a facial performance video of another person. Different from traditional facial animation approaches, our system takes advantage of an existing facial performance database of the target person, and generates the final video by retrieving frames from the database that have similar expressions to the input ones. To achieve this we develop an expression similarity metric for accurately measuring the expression difference between two video frames. To enforce temporal coherence, our system employs a shortest path algorithm to choose the optimal image for each frame from a set of candidate frames determined by the similarity metric. Finally, our system adopts an expression mapping method to further minimize the expression difference between the input and retrieved frames. Experimental results show that our system can generate high quality facial animation using the proposed data-driven approach.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"49243317\",\"name\":\"K. Li\",\"url\":\"https://www.semanticscholar.org/author/49243317\"},{\"authorId\":\"143979434\",\"name\":\"Feng Xu\",\"url\":\"https://www.semanticscholar.org/author/143979434\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\",\"url\":\"https://www.semanticscholar.org/author/48094509\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\",\"url\":\"https://www.semanticscholar.org/author/144954808\"},{\"authorId\":\"1680777\",\"name\":\"Yebin Liu\",\"url\":\"https://www.semanticscholar.org/author/1680777\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3182644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0af15b37d9a24c05df92d9004d11f78fa69b00c8\",\"title\":\"FaceVR: Real-Time Gaze-Aware Facial Reenactment in Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/0af15b37d9a24c05df92d9004d11f78fa69b00c8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2168593\",\"name\":\"R. Testa\"},{\"authorId\":\"35087278\",\"name\":\"C. Corr\\u00eaa\"},{\"authorId\":\"1400758287\",\"name\":\"A. Machado-Lima\"},{\"authorId\":\"143753143\",\"name\":\"F. Nunes\"}],\"doi\":\"10.1145/3292652\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2b0e74bfaa0ba299a2da2e9204edcb10e481f04\",\"title\":\"Synthesis of Facial Expressions in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/e2b0e74bfaa0ba299a2da2e9204edcb10e481f04\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":\"1610.03151\",\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3084822.3084841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b82576f647e74f83cf02023ece6610cc7c2eff7f\",\"title\":\"Demo of FaceVR: real-time facial reenactment and eye gaze control in virtual reality\",\"url\":\"https://www.semanticscholar.org/paper/b82576f647e74f83cf02023ece6610cc7c2eff7f\",\"venue\":\"SIGGRAPH Emerging Technologies\",\"year\":2017},{\"arxivId\":\"1712.03474\",\"authors\":[{\"authorId\":\"3051419\",\"name\":\"Lingxiao Song\"},{\"authorId\":\"9702077\",\"name\":\"Zhihe Lu\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1145/3240508.3240612\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f879556115284946637992191563849e840789d1\",\"title\":\"Geometry Guided Adversarial Facial Expression Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f879556115284946637992191563849e840789d1\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2508363.2508380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"976208323fd68f403e3d7c66f66d39f8788fe24c\",\"title\":\"Reconstructing detailed dynamic face geometry from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/976208323fd68f403e3d7c66f66d39f8788fe24c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47558508\",\"name\":\"Y. Chen\"},{\"authorId\":\"3327521\",\"name\":\"Chun-jian Hua\"},{\"authorId\":\"2191133\",\"name\":\"Xiuxiao Guo\"}],\"doi\":\"10.1007/s11045-015-0326-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9aea2f33f81694736236840d9df799bfb7aa4921\",\"title\":\"Face model fitting on video sequences based on incremental virtual active appearance model\",\"url\":\"https://www.semanticscholar.org/paper/9aea2f33f81694736236840d9df799bfb7aa4921\",\"venue\":\"Multidimens. Syst. Signal Process.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35375835\",\"name\":\"Erkam Uzun\"},{\"authorId\":\"51168620\",\"name\":\"S. P. Chung\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1738428\",\"name\":\"W. Lee\"}],\"doi\":\"10.14722/NDSS.2018.23253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cba275c14ba17e0cbbf7ff9979498a6eccfc87f1\",\"title\":\"rtCaptcha: A Real-Time CAPTCHA Based Liveness Detection System\",\"url\":\"https://www.semanticscholar.org/paper/cba275c14ba17e0cbbf7ff9979498a6eccfc87f1\",\"venue\":\"NDSS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49243317\",\"name\":\"K. Li\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"1680777\",\"name\":\"Yebin Liu\"},{\"authorId\":\"143979434\",\"name\":\"Feng Xu\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/TMM.2013.2293064\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"36c23dcfb7b5ae354d44caeb109b38292152e077\",\"title\":\"A Data-Driven Approach for Facial Expression Retargeting in Video\",\"url\":\"https://www.semanticscholar.org/paper/36c23dcfb7b5ae354d44caeb109b38292152e077\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50764005\",\"name\":\"Jesse Brizzi\"},{\"authorId\":\"1698267\",\"name\":\"D. Goldgof\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"},{\"authorId\":\"2835780\",\"name\":\"Matthew Shreve\"}],\"doi\":\"10.1109/ICPR.2014.98\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a17cf103e2eb409488d4ba8c709d6048c9cc10ba\",\"title\":\"Optical Flow Based Expression Suppression in Video\",\"url\":\"https://www.semanticscholar.org/paper/a17cf103e2eb409488d4ba8c709d6048c9cc10ba\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140064\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1109/CVPR.2016.262\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba11b4feb04a472cb5e5962697ed6faa653dc647\",\"title\":\"Face2Face: Real-Time Face Capture and Reenactment of RGB Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba11b4feb04a472cb5e5962697ed6faa653dc647\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2867075\",\"name\":\"Tomoki Hosoi\"}],\"doi\":\"10.1109/FG.2017.142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fb45e704ef3ca1f9c70e7be3fb93b53714ed8b5\",\"title\":\"Head Pose and Expression Transfer Using Facial Status Score\",\"url\":\"https://www.semanticscholar.org/paper/0fb45e704ef3ca1f9c70e7be3fb93b53714ed8b5\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"1710.06090\",\"authors\":[{\"authorId\":\"27013768\",\"name\":\"Runze Xu\"},{\"authorId\":\"145385776\",\"name\":\"Zhiming Zhou\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b7f82f86daae90b44b19db317a8005af29e8356\",\"title\":\"Face Transfer with Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/0b7f82f86daae90b44b19db317a8005af29e8356\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089247\",\"name\":\"L. Ma\"},{\"authorId\":\"144996593\",\"name\":\"Z. Deng\"}],\"doi\":\"10.1111/cgf.13586\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3829a78a84faf5c2610737f381cab0c4b496aaf3\",\"title\":\"Real\\u2010Time Facial Expression Transformation for Monocular RGB Video\",\"url\":\"https://www.semanticscholar.org/paper/3829a78a84faf5c2610737f381cab0c4b496aaf3\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712411\",\"name\":\"Swapna Agarwal\"},{\"authorId\":\"145478199\",\"name\":\"D. Mukherjee\"}],\"doi\":\"10.1109/TMM.2018.2871417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c644218ba51df87fa7b5c740a962c1b5b1ae131d\",\"title\":\"Synthesis of Realistic Facial Expressions Using Expression Map\",\"url\":\"https://www.semanticscholar.org/paper/c644218ba51df87fa7b5c740a962c1b5b1ae131d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021652\",\"name\":\"Changwei Luo\"},{\"authorId\":\"50812076\",\"name\":\"J. Yu\"},{\"authorId\":\"47057167\",\"name\":\"Xian Li\"},{\"authorId\":\"1766719\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/ICMEW.2014.6890554\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a6d7a3677e99b2e6ba7612c4bbf83cd1926f061\",\"title\":\"Realtime speech-driven facial animation using Gaussian Mixture Models\",\"url\":\"https://www.semanticscholar.org/paper/8a6d7a3677e99b2e6ba7612c4bbf83cd1926f061\",\"venue\":\"2014 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23728438\",\"name\":\"P. Adrian\"}],\"doi\":\"10.22028/D291-26785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15a3c96a0cf4c0d7f4abd025572255f82e017ff7\",\"title\":\"High-quality face capture, animation and editing from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/15a3c96a0cf4c0d7f4abd025572255f82e017ff7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2384894\",\"name\":\"Yunlian Sun\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"1725688\",\"name\":\"M. Tistarelli\"}],\"doi\":\"10.1109/TIFS.2020.2980792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d68882ef94965483b0301b44c8ae3705bc18c66\",\"title\":\"Facial Age and Expression Synthesis Using Ordinal Ranking Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d68882ef94965483b0301b44c8ae3705bc18c66\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2054975\",\"name\":\"Jingwan Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9c2e3d36b90a8341b37b35b7a96eeca4154a351\",\"title\":\"Data-driven Digital Drawing and Painting\",\"url\":\"https://www.semanticscholar.org/paper/c9c2e3d36b90a8341b37b35b7a96eeca4154a351\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"}],\"doi\":\"10.2312/2631994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4b03bb5ef6bae133a5ee6f6989d2c79220696b4\",\"title\":\"Face2Face: Real-time Facial Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/c4b03bb5ef6bae133a5ee6f6989d2c79220696b4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37016781\",\"name\":\"Supasorn Suwajanakorn\"},{\"authorId\":\"1396612598\",\"name\":\"Steven M. Seitz\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1145/3072959.3073640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"title\":\"Synthesizing Obama\",\"url\":\"https://www.semanticscholar.org/paper/7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1602.02651\",\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"2020396\",\"name\":\"Ole Rehmsen\"},{\"authorId\":\"2543070\",\"name\":\"Thorsten Thorm\\u00e4hlen\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1109/CVPR.2014.537\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a285f7d80e47b05ebff83387424cd0df8cb7833d\",\"title\":\"Automatic Face Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/a285f7d80e47b05ebff83387424cd0df8cb7833d\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143292\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"2020396\",\"name\":\"Ole Rehmsen\"},{\"authorId\":\"2543070\",\"name\":\"Thorsten Thorm\\u00e4hlen\"},{\"authorId\":\"144565378\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"46537749\",\"name\":\"C. Theobalt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22c985210a4d24235e08b52b49c85a9ae40b689d\",\"title\":\"Automatic Face Reenactment Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/22c985210a4d24235e08b52b49c85a9ae40b689d\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"3860190\",\"name\":\"Cem Keskin\"},{\"authorId\":null,\"name\":\"Jonathan Taylor\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"79406746\",\"name\":\"S. Izadi\"}],\"doi\":\"10.1109/3DV.2014.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48024400ea8c18cce47cc1391b5b95df446af298\",\"title\":\"Real-Time Face Reconstruction from a Single Depth Image\",\"url\":\"https://www.semanticscholar.org/paper/48024400ea8c18cce47cc1391b5b95df446af298\",\"venue\":\"2014 2nd International Conference on 3D Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388323535\",\"name\":\"Hadar Averbuch-Elor\"},{\"authorId\":\"1388323541\",\"name\":\"D. Cohen-Or\"},{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"}],\"doi\":\"10.1145/3130800.3130818\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99c46753dee61203dbdcbe65d5a19d4cba6e9b7c\",\"title\":\"Bringing portraits to life\",\"url\":\"https://www.semanticscholar.org/paper/99c46753dee61203dbdcbe65d5a19d4cba6e9b7c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b3cbfbb2774d05e217486ba662bd2b484513152\",\"title\":\"PROGRESSIVELY ATTENTIVE GANS\",\"url\":\"https://www.semanticscholar.org/paper/0b3cbfbb2774d05e217486ba662bd2b484513152\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2316162\",\"name\":\"Wanxin Xu\"}],\"doi\":\"10.13023/ETD.2018.303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"784b91dd2fa8ad5af854606132a5fb643309b2fa\",\"title\":\"AFFECT-PRESERVING VISUAL PRIVACY PROTECTION\",\"url\":\"https://www.semanticscholar.org/paper/784b91dd2fa8ad5af854606132a5fb643309b2fa\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"1401658974\",\"name\":\"Hamid Sarmadi\"},{\"authorId\":\"41178028\",\"name\":\"I. Steiner\"},{\"authorId\":\"13640633\",\"name\":\"K. Varanasi\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/cgf.12552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8128fb68dc94c086ba213a28ac132e53eb8da02a\",\"title\":\"VDub: Modifying Face Video of Actors for Plausible Visual Alignment to a Dubbed Audio Track\",\"url\":\"https://www.semanticscholar.org/paper/8128fb68dc94c086ba213a28ac132e53eb8da02a\",\"venue\":\"Comput. Graph. Forum\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153275560\",\"name\":\"Jiahao Geng\"},{\"authorId\":\"34620893\",\"name\":\"T. Shao\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"143663883\",\"name\":\"Y. Weng\"},{\"authorId\":\"144078074\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1145/3272127.3275043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59c654d13b3e228a15e83853d23b85dce106f994\",\"title\":\"Warp-guided GANs for single-photo facial animation\",\"url\":\"https://www.semanticscholar.org/paper/59c654d13b3e228a15e83853d23b85dce106f994\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"2007.14808\",\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3292039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"title\":\"Face2Face: real-time face capture and reenactment of RGB videos\",\"url\":\"https://www.semanticscholar.org/paper/bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"venue\":\"Commun. ACM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151914\",\"name\":\"Baris Gecer\"},{\"authorId\":\"50815847\",\"name\":\"Alexander Lattas\"},{\"authorId\":\"2015036\",\"name\":\"Stylianos Ploumpis\"},{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"144848303\",\"name\":\"A. Papaioannou\"},{\"authorId\":\"24278037\",\"name\":\"Stylianos Moschoglou\"},{\"authorId\":\"1379747201\",\"name\":\"Stefanos Zafeiriou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db04cf426357724df54519f8b8af1ca8b56dc38e\",\"title\":\"Synthesizing Coupled 3 D Face Modalities by Trunk-Branch Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/db04cf426357724df54519f8b8af1ca8b56dc38e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.02215\",\"authors\":[{\"authorId\":\"2151914\",\"name\":\"Baris Gecer\"},{\"authorId\":\"50815847\",\"name\":\"Alexander Lattas\"},{\"authorId\":\"2015036\",\"name\":\"Stylianos Ploumpis\"},{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"144848303\",\"name\":\"A. Papaioannou\"},{\"authorId\":\"24278037\",\"name\":\"Stylianos Moschoglou\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1007/978-3-030-58526-6_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13d7deb38eaad59a0121392731c2e6832b2d83f3\",\"title\":\"Synthesizing Coupled 3D Face Modalities by Trunk-Branch Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/13d7deb38eaad59a0121392731c2e6832b2d83f3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1807.11079\",\"authors\":[{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"6693591\",\"name\":\"Yunxuan Zhang\"},{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":null,\"name\":\"Chen Qian\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/978-3-030-01246-5_37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bfccbf6f4e88a92a7b1f2b5c588b68c5fa45a92\",\"title\":\"ReenactGAN: Learning to Reenact Faces via Boundary Transfer\",\"url\":\"https://www.semanticscholar.org/paper/2bfccbf6f4e88a92a7b1f2b5c588b68c5fa45a92\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.01815\",\"authors\":[{\"authorId\":\"34460642\",\"name\":\"B. Egger\"},{\"authorId\":\"145242734\",\"name\":\"W. Smith\"},{\"authorId\":\"9102722\",\"name\":\"A. Tewari\"},{\"authorId\":\"1792200\",\"name\":\"Stefanie Wuhrer\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"39600032\",\"name\":\"F. Bernard\"},{\"authorId\":\"1780750\",\"name\":\"Timo Bolkart\"},{\"authorId\":\"2780587\",\"name\":\"Adam Kortylewski\"},{\"authorId\":\"3293655\",\"name\":\"S. Romdhani\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2880906\",\"name\":\"V. Blanz\"},{\"authorId\":\"152979813\",\"name\":\"T. Vetter\"}],\"doi\":\"10.1145/3395208\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"579fe5fa694cf6b27229fd0f0ce7dc487e0ceb18\",\"title\":\"3D Morphable Face Models\\u2014Past, Present, and Future\",\"url\":\"https://www.semanticscholar.org/paper/579fe5fa694cf6b27229fd0f0ce7dc487e0ceb18\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2760845\",\"name\":\"Wolfgang Paier\"},{\"authorId\":\"2651791\",\"name\":\"M. Kettern\"},{\"authorId\":\"3353355\",\"name\":\"A. Hilsmann\"},{\"authorId\":\"46588404\",\"name\":\"P. Eisert\"}],\"doi\":\"10.1109/TCSVT.2016.2610078\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d842655236731c6dfae1fc7949bb3b41cf6d7b\",\"title\":\"A Hybrid Approach for Facial Performance Analysis and Editing\",\"url\":\"https://www.semanticscholar.org/paper/10d842655236731c6dfae1fc7949bb3b41cf6d7b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32069527\",\"name\":\"D. K. Jain\"},{\"authorId\":\"48805574\",\"name\":\"Zhang Zhang\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1016/J.PATREC.2017.06.025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc32d8f8a4401a40248c7de7414f6282e8a9246f\",\"title\":\"Multi angle optimal pattern-based deep learning for automatic facial expression recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc32d8f8a4401a40248c7de7414f6282e8a9246f\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2816795.2818056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"890f137efc064f82450c776e6a4141eb9f08fabc\",\"title\":\"Real-time expression transfer for facial reenactment\",\"url\":\"https://www.semanticscholar.org/paper/890f137efc064f82450c776e6a4141eb9f08fabc\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064558\",\"name\":\"L. Yang\"},{\"authorId\":\"144488755\",\"name\":\"H. Cheng\"},{\"authorId\":\"48692419\",\"name\":\"Jiasheng Hao\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"3008045\",\"name\":\"Yiqun Kuang\"}],\"doi\":\"10.1007/978-3-319-24078-7_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eba76117d991ad8a3e8f3af8e388f1b9fa6e93d5\",\"title\":\"A Survey on Media Interaction in Social Robotics\",\"url\":\"https://www.semanticscholar.org/paper/eba76117d991ad8a3e8f3af8e388f1b9fa6e93d5\",\"venue\":\"PCM\",\"year\":2015}],\"corpusId\":13891935,\"doi\":\"10.1109/CVPR.2012.6247658\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"b5fa5a541bf985b99d6174291ec2a233e7315aea\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"7205190\",\"name\":\"T. Cootes\"},{\"authorId\":\"50564384\",\"name\":\"G. Edwards\"},{\"authorId\":\"144482985\",\"name\":\"C. Taylor\"}],\"doi\":\"10.1007/BFb0054760\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76b532e2cb573fdf29f3ae68dc1372f3319c93c2\",\"title\":\"Active Appearance Models\",\"url\":\"https://www.semanticscholar.org/paper/76b532e2cb573fdf29f3ae68dc1372f3319c93c2\",\"venue\":\"ECCV\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50160727\",\"name\":\"M. Lyons\"},{\"authorId\":\"49052113\",\"name\":\"S. Akamatsu\"},{\"authorId\":\"47451213\",\"name\":\"M. Kamachi\"},{\"authorId\":\"8365437\",\"name\":\"J. Gyoba\"}],\"doi\":\"10.1109/AFGR.1998.670949\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee48190c8c5429c1633100777d226c4855cc6224\",\"title\":\"Coding facial expressions with Gabor wavelets\",\"url\":\"https://www.semanticscholar.org/paper/ee48190c8c5429c1633100777d226c4855cc6224\",\"venue\":\"Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2246174\",\"name\":\"T. Weise\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/1599470.1599472\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b56de69c598ebdf9a53e5c4c16fa11e07a3e24b1\",\"title\":\"Face/Off: live facial puppetry\",\"url\":\"https://www.semanticscholar.org/paper/b56de69c598ebdf9a53e5c4c16fa11e07a3e24b1\",\"venue\":\"SCA '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817134\",\"name\":\"F. Pighin\"},{\"authorId\":\"49087082\",\"name\":\"Jamie Hecker\"},{\"authorId\":\"1684384\",\"name\":\"Dani Lischinski\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"}],\"doi\":\"10.1145/280814.280825\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"060d064400246f35a0e71494b8bd24413683f067\",\"title\":\"Synthesizing realistic facial expressions from photographs\",\"url\":\"https://www.semanticscholar.org/paper/060d064400246f35a0e71494b8bd24413683f067\",\"venue\":\"SIGGRAPH '98\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36274723\",\"name\":\"L. Kovar\"},{\"authorId\":\"1776507\",\"name\":\"M. Gleicher\"}],\"doi\":\"10.2312/SCA03/214-224\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"806c258ec33890e2c95eb79f27ed07a13c42c219\",\"title\":\"Flexible automatic motion blending with registration curves\",\"url\":\"https://www.semanticscholar.org/paper/806c258ec33890e2c95eb79f27ed07a13c42c219\",\"venue\":\"SCA '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706573\",\"name\":\"L. Williams\"}],\"doi\":\"10.1145/97879.97906\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5569fc532eb94ec167f8ffc204ef17585e040c8c\",\"title\":\"Performance-driven facial animation\",\"url\":\"https://www.semanticscholar.org/paper/5569fc532eb94ec167f8ffc204ef17585e040c8c\",\"venue\":\"SIGGRAPH\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059221\",\"name\":\"L. Zhang\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"143800609\",\"name\":\"Brian Curless\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1145/1015706.1015759\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a2096584572b6e4a22d0999c15073ebd78af4f6\",\"title\":\"Spacetime faces: high resolution capture for modeling and animation\",\"url\":\"https://www.semanticscholar.org/paper/7a2096584572b6e4a22d0999c15073ebd78af4f6\",\"venue\":\"SIGGRAPH 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144522420\",\"name\":\"T. Ojala\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"},{\"authorId\":\"26883091\",\"name\":\"Topi M\\u00e4enp\\u00e4\\u00e4\"}],\"doi\":\"10.1109/TPAMI.2002.1017623\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f11a7136b6b7854bd0998ef463ffa8e907c411a2\",\"title\":\"Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns\",\"url\":\"https://www.semanticscholar.org/paper/f11a7136b6b7854bd0998ef463ffa8e907c411a2\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2246174\",\"name\":\"T. Weise\"},{\"authorId\":\"35119991\",\"name\":\"Sofien Bouaziz\"},{\"authorId\":\"144966719\",\"name\":\"Hao Li\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/1964921.1964972\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"177e876c9e0f1ade353b4744dcee7754d6411837\",\"title\":\"Realtime performance-based facial animation\",\"url\":\"https://www.semanticscholar.org/paper/177e876c9e0f1ade353b4744dcee7754d6411837\",\"venue\":\"SIGGRAPH '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21451088\",\"name\":\"P. Ekman\"},{\"authorId\":\"37652085\",\"name\":\"W. Friesen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1566cf20e2ba91ca8857c30083419bf7c127094b\",\"title\":\"Facial action coding system: a technique for the measurement of facial movement\",\"url\":\"https://www.semanticscholar.org/paper/1566cf20e2ba91ca8857c30083419bf7c127094b\",\"venue\":\"\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144097660\",\"name\":\"M. Turk\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71d67283157475c4e6460c52408c00e9f6b8d2fe\",\"title\":\"A morphable model for the synthesis of 3D faces\",\"url\":\"https://www.semanticscholar.org/paper/71d67283157475c4e6460c52408c00e9f6b8d2fe\",\"venue\":\"SIGGRAPH 1999\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144039941\",\"name\":\"K. Dale\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"13594727\",\"name\":\"Micah K. Johnson\"},{\"authorId\":\"1880628\",\"name\":\"D. Vlasic\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/2024156.2024164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f326fd805ae74f3773c5eda789aee890b59cc1fb\",\"title\":\"Video face replacement\",\"url\":\"https://www.semanticscholar.org/paper/f326fd805ae74f3773c5eda789aee890b59cc1fb\",\"venue\":\"SA '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3039711\",\"name\":\"Yue Deng\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"},{\"authorId\":\"1778135\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1109/TIP.2011.2109729\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf749985354ab81240a7bd69bd9d943e57e32889\",\"title\":\"Graph Laplace for Occluded Face Completion and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf749985354ab81240a7bd69bd9d943e57e32889\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40019208\",\"name\":\"T. Beier\"},{\"authorId\":\"35176778\",\"name\":\"S. Neely\"}],\"doi\":\"10.1145/133994.134003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be73726c6a538bc3ed05e62ba5faec183f777ff6\",\"title\":\"Feature-based image metamorphosis\",\"url\":\"https://www.semanticscholar.org/paper/be73726c6a538bc3ed05e62ba5faec183f777ff6\",\"venue\":\"SIGGRAPH '92\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713496\",\"name\":\"P. Lucey\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"2398245\",\"name\":\"Jason M. Saragih\"},{\"authorId\":\"2059653\",\"name\":\"Z. Ambadar\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"}],\"doi\":\"10.1109/CVPRW.2010.5543262\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dcdfe89a36e4e54d33362c164e09709a19bef7f\",\"title\":\"The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression\",\"url\":\"https://www.semanticscholar.org/paper/7dcdfe89a36e4e54d33362c164e09709a19bef7f\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750780\",\"name\":\"X. Yang\"}],\"doi\":\"10.1016/B978-0-12-416743-8.00001-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a074e2ac78ebb6158457aa4045fd92aeaba1ac1\",\"title\":\"Introduction to Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/2a074e2ac78ebb6158457aa4045fd92aeaba1ac1\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46324643\",\"name\":\"Qingshan Zhang\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"143632999\",\"name\":\"B. Guo\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"}],\"doi\":\"10.1109/TVCG.2006.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09f8c1ecb3f868249fcc86cd3f6cbe112a661fe8\",\"title\":\"Geometry-driven photorealistic facial expression synthesis\",\"url\":\"https://www.semanticscholar.org/paper/09f8c1ecb3f868249fcc86cd3f6cbe112a661fe8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143979434\",\"name\":\"Feng Xu\"},{\"authorId\":\"1680777\",\"name\":\"Yebin Liu\"},{\"authorId\":\"2217934\",\"name\":\"Carsten Stoll\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"3090007\",\"name\":\"Gaurav Bharaj\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/1964921.1964927\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33850e715dfbf05109d6eb8c1745b96b8d5c0115\",\"title\":\"Video-based characters: creating new human performances from a multi-view video database\",\"url\":\"https://www.semanticscholar.org/paper/33850e715dfbf05109d6eb8c1745b96b8d5c0115\",\"venue\":\"ACM Trans. Graph.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116454272\",\"name\":\"Jun-yong Noh\"},{\"authorId\":\"143840663\",\"name\":\"U. Neumann\"}],\"doi\":\"10.1145/383259.383290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0c58661d9b5197a7c9990b4cd86bf9c9282365\",\"title\":\"Expression cloning\",\"url\":\"https://www.semanticscholar.org/paper/1a0c58661d9b5197a7c9990b4cd86bf9c9282365\",\"venue\":\"SIGGRAPH Courses\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2724380\",\"name\":\"Gwen Littlewort\"},{\"authorId\":\"143973061\",\"name\":\"Jacob Whitehill\"},{\"authorId\":\"4072965\",\"name\":\"Tingfan Wu\"},{\"authorId\":\"2039025\",\"name\":\"Ian R. Fasel\"},{\"authorId\":\"49363690\",\"name\":\"M. Frank\"},{\"authorId\":\"1741200\",\"name\":\"J. Movellan\"},{\"authorId\":\"2218905\",\"name\":\"M. Bartlett\"}],\"doi\":\"10.1109/FG.2011.5771414\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b638b5fd3cf2d1c4361ca5f8fc8f5c91a64a4e7b\",\"title\":\"The computer expression recognition toolbox (CERT)\",\"url\":\"https://www.semanticscholar.org/paper/b638b5fd3cf2d1c4361ca5f8fc8f5c91a64a4e7b\",\"venue\":\"Face and Gesture 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"},{\"authorId\":\"1724754\",\"name\":\"C. Dyer\"}],\"doi\":\"10.1145/237170.237196\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c7fe406304cfc2d12fd478a0dddeedcf853c6a3\",\"title\":\"View morphing\",\"url\":\"https://www.semanticscholar.org/paper/1c7fe406304cfc2d12fd478a0dddeedcf853c6a3\",\"venue\":\"SIGGRAPH '96\",\"year\":1996},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Figure 8 Result of query sequence 2 performed on subject S130 from CK+. (top) Query frames. (middle) Retrieved and EMI frames (left and right, respectively). (bottom) Final synthesized frames\",\"url\":\"\",\"venue\":\"Figure 8 Result of query sequence 2 performed on subject S130 from CK+. (top) Query frames. (middle) Retrieved and EMI frames (left and right, respectively). (bottom) Final synthesized frames\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7205190\",\"name\":\"T. Cootes\"},{\"authorId\":\"144482985\",\"name\":\"C. Taylor\"},{\"authorId\":\"32250556\",\"name\":\"D. Cooper\"},{\"authorId\":\"47581828\",\"name\":\"J. Graham\"}],\"doi\":\"10.1006/cviu.1995.1004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f731b6745d829241941307c3ebf163e90e200318\",\"title\":\"Active Shape Models-Their Training and Application\",\"url\":\"https://www.semanticscholar.org/paper/f731b6745d829241941307c3ebf163e90e200318\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1880628\",\"name\":\"D. Vlasic\"},{\"authorId\":\"144549270\",\"name\":\"M. Brand\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"},{\"authorId\":\"145492783\",\"name\":\"J. Popovic\"}],\"doi\":\"10.1145/1186822.1073209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2290765ce72ea84af8ac7535d4159f223eefdd3\",\"title\":\"Face transfer with multilinear models\",\"url\":\"https://www.semanticscholar.org/paper/a2290765ce72ea84af8ac7535d4159f223eefdd3\",\"venue\":\"ACM Trans. Graph.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"145089705\",\"name\":\"Ying Shan\"},{\"authorId\":\"1809184\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1145/383259.383289\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d11a02bd1b5b14cac8ba7011671cf1bfd6c165b2\",\"title\":\"Expressive expression mapping with ratio images\",\"url\":\"https://www.semanticscholar.org/paper/d11a02bd1b5b14cac8ba7011671cf1bfd6c165b2\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"145624835\",\"name\":\"Rahul Garg\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1145/1964921.1964956\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ce3a91214c94ed05f15343490981ec7cc810016\",\"title\":\"Exploring photobios\",\"url\":\"https://www.semanticscholar.org/paper/1ce3a91214c94ed05f15343490981ec7cc810016\",\"venue\":\"ACM Trans. Graph.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2880906\",\"name\":\"V. Blanz\"},{\"authorId\":\"35943905\",\"name\":\"C. Basso\"},{\"authorId\":\"1685292\",\"name\":\"T. Poggio\"},{\"authorId\":\"144517651\",\"name\":\"T. Vetter\"}],\"doi\":\"10.1111/1467-8659.t01-1-00712\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba81d93e6da193d458be0ae1bd896ba47afce4b5\",\"title\":\"Reanimating Faces in Images and Video\",\"url\":\"https://www.semanticscholar.org/paper/ba81d93e6da193d458be0ae1bd896ba47afce4b5\",\"venue\":\"Comput. Graph. Forum\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66313d48a6352e731e40450f80a66c64aabae817\",\"title\":\"Exploring new representations and applications for motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/66313d48a6352e731e40450f80a66c64aabae817\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2615673\",\"name\":\"Peter Litwinowicz\"},{\"authorId\":\"145706573\",\"name\":\"L. Williams\"}],\"doi\":\"10.1145/192161.192270\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"486fd6cb2c7415125fce9fdb55799ff38fbe0246\",\"title\":\"Animating images with drawings\",\"url\":\"https://www.semanticscholar.org/paper/486fd6cb2c7415125fce9fdb55799ff38fbe0246\",\"venue\":\"SIGGRAPH '94\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"},{\"authorId\":\"145630386\",\"name\":\"Aditya Sankar\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-642-15549-9_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7862f646d640cbf9f88e5ba94a7d642e2a552ec9\",\"title\":\"Being John Malkovich\",\"url\":\"https://www.semanticscholar.org/paper/7862f646d640cbf9f88e5ba94a7d642e2a552ec9\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398245\",\"name\":\"Jason M. Saragih\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"}],\"doi\":\"10.1109/FG.2011.5771383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f744f25118d5afe35fdad4741222acdc21fe2af7\",\"title\":\"Real-time avatar animation from a single image\",\"url\":\"https://www.semanticscholar.org/paper/f744f25118d5afe35fdad4741222acdc21fe2af7\",\"venue\":\"Face and Gesture 2011\",\"year\":2011}],\"title\":\"A data-driven approach for facial expression synthesis in video\",\"topics\":[{\"topic\":\"Collision detection\",\"topicId\":\"38329\",\"url\":\"https://www.semanticscholar.org/topic/38329\"},{\"topic\":\"Dijkstra's algorithm\",\"topicId\":\"107933\",\"url\":\"https://www.semanticscholar.org/topic/107933\"},{\"topic\":\"Facial recognition system\",\"topicId\":\"30847\",\"url\":\"https://www.semanticscholar.org/topic/30847\"},{\"topic\":\"Shortest path problem\",\"topicId\":\"28585\",\"url\":\"https://www.semanticscholar.org/topic/28585\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Display resolution\",\"topicId\":\"11387\",\"url\":\"https://www.semanticscholar.org/topic/11387\"}],\"url\":\"https://www.semanticscholar.org/paper/b5fa5a541bf985b99d6174291ec2a233e7315aea\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012}\n"