"{\"abstract\":\"This paper proposes the novel task of video generation conditioned on a SINGLE semantic label map, which provides a good balance between flexibility and quality in the generation process. Different from typical end-to-end approaches, which model both scene content and dynamics in a single step, we propose to decompose this difficult task into two sub-problems. As current image generation methods do better than video generation in terms of detail, we synthesize high quality content by only generating the first frame. Then we animate the scene based on its semantic meaning to obtain temporally coherent video, giving us excellent results overall. We employ a cVAE for predicting optical flow as a beneficial intermediate step to generate a video sequence conditioned on the initial single frame. A semantic label map is integrated into the flow prediction module to achieve major improvements in the image-to-video generation process. Extensive experiments on the Cityscapes dataset show that our method outperforms all competing methods.\",\"arxivId\":\"1903.04480\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\",\"url\":\"https://www.semanticscholar.org/author/7588865\"},{\"authorId\":null,\"name\":\"Chengyu Wang\",\"url\":null},{\"authorId\":\"143904396\",\"name\":\"Xu Jia\",\"url\":\"https://www.semanticscholar.org/author/143904396\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\",\"url\":\"https://www.semanticscholar.org/author/144478188\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\",\"url\":\"https://www.semanticscholar.org/author/37145669\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\",\"url\":\"https://www.semanticscholar.org/author/1721677\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\",\"url\":\"https://www.semanticscholar.org/author/31843833\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":\"2001.02354\",\"authors\":[{\"authorId\":\"13457166\",\"name\":\"Yanliang Zhu\"},{\"authorId\":\"3405992\",\"name\":\"Deheng Qian\"},{\"authorId\":\"2983017\",\"name\":\"Dongchun Ren\"},{\"authorId\":\"40044578\",\"name\":\"H. Xia\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5293f5e35db32296d1ef17bdf4c472d45755cbe1\",\"title\":\"VisionNet: A Drivable-space-based Interactive Motion Prediction Network for Autonomous Driving\",\"url\":\"https://www.semanticscholar.org/paper/5293f5e35db32296d1ef17bdf4c472d45755cbe1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"8756547\",\"name\":\"Liya Kong\"},{\"authorId\":\"153043900\",\"name\":\"Zhi-Ping Zhou\"}],\"doi\":\"10.1016/j.jvcir.2020.102956\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32a9b74561ee7c7b2d9663248b515168676d9321\",\"title\":\"Improved-StoryGAN for sequential images visualization\",\"url\":\"https://www.semanticscholar.org/paper/32a9b74561ee7c7b2d9663248b515168676d9321\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"2008.04776\",\"authors\":[{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"145194966\",\"name\":\"Chao Xu\"},{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1490938675\",\"name\":\"Xia Wu\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"},{\"authorId\":\"122376816\",\"name\":\"Yunliang Jiang\"}],\"doi\":\"10.1007/978-3-030-58558-7_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1847cbb4064ca05593f7b408783e9f183953488\",\"title\":\"DTVNet: Dynamic Time-lapse Video Generation via Single Still Image\",\"url\":\"https://www.semanticscholar.org/paper/c1847cbb4064ca05593f7b408783e9f183953488\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.08397\",\"authors\":[{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-58571-6_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4e84b1cbf81a6c89c1f0cc9ed2496ea5102fa56\",\"title\":\"Controllable Image Synthesis via SegVAE\",\"url\":\"https://www.semanticscholar.org/paper/c4e84b1cbf81a6c89c1f0cc9ed2496ea5102fa56\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.08509\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36775862\",\"name\":\"K. Sapra\"},{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"}],\"doi\":\"10.1007/978-3-030-58598-3_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"633a7a0c92dd8c254b65a11b759b99c157e115c7\",\"title\":\"World-Consistent Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/633a7a0c92dd8c254b65a11b759b99c157e115c7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993663564\",\"name\":\"Mingyao Hong\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413517\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2009d525afc02cdc60270669ec760d222ef5bd32\",\"title\":\"Generalized Zero-Shot Video Classification via Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2009d525afc02cdc60270669ec760d222ef5bd32\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1812.01874\",\"authors\":[{\"authorId\":\"5437547\",\"name\":\"Qiyang Hu\"},{\"authorId\":\"1822120361\",\"name\":\"Adrian Walchli\"},{\"authorId\":\"21529935\",\"name\":\"Tiziano Portenier\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bb74e29321772ea815f88769d31a902a2c3e996\",\"title\":\"Learning to Take Directions One Step at a Time\",\"url\":\"https://www.semanticscholar.org/paper/6bb74e29321772ea815f88769d31a902a2c3e996\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.02250\",\"authors\":[{\"authorId\":\"51235324\",\"name\":\"Nuha Aldausari\"},{\"authorId\":\"145313633\",\"name\":\"A. Sowmya\"},{\"authorId\":\"47600265\",\"name\":\"N. Marcus\"},{\"authorId\":\"4911295\",\"name\":\"G. Mohammadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b\",\"title\":\"Video Generative Adversarial Networks: A Review\",\"url\":\"https://www.semanticscholar.org/paper/5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.01823\",\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"title\":\"Temporal Shift GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.05523\",\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/CVPR42600.2020.00531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33392bb15145ba1c7681061ce891f2e49354ca17\",\"title\":\"G3AN: Disentangling Appearance and Motion for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/33392bb15145ba1c7681061ce891f2e49354ca17\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101947437\",\"name\":\"J. Saric\"},{\"authorId\":\"3009751\",\"name\":\"M. Orsic\"},{\"authorId\":\"2111962\",\"name\":\"Tonci Antunovic\"},{\"authorId\":\"3237756\",\"name\":\"Sacha Vrazic\"},{\"authorId\":\"3166278\",\"name\":\"Sinisa Segvic\"}],\"doi\":\"10.1109/CVPR42600.2020.01066\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"921faa221b44a3cac6587172866fb58073bbc3c0\",\"title\":\"Warp to the Future: Joint Forecasting of Features and Feature Motion\",\"url\":\"https://www.semanticscholar.org/paper/921faa221b44a3cac6587172866fb58073bbc3c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.15128\",\"authors\":[{\"authorId\":\"118300344\",\"name\":\"Aleksander Holynski\"},{\"authorId\":\"1396759259\",\"name\":\"Brian Curless\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"title\":\"Animating Pictures with Eulerian Motion Fields\",\"url\":\"https://www.semanticscholar.org/paper/a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06628\",\"authors\":[{\"authorId\":\"121544228\",\"name\":\"Z. Li\"},{\"authorId\":\"1813796\",\"name\":\"Zhaopeng Cui\"},{\"authorId\":\"1821761\",\"name\":\"M. Oswald\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbaa5a95aba6cccb7c9885db0329c413f12bbb22\",\"title\":\"Street-view Panoramic Video Synthesis from a Single Satellite Image\",\"url\":\"https://www.semanticscholar.org/paper/bbaa5a95aba6cccb7c9885db0329c413f12bbb22\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"title\":\"Multi-Variate Temporal GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.12713\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea92a69b48287caa3a25ff3dfe727bed8888348\",\"title\":\"Few-shot Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bea92a69b48287caa3a25ff3dfe727bed8888348\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2008.09646\",\"authors\":[{\"authorId\":\"1581479411\",\"name\":\"Abhinav Sagar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b367a582b8921997bbbea433bf99c4671568b44c\",\"title\":\"HRVGAN: High Resolution Video Generation using Spatio-Temporal GAN\",\"url\":\"https://www.semanticscholar.org/paper/b367a582b8921997bbbea433bf99c4671568b44c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cfb522acca27ee7b0cdd1e4a8f5af492ac5c87d\",\"title\":\"G3AN: This video does not exist. Disentangling motion and appearance for video generation\",\"url\":\"https://www.semanticscholar.org/paper/8cfb522acca27ee7b0cdd1e4a8f5af492ac5c87d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"48605271\",\"name\":\"J. Guo\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/s11263-020-01334-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"991649f2903d05a27243a7d26016c4df735a6fbb\",\"title\":\"High-Quality Video Generation from Static Structural Annotations\",\"url\":\"https://www.semanticscholar.org/paper/991649f2903d05a27243a7d26016c4df735a6fbb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2006.10704\",\"authors\":[{\"authorId\":\"145411379\",\"name\":\"R. Rakhimov\"},{\"authorId\":\"9937997\",\"name\":\"Denis Volkhonskiy\"},{\"authorId\":\"145235439\",\"name\":\"A. Artemov\"},{\"authorId\":\"145516498\",\"name\":\"D. Zorin\"},{\"authorId\":\"51139941\",\"name\":\"Evgeny Burnaev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef25fe928b5a9f53296a938339dff5aeffcf6e7b\",\"title\":\"Latent Video Transformer\",\"url\":\"https://www.semanticscholar.org/paper/ef25fe928b5a9f53296a938339dff5aeffcf6e7b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"144978989\",\"name\":\"Y. Tian\"},{\"authorId\":\"1379758006\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/s11263-020-01328-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"title\":\"Towards Image-to-Video Translation: A Structure-Aware Approach via Multi-stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2008.09655\",\"authors\":[{\"authorId\":\"145879692\",\"name\":\"E. Logacheva\"},{\"authorId\":\"1956107\",\"name\":\"R. Suvorov\"},{\"authorId\":\"50168812\",\"name\":\"Oleg Khomenko\"},{\"authorId\":\"51995877\",\"name\":\"A. Mashikhin\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"7594d6e232599e7f792e416a420a4102435ce631\",\"title\":\"DeepLandscape: Adversarial Modeling of Landscape Video\",\"url\":\"https://www.semanticscholar.org/paper/7594d6e232599e7f792e416a420a4102435ce631\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13898\",\"authors\":[{\"authorId\":\"145462897\",\"name\":\"Hao Tang\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"144742695\",\"name\":\"D. Xu\"},{\"authorId\":\"1730268\",\"name\":\"P. H. S. Torr\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"453d41957a9a0ee807790be4f673da147128d468\",\"title\":\"Edge Guided GANs with Semantic Preserving for Semantic Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/453d41957a9a0ee807790be4f673da147128d468\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":73728538,\"doi\":\"10.1109/CVPR.2019.00385\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"2f66d531439f5847afa7b31f49db87a44b788690\",\"references\":[{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1604.01685\",\"authors\":[{\"authorId\":\"2841796\",\"name\":\"Marius Cordts\"},{\"authorId\":\"144187309\",\"name\":\"Mohamed Omran\"},{\"authorId\":\"39940699\",\"name\":\"Sebastian Ramos\"},{\"authorId\":\"3393153\",\"name\":\"Timo Rehfeld\"},{\"authorId\":\"1765022\",\"name\":\"M. Enzweiler\"},{\"authorId\":\"1798000\",\"name\":\"Rodrigo Benenson\"},{\"authorId\":\"145582788\",\"name\":\"Uwe Franke\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2016.350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8c494ee5488fe20e0aa01bddf3fc4632086d654\",\"title\":\"The Cityscapes Dataset for Semantic Urban Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c8c494ee5488fe20e0aa01bddf3fc4632086d654\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1710.11252\",\"authors\":[{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"143775101\",\"name\":\"R. Campbell\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"title\":\"Stochastic Variational Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1701.01821\",\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"3378457\",\"name\":\"Boya Peng\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"title\":\"Unsupervised Learning of Long-Term Motion Dynamics for Videos\",\"url\":\"https://www.semanticscholar.org/paper/cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1804.07739\",\"authors\":[{\"authorId\":\"47231927\",\"name\":\"G. Balakrishnan\"},{\"authorId\":\"2584689\",\"name\":\"Amy Zhao\"},{\"authorId\":\"3046516\",\"name\":\"Adrian V. Dalca\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1724429\",\"name\":\"J. Guttag\"}],\"doi\":\"10.1109/CVPR.2018.00870\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bd2ce1d6b4f675dfba3a12ca0254c1ba8f6689a\",\"title\":\"Synthesizing Images of Humans in Unseen Poses\",\"url\":\"https://www.semanticscholar.org/paper/1bd2ce1d6b4f675dfba3a12ca0254c1ba8f6689a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.09368\",\"authors\":[{\"authorId\":\"1847145\",\"name\":\"Liqian Ma\"},{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33469aa1130c6bfb838fbb6216f5c42c483a2799\",\"title\":\"Pose Guided Person Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/33469aa1130c6bfb838fbb6216f5c42c483a2799\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1705.00053\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2017.361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"title\":\"The Pose Knows: Video Forecasting by Generating Pose Futures\",\"url\":\"https://www.semanticscholar.org/paper/3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1802.07687\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de3b9eb697feed3d097e3f671afe395f48c1ab76\",\"title\":\"Stochastic Video Generation with a Learned Prior\",\"url\":\"https://www.semanticscholar.org/paper/de3b9eb697feed3d097e3f671afe395f48c1ab76\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1612.07828\",\"authors\":[{\"authorId\":\"144135527\",\"name\":\"A. Shrivastava\"},{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"153410114\",\"name\":\"Josh Susskind\"},{\"authorId\":\"46314780\",\"name\":\"Wenda Wang\"},{\"authorId\":\"143606380\",\"name\":\"R. Webb\"}],\"doi\":\"10.1109/CVPR.2017.241\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68cb9fce1e6af2740377494350b650533c9a29e1\",\"title\":\"Learning from Simulated and Unsupervised Images through Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/68cb9fce1e6af2740377494350b650533c9a29e1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48935207\",\"name\":\"C. Zhang\"},{\"authorId\":\"46947640\",\"name\":\"Z. Li\"},{\"authorId\":\"145625690\",\"name\":\"Rui Cai\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1007/978-3-319-10605-2_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6989cdd3774e2a782c10dbbbaf5b979a503ac7b4\",\"title\":\"As-Rigid-As-Possible Stereo under Second Order Smoothness Priors\",\"url\":\"https://www.semanticscholar.org/paper/6989cdd3774e2a782c10dbbbaf5b979a503ac7b4\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1612.05424\",\"authors\":[{\"authorId\":\"2732737\",\"name\":\"Konstantinos Bousmalis\"},{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"35363891\",\"name\":\"David Dohan\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"1707347\",\"name\":\"Dilip Krishnan\"}],\"doi\":\"10.1109/CVPR.2017.18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"220ac48a22547a455d05f416e1fd22bbd0b0788d\",\"title\":\"Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/220ac48a22547a455d05f416e1fd22bbd0b0788d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1611.06624\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":\"10.1109/ICCV.2017.308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"title\":\"Temporal Generative Adversarial Nets with Singular Value Clipping\",\"url\":\"https://www.semanticscholar.org/paper/062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"},{\"authorId\":\"37108776\",\"name\":\"Philip Lenz\"},{\"authorId\":\"1760556\",\"name\":\"C. Stiller\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1177/0278364913491297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79b949d9b35c3f51dd20fb5c746cc81fc87147eb\",\"title\":\"Vision meets robotics: The KITTI dataset\",\"url\":\"https://www.semanticscholar.org/paper/79b949d9b35c3f51dd20fb5c746cc81fc87147eb\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1996106\",\"name\":\"Werner Trobin\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-69321-5_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ac4d71354f682fc57c8da39c0b4668ec5e6f1a2\",\"title\":\"An Unbiased Second-Order Prior for High-Accuracy Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/6ac4d71354f682fc57c8da39c0b4668ec5e6f1a2\",\"venue\":\"DAGM-Symposium\",\"year\":2008},{\"arxivId\":\"1706.08033\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"title\":\"Decomposing Motion and Content for Natural Video Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1804.01622\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"25445698\",\"name\":\"Agrim Gupta\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2018.00133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46b5d408d950287637dd21ce04772d9b2bacfd14\",\"title\":\"Image Generation from Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/46b5d408d950287637dd21ce04772d9b2bacfd14\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1807.09755\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01240-3_37\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"27680266bcfa3febb1a1537180a83129d2be4834\",\"title\":\"Flow-Grounded Spatial-Temporal Video Prediction from Still Images\",\"url\":\"https://www.semanticscholar.org/paper/27680266bcfa3febb1a1537180a83129d2be4834\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1601.06759\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"41f1d50c85d3180476c4c7b3eea121278b0d8474\",\"title\":\"Pixel Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/41f1d50c85d3180476c4c7b3eea121278b0d8474\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1711.07837\",\"authors\":[{\"authorId\":\"24362273\",\"name\":\"S. Meister\"},{\"authorId\":\"2470340\",\"name\":\"Junhwa Hur\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e77b5157b0fa0f365808e26af287c3164e002f\",\"title\":\"UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional Census Loss\",\"url\":\"https://www.semanticscholar.org/paper/43e77b5157b0fa0f365808e26af287c3164e002f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/ICPR.2004.747\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"046ad9e42bc9ca6c63406836b95cf1bb62271249\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/046ad9e42bc9ca6c63406836b95cf1bb62271249\",\"venue\":\"ICPR 2004\",\"year\":2004},{\"arxivId\":\"1802.02611\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":\"10.1007/978-3-030-01234-2_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"title\":\"Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1706.08500\",\"authors\":[{\"authorId\":\"2445103\",\"name\":\"Martin Heusel\"},{\"authorId\":\"19219270\",\"name\":\"Hubert Ramsauer\"},{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"37082831\",\"name\":\"Bernhard Nessler\"},{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"231af7dc01a166cac3b5b01ca05778238f796e41\",\"title\":\"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\",\"url\":\"https://www.semanticscholar.org/paper/231af7dc01a166cac3b5b01ca05778238f796e41\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1711.11585\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/CVPR.2018.00917\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0a0c0f0d6a7ff53abea40a8c0c678ed570bf851\",\"title\":\"High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs\",\"url\":\"https://www.semanticscholar.org/paper/f0a0c0f0d6a7ff53abea40a8c0c678ed570bf851\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1605.09673\",\"authors\":[{\"authorId\":\"40347509\",\"name\":\"Xu Jia\"},{\"authorId\":\"3384995\",\"name\":\"Bert De Brabandere\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"title\":\"Dynamic Filter Networks\",\"url\":\"https://www.semanticscholar.org/paper/aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1605.02226\",\"authors\":[{\"authorId\":\"2825051\",\"name\":\"B. Uria\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"145797336\",\"name\":\"I. Murray\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cccc93064dae265eeb7bc76d02cdc67c942f0a5\",\"title\":\"Neural Autoregressive Distribution Estimation\",\"url\":\"https://www.semanticscholar.org/paper/3cccc93064dae265eeb7bc76d02cdc67c942f0a5\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2016},{\"arxivId\":\"1707.04993\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00165\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"title\":\"MoCoGAN: Decomposing Motion and Content for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Video Generation From Single Semantic Label Map\",\"topics\":[{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Glossary of computer graphics\",\"topicId\":\"12790\",\"url\":\"https://www.semanticscholar.org/topic/12790\"},{\"topic\":\"Technical support\",\"topicId\":\"44839\",\"url\":\"https://www.semanticscholar.org/topic/44839\"},{\"topic\":\"Display resolution\",\"topicId\":\"11387\",\"url\":\"https://www.semanticscholar.org/topic/11387\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"}],\"url\":\"https://www.semanticscholar.org/paper/2f66d531439f5847afa7b31f49db87a44b788690\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"