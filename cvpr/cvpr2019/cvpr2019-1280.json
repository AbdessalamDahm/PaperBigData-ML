"{\"abstract\":\"Standard image captioning tasks such as COCO and Flickr30k are factual, neutral in tone and (to a human) state the obvious (e.g., \\u201ca man playing a guitar\\u201d). While such tasks are useful to verify that a machine understands the content of an image, they are not engaging to humans as captions. With this in mind we define a new task, PERSONALITY-CAPTIONS, where the goal is to be as engaging to humans as possible by incorporating controllable style and personality traits. We collect and release a large dataset of 241,858 of such captions conditioned over 215 possible traits. We build models that combine existing work from (i) sentence representations [36] with Transformers trained on 1.7 billion dialogue examples; and (ii) image representations [32] with ResNets trained on 3.5 billion social media images. We obtain state-of-the-art performance on Flickr30k and COCO, and strong performance on our new task. Finally, online evaluations validate that our task and models are engaging to humans, with our best model close to human performance.\",\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\",\"url\":\"https://www.semanticscholar.org/author/35752280\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\",\"url\":\"https://www.semanticscholar.org/author/2795882\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\",\"url\":\"https://www.semanticscholar.org/author/2804000\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\",\"url\":\"https://www.semanticscholar.org/author/1713934\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\",\"url\":\"https://www.semanticscholar.org/author/145183709\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":\"2009.10855\",\"authors\":[{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"1400416878\",\"name\":\"Diana Gonzalez-Rico\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75f061c958505ef5ecc0442d4bcc8fd4c4ee4688\",\"title\":\"Controlling Style in Generated Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/75f061c958505ef5ecc0442d4bcc8fd4c4ee4688\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.00945\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.219\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"title\":\"Image-Chat: Engaging Grounded Conversations\",\"url\":\"https://www.semanticscholar.org/paper/b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184535\",\"name\":\"Rintaro Yanagi\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ACCESS.2020.2995815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"title\":\"Enhancing Cross-Modal Retrieval Based on Modality-Specific and Embedding Spaces\",\"url\":\"https://www.semanticscholar.org/paper/5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.00693\",\"authors\":[{\"authorId\":\"144533942\",\"name\":\"Pengyu Cheng\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"3200180\",\"name\":\"Christopher Malon\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":null,\"name\":\"Yitong Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.acl-main.673\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fe497d7c5a60806aae431d443aa155a4325661a\",\"title\":\"Improving Disentangled Text Representation Learning with Information-Theoretic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/9fe497d7c5a60806aae431d443aa155a4325661a\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1901.06595\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCVW.2019.00237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"title\":\"Evaluating Text-to-Image Matching using Binary Image Selection (BISON)\",\"url\":\"https://www.semanticscholar.org/paper/5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92351120\",\"name\":\"Yuan Li\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"2250250\",\"name\":\"Guoqing Zheng\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I05.6346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c07fde0164b1415180e72320094d0a12edb92b8\",\"title\":\"Complementary Auxiliary Classifiers for Label-Conditional Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/6c07fde0164b1415180e72320094d0a12edb92b8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1901.05415\",\"authors\":[{\"authorId\":\"34302368\",\"name\":\"B. Hancock\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"41016680\",\"name\":\"Pierre-Emmanuel Mazar\\u00e9\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/P19-1358\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0b96270a9bbeb9f3ec040e70114d565fbcaaed9\",\"title\":\"Learning from Dialogue after Deployment: Feed Yourself, Chatbot!\",\"url\":\"https://www.semanticscholar.org/paper/b0b96270a9bbeb9f3ec040e70114d565fbcaaed9\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944765097\",\"name\":\"Beigeng Zhao\"}],\"doi\":\"10.1109/ACCESS.2020.3021312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"title\":\"DrunaliaCap: Image Captioning for Drug-Related Paraphernalia With Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2010.01082\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"title\":\"Multi-Modal Open-Domain Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108358199\",\"name\":\"Viktar Atliha\"},{\"authorId\":\"1990294\",\"name\":\"D. Sesok\"}],\"doi\":\"10.1109/eStream50540.2020.9108880\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08aa7d4d4e7fe6637ab83b8f8ae4144da517cdd6\",\"title\":\"Comparison of VGG and ResNet used as Encoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/08aa7d4d4e7fe6637ab83b8f8ae4144da517cdd6\",\"venue\":\"2020 IEEE Open Conference of Electrical, Electronic and Information Sciences (eStream)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc8df4ad35282ccf19261e02de87d8e35c956537\",\"title\":\"Binary Image Selection (BISON): Interpretable Evaluation of Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fc8df4ad35282ccf19261e02de87d8e35c956537\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123247172\",\"name\":\"W. Zhang\"},{\"authorId\":\"39390758\",\"name\":\"Yue Ying\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":\"10.1609/AAAI.V34I05.6503\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"076b02b481a41f1e07b8a2bdbe0ac8d946f9872e\",\"title\":\"Learning Long- and Short-Term User Literal-Preference with Multimodal Hierarchical Transformer Network for Personalized Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/076b02b481a41f1e07b8a2bdbe0ac8d946f9872e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1910.08293\",\"authors\":[{\"authorId\":\"29382256\",\"name\":\"Aaron W. Li\"},{\"authorId\":\"108571549\",\"name\":\"Veronica Jiang\"},{\"authorId\":\"152913678\",\"name\":\"Steven Y. Feng\"},{\"authorId\":\"1380503731\",\"name\":\"Julia Sprague\"},{\"authorId\":\"145172487\",\"name\":\"W. Zhou\"},{\"authorId\":\"145803385\",\"name\":\"J. Hoey\"}],\"doi\":\"10.1609/aaai.v34i05.6328\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc9583168b760d9cb76a0589c6ee64643b829cdd\",\"title\":\"ALOHA: Artificial Learning of Human Attributes for Dialogue Agents\",\"url\":\"https://www.semanticscholar.org/paper/dc9583168b760d9cb76a0589c6ee64643b829cdd\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184535\",\"name\":\"Rintaro Yanagi\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ICIP40778.2020.9190966\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87a6f1594d7efadc93628b519b1cc699e4659dec\",\"title\":\"Image Retrieval With Lingual And Visual Paraphrasing Via Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/87a6f1594d7efadc93628b519b1cc699e4659dec\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1911.10097\",\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"22198846\",\"name\":\"Rongtian Ye\"},{\"authorId\":\"39742349\",\"name\":\"X. Wang\"},{\"authorId\":\"50341799\",\"name\":\"Shuaipeng Li\"}],\"doi\":\"10.1609/AAAI.V34I07.6823\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"51c669e7deed061f3e7f110330ecc28e0ed076f8\",\"title\":\"HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs\",\"url\":\"https://www.semanticscholar.org/paper/51c669e7deed061f3e7f110330ecc28e0ed076f8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12744\",\"authors\":[{\"authorId\":\"4861083\",\"name\":\"A. Fan\"},{\"authorId\":\"1794075\",\"name\":\"Claire Gardent\"},{\"authorId\":\"2929661\",\"name\":\"C. Braud\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd8f636c6af00c0797ceb92a52dbcf8ccc8463d4\",\"title\":\"Augmenting Transformers with KNN-Based Composite Memory for Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/dd8f636c6af00c0797ceb92a52dbcf8ccc8463d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"46448616\",\"name\":\"Xueting Zhang\"},{\"authorId\":\"145909469\",\"name\":\"Wei Huang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/tgrs.2020.3010106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f79bc9f9bf488f4580f1f4d9a360ac06a26e9e3e\",\"title\":\"Truncation Cross Entropy Loss for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79bc9f9bf488f4580f1f4d9a360ac06a26e9e3e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"title\":\"Engaging Image Chat: Modeling Personality in Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.10658\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICCV.2019.01042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"title\":\"Unpaired Image Captioning via Scene Graph Alignments\",\"url\":\"https://www.semanticscholar.org/paper/f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29382256\",\"name\":\"Aaron W. Li\"},{\"authorId\":\"108571549\",\"name\":\"Veronica Jiang\"},{\"authorId\":\"152913678\",\"name\":\"Steven Y. Feng\"},{\"authorId\":\"1380503731\",\"name\":\"Julia Sprague\"},{\"authorId\":\"95003909\",\"name\":\"W. Zhou\"},{\"authorId\":\"145803385\",\"name\":\"J. Hoey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"175ec408bed3abb176ee9af6a1f2dabeaae9b8a5\",\"title\":\"Follow Alice into the Rabbit Hole: Giving Dialogue Agents Understanding of Human Level Attributes\",\"url\":\"https://www.semanticscholar.org/paper/175ec408bed3abb176ee9af6a1f2dabeaae9b8a5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"title\":\"Attacking Image Captioning Towards Accuracy-Preserving Target Words Removal\",\"url\":\"https://www.semanticscholar.org/paper/0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.08543\",\"authors\":[{\"authorId\":\"152601809\",\"name\":\"Minh Thu Nguyen\"},{\"authorId\":\"6195410\",\"name\":\"D. Phung\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"2008200586\",\"name\":\"Thien Huu Nguyen\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.411\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"title\":\"Structural and Functional Decomposition for Personality Image Captioning in a Communication Game\",\"url\":\"https://www.semanticscholar.org/paper/28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2375749\",\"name\":\"T. Durand\"}],\"doi\":\"10.1109/cvpr42600.2020.00979\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b202588b7a62d19512770a6c06549deb808217ba\",\"title\":\"Learning User Representations for Open Vocabulary Image Hashtag Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b202588b7a62d19512770a6c06549deb808217ba\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938051940\",\"name\":\"Dylan Flaute\"},{\"authorId\":\"2405109\",\"name\":\"B. Narayanan\"}],\"doi\":\"10.1117/12.2568016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"title\":\"Video captioning using weakly supervised convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"venue\":\"Optical Engineering + Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1007/978-3-030-37731-1_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"title\":\"Image Captioning Based on Visual and Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"2005.00908\",\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"122615952\",\"name\":\"Sheng-Jie Li\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"48060050\",\"name\":\"M. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cc8205ddf8211d6ae2fce03de2953a4b978b66a\",\"title\":\"Clue: Cross-modal Coherence Modeling for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/7cc8205ddf8211d6ae2fce03de2953a4b978b66a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08565\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"150353841\",\"name\":\"Yinan Zhao\"},{\"authorId\":\"1409765557\",\"name\":\"Meng Zhang\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"}],\"doi\":\"10.1007/978-3-030-58520-4_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c936d878003254cdab662a966cecd29e8be652d0\",\"title\":\"Captioning Images Taken by People Who Are Blind\",\"url\":\"https://www.semanticscholar.org/paper/c936d878003254cdab662a966cecd29e8be652d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"145523338\",\"name\":\"Peng Yao\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00433\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"title\":\"MSCap: Multi-Style Image Captioning With Unpaired Stylized Text\",\"url\":\"https://www.semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.12394\",\"authors\":[{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aa5454addde1542e0d01cfc68e6f5129630964d\",\"title\":\"All-in-One Image-Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/4aa5454addde1542e0d01cfc68e6f5129630964d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.03768\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"144745718\",\"name\":\"Stephen Roller\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3066ec95113636ca546cf4339772fbd495c27e4\",\"title\":\"The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/d3066ec95113636ca546cf4339772fbd495c27e4\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2006.12442\",\"authors\":[{\"authorId\":\"144745718\",\"name\":\"Stephen Roller\"},{\"authorId\":\"2656573\",\"name\":\"Y.-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"4861083\",\"name\":\"A. Fan\"},{\"authorId\":\"2121780\",\"name\":\"D. Gunning\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"6649233\",\"name\":\"Margaret Li\"},{\"authorId\":\"1753626755\",\"name\":\"Spencer Poff\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"39219656\",\"name\":\"Jack Urbanek\"},{\"authorId\":\"49160304\",\"name\":\"M. Williamson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebf79630966e36761f2275990075384fdcb8d3a7\",\"title\":\"Open-Domain Conversational Agents: Current Progress, Open Problems, and Future Directions\",\"url\":\"https://www.semanticscholar.org/paper/ebf79630966e36761f2275990075384fdcb8d3a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04170\",\"authors\":[{\"authorId\":\"1482545250\",\"name\":\"Yohan Chalier\"},{\"authorId\":\"2499758\",\"name\":\"Simon Razniewski\"},{\"authorId\":\"1751591\",\"name\":\"G. Weikum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"269034969aeeec3286d123e0632ce33f53aa4454\",\"title\":\"Joint Reasoning for Multi-Faceted Commonsense Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/269034969aeeec3286d123e0632ce33f53aa4454\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897421\",\"name\":\"Rachel N. Simons\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"3079031\",\"name\":\"Kenneth R. Fleischmann\"}],\"doi\":\"10.1145/3415176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"title\":\"\\\"I Hope This Is Helpful\\\"\",\"url\":\"https://www.semanticscholar.org/paper/f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"51019115\",\"name\":\"S. Li\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.18653/v1/2020.acl-main.583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb05ea53c4bfee60e045d26cc487d20141482949\",\"title\":\"Cross-modal Coherence Modeling for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/bb05ea53c4bfee60e045d26cc487d20141482949\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.14451\",\"authors\":[{\"authorId\":\"21771052\",\"name\":\"Allen Nie\"},{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88c86523d500d636f453647385ddaa04085b5f1b\",\"title\":\"Pragmatic Issue-Sensitive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88c86523d500d636f453647385ddaa04085b5f1b\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":53022581,\"doi\":\"10.1109/CVPR.2019.01280\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145607451\",\"name\":\"S. Marcel\"},{\"authorId\":\"145835170\",\"name\":\"Y. Rodriguez\"}],\"doi\":\"10.1145/1873951.1874254\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41bebd1951e57588e7829e44fab1bac0cc9251d2\",\"title\":\"Torchvision the machine-vision package of torch\",\"url\":\"https://www.semanticscholar.org/paper/41bebd1951e57588e7829e44fab1bac0cc9251d2\",\"venue\":\"ACM Multimedia\",\"year\":2010},{\"arxivId\":\"1510.01431\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"title\":\"SentiCap: Generating Image Descriptions with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.01984\",\"authors\":[{\"authorId\":\"41016680\",\"name\":\"Pierre-Emmanuel Mazar\\u00e9\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"10707709\",\"name\":\"Martin Raison\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"}],\"doi\":\"10.18653/v1/D18-1298\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dde89e64a7f375b90e1cc594142940f4161e1592\",\"title\":\"Training Millions of Personalized Dialogue Agents\",\"url\":\"https://www.semanticscholar.org/paper/dde89e64a7f375b90e1cc594142940f4161e1592\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1801.10121\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"title\":\"Image Captioning at Will: A Versatile Scheme for Effectively Injecting Sentiments into Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Papineni\"},{\"authorId\":null,\"name\":\"S. Roukos\"},{\"authorId\":null,\"name\":\"T. Ward\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Automatic image captioning . In Multimedia and Expo , 2004 . ICME \\u2019 04\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12094097\",\"name\":\"Pratik P. Rane\"},{\"authorId\":\"118145941\",\"name\":\"A. Sargar\"},{\"authorId\":\"47039181\",\"name\":\"Faiza Shaikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f77a604410d88307ec5c6331c8b6133272fbaa10\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f77a604410d88307ec5c6331c8b6133272fbaa10\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.08023\",\"authors\":[{\"authorId\":\"50557647\",\"name\":\"C. Liu\"},{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"35224828\",\"name\":\"I. Serban\"},{\"authorId\":\"38107789\",\"name\":\"Michael Noseworthy\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"}],\"doi\":\"10.18653/v1/D16-1230\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"129cbad01be98ee88a930e31898cb76be79c41c1\",\"title\":\"How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/129cbad01be98ee88a930e31898cb76be79c41c1\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82216892\",\"name\":\"C. Watkins\"},{\"authorId\":\"8346137\",\"name\":\"V. L. Campbell\"}],\"doi\":\"10.4324/9781410604323-10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1e7a7700fe52e57065030f0810eb99094ac8f31\",\"title\":\"The Sixteen Personality Factor Questionnaire (16PF)\",\"url\":\"https://www.semanticscholar.org/paper/e1e7a7700fe52e57065030f0810eb99094ac8f31\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3222239\",\"name\":\"A. Abele\"},{\"authorId\":\"2585858\",\"name\":\"B. Wojciszke\"}],\"doi\":\"10.1037/0022-3514.93.5.751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ca2595b6e5b1ba72fb0469b9aeb89f44ad81279\",\"title\":\"Agency and communion from the perspective of self versus others.\",\"url\":\"https://www.semanticscholar.org/paper/5ca2595b6e5b1ba72fb0469b9aeb89f44ad81279\",\"venue\":\"Journal of personality and social psychology\",\"year\":2007},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1805.00932\",\"authors\":[{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"7769997\",\"name\":\"Y. Li\"},{\"authorId\":\"46208883\",\"name\":\"Ashwin Bharambe\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-030-01216-8_12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f885fd46064d271d4404cf9bb3d758e1a6f8d55\",\"title\":\"Exploring the Limits of Weakly Supervised Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/0f885fd46064d271d4404cf9bb3d758e1a6f8d55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6e695ddd07aad719001c0fc1129328452385949\",\"title\":\"The New Data and New Challenges in Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/a6e695ddd07aad719001c0fc1129328452385949\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5745729\",\"name\":\"R. Jo\\u0144czyk\"}],\"doi\":\"10.1007/978-3-319-47635-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e01c4771fd6dae8fc87804556c93c2c3de26481\",\"title\":\"Affect-Language Interactions in Native and Non-Native English Speakers\",\"url\":\"https://www.semanticscholar.org/paper/9e01c4771fd6dae8fc87804556c93c2c3de26481\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630277553\",\"name\":\"M. Sankar\"}],\"doi\":\"10.1515/9783111548050-024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"title\":\"M\",\"url\":\"https://www.semanticscholar.org/paper/517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2731506\",\"name\":\"Yuheng Hu\"},{\"authorId\":\"2630752\",\"name\":\"L. Manikonda\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a92831841307b513ca9c1b2c65499b08eb4c156\",\"title\":\"What We Instagram: A First Analysis of Instagram Photo Content and User Types\",\"url\":\"https://www.semanticscholar.org/paper/8a92831841307b513ca9c1b2c65499b08eb4c156\",\"venue\":\"ICWSM\",\"year\":2014},{\"arxivId\":\"1701.08251\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"3130583\",\"name\":\"Georgios P. Spithourakis\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880fca26169023a900c0f7d65d9b85abc5240a0\",\"title\":\"Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/c880fca26169023a900c0f7d65d9b85abc5240a0\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":\"1607.04606\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":\"10.1162/tacl_a_00051\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2dba792360873aef125572812f3673b1a85d850\",\"title\":\"Enriching Word Vectors with Subword Information\",\"url\":\"https://www.semanticscholar.org/paper/e2dba792360873aef125572812f3673b1a85d850\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1805.07030\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2018.00896\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"title\":\"SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\",\"url\":\"https://www.semanticscholar.org/paper/beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32437830\",\"name\":\"T. Jay\"},{\"authorId\":\"5268454\",\"name\":\"Kristin Janschewitz\"}],\"doi\":\"10.1515/TL.2007.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83e6fa00a7677050aa26c63ebbcfa3798d30462e\",\"title\":\"Filling the emotion gap in linguistic theory: Commentary on Potts' expressive dimension\",\"url\":\"https://www.semanticscholar.org/paper/83e6fa00a7677050aa26c63ebbcfa3798d30462e\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. Wolf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Vqa : Visual question answering The sixteen personality factor questionnaire ( 16 pf )\",\"url\":\"\",\"venue\":\"The SAGE handbook of personality theory and assessment\",\"year\":2008},{\"arxivId\":\"1801.07243\",\"authors\":[{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"39219656\",\"name\":\"Jack Urbanek\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/P18-1205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c7046195f64cccac1ed3275d88d77655534b5a4\",\"title\":\"Personalizing Dialogue Agents: I have a dog, do you have pets too?\",\"url\":\"https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1611.05588\",\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2017.767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"title\":\"Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144426057\",\"name\":\"M. Zhou\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2017.208\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad5dc94b28bee087a34f52114c52bd09d2acd8cb\",\"title\":\"Hierarchical Multimodal LSTM for Dense Visual-Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/ad5dc94b28bee087a34f52114c52bd09d2acd8cb\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Mahajan\"},{\"authorId\":null,\"name\":\"R. B. Girshick\"},{\"authorId\":null,\"name\":\"V. Ramanathan\"},{\"authorId\":null,\"name\":\"K. He\"},{\"authorId\":null,\"name\":\"M. Paluri\"},{\"authorId\":null,\"name\":\"Y. Li\"},{\"authorId\":null,\"name\":\"A. Bharambe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and L\",\"url\":\"\",\"venue\":\"van der Maaten. Exploring the limits of weakly supervised pretraining. CoRR, abs/1805.00932\",\"year\":2018},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1805.11850\",\"authors\":[{\"authorId\":\"2825955\",\"name\":\"K. Yoshida\"},{\"authorId\":\"46242473\",\"name\":\"Munetaka Minoguchi\"},{\"authorId\":\"46237076\",\"name\":\"Kenichiro Wani\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5ecbe9e93eec0d2744bbe0b4d84016ec07562c5\",\"title\":\"Neural Joking Machine : Humorous image captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5ecbe9e93eec0d2744bbe0b4d84016ec07562c5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.06420\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724b253a55e86ad230ba05c7eb78f249e09258d9\",\"title\":\"Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/724b253a55e86ad230ba05c7eb78f249e09258d9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fartash Faghri\"},{\"authorId\":null,\"name\":\"David J. Fleet\"},{\"authorId\":null,\"name\":\"Ryan Kiros\"},{\"authorId\":null,\"name\":\"Sanja Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VSE++: improved visual-semantic\",\"url\":\"\",\"venue\":\"embeddings. CoRR,\",\"year\":2017},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.01720\",\"authors\":[{\"authorId\":\"35376394\",\"name\":\"Martin Engilberge\"},{\"authorId\":\"39255836\",\"name\":\"Louis Chevallier\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1109/CVPR.2018.00419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9645e8b4829c04879a642d8dd6b3cdf5cf264afb\",\"title\":\"Finding Beans in Burgers: Deep Semantic-Visual Embedding with Localization\",\"url\":\"https://www.semanticscholar.org/paper/9645e8b4829c04879a642d8dd6b3cdf5cf264afb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.06485\",\"authors\":[{\"authorId\":\"47465525\",\"name\":\"Cesc Chunseong Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.681\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"title\":\"Attend to You: Personalized Image Captioning with Context Sequence Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793014\",\"name\":\"Matthias Scheutz\"},{\"authorId\":\"2510893\",\"name\":\"P. Schermerhorn\"},{\"authorId\":\"2609362\",\"name\":\"J. Kramer\"}],\"doi\":\"10.1145/1121241.1121281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5010cb1dc9b0ae3a5649c12e1011a204a5aaac1\",\"title\":\"The utility of affect expression in natural language interactions in joint human-robot tasks\",\"url\":\"https://www.semanticscholar.org/paper/e5010cb1dc9b0ae3a5649c12e1011a204a5aaac1\",\"venue\":\"HRI '06\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1145/2783258.2788576\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5012a6a4933e26ed9b23b0c38c073bb8063533f\",\"title\":\"User Conditional Hashtag Prediction for Images\",\"url\":\"https://www.semanticscholar.org/paper/d5012a6a4933e26ed9b23b0c38c073bb8063533f\",\"venue\":\"KDD\",\"year\":2015},{\"arxivId\":\"1704.03470\",\"authors\":[{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"19353632\",\"name\":\"J. Huang\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/TPAMI.2018.2797921\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"title\":\"Learning Two-Branch Neural Networks for Image-Text Matching Tasks\",\"url\":\"https://www.semanticscholar.org/paper/f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Gu\"},{\"authorId\":null,\"name\":\"J. Cai\"},{\"authorId\":null,\"name\":\"S. R. Joty\"},{\"authorId\":null,\"name\":\"L. Niu\"},{\"authorId\":null,\"name\":\"G. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Look\",\"url\":\"\",\"venue\":\"imagine and match: Improving textual-visual cross-modal retrieval with generative models. CoRR, abs/1711.06420\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1943594\",\"name\":\"Jia-Yu Pan\"},{\"authorId\":\"97598888\",\"name\":\"Hyung-Jeong Yang\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"1702392\",\"name\":\"C. Faloutsos\"}],\"doi\":\"10.1109/ICME.2004.1394652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc58597d33d5ff5a51d7810512e2b90b056840ca\",\"title\":\"Automatic image captioning\",\"url\":\"https://www.semanticscholar.org/paper/cc58597d33d5ff5a51d7810512e2b90b056840ca\",\"venue\":\"2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116944833\",\"name\":\"H. E. Cattell\"},{\"authorId\":\"46873666\",\"name\":\"A. D. Mead\"}],\"doi\":\"10.4135/9781849200479.N7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ce12d90634b385bb0dfb25bdf0f4d192231e83a\",\"title\":\"The Sixteen Personality Factor Questionnaire (16PF).\",\"url\":\"https://www.semanticscholar.org/paper/3ce12d90634b385bb0dfb25bdf0f4d192231e83a\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Marcel\"},{\"authorId\":null,\"name\":\"Y. Rodriguez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Torchvision the machinevision package of torch\",\"url\":\"\",\"venue\":\"Proceedings of the 18th ACM International Conference on Multimedia, MM \\u201910, pages 1485\\u20131488, New York, NY, USA\",\"year\":2010},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1704.08224\",\"authors\":[{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/N18-2121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d9830134f3ad0f66f75331ba73fe416bd76320f\",\"title\":\"Punny Captions: Witty Wordplay in Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2d9830134f3ad0f66f75331ba73fe416bd76320f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451681\",\"name\":\"Aviv Eisenschtat\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1beb4d7a0d09f4da6a934e2ad37323b8166070a0\",\"title\":\"Capturing Deep Correlations with 2-Way Nets\",\"url\":\"https://www.semanticscholar.org/paper/1beb4d7a0d09f4da6a934e2ad37323b8166070a0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145315291\",\"name\":\"Onno Kampman\"},{\"authorId\":\"3407465\",\"name\":\"Farhad Bin Siddique\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"1683412\",\"name\":\"Pascale Fung\"}],\"doi\":\"10.1007/978-3-319-92108-2_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fc8d5a6c89abbf5f8bd893584ea5280ce91b8e3\",\"title\":\"Adapting a Virtual Agent to User Personality\",\"url\":\"https://www.semanticscholar.org/paper/7fc8d5a6c89abbf5f8bd893584ea5280ce91b8e3\",\"venue\":\"IWSDS\",\"year\":2017},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145336124\",\"name\":\"J. Jacques\"},{\"authorId\":\"2706315\",\"name\":\"Ya\\u011fmur G\\u00fc\\u00e7l\\u00fct\\u00fcrk\"},{\"authorId\":\"145059215\",\"name\":\"Marc P\\u00e9rez\"},{\"authorId\":\"3038211\",\"name\":\"Umut G\\u00fc\\u00e7l\\u00fc\"},{\"authorId\":\"145765692\",\"name\":\"Carlos And\\u00fajar\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1743797\",\"name\":\"I. Guyon\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"},{\"authorId\":\"38485168\",\"name\":\"R. Lier\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c964e59bdac6b8044993ca96b47a9a0addedfb8\",\"title\":\"First Impressions: A Survey on Computer Vision-Based Apparent Personality Trait Analysis\",\"url\":\"https://www.semanticscholar.org/paper/6c964e59bdac6b8044993ca96b47a9a0addedfb8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005}],\"title\":\"Engaging Image Captioning via Personality\",\"topics\":[{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"Software agent\",\"topicId\":\"45428\",\"url\":\"https://www.semanticscholar.org/topic/45428\"},{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"Mind\",\"topicId\":\"59591\",\"url\":\"https://www.semanticscholar.org/topic/59591\"},{\"topic\":\"Transformers\",\"topicId\":\"927204\",\"url\":\"https://www.semanticscholar.org/topic/927204\"},{\"topic\":\"Social media\",\"topicId\":\"6015\",\"url\":\"https://www.semanticscholar.org/topic/6015\"},{\"topic\":\"Natural language generation\",\"topicId\":\"6196\",\"url\":\"https://www.semanticscholar.org/topic/6196\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Condition number\",\"topicId\":\"5434\",\"url\":\"https://www.semanticscholar.org/topic/5434\"}],\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"