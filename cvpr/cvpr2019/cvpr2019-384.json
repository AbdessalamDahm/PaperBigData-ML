"{\"abstract\":\"Video inpainting, which aims at filling in missing regions in a video, remains challenging due to the difficulty of preserving the precise spatial and temporal coherence of video contents. In this work we propose a novel flow-guided video inpainting approach. Rather than filling in the RGB pixels of each frame directly, we consider the video inpainting as a pixel propagation problem. We first synthesize a spatially and temporally coherent optical flow field across video frames using a newly designed Deep Flow Completion network, then use the synthesized flow fields to guide the propagation of pixels to fill up the missing regions in the video. Specifically, the Deep Flow Competion network follows a coarse-to-fine refinement strategy to complete the flow fields, while their quality is further improved by hard flow example mining. Following the guide of the completed flow fields, the missing video regions can be filled up precisely. Our method is evaluated on DAVIS and YouTubeVOS datasets qualitatively and quantitatively, achieving the state-of-the-art performance in terms of inpainting quality and speed.\",\"arxivId\":\"1905.02884\",\"authors\":[{\"authorId\":\"144996246\",\"name\":\"Rui Xu\",\"url\":\"https://www.semanticscholar.org/author/144996246\"},{\"authorId\":\"48569853\",\"name\":\"X. Li\",\"url\":\"https://www.semanticscholar.org/author/48569853\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\",\"url\":\"https://www.semanticscholar.org/author/145291669\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\",\"url\":\"https://www.semanticscholar.org/author/1717179\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":\"2004.01180\",\"authors\":[{\"authorId\":\"47909298\",\"name\":\"Y. Liu\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR42600.2020.01422\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8395a6b8cc14effa9dd5c9b8465417a950725f43\",\"title\":\"Learning to See Through Obstructions\",\"url\":\"https://www.semanticscholar.org/paper/8395a6b8cc14effa9dd5c9b8465417a950725f43\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.16003\",\"authors\":[{\"authorId\":\"50618292\",\"name\":\"S. Han\"},{\"authorId\":\"2483263\",\"name\":\"D. Y. Suh\"}],\"doi\":\"10.32604/cmc.2020.012223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d737563a41a7224c05beae7c95c735d6cc3b835f\",\"title\":\"PIINET: A 360-degree Panoramic Image Inpainting Network Using a Cube Map\",\"url\":\"https://www.semanticscholar.org/paper/d737563a41a7224c05beae7c95c735d6cc3b835f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.04433\",\"authors\":[{\"authorId\":\"40326718\",\"name\":\"Hossein Javidnia\"},{\"authorId\":\"1491819441\",\"name\":\"Franccois Piti'e\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ae806b54bf2e9872607ddbd03727f613ded7c588\",\"title\":\"Background Matting\",\"url\":\"https://www.semanticscholar.org/paper/ae806b54bf2e9872607ddbd03727f613ded7c588\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.02501\",\"authors\":[{\"authorId\":\"2302673\",\"name\":\"Jin-shan Pan\"},{\"authorId\":\"39227442\",\"name\":\"Haoran Bai\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":\"10.1109/CVPR42600.2020.00311\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3828db87fd660b29d32e47ef2917ae499ca24c6f\",\"title\":\"Cascaded Deep Video Deblurring Using Temporal Sharpness Prior\",\"url\":\"https://www.semanticscholar.org/paper/3828db87fd660b29d32e47ef2917ae499ca24c6f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.05481\",\"authors\":[{\"authorId\":\"1807608416\",\"name\":\"Pierre Godet\"},{\"authorId\":\"2300845\",\"name\":\"Alexandre Boulch\"},{\"authorId\":\"3369573\",\"name\":\"A. Plyer\"},{\"authorId\":\"1787751\",\"name\":\"G. L. Besnerais\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d436ba1745f0b4116d025cc39c81678ae2881dcf\",\"title\":\"STaRFlow: A SpatioTemporal Recurrent Cell for Lightweight Multi-Frame Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/d436ba1745f0b4116d025cc39c81678ae2881dcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.02188\",\"authors\":[{\"authorId\":\"46583588\",\"name\":\"Jiaqi Wang\"},{\"authorId\":\"34526205\",\"name\":\"K. Chen\"},{\"authorId\":\"144996246\",\"name\":\"Rui Xu\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00310\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"477dbe3139216d5d1af7c0a379ed32a7a4dc4ba7\",\"title\":\"CARAFE: Content-Aware ReAssembly of FEatures\",\"url\":\"https://www.semanticscholar.org/paper/477dbe3139216d5d1af7c0a379ed32a7a4dc4ba7\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.05721\",\"authors\":[{\"authorId\":\"100895685\",\"name\":\"Ang Li\"},{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"50175298\",\"name\":\"M. Gong\"},{\"authorId\":\"145663352\",\"name\":\"Jianzhong Qi\"},{\"authorId\":\"143758471\",\"name\":\"Rui Zhang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"50278164\",\"name\":\"R. Kotagiri\"}],\"doi\":\"10.1007/978-3-030-58548-8_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e198f21b3d052a809d3198ace4de78be32ee843c\",\"title\":\"Short-Term and Long-Term Context Aggregation Network for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/e198f21b3d052a809d3198ace4de78be32ee843c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1909.07957\",\"authors\":[{\"authorId\":\"49724177\",\"name\":\"Hao-Tian Zhang\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"1680236\",\"name\":\"J. Collomosse\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.1109/ICCV.2019.00281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"title\":\"An Internal Learning Approach to Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40506942\",\"name\":\"Woobin Im\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"},{\"authorId\":\"49460338\",\"name\":\"S. Yoon\"}],\"doi\":\"10.1007/978-3-030-58586-0_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60c45ceea3ad5373fcb2801cfc846985e3ed38d3\",\"title\":\"Unsupervised Learning of Optical Flow with Deep Feature Similarity\",\"url\":\"https://www.semanticscholar.org/paper/60c45ceea3ad5373fcb2801cfc846985e3ed38d3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3058654\",\"name\":\"J. Wang\"},{\"authorId\":\"152568027\",\"name\":\"Kai Chen\"},{\"authorId\":\"152287816\",\"name\":\"Rui Xu\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cbcfb2e5708e3c2d9fcc1a722e7e96b150d8679\",\"title\":\"\\u2a02 = Content-aware Reassembly Module Content Encoder Kernel Normalizer Channel Compressor\",\"url\":\"https://www.semanticscholar.org/paper/0cbcfb2e5708e3c2d9fcc1a722e7e96b150d8679\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453588312\",\"name\":\"Dezhi Bo\"},{\"authorId\":\"1905979910\",\"name\":\"Ran Ma\"},{\"authorId\":\"47373041\",\"name\":\"Keke Wang\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"150257036\",\"name\":\"Ping An\"}],\"doi\":\"10.1117/12.2574393\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ec53652c6b1a40c6351752aba9276178dfc6fad\",\"title\":\"High resolution video inpainting based on spatial structure and temporal edge information\",\"url\":\"https://www.semanticscholar.org/paper/5ec53652c6b1a40c6351752aba9276178dfc6fad\",\"venue\":\"SPIE/COS Photonics Asia\",\"year\":2020},{\"arxivId\":\"2004.00542\",\"authors\":[{\"authorId\":\"89971337\",\"name\":\"Yue Wu\"},{\"authorId\":\"48984651\",\"name\":\"Rongrong Gao\"},{\"authorId\":\"2870153\",\"name\":\"Jaesik Park\"},{\"authorId\":\"143832240\",\"name\":\"Qifeng Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.00558\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bfd55a4b1defa21c9efbbbcae2d04ca9e3b8b97\",\"title\":\"Future Video Synthesis With Object Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8bfd55a4b1defa21c9efbbbcae2d04ca9e3b8b97\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.14814\",\"authors\":[{\"authorId\":\"2029490842\",\"name\":\"Gal Lifshitz\"},{\"authorId\":\"2283049\",\"name\":\"Dan Raviv\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17d3ecc84d06c2d5d19e5b3a90885534a1707e6e\",\"title\":\"Unsupervised Optical Flow Using Cost Function Unrolling\",\"url\":\"https://www.semanticscholar.org/paper/17d3ecc84d06c2d5d19e5b3a90885534a1707e6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.08854\",\"authors\":[{\"authorId\":\"46840906\",\"name\":\"Miao Liao\"},{\"authorId\":\"46185527\",\"name\":\"Feixiang Lu\"},{\"authorId\":\"37947573\",\"name\":\"Dingfu Zhou\"},{\"authorId\":\"144268595\",\"name\":\"Sibo Zhang\"},{\"authorId\":null,\"name\":\"Wei Li\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1007/978-3-030-58589-1_1\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb4e62e7fbc78b20a7cfc499ab804748fd81bcd6\",\"title\":\"DVI: Depth Guided Video Inpainting for Autonomous Driving\",\"url\":\"https://www.semanticscholar.org/paper/eb4e62e7fbc78b20a7cfc499ab804748fd81bcd6\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.01835\",\"authors\":[{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"1873347743\",\"name\":\"Ayush Saraf\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"},{\"authorId\":\"2891193\",\"name\":\"Johannes Kopf\"}],\"doi\":\"10.1007/978-3-030-58610-2_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fed1bccd50dd8df173a1c53e50967eae3668b623\",\"title\":\"Flow-edge Guided Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/fed1bccd50dd8df173a1c53e50967eae3668b623\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.12950\",\"authors\":[{\"authorId\":\"19282988\",\"name\":\"Wenqi Xian\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"},{\"authorId\":\"2891193\",\"name\":\"Johannes Kopf\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f1da5e77ceac158b84d9c9c4b2016ca1944fe3\",\"title\":\"Space-time Neural Irradiance Fields for Free-Viewpoint Video\",\"url\":\"https://www.semanticscholar.org/paper/15f1da5e77ceac158b84d9c9c4b2016ca1944fe3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1109/TPAMI.2019.2958083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"title\":\"Recurrent Temporal Aggregation Framework for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2011.06294\",\"authors\":[{\"authorId\":\"14042304\",\"name\":\"Zhewei Huang\"},{\"authorId\":\"123437116\",\"name\":\"Tianyuan Zhang\"},{\"authorId\":\"145577184\",\"name\":\"Wen Heng\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"35132667\",\"name\":\"Shuchang Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"title\":\"RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03548\",\"authors\":[{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"80180784\",\"name\":\"Xuekun Jiang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58621-8_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"title\":\"A Unified Framework for Shot Type Classification Based on Subject Centric Lens\",\"url\":\"https://www.semanticscholar.org/paper/49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.04902\",\"authors\":[{\"authorId\":\"47909298\",\"name\":\"Y. Liu\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"},{\"authorId\":\"49024793\",\"name\":\"Jiabin Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74347822f69cd36988f866dcfb31fcad065ba4ef\",\"title\":\"Learning to See Through Obstructions with Layered Decomposition.\",\"url\":\"https://www.semanticscholar.org/paper/74347822f69cd36988f866dcfb31fcad065ba4ef\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-58583-9_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4ae2e88c470975209769abe12c895dcf0b534d5\",\"title\":\"Proposal-Based Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/e4ae2e88c470975209769abe12c895dcf0b534d5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47246298\",\"name\":\"Ruixin Liu\"},{\"authorId\":\"151270908\",\"name\":\"Zhenyu Weng\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"},{\"authorId\":\"103717726\",\"name\":\"Bairong Li\"}],\"doi\":\"10.24963/ijcai.2020/129\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0db83dbdb6825596860ea08cc2ad090410cd335b\",\"title\":\"Temporal Adaptive Alignment Network for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/0db83dbdb6825596860ea08cc2ad090410cd335b\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1905.13066\",\"authors\":[{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"title\":\"Align-and-Attend Network for Globally and Locally Coherent Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.10247\",\"authors\":[{\"authorId\":\"5764695\",\"name\":\"Y. Zeng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1007/978-3-030-58517-4_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7f89feee68b6856c0a980a5888b42d18231be07\",\"title\":\"Learning Joint Spatial-Temporal Transformations for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/f7f89feee68b6856c0a980a5888b42d18231be07\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.04733\",\"authors\":[{\"authorId\":\"3058654\",\"name\":\"J. Wang\"},{\"authorId\":\"2013538485\",\"name\":\"Kai Chen\"},{\"authorId\":\"1606128526\",\"name\":\"Rui Xu\"},{\"authorId\":\"49293505\",\"name\":\"Z. Liu\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b648bf8435627260f98d318fdde7d406e73de88\",\"title\":\"CARAFE++: Unified Content-Aware ReAssembly of FEatures\",\"url\":\"https://www.semanticscholar.org/paper/7b648bf8435627260f98d318fdde7d406e73de88\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13045\",\"authors\":[{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"1452345139\",\"name\":\"Ruifei He\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"}],\"doi\":\"10.1109/cvpr42600.2020.00652\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0555d625f3cc6992c503489933784e06c96abc68\",\"title\":\"Learning by Analogy: Reliable Supervision From Transformations for Unsupervised Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/0555d625f3cc6992c503489933784e06c96abc68\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147028083\",\"name\":\"Jacqueline Bellon\"}],\"doi\":\"10.2478/gth-2019-0027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f93689b948349467c776ef1fd069ddc7c249410\",\"title\":\"Figure, Ground and the Notion of Equilibria in the Work of Gilbert Simondon and Gestalt theory\",\"url\":\"https://www.semanticscholar.org/paper/5f93689b948349467c776ef1fd069ddc7c249410\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46354187\",\"name\":\"H. Hu\"},{\"authorId\":\"71201688\",\"name\":\"Bo. Gao\"},{\"authorId\":\"49020094\",\"name\":\"Zhiyuan Shen\"},{\"authorId\":\"48378687\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2992772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5058f9de8ceddd27bb17aa52d512f15fbaebe264\",\"title\":\"Image Smear Removal via Improved Conditional GAN and Semantic Network\",\"url\":\"https://www.semanticscholar.org/paper/5058f9de8ceddd27bb17aa52d512f15fbaebe264\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1844606652\",\"name\":\"Ryo Shimamura\"},{\"authorId\":\"145515373\",\"name\":\"Qi Feng\"},{\"authorId\":\"34789394\",\"name\":\"Y. Koyama\"},{\"authorId\":\"1844432504\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"1844564460\",\"name\":\"Satoru Fukayama\"},{\"authorId\":\"1783855\",\"name\":\"M. Hamasaki\"},{\"authorId\":\"1720652\",\"name\":\"Masataka Goto\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":\"10.1007/s00371-020-01918-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"015834dcf31d4d6156cf67bd4f947feaac58584a\",\"title\":\"Audio\\u2013visual object removal in 360-degree videos\",\"url\":\"https://www.semanticscholar.org/paper/015834dcf31d4d6156cf67bd4f947feaac58584a\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1911.12588\",\"authors\":[{\"authorId\":\"24282778\",\"name\":\"R. Zhang\"},{\"authorId\":\"39848690\",\"name\":\"Wei Li\"},{\"authorId\":\"49161455\",\"name\":\"P. Wang\"},{\"authorId\":\"51226237\",\"name\":\"Chenye Guan\"},{\"authorId\":\"145791861\",\"name\":\"J. Fang\"},{\"authorId\":null,\"name\":\"Yuhang Song\"},{\"authorId\":\"34331831\",\"name\":\"J. Yu\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"152261442\",\"name\":\"Wei-wei Xu\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6982\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a736563e276d74f425222d7bcf7d3641c5cf999b\",\"title\":\"AutoRemover: Automatic Object Removal for Autonomous Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/a736563e276d74f425222d7bcf7d3641c5cf999b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.04950\",\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"1382637019\",\"name\":\"Mostafa El-Khamy\"},{\"authorId\":\"35462690\",\"name\":\"Jungwon Lee\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d52448d649ce5d35189abdeecdc62db647b4246\",\"title\":\"HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0d52448d649ce5d35189abdeecdc62db647b4246\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":147704181,\"doi\":\"10.1109/CVPR.2019.00384\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f3f1ea39c55e9c85a68fe50450cd7dfa6515e55c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"},{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"}],\"doi\":\"10.1145/2980179.2982398\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"title\":\"Temporally coherent completion of dynamic video\",\"url\":\"https://www.semanticscholar.org/paper/cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"2991293\",\"name\":\"L. Vese\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1782265\",\"name\":\"S. Osher\"}],\"doi\":\"10.1109/TIP.2003.815261\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3d98453794e970e04f9c11f1f841fd18acb81c9\",\"title\":\"Simultaneous structure and texture image inpainting\",\"url\":\"https://www.semanticscholar.org/paper/b3d98453794e970e04f9c11f1f841fd18acb81c9\",\"venue\":\"IEEE Trans. Image Process.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38551815\",\"name\":\"A. Levin\"},{\"authorId\":\"2084674\",\"name\":\"A. Zomet\"},{\"authorId\":\"30400079\",\"name\":\"Yair Weiss\"}],\"doi\":\"10.1109/ICCV.2003.1238360\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81410e41f92a63a4aa9618ce0032c9031203a1e7\",\"title\":\"Learning how to inpaint from global image statistics\",\"url\":\"https://www.semanticscholar.org/paper/81410e41f92a63a4aa9618ce0032c9031203a1e7\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1145/383259.383296\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd7bf950093fc65f3ae6ad79666ce1077f9dfb2e\",\"title\":\"Image quilting for texture synthesis and transfer\",\"url\":\"https://www.semanticscholar.org/paper/dd7bf950093fc65f3ae6ad79666ce1077f9dfb2e\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434773\",\"name\":\"M. Strobel\"},{\"authorId\":\"2153073\",\"name\":\"Julia Diebold\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"}],\"doi\":\"10.1007/978-3-319-11752-2_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53ff7de5c13fa62821bf7d0f4aa7979560d2921b\",\"title\":\"Flow and Color Inpainting for Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/53ff7de5c13fa62821bf7d0f4aa7979560d2921b\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":\"1503.05528\",\"authors\":[{\"authorId\":\"1902919\",\"name\":\"A. Newson\"},{\"authorId\":\"1713633\",\"name\":\"Andr\\u00e9s Almansa\"},{\"authorId\":\"3284350\",\"name\":\"M. Fradet\"},{\"authorId\":\"1796594\",\"name\":\"Y. Gousseau\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1137/140954933\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a57afd150ab309f868c9030cddfc0fd896f67308\",\"title\":\"Video Inpainting of Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/a57afd150ab309f868c9030cddfc0fd896f67308\",\"venue\":\"SIAM J. Imaging Sci.\",\"year\":2014},{\"arxivId\":\"1801.07892\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00577\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"title\":\"Generative Image Inpainting with Contextual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30991253\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"8004695\",\"name\":\"V. Caselles\"},{\"authorId\":\"34688079\",\"name\":\"C. Ballester\"}],\"doi\":\"10.1145/344779.344972\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"title\":\"Image inpainting\",\"url\":\"https://www.semanticscholar.org/paper/4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"venue\":\"SIGGRAPH '00\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"}],\"doi\":\"10.1007/978-3-642-15558-1_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41765f1f10bf2830c7749d8672eeabcb028381ae\",\"title\":\"The Generalized PatchMatch Correspondence Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/41765f1f10bf2830c7749d8672eeabcb028381ae\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1804.07723\",\"authors\":[{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01252-6_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a417a16473e2bcb1c98cd7814bc106760925e60\",\"title\":\"Image Inpainting for Irregular Holes Using Partial Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/2a417a16473e2bcb1c98cd7814bc106760925e60\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"38824925\",\"name\":\"A. Finkelstein\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"}],\"doi\":\"10.1145/1576246.1531330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"title\":\"PatchMatch: a randomized correspondence algorithm for structural image editing\",\"url\":\"https://www.semanticscholar.org/paper/744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2009},{\"arxivId\":\"1805.07036\",\"authors\":[{\"authorId\":\"33385667\",\"name\":\"Tak-Wai Hui\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/CVPR.2018.00936\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"051b3763c2ad4e4271db712b0e9a4cfe298d05db\",\"title\":\"LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/051b3763c2ad4e4271db712b0e9a4cfe298d05db\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.03327\",\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"84426766\",\"name\":\"Dingcheng Yue\"},{\"authorId\":\"21160992\",\"name\":\"Yuchen Liang\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad\",\"title\":\"YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"144722242\",\"name\":\"A. Bertozzi\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"}],\"doi\":\"10.1109/CVPR.2001.990497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95498890efa965658d77c118eaec935622634fc0\",\"title\":\"Navier-stokes, fluid dynamics, and image and video inpainting\",\"url\":\"https://www.semanticscholar.org/paper/95498890efa965658d77c118eaec935622634fc0\",\"venue\":\"Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2810911\",\"name\":\"K. Patwardhan\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"}],\"doi\":\"10.1109/TIP.2006.888343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56210467fe8e222e3b1d5fb940d466bb983cf66a\",\"title\":\"Video Inpainting Under Constrained Camera Motion\",\"url\":\"https://www.semanticscholar.org/paper/56210467fe8e222e3b1d5fb940d466bb983cf66a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805328\",\"name\":\"Nick C. Tang\"},{\"authorId\":\"1687384\",\"name\":\"Chiou-Ting Hsu\"},{\"authorId\":\"2020273\",\"name\":\"Chih-Wen Su\"},{\"authorId\":\"2215094\",\"name\":\"T. Shih\"},{\"authorId\":\"1704678\",\"name\":\"H. Liao\"}],\"doi\":\"10.1109/TMM.2011.2112642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5076b158da58310480fcfaf7d2a43d69e5ba4222\",\"title\":\"Video Inpainting on Digitized Vintage Films via Maintaining Spatiotemporal Continuity\",\"url\":\"https://www.semanticscholar.org/paper/5076b158da58310480fcfaf7d2a43d69e5ba4222\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2215094\",\"name\":\"T. Shih\"},{\"authorId\":\"1805328\",\"name\":\"Nick C. Tang\"},{\"authorId\":\"145159381\",\"name\":\"J. Hwang\"}],\"doi\":\"10.1109/TCSVT.2009.2013519\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3961f8317eac38cc0b1ecc35625e09b70ba5e02d\",\"title\":\"Exemplar-Based Video Inpainting Without Ghost Shadow Artifacts by Maintaining Temporal Continuity\",\"url\":\"https://www.semanticscholar.org/paper/3961f8317eac38cc0b1ecc35625e09b70ba5e02d\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"144479026\",\"name\":\"Q. Yan\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4487dba91f5b51d6cdc2390b9fcc527b19f685f9\",\"title\":\"Shepard Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4487dba91f5b51d6cdc2390b9fcc527b19f685f9\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1902919\",\"name\":\"A. Newson\"},{\"authorId\":\"1713633\",\"name\":\"Andr\\u00e9s Almansa\"},{\"authorId\":\"3284350\",\"name\":\"M. Fradet\"},{\"authorId\":\"1796594\",\"name\":\"Y. Gousseau\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1145/2534008.2534019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47c0a8b11d935af8eeb0d6591ba9ecf1d0bca1c1\",\"title\":\"Towards fast, generic video inpainting\",\"url\":\"https://www.semanticscholar.org/paper/47c0a8b11d935af8eeb0d6591ba9ecf1d0bca1c1\",\"venue\":\"CVMP '13\",\"year\":2013},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702012\",\"name\":\"C. Ballester\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"8004695\",\"name\":\"V. Caselles\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"144959292\",\"name\":\"J. Verdera\"}],\"doi\":\"10.1109/83.935036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75bc9595744b133a86c2f2da9b207b4206b88dd4\",\"title\":\"Filling-in by joint interpolation of vector fields and gray levels\",\"url\":\"https://www.semanticscholar.org/paper/75bc9595744b133a86c2f2da9b207b4206b88dd4\",\"venue\":\"IEEE Trans. Image Process.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40303404\",\"name\":\"R. K\\u00f6hler\"},{\"authorId\":\"1814533\",\"name\":\"C. Schuler\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1007/978-3-319-11752-2_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52303688c8d60969587ba45a3cb345e2c7bf91d6\",\"title\":\"Mask-Specific Inpainting with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52303688c8d60969587ba45a3cb345e2c7bf91d6\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":\"1604.03540\",\"authors\":[{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2016.89\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63333669bcf694aba2e1928f6060ab1d6a5161fe\",\"title\":\"Training Region-Based Object Detectors with Online Hard Example Mining\",\"url\":\"https://www.semanticscholar.org/paper/63333669bcf694aba2e1928f6060ab1d6a5161fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1890945\",\"name\":\"Mounira Ebdelli\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1780587\",\"name\":\"C. Guillemot\"}],\"doi\":\"10.1109/TIP.2015.2437193\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"379012663454bc990409c7c833d6fed1914d74c3\",\"title\":\"Video Inpainting With Short-Term Windows: Application to Object Removal and Error Concealment\",\"url\":\"https://www.semanticscholar.org/paper/379012663454bc990409c7c833d6fed1914d74c3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":\"1903.07414\",\"authors\":[{\"authorId\":\"33385667\",\"name\":\"Tak-Wai Hui\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/tpami.2020.2976928\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50fbf62ed38a6c4ff1acdfb0bae6465f89866fc6\",\"title\":\"A Lightweight Optical Flow CNN - Revisiting Data Fidelity and Regularization\",\"url\":\"https://www.semanticscholar.org/paper/50fbf62ed38a6c4ff1acdfb0bae6465f89866fc6\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2600320\",\"name\":\"Soheil Darabi\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"143881938\",\"name\":\"P. Sen\"}],\"doi\":\"10.1145/2185520.2185578\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd61d60c446a491c6110d568841ca594391b38e6\",\"title\":\"Image melding: combining inconsistent images using patch-based synthesis\",\"url\":\"https://www.semanticscholar.org/paper/fd61d60c446a491c6110d568841ca594391b38e6\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39990338\",\"name\":\"S. Iizuka\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/3072959.3073659\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d21ebaab3f715dc7178966ff146711882e6a6fee\",\"title\":\"Globally and locally consistent image completion\",\"url\":\"https://www.semanticscholar.org/paper/d21ebaab3f715dc7178966ff146711882e6a6fee\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41223368\",\"name\":\"D. Simakov\"},{\"authorId\":\"2289537\",\"name\":\"Y. Caspi\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1109/CVPR.2008.4587842\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e93e27d64243fd0b77c6f22d4655990d9e9204e\",\"title\":\"Summarizing visual data using bidirectional similarity\",\"url\":\"https://www.semanticscholar.org/paper/2e93e27d64243fd0b77c6f22d4655990d9e9204e\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1412.7062\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39ad6c911f3351a3b390130a6e4265355b4d593b\",\"title\":\"Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs\",\"url\":\"https://www.semanticscholar.org/paper/39ad6c911f3351a3b390130a6e4265355b4d593b\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2016.85\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05e9e85b5137016c93d042170e82f77bb551a108\",\"title\":\"A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/05e9e85b5137016c93d042170e82f77bb551a108\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1709.02371\",\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00931\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"title\":\"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume\",\"url\":\"https://www.semanticscholar.org/paper/d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Deep Flow-Guided Video Inpainting\",\"topics\":[{\"topic\":\"Inpainting\",\"topicId\":\"146260\",\"url\":\"https://www.semanticscholar.org/topic/146260\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Collision detection\",\"topicId\":\"38329\",\"url\":\"https://www.semanticscholar.org/topic/38329\"},{\"topic\":\"Refinement (computing)\",\"topicId\":\"5410\",\"url\":\"https://www.semanticscholar.org/topic/5410\"},{\"topic\":\"Software propagation\",\"topicId\":\"2021211\",\"url\":\"https://www.semanticscholar.org/topic/2021211\"},{\"topic\":\"MOE\",\"topicId\":\"95374\",\"url\":\"https://www.semanticscholar.org/topic/95374\"},{\"topic\":\"Multitier architecture\",\"topicId\":\"19387\",\"url\":\"https://www.semanticscholar.org/topic/19387\"},{\"topic\":\"Tier 1 network\",\"topicId\":\"622670\",\"url\":\"https://www.semanticscholar.org/topic/622670\"}],\"url\":\"https://www.semanticscholar.org/paper/f3f1ea39c55e9c85a68fe50450cd7dfa6515e55c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"