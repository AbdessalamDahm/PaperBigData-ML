"{\"abstract\":\"There have been a few recent methods proposed in text to video moment retrieval using natural language queries, but requiring full supervision during training. However, acquiring a large number of training videos with temporal boundary annotations for each text description is extremely time-consuming and often not scalable. In order to cope with this issue, in this work, we introduce the problem of learning from weak labels for the task of text to video moment retrieval. The weak nature of the supervision is because, during training, we only have access to the video-text pairs rather than the temporal extent of the video to which different text descriptions relate. We propose a joint visual-semantic embedding based framework that learns the notion of relevant segments from video using only video-level sentence descriptions. Specifically, our main idea is to utilize latent alignment between video frames and sentence descriptions using Text-Guided Attention (TGA). TGA is then used during the test phase to retrieve relevant moments. Experiments on two benchmark datasets demonstrate that our method achieves comparable performance to state-of-the-art fully supervised approaches.\",\"arxivId\":\"1904.03282\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\",\"url\":\"https://www.semanticscholar.org/author/47733442\"},{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\",\"url\":\"https://www.semanticscholar.org/author/49616225\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\",\"url\":\"https://www.semanticscholar.org/author/1404727582\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"7621447\",\"name\":\"X. Wei\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7928ff4b66e866e7052915cd34861f1db2288cc4\",\"title\":\"Adversarial Video Moment Retrieval by Jointly Modeling Ranking and Localization\",\"url\":\"https://www.semanticscholar.org/paper/7928ff4b66e866e7052915cd34861f1db2288cc4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49251818\",\"name\":\"Junwen Chen\"},{\"authorId\":\"2342453\",\"name\":\"Wentao Bao\"},{\"authorId\":\"144790316\",\"name\":\"Y. Kong\"}],\"doi\":\"10.1145/3394171.3413614\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"83190706a4075cc2a44d2b43da2903bdf861d28d\",\"title\":\"Activity-driven Weakly-Supervised Spatio-Temporal Grounding from Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/83190706a4075cc2a44d2b43da2903bdf861d28d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1912.06617\",\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR42600.2020.00095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bc01f26b29282855e7cc997a737aa72697a4cac\",\"title\":\"Action Modifiers: Learning From Adverbs in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bc01f26b29282855e7cc997a737aa72697a4cac\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e91926b744564bd6e7a88b9bb3706fd391b77488\",\"title\":\"UCR-VCG @ TRECVID 2018: Video to Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/e91926b744564bd6e7a88b9bb3706fd391b77488\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3234471\",\"name\":\"D. Galanopoulos\"},{\"authorId\":\"1737436\",\"name\":\"V. Mezaris\"}],\"doi\":\"10.1145/3372278.3390737\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf89a2c1c58bcd5aefd1bb08d9773a33084867f0\",\"title\":\"Attention Mechanisms, Signal Encodings and Fusion Strategies for Improved Ad-hoc Video Search with Dual Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/bf89a2c1c58bcd5aefd1bb08d9773a33084867f0\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27720832\",\"name\":\"T. Long\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"title\":\"Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.08199\",\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9388ec8a0de86969afce29947b8b80b5698e4a21\",\"title\":\"Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\",\"url\":\"https://www.semanticscholar.org/paper/9388ec8a0de86969afce29947b8b80b5698e4a21\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"title\":\"wMAN: Weakly-supervised Moment Alignment Network for Text-based Video Segment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.10238\",\"authors\":[{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"30559382\",\"name\":\"S. Yoon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"1753686270\",\"name\":\"Young-Joon Lee\"},{\"authorId\":\"3315036\",\"name\":\"S. Kang\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1007/978-3-030-58604-1_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"425278984b2be6b5412e264c7a200b797018ae8f\",\"title\":\"VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/425278984b2be6b5412e264c7a200b797018ae8f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"1993659018\",\"name\":\"Xinjian Gao\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3394171.3413610\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"title\":\"Weakly-Supervised Video Object Grounding by Exploring Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.07048\",\"authors\":[{\"authorId\":\"2250163\",\"name\":\"Yijun Song\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":null,\"name\":\"Jun Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e655c524630b0fb37f11b01468dab5477c58db0f\",\"title\":\"Weakly-Supervised Multi-Level Attentional Reconstruction Network for Grounding Textual Queries in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e655c524630b0fb37f11b01468dab5477c58db0f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.06941\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2422046\",\"name\":\"Baoxing Huai\"},{\"authorId\":\"145078771\",\"name\":\"J. Yuan\"}],\"doi\":\"10.24963/ijcai.2020/149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"title\":\"Object-Aware Multi-Branch Relation Networks for Spatio-Temporal Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/ICIP40778.2020.9190869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"title\":\"A Feature Pair Fusion And Hierarchical Learning Framework For Video Re-Localization\",\"url\":\"https://www.semanticscholar.org/paper/4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2006.11747\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"1521319166\",\"name\":\"Zhe Wang\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"a792ff56eeed530fab1935168510cbb16b0f1b68\",\"title\":\"Weak Supervision and Referring Attention for Temporal-Textual Association Learning\",\"url\":\"https://www.semanticscholar.org/paper/a792ff56eeed530fab1935168510cbb16b0f1b68\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08614\",\"authors\":[{\"authorId\":\"2017491\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1145/3394171.3413862\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"949b698f4aaaeea923d451db8175c5b464520f27\",\"title\":\"Reinforcement Learning for Weakly Supervised Temporal Grounding of Natural Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/949b698f4aaaeea923d451db8175c5b464520f27\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.01403\",\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"},{\"authorId\":\"2956815\",\"name\":\"Zichuan Xu\"}],\"doi\":\"10.1145/3394171.3414026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b632209923bfe3452ac19f23b46c70455fae465\",\"title\":\"Jointly Cross- and Self-Modal Graph Attention Network for Query-Based Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/2b632209923bfe3452ac19f23b46c70455fae465\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.08716\",\"authors\":[{\"authorId\":\"152666334\",\"name\":\"Sudipta Paul\"},{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"title\":\"Text-based Localization of Moments in a Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.09308\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"144963373\",\"name\":\"Peng Tang\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"02c9abd1c4567ba82289b1a989a51243087c6521\",\"title\":\"Look Closer to Ground Better: Weakly-Supervised Temporal Grounding of Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/02c9abd1c4567ba82289b1a989a51243087c6521\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"title\":\"STRONG: Spatio-Temporal Reinforcement Learning for Cross-Modal Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.13784\",\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"title\":\"LoGAN: Latent Graph Co-Attention Network for Weakly-Supervised Video Moment Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.09877\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"title\":\"Graph Neural Network for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08257\",\"authors\":[{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":\"10.1145/3394171.3413967\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"02e5188e19523140b82d05f00bee10933ccc3b50\",\"title\":\"Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/02e5188e19523140b82d05f00bee10933ccc3b50\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.08617\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-58523-5_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"432921b7a2c782cedc2a7d87b6194b906e31086d\",\"title\":\"Preserving Semantic Neighborhoods for Robust Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/432921b7a2c782cedc2a7d87b6194b906e31086d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10631\",\"authors\":[{\"authorId\":\"1882695\",\"name\":\"X. Wang\"},{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"30164077\",\"name\":\"Dripta S. Raychaudhuri\"},{\"authorId\":\"94628296\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Yaonan Wang\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50e5ca477ee8cc2b9dd58de78ceacf37cc085d18\",\"title\":\"Learning Person Re-identification Models from Videos with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/50e5ca477ee8cc2b9dd58de78ceacf37cc085d18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1912074118\",\"name\":\"Jianfeng Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"title\":\"Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network\",\"url\":\"https://www.semanticscholar.org/paper/83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2008.08977\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"title\":\"Generating Adjacency Matrix for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47795983\",\"name\":\"Yu-Lan Yang\"},{\"authorId\":\"51484605\",\"name\":\"Z. Li\"},{\"authorId\":\"1519001806\",\"name\":\"Gangyan Zeng\"}],\"doi\":\"10.1109/ICCST50977.2020.00123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"title\":\"A Survey of Temporal Activity Localization via Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3705643\",\"name\":\"H. Wang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"491bfcc0dbcca04b4983d2716e9125b76a45ede2\",\"title\":\"Context Modulated Dynamic Networks for Actor and Action Video Segmentation with Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/491bfcc0dbcca04b4983d2716e9125b76a45ede2\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TIP.2020.3042086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"title\":\"Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021}],\"corpusId\":102351477,\"doi\":\"10.1109/CVPR.2019.01186\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":11,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1654e19de0187085e9d1da2d9e8718f49cd2f731\",\"title\":\"Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework\",\"url\":\"https://www.semanticscholar.org/paper/1654e19de0187085e9d1da2d9e8718f49cd2f731\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/s13735-018-00166-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6305115f393d96df92f9044b8951969e28aa7114\",\"title\":\"Joint embeddings with multimodal cues for video-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6305115f393d96df92f9044b8951969e28aa7114\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2018},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1711.05535\",\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40a943746d3a6156f9ca477e437263c7841118ac\",\"title\":\"Dual-Path Convolutional Image-Text Embedding\",\"url\":\"https://www.semanticscholar.org/paper/40a943746d3a6156f9ca477e437263c7841118ac\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrea Frome\"},{\"authorId\":null,\"name\":\"Greg S Corrado\"},{\"authorId\":null,\"name\":\"Jon Shlens\"},{\"authorId\":null,\"name\":\"Samy Bengio\"},{\"authorId\":null,\"name\":\"Jeff Dean\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Devise: A deep visualsemantic embedding model\",\"url\":\"\",\"venue\":\"In NIPS,\",\"year\":2013},{\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.563\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39904503\",\"name\":\"C. A. Henning\"},{\"authorId\":\"1738703\",\"name\":\"R. Ewerth\"}],\"doi\":\"10.1145/3078971.3078991\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfe4c02324d7adc8ef059c02cee4798f3b296763\",\"title\":\"Estimating the Information Gap between Textual and Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/cfe4c02324d7adc8ef059c02cee4798f3b296763\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1807.10418\",\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/978-3-030-01225-0_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"title\":\"W-TALC: Weakly-supervised Temporal Activity Localization and Classification\",\"url\":\"https://www.semanticscholar.org/paper/b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1412.3555\",\"authors\":[{\"authorId\":\"8270717\",\"name\":\"J. Chung\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"title\":\"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1704.03470\",\"authors\":[{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"19353632\",\"name\":\"J. Huang\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/TPAMI.2018.2797921\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"title\":\"Learning Two-Branch Neural Networks for Image-Text Matching Tasks\",\"url\":\"https://www.semanticscholar.org/paper/f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"de228875bc33e9db85123469ef80fc0071a92386\",\"title\":\"Word2VisualVec: Image and Video to Sentence Matching by Visual Feature Prediction\",\"url\":\"https://www.semanticscholar.org/paper/de228875bc33e9db85123469ef80fc0071a92386\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1808.07793\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"3000659\",\"name\":\"Evangelos E. Papalexakis\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3240508.3240712\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"title\":\"Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3123266.3123317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"title\":\"Multi-Networks Joint Learning for Large-Scale Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"}],\"doi\":\"10.1109/CVPR.2016.216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"title\":\"A Multi-stream Bi-directional Recurrent Neural Network for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39904503\",\"name\":\"C. A. Henning\"},{\"authorId\":\"1738703\",\"name\":\"R. Ewerth\"}],\"doi\":\"10.1007/s13735-017-0142-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24d967ac44319cd053544c1b77e2e294b90efe81\",\"title\":\"Estimating the information gap between textual and visual representations\",\"url\":\"https://www.semanticscholar.org/paper/24d967ac44319cd053544c1b77e2e294b90efe81\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/CVPR.2016.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"title\":\"Learning Activity Progression in LSTMs for Activity Detection and Early Detection\",\"url\":\"https://www.semanticscholar.org/paper/e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240549\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"175864710def9b3e8b42e4613856d0b840c37615\",\"title\":\"Cross-modal Moment Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/175864710def9b3e8b42e4613856d0b840c37615\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2015.7299073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51239b320c73f3f2219286bf62f24d6763379328\",\"title\":\"Associating neural word embeddings with deep image representations using Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/51239b320c73f3f2219286bf62f24d6763379328\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3206025.3206064\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9dbca9da6a72ba3739813288b677888a6cf76272\",\"title\":\"Learning Joint Embedding with Multimodal Cues for Cross-Modal Video-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9dbca9da6a72ba3739813288b677888a6cf76272\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1505.06027\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3215950\",\"name\":\"R\\u00e9mi Lajugie\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.507\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"59ac98f3910dad473e7771ac61f796a038f1708f\",\"title\":\"Weakly-Supervised Alignment of Video with Text\",\"url\":\"https://www.semanticscholar.org/paper/59ac98f3910dad473e7771ac61f796a038f1708f\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018}],\"title\":\"Weakly Supervised Video Moment Retrieval From Text Queries\",\"topics\":[{\"topic\":\"Supervised learning\",\"topicId\":\"8357\",\"url\":\"https://www.semanticscholar.org/topic/8357\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"},{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"},{\"topic\":\"Truevision TGA\",\"topicId\":\"117963\",\"url\":\"https://www.semanticscholar.org/topic/117963\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"