"{\"abstract\":\"Current studies on action detection in untrimmed videos are mostly designed for action classes, where an action is described at word level such as jumping, tumbling, swing, etc. This paper focuses on a rarely investigated problem of localizing an activity via a sentence query which would be more challenging and practical. Considering that current methods are generally time-consuming due to the dense frame-processing manner, we propose a recurrent neural network based reinforcement learning model which selectively observes a sequence of frames and associates the given sentence with video content in a matching-based manner. However, directly matching sentences with video content performs poorly due to the large visual-semantic discrepancy. Thus, we extend the method to a semantic matching reinforcement learning (SM-RL) model by extracting semantic concepts of videos and then fusing them with global context features. Extensive experiments on three benchmark datasets, TACoS, Charades-STA and DiDeMo, show that our method achieves the state-of-the-art performance with a high detection speed, demonstrating both effectiveness and efficiency of our method.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"49336560\",\"name\":\"Weining Wang\",\"url\":\"https://www.semanticscholar.org/author/49336560\"},{\"authorId\":\"144368926\",\"name\":\"Yan Huang\",\"url\":\"https://www.semanticscholar.org/author/144368926\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\",\"url\":\"https://www.semanticscholar.org/author/123865558\"}],\"citationVelocity\":17,\"citations\":[{\"arxivId\":\"2008.08257\",\"authors\":[{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":\"10.1145/3394171.3413967\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"02e5188e19523140b82d05f00bee10933ccc3b50\",\"title\":\"Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/02e5188e19523140b82d05f00bee10933ccc3b50\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.11232\",\"authors\":[{\"authorId\":\"1432778730\",\"name\":\"Binjie Zhang\"},{\"authorId\":\"1940342\",\"name\":\"Y. Li\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"2091174\",\"name\":\"Pin Jiang\"},{\"authorId\":\"1387190008\",\"name\":\"Ying Shan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e645df446ccdc985b85864ac0b91b053090c14d\",\"title\":\"A Simple Yet Effective Method for Video Temporal Grounding with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e645df446ccdc985b85864ac0b91b053090c14d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.05010\",\"authors\":[{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6897\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"title\":\"Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"7621447\",\"name\":\"X. Wei\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413841\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7928ff4b66e866e7052915cd34861f1db2288cc4\",\"title\":\"Adversarial Video Moment Retrieval by Jointly Modeling Ranking and Localization\",\"url\":\"https://www.semanticscholar.org/paper/7928ff4b66e866e7052915cd34861f1db2288cc4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.10434\",\"authors\":[{\"authorId\":\"49687714\",\"name\":\"Haoyu Tang\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"title\":\"Frame-wise Cross-modal Match for Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413975\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"title\":\"Dual Path Interaction Network for Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.13931\",\"authors\":[{\"authorId\":\"153504695\",\"name\":\"Hao Zhang\"},{\"authorId\":\"1735962\",\"name\":\"Aixin Sun\"},{\"authorId\":\"1492128584\",\"name\":\"Wei Jing\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"}],\"doi\":\"10.18653/v1/2020.acl-main.585\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"title\":\"Span-based Localizing Network for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.10132\",\"authors\":[{\"authorId\":\"51218991\",\"name\":\"Sisi Qu\"},{\"authorId\":\"150234800\",\"name\":\"Mattia Soldan\"},{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1402915033\",\"name\":\"Jesper Tegn\\u00e9r\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"075ce64105cc54cec2b54c24f8f890f2c62d090b\",\"title\":\"VLG-Net: Video-Language Graph Matching Network for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/075ce64105cc54cec2b54c24f8f890f2c62d090b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charades-STA\"},{\"authorId\":null,\"name\":\"ActivityNet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.08614\",\"authors\":[{\"authorId\":\"2017491\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1145/3394171.3413862\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"949b698f4aaaeea923d451db8175c5b464520f27\",\"title\":\"Reinforcement Learning for Weakly Supervised Temporal Grounding of Natural Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/949b698f4aaaeea923d451db8175c5b464520f27\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447373\",\"name\":\"X. Zhang\"},{\"authorId\":\"48019166\",\"name\":\"J. Zhao\"},{\"authorId\":null,\"name\":\"Long Chen\"},{\"authorId\":\"71074804\",\"name\":\"W. Wang\"}],\"doi\":\"10.1007/978-3-030-64221-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd8930e23b8aa474df701469a4e9d8c8098c9432\",\"title\":\"Advances in Neural Networks \\u2013 ISNN 2020: 17th International Symposium on Neural Networks, ISNN 2020, Cairo, Egypt, December 4\\u20136, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/cd8930e23b8aa474df701469a4e9d8c8098c9432\",\"venue\":\"ISNN\",\"year\":2020},{\"arxivId\":\"1911.08199\",\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6820\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9388ec8a0de86969afce29947b8b80b5698e4a21\",\"title\":\"Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\",\"url\":\"https://www.semanticscholar.org/paper/9388ec8a0de86969afce29947b8b80b5698e4a21\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2001.06680\",\"authors\":[{\"authorId\":\"71170299\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1609/AAAI.V34I07.6924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"title\":\"Tree-Structured Policy based Progressive Reinforcement Learning for Temporally Language Grounding in Video\",\"url\":\"https://www.semanticscholar.org/paper/b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.09936\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"title\":\"Tripping through time: Efficient Localization of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.02646\",\"authors\":[{\"authorId\":\"1992634637\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"2027130177\",\"name\":\"J. Fu\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"261582574b9e039be1518bc7c8e405a4af75a41a\",\"title\":\"Multi-Scale 2D Temporal Adjacent Networks for Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/261582574b9e039be1518bc7c8e405a4af75a41a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93353108\",\"name\":\"Cheng Chen\"},{\"authorId\":\"1649999106\",\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1007/978-3-030-64221-1_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6b6e4860665d9185dfd80af63d93334582c56be\",\"title\":\"Semantic Modulation Based Residual Network for Temporal Language Queries Grounding in Video\",\"url\":\"https://www.semanticscholar.org/paper/c6b6e4860665d9185dfd80af63d93334582c56be\",\"venue\":\"ISNN\",\"year\":2020},{\"arxivId\":\"1912.03590\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6984\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cef4a58c08816c3d3bd56826a418508720d4b20d\",\"title\":\"Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/cef4a58c08816c3d3bd56826a418508720d4b20d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.03545\",\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2342663\",\"name\":\"H. Xu\"},{\"authorId\":\"51026885\",\"name\":\"W. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/cvpr42600.2020.01030\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"355403d7ce4b625307fd3ebb2beea269ecc15213\",\"title\":\"Dense Regression Network for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/355403d7ce4b625307fd3ebb2beea269ecc15213\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.07236\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":\"10.1109/WACV45572.2020.9093328\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"title\":\"Proposal-free Temporal Moment Localization of a Natural-Language Query in Video using Guided Attention\",\"url\":\"https://www.semanticscholar.org/paper/03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"71208047\",\"name\":\"C. Tan\"},{\"authorId\":\"47056890\",\"name\":\"Xiao-Lin Li\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.18653/v1/D19-1518\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"872091517b0bfad0e9bc1826d4668022d1d57953\",\"title\":\"DEBUG: A Dense Bottom-Up Grounding Approach for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/872091517b0bfad0e9bc1826d4668022d1d57953\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2004.07514\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR42600.2020.01082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"title\":\"Local-Global Video-Text Interactions for Temporal Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.14552\",\"authors\":[{\"authorId\":\"46999304\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"beeafc087178102645be19fb6975f53b798061b4\",\"title\":\"Compare and Select: Video Summarization with Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/beeafc087178102645be19fb6975f53b798061b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58565-5_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"853069fa3f976fe368858ce4650b6348a17a3764\",\"title\":\"Hierarchical Visual-Textual Graph for Temporal Activity Localization via Language\",\"url\":\"https://www.semanticscholar.org/paper/853069fa3f976fe368858ce4650b6348a17a3764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413840\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"title\":\"STRONG: Spatio-Temporal Reinforcement Learning for Cross-Modal Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.10457\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"title\":\"Language Guided Networks for Cross-modal Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144978660\",\"name\":\"Q. Li\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1007/s11263-020-01327-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60deedaffacfdcc72d5a1111d487932f19f61e08\",\"title\":\"A General Framework for Deep Supervised Discrete Hashing\",\"url\":\"https://www.semanticscholar.org/paper/60deedaffacfdcc72d5a1111d487932f19f61e08\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2009.00325\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"48679036\",\"name\":\"J. Heikkila\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.02602\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"title\":\"Human Action Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.07048\",\"authors\":[{\"authorId\":\"2250163\",\"name\":\"Yijun Song\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":null,\"name\":\"Jun Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e655c524630b0fb37f11b01468dab5477c58db0f\",\"title\":\"Weakly-Supervised Multi-Level Attentional Reconstruction Network for Grounding Textual Queries in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e655c524630b0fb37f11b01468dab5477c58db0f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47795983\",\"name\":\"Yu-Lan Yang\"},{\"authorId\":\"51484605\",\"name\":\"Z. Li\"},{\"authorId\":\"1519001806\",\"name\":\"Gangyan Zeng\"}],\"doi\":\"10.1109/ICCST50977.2020.00123\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"title\":\"A Survey of Temporal Activity Localization via Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020}],\"corpusId\":198186702,\"doi\":\"10.1109/CVPR.2019.00042\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"0fa68cde4db12779adacb70a24961cf09b1adf73\",\"references\":[{\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.563\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.01180\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34a468c0f6e299db7ca1228726f161856a3082ec\",\"title\":\"Cascaded Boundary Regression for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/34a468c0f6e299db7ca1228726f161856a3082ec\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00645\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1710.06236\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1145/3123266.3123343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"title\":\"Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1708.02349\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"144091320\",\"name\":\"Guyue Zhang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"10727378\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICCV.2017.610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f0167299d73b19d800953dd2859a0af2244a0c5\",\"title\":\"Temporal Context Network for Activity Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5f0167299d73b19d800953dd2859a0af2244a0c5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.07770\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.130\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"title\":\"Captioning Images with Diverse Objects\",\"url\":\"https://www.semanticscholar.org/paper/b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.5244/C.31.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"title\":\"End-to-End, Single-Stream Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.04671\",\"authors\":[{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144720255\",\"name\":\"T. Lu\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/CVPR.2017.342\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60ca4a90d751e315a2b143289a5c54488e324949\",\"title\":\"Temporal Action Localization by Structured Maximal Sums\",\"url\":\"https://www.semanticscholar.org/paper/60ca4a90d751e315a2b143289a5c54488e324949\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3209978.3210003\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"519da94369c1d87e09c592f239b55cc9486b5b7c\",\"title\":\"Attentive Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/519da94369c1d87e09c592f239b55cc9486b5b7c\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"24138684\",\"name\":\"Dominikus Wetzel\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.1162/tacl_a_00207\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"title\":\"Grounding Action Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2016.211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bac994dda1385cd709e08e24170c711d8c573676\",\"title\":\"Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bac994dda1385cd709e08e24170c711d8c573676\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Language-Driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Semantic matching\",\"topicId\":\"111380\",\"url\":\"https://www.semanticscholar.org/topic/111380\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Concatenation\",\"topicId\":\"2262\",\"url\":\"https://www.semanticscholar.org/topic/2262\"},{\"topic\":\"Digital video\",\"topicId\":\"44670\",\"url\":\"https://www.semanticscholar.org/topic/44670\"},{\"topic\":\"Internationalization and localization\",\"topicId\":\"69706\",\"url\":\"https://www.semanticscholar.org/topic/69706\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Static timing analysis\",\"topicId\":\"34178\",\"url\":\"https://www.semanticscholar.org/topic/34178\"},{\"topic\":\"Oracle Fusion Architecture\",\"topicId\":\"4475853\",\"url\":\"https://www.semanticscholar.org/topic/4475853\"},{\"topic\":\"Discrepancy function\",\"topicId\":\"1146712\",\"url\":\"https://www.semanticscholar.org/topic/1146712\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"}],\"url\":\"https://www.semanticscholar.org/paper/0fa68cde4db12779adacb70a24961cf09b1adf73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"