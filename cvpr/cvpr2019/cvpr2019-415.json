"{\"abstract\":\"Despite the recent success in face recognition and object classification, in the field of human gaze prediction, computer models are still struggling to accurately mimic human attention. One main reason is that visual attention is a complex human behavior influenced by multiple factors, ranging from low-level features (e.g., color, contrast) to high-level human perception (e.g., objects interactions, object sentiment), making it difficult to model computationally. In this work, we investigate the relation between object sentiment and human attention. We first introduce a new evaluation metric (AttI) for measuring human attention that focuses on human fixation consensus. A series of empirical data analyses with AttI indicate that emotion-evoking objects receive attention favor, especially when they co-occur with emotionally-neutral objects, and this favor varies with different image complexity. Based on the empirical analyses, we design a deep neural network for human attention prediction which allows the attention bias on emotion-evoking objects to be encoded in its feature space. Experiments on two benchmark datasets demonstrate its superior performance, especially on metrics that evaluate relative importance of salient regions. This research provides the clearest picture to date on how object sentiments influence human attention, and it makes one of the first attempts to model this phenomenon computationally.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\",\"url\":\"https://www.semanticscholar.org/author/48084733\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\",\"url\":\"https://www.semanticscholar.org/author/2087470\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\",\"url\":\"https://www.semanticscholar.org/author/1700911\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\",\"url\":\"https://www.semanticscholar.org/author/1744045\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753529\",\"name\":\"Ruifeng Xu\"},{\"authorId\":\"39305740\",\"name\":\"W. De\"},{\"authorId\":\"47896751\",\"name\":\"W. Zhong\"},{\"authorId\":\"1913816839\",\"name\":\"Ling Tian\"},{\"authorId\":\"121498038\",\"name\":\"Yongsheng Bai\"},{\"authorId\":\"102828451\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/978-3-030-59605-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"544c6e787d84f303008a0d9828907baf58a04013\",\"title\":\"Artificial Intelligence and Mobile Services \\u2013 AIMS 2020: 9th International Conference, Held as Part of the Services Conference Federation, SCF 2020, Honolulu, HI, USA, September 18-20, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/544c6e787d84f303008a0d9828907baf58a04013\",\"venue\":\"AIMS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48297070\",\"name\":\"Tetsuya Asakawa\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0da8eb8bbb0e70d77957ebe8598986543094c7e\",\"title\":\"Median based Multi-label Prediction by Inflating Emotions with Dyads for Visual Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e0da8eb8bbb0e70d77957ebe8598986543094c7e\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1007/s42979-019-0061-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be2e75a806c39bd6d4b8c3657097298e2cbac692\",\"title\":\"A Deeper Look at Human Visual Perception of Images\",\"url\":\"https://www.semanticscholar.org/paper/be2e75a806c39bd6d4b8c3657097298e2cbac692\",\"venue\":\"SN Comput. Sci.\",\"year\":2020}],\"corpusId\":198118970,\"doi\":\"10.1109/CVPR.2019.00415\",\"fieldsOfStudy\":[\"Computer Science\",\"Geology\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"6734096\",\"name\":\"J. Fleiss\"},{\"authorId\":\"81550700\",\"name\":\"B. Levin\"},{\"authorId\":\"47772931\",\"name\":\"M. Paik\"}],\"doi\":\"10.1002/0471445428.CH18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cf7ef12a7d6211ac4bf6fa0e8aa45028bd8bac2\",\"title\":\"The measurement of interrater agreement\",\"url\":\"https://www.semanticscholar.org/paper/3cf7ef12a7d6211ac4bf6fa0e8aa45028bd8bac2\",\"venue\":\"\",\"year\":2004},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2152501\",\"name\":\"P. Vuilleumier\"}],\"doi\":\"10.1016/j.tics.2005.10.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efdcc6a400bab0a2eca571b5d431a38ee3d7d247\",\"title\":\"How brains beware: neural mechanisms of emotional attention\",\"url\":\"https://www.semanticscholar.org/paper/efdcc6a400bab0a2eca571b5d431a38ee3d7d247\",\"venue\":\"Trends in Cognitive Sciences\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-642-15561-1_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"title\":\"An Eye Fixation Database for Saliency Detection in Images\",\"url\":\"https://www.semanticscholar.org/paper/ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2811292\",\"name\":\"Rachit Dubey\"},{\"authorId\":\"6672056\",\"name\":\"Joshua C. Peterson\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/ICCV.2015.130\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b19fbdd1a8675d9e5321dc29db8be7856f9e5f48\",\"title\":\"What Makes an Object Memorable?\",\"url\":\"https://www.semanticscholar.org/paper/b19fbdd1a8675d9e5321dc29db8be7856f9e5f48\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2013.320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37c49d49817d9a689b57d7bbd2113cc80792bea1\",\"title\":\"Social Role Discovery in Human Events\",\"url\":\"https://www.semanticscholar.org/paper/37c49d49817d9a689b57d7bbd2113cc80792bea1\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2280303\",\"name\":\"Huiying Liu\"},{\"authorId\":\"145093159\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144072009\",\"name\":\"Tianrong Rao\"},{\"authorId\":\"1781683\",\"name\":\"I. Burnett\"}],\"doi\":\"10.1109/TNNLS.2016.2553579\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3833247481c29203a51efd494480923e9644318e\",\"title\":\"Improving Visual Saliency Computing With Emotion Intensity\",\"url\":\"https://www.semanticscholar.org/paper/3833247481c29203a51efd494480923e9644318e\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/ICCV.2017.513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"title\":\"Understanding Low- and High-Level Contributions to Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Oliva\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CAT 2000 : A large scale fixation dataset for boosting saliency research . CVPR 2015 workshop on \\u201d Future of Datasets \\u201d\",\"url\":\"\",\"venue\":\"\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1986858\",\"name\":\"P. Niedenthal\"},{\"authorId\":\"34648282\",\"name\":\"S. Kitayama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0fff409da8828ce4c96aa63e4eacd60c9f51d4f\",\"title\":\"The heart's eye: Emotional influences in perception and attention.\",\"url\":\"https://www.semanticscholar.org/paper/c0fff409da8828ce4c96aa63e4eacd60c9f51d4f\",\"venue\":\"\",\"year\":1994},{\"arxivId\":\"1703.06870\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2500502\",\"name\":\"Chuanbo Chen\"},{\"authorId\":\"153498894\",\"name\":\"H. Tang\"},{\"authorId\":\"2217669\",\"name\":\"Z. Lyu\"},{\"authorId\":\"48333321\",\"name\":\"Hu Liang\"},{\"authorId\":\"49897626\",\"name\":\"Jun Shang\"},{\"authorId\":\"3221422\",\"name\":\"M. Sarem\"}],\"doi\":\"10.1117/1.JEI.23.5.053023\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"645194693abd70a0c8947f336c3be357251e572d\",\"title\":\"Saliency modeling via outlier detection\",\"url\":\"https://www.semanticscholar.org/paper/645194693abd70a0c8947f336c3be357251e572d\",\"venue\":\"J. Electronic Imaging\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Judd Bylinskii\"},{\"authorId\":null,\"name\":\"A. Oliva\"},{\"authorId\":null,\"name\":\"A. Torralba\"},{\"authorId\":null,\"name\":\"F. Durand\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CAT 2000 : A large scale fixation dataset for boosting saliency research . CVPR 2015 workshop on \\u201d Future of Datasets \\u201d\",\"url\":\"\",\"venue\":\"\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"}],\"doi\":\"10.1109/CVPR.2013.152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d7924e07914a147d7f6b868050d4edd093b952d\",\"title\":\"Learning Video Saliency from Human Gaze Using Candidate Selection\",\"url\":\"https://www.semanticscholar.org/paper/3d7924e07914a147d7f6b868050d4edd093b952d\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152669131\",\"name\":\"M. Sun\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"73019850\",\"name\":\"Kai Wang\"},{\"authorId\":\"144787557\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/ICME.2016.7552961\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"66cb25187cd4342ae258b21440ec572099f71e8d\",\"title\":\"Discovering affective regions in deep convolutional neural networks for visual sentiment prediction\",\"url\":\"https://www.semanticscholar.org/paper/66cb25187cd4342ae258b21440ec572099f71e8d\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2692770\",\"name\":\"K. Peng\"},{\"authorId\":\"1803066\",\"name\":\"A. Sadovnik\"},{\"authorId\":\"50716462\",\"name\":\"A. Gallagher\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICIP.2016.7532430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10e74ae94716de94fe404b8add04bc51a3f7631f\",\"title\":\"Where do emotions come from? Predicting the Emotion Stimuli Map\",\"url\":\"https://www.semanticscholar.org/paper/10e74ae94716de94fe404b8add04bc51a3f7631f\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Pan\"},{\"authorId\":null,\"name\":\"C. Canton\"},{\"authorId\":null,\"name\":\"K. McGuinness\"},{\"authorId\":null,\"name\":\"N. E. O\\u2019Connor\"},{\"authorId\":null,\"name\":\"J. Torres\"},{\"authorId\":null,\"name\":\"E. Sayrol\"},{\"authorId\":null,\"name\":\"X. a\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Giro-i Nieto. SalGAN: Visual saliency prediction with generative adversarial networks\",\"url\":\"\",\"venue\":\"arXiv: 1701.01081v2,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50827772\",\"name\":\"G. Patterson\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1007/978-3-319-46466-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8db052e5eea17c28d8a98b9d5a5e7c32bee2655c\",\"title\":\"COCO Attributes: Attributes for People, Animals, and Objects\",\"url\":\"https://www.semanticscholar.org/paper/8db052e5eea17c28d8a98b9d5a5e7c32bee2655c\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M.-L. Chua Richard\"},{\"authorId\":null,\"name\":\"Phyllis\"},{\"authorId\":null,\"name\":\"J. Dolan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Common effects of emotional valence , arousal and attention on neural activation during visual processing of pictures\",\"url\":\"\",\"venue\":\"Neuropsychologia\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50480971\",\"name\":\"R. Lane\"},{\"authorId\":\"1896976\",\"name\":\"P. Chua\"},{\"authorId\":\"145451558\",\"name\":\"R. Dolan\"}],\"doi\":\"10.1016/S0028-3932(99)00017-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2feaf63306c0604b3ce4f533c5ed20cab6e8026e\",\"title\":\"Common effects of emotional valence, arousal and attention on neural activation during visual processing of pictures\",\"url\":\"https://www.semanticscholar.org/paper/2feaf63306c0604b3ce4f533c5ed20cab6e8026e\",\"venue\":\"Neuropsychologia\",\"year\":1999},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2075727\",\"name\":\"A. Shackman\"},{\"authorId\":\"145094839\",\"name\":\"L. Pessoa\"},{\"authorId\":\"48639094\",\"name\":\"S. Lim\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"8a3bcae0bc46e4625f132640ef4e3d813464d8e4\",\"title\":\"Top-down modulation of attention by emotion\",\"url\":\"https://www.semanticscholar.org/paper/8a3bcae0bc46e4625f132640ef4e3d813464d8e4\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8474695\",\"name\":\"R. Fazio\"},{\"authorId\":\"1402305961\",\"name\":\"D. Roskos-Ewoldsen\"},{\"authorId\":\"47852231\",\"name\":\"M. C. Powell\"}],\"doi\":\"10.1016/B978-0-12-410560-7.50015-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e60b23e6e041af989623ce11785d90a8a0d79664\",\"title\":\"Attitudes, Perception, and Attention\",\"url\":\"https://www.semanticscholar.org/paper/e60b23e6e041af989623ce11785d90a8a0d79664\",\"venue\":\"\",\"year\":1994},{\"arxivId\":\"1610.01563\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d160d375a7c187dfe10c110e9e733f36accb87e6\",\"title\":\"DeepGaze II: Reading fixations from deep features trained on object recognition\",\"url\":\"https://www.semanticscholar.org/paper/d160d375a7c187dfe10c110e9e733f36accb87e6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"2055335\",\"name\":\"Fabian Nater\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICCV.2013.205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbec6f6e3c1493a403e8b66134977e0c93743733\",\"title\":\"The Interestingness of Images\",\"url\":\"https://www.semanticscholar.org/paper/cbec6f6e3c1493a403e8b66134977e0c93743733\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"38163342\",\"name\":\"Merrielle Spain\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1167/8.14.18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"title\":\"Objects predict fixations better than early saliency.\",\"url\":\"https://www.semanticscholar.org/paper/c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"144506018\",\"name\":\"Z. Shen\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2018.00785\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"title\":\"Emotional Attention: A Study of Image Sentiment and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2152501\",\"name\":\"P. Vuilleumier\"},{\"authorId\":\"144169525\",\"name\":\"J. Driver\"}],\"doi\":\"10.1098/rstb.2007.2092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2874ae6869e83a86c5607aa40dd7d049857b07\",\"title\":\"Modulation of visual processing by attention and emotion: windows on causal interactions between human brain regions\",\"url\":\"https://www.semanticscholar.org/paper/fa2874ae6869e83a86c5607aa40dd7d049857b07\",\"venue\":\"Philosophical Transactions of the Royal Society B: Biological Sciences\",\"year\":2007},{\"arxivId\":\"1505.03581\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"519feb1f3c23baea6960dfa204521f96a74b82bb\",\"title\":\"CAT2000: A Large Scale Fixation Dataset for Boosting Saliency Research\",\"url\":\"https://www.semanticscholar.org/paper/519feb1f3c23baea6960dfa204521f96a74b82bb\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48534965\",\"name\":\"J. Anderson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b8ba26fdc9b65567733c8568f182ae3dbf2773e\",\"title\":\"Cognitive Psychology and Its Implications\",\"url\":\"https://www.semanticscholar.org/paper/8b8ba26fdc9b65567733c8568f182ae3dbf2773e\",\"venue\":\"\",\"year\":1980},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"22631231\",\"name\":\"Dongyu She\"},{\"authorId\":null,\"name\":\"Ming Sun\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TMM.2018.2803520\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31eb6deb36961d32496a1c3ea9484c583cdbf4a9\",\"title\":\"Visual Sentiment Prediction Based on Automatic Discovery of Affective Regions\",\"url\":\"https://www.semanticscholar.org/paper/31eb6deb36961d32496a1c3ea9484c583cdbf4a9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015}],\"title\":\"Emotion-Aware Human Attention Prediction\",\"topics\":[{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Modulation\",\"topicId\":\"2260\",\"url\":\"https://www.semanticscholar.org/topic/2260\"},{\"topic\":\"Consensus (computer science)\",\"topicId\":\"16541\",\"url\":\"https://www.semanticscholar.org/topic/16541\"},{\"topic\":\"Subnetwork\",\"topicId\":\"36979\",\"url\":\"https://www.semanticscholar.org/topic/36979\"},{\"topic\":\"Facial recognition system\",\"topicId\":\"30847\",\"url\":\"https://www.semanticscholar.org/topic/30847\"},{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"Computer simulation\",\"topicId\":\"7425\",\"url\":\"https://www.semanticscholar.org/topic/7425\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Lazy evaluation\",\"topicId\":\"19479\",\"url\":\"https://www.semanticscholar.org/topic/19479\"},{\"topic\":\"Sentiment analysis\",\"topicId\":\"6011\",\"url\":\"https://www.semanticscholar.org/topic/6011\"}],\"url\":\"https://www.semanticscholar.org/paper/d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"