"{\"abstract\":\"We propose Scene Graph Auto-Encoder (SGAE) that incorporates the language inductive bias into the encoder-decoder image captioning framework for more human-like captions. Intuitively, we humans use the inductive bias to compose collocations and contextual inference in discourse. For example, when we see the relation ``person on bike'', it is natural to replace ``on'' with ``ride'' and infer ``person riding bike on a road'' even the ``road'' is not evident. Therefore, exploiting such bias as a language prior is expected to help the conventional encoder-decoder models less likely to overfit to the dataset bias and focus on reasoning. Specifically, we use the scene graph --- a directed graph (G) where an object node is connected by adjective nodes and relationship nodes --- to represent the complex structural layout of both image (I) and sentence (S). In the textual domain, we use SGAE to learn a dictionary (D) that helps to reconstruct sentences in the S -> G -> D -> S pipeline, where D encodes the desired language prior; in the vision-language domain, we use the shared D to guide the encoder-decoder in the I -> G -> D -> S pipeline. Thanks to the scene graph representation and shared dictionary, the inductive bias is transferred across domains in principle. We validate the effectiveness of SGAE on the challenging MS-COCO image captioning benchmark, \\\\eg, our SGAE-based single-model achieves a new state-of-the-art 127.8 CIDEr-D on the Karpathy split, and a competitive 125.5 CIDEr-D (c40) on the official server even compared to other ensemble models. Code has been made available at: https://github.com/yangxuntu/SGAE.\",\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\",\"url\":\"https://www.semanticscholar.org/author/47008946\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\",\"url\":\"https://www.semanticscholar.org/author/10817432\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\",\"url\":\"https://www.semanticscholar.org/author/5462268\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\",\"url\":\"https://www.semanticscholar.org/author/1688642\"}],\"citationVelocity\":64,\"citations\":[{\"arxivId\":\"2004.00277\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01093\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"title\":\"Graph Structured Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"47059067\",\"name\":\"L. Zhang\"},{\"authorId\":\"2836997\",\"name\":\"Songrui Guo\"},{\"authorId\":\"1406190317\",\"name\":\"Y. Xiao\"},{\"authorId\":\"152985786\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3394955\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"title\":\"Image Captioning with a Joint Attention Mechanism by Visual Concept Samples\",\"url\":\"https://www.semanticscholar.org/paper/2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2004.12704\",\"authors\":[{\"authorId\":\"3470231\",\"name\":\"Liangming Pan\"},{\"authorId\":\"46268944\",\"name\":\"Yuxi Xie\"},{\"authorId\":\"1717629\",\"name\":\"Yansong Feng\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"37596605\",\"name\":\"Min-Yen Kan\"}],\"doi\":\"10.18653/v1/2020.acl-main.135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e516a4fb5bed1306bdcf10482904f6c7ba8a52c\",\"title\":\"Semantic Graphs for Generating Deep Questions\",\"url\":\"https://www.semanticscholar.org/paper/6e516a4fb5bed1306bdcf10482904f6c7ba8a52c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2002.11949\",\"authors\":[{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"1508668394\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"49887423\",\"name\":\"Jiaxin Shi\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00377\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"10874b307d89f1ff9e049f2464afa6d91237ce4c\",\"title\":\"Unbiased Scene Graph Generation From Biased Training\",\"url\":\"https://www.semanticscholar.org/paper/10874b307d89f1ff9e049f2464afa6d91237ce4c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TIP.2020.3042086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"title\":\"Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993656298\",\"name\":\"Jingwen Hou\"},{\"authorId\":\"144545118\",\"name\":\"Sheng Yang\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"}],\"doi\":\"10.1145/3394171.3413695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3be8cfb1299582b8ac6eca28350537c8b6f3777f\",\"title\":\"Object-level Attention for Aesthetic Rating Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3be8cfb1299582b8ac6eca28350537c8b6f3777f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1911.10082\",\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"title\":\"Injecting Prior Knowledge into Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"46448616\",\"name\":\"Xueting Zhang\"},{\"authorId\":\"145909469\",\"name\":\"Wei Huang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/tgrs.2020.3010106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f79bc9f9bf488f4580f1f4d9a360ac06a26e9e3e\",\"title\":\"Truncation Cross Entropy Loss for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79bc9f9bf488f4580f1f4d9a360ac06a26e9e3e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.02420\",\"authors\":[{\"authorId\":\"1891100220\",\"name\":\"Junyu Luo\"},{\"authorId\":\"2031857668\",\"name\":\"Zifei Zheng\"},{\"authorId\":\"46489195\",\"name\":\"H. Ye\"},{\"authorId\":\"1898157310\",\"name\":\"Muchao Ye\"},{\"authorId\":null,\"name\":\"Yaqing Wang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1863907206\",\"name\":\"Cao Xiao\"},{\"authorId\":\"2988239\",\"name\":\"Fenglong Ma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2de56959d2180137b922c4542759bcdc67f2db4e\",\"title\":\"A Benchmark Dataset for Understandable Medical Language Translation\",\"url\":\"https://www.semanticscholar.org/paper/2de56959d2180137b922c4542759bcdc67f2db4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.00893\",\"authors\":[{\"authorId\":\"1657305709\",\"name\":\"Shaotian Yan\"},{\"authorId\":\"50413866\",\"name\":\"Chen Shen\"},{\"authorId\":\"2427514\",\"name\":\"Zhongming Jin\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":\"10.1145/3394171.3413722\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52eb5a3f7d1fcf7982db205ed4130c4b4843ffd9\",\"title\":\"PCPL: Predicate-Correlation Perception Learning for Unbiased Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/52eb5a3f7d1fcf7982db205ed4130c4b4843ffd9\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.05156\",\"authors\":[{\"authorId\":\"145281271\",\"name\":\"Meng Wei\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"40373267\",\"name\":\"Xiaoyu Yue\"},{\"authorId\":\"1742084905\",\"name\":\"Kuo Zhong\"}],\"doi\":\"10.1145/3394171.3413575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bcaa4923db115f05159b804622adb570dfaff1b\",\"title\":\"HOSE-Net: Higher Order Structure Embedded Network for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/3bcaa4923db115f05159b804622adb570dfaff1b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"title\":\"Learning to Caption Images with Two-Stream Attention and Sentence Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.00640\",\"authors\":[{\"authorId\":\"153668454\",\"name\":\"Hongdong Zheng\"},{\"authorId\":\"2643877\",\"name\":\"Yalong Bai\"},{\"authorId\":\"143715293\",\"name\":\"Weidong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81ad4ac4259c2b64ecc6c1766e2c93ef8f00e973\",\"title\":\"Relationship-Aware Spatial Perception Fusion for Realistic Scene Layout Generation\",\"url\":\"https://www.semanticscholar.org/paper/81ad4ac4259c2b64ecc6c1766e2c93ef8f00e973\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"1915664\",\"name\":\"Di Chen\"},{\"authorId\":\"1521935487\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/TMM.2020.2972168\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"c1016eb1f2517418e48727417e14590f04eb8a96\",\"title\":\"Adversarial Attribute-Text Embedding for Person Search With Natural Language Query\",\"url\":\"https://www.semanticscholar.org/paper/c1016eb1f2517418e48727417e14590f04eb8a96\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1976497925\",\"name\":\"Yujun Cai\"},{\"authorId\":\"1491237316\",\"name\":\"Lin Huang\"},{\"authorId\":null,\"name\":\"Yiwei Wang\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"17120707\",\"name\":\"Jianfei Cai\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":\"1820892607\",\"name\":\"Xu Yang\"},{\"authorId\":\"1491626189\",\"name\":\"Yiheng Zhu\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"1387241200\",\"name\":\"N. Magnenat-Thalmann\"}],\"doi\":\"10.1007/978-3-030-58571-6_14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7bb02122135c4d6e2fd718401ba3c15fa77fe58\",\"title\":\"Learning Progressive Joint Propagation for Human Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f7bb02122135c4d6e2fd718401ba3c15fa77fe58\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037486210\",\"name\":\"Qiaoqiao Yang\"},{\"authorId\":\"1410201319\",\"name\":\"Guangxing Wang\"},{\"authorId\":\"1695975266\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"2037477833\",\"name\":\"Christos Grecos\"},{\"authorId\":\"143823414\",\"name\":\"Peng Ren\"}],\"doi\":\"10.2112/SI102-018.1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"556edd10f961c30fc523f291fe657db56a297850\",\"title\":\"Coastal Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/556edd10f961c30fc523f291fe657db56a297850\",\"venue\":\"Journal of Coastal Research\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696589727\",\"name\":\"Dongming Zhou\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"48708659\",\"name\":\"Zhiwen Wang\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"title\":\"Multi-level Visual Fusion Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.00190\",\"authors\":[{\"authorId\":\"1578237379\",\"name\":\"Rishabh Baghel\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2e5f919fe41481466b1fd86ee0bb8c7bc139098\",\"title\":\"OPAL-Net: A Generative Model for Part-based Object Layout Generation\",\"url\":\"https://www.semanticscholar.org/paper/d2e5f919fe41481466b1fd86ee0bb8c7bc139098\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.07459\",\"authors\":[{\"authorId\":\"103393695\",\"name\":\"C. Jiang\"},{\"authorId\":\"3560734\",\"name\":\"Steven Weikai Lu\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3467c9977b875544221abbd8153facf2cb176759\",\"title\":\"Constructing Dynamic Knowledge Graph for Visual Semantic Understanding and Applications in Autonomous Robotics\",\"url\":\"https://www.semanticscholar.org/paper/3467c9977b875544221abbd8153facf2cb176759\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.04965\",\"authors\":[{\"authorId\":\"123645165\",\"name\":\"Meng-Jiun Chiou\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"180c8732d3f40984c07ad1f2203875e2bf9f9de2\",\"title\":\"Visual Relationship Detection with Visual-Linguistic Knowledge from Multimodal Representations.\",\"url\":\"https://www.semanticscholar.org/paper/180c8732d3f40984c07ad1f2203875e2bf9f9de2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.02127\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"145851264\",\"name\":\"Wei Luo\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350943\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"133921bb5e559de464c0078f5fa67409aca27917\",\"title\":\"Aligning Linguistic Words and Visual Semantic Units for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/133921bb5e559de464c0078f5fa67409aca27917\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"50172036\",\"name\":\"X. Wu\"},{\"authorId\":\"1993634137\",\"name\":\"Shen Ge\"},{\"authorId\":\"47958349\",\"name\":\"X. Zhang\"},{\"authorId\":\"144934703\",\"name\":\"Wei Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1145/3394171.3414004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"title\":\"Bridging the Gap between Vision and Language Domains for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.12511\",\"authors\":[{\"authorId\":\"3428457\",\"name\":\"Tai-Yin Chiu\"},{\"authorId\":\"31812669\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1109/cvpr42600.2020.00370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"795435da0de2cb9772e8ebec9a4242de7e677b30\",\"title\":\"Assessing Image Quality Issues for Real-World Problems\",\"url\":\"https://www.semanticscholar.org/paper/795435da0de2cb9772e8ebec9a4242de7e677b30\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.05963\",\"authors\":[{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"40441990\",\"name\":\"Armin Kappeler\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"},{\"authorId\":\"145730823\",\"name\":\"J. Soares\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b499228aa74b59be32711c3926e44de208d6b636\",\"title\":\"Image Captioning: Transforming Objects into Words\",\"url\":\"https://www.semanticscholar.org/paper/b499228aa74b59be32711c3926e44de208d6b636\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2007.08751\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1007/978-3-030-58523-5_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"773e7d33411fc2cdd6829356b7ce8ed34e14cd65\",\"title\":\"Knowledge-Based Video Question Answering with Unsupervised Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/773e7d33411fc2cdd6829356b7ce8ed34e14cd65\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.03561\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"title\":\"Joint Visual Grounding with Language Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.14208\",\"authors\":[{\"authorId\":\"9095876\",\"name\":\"Jipeng Wu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"61b1bb801d03a9b0da5721c6beaabf1dc6cd90c0\",\"title\":\"Hidden State Guidance: Improving Image Captioning Using an Image Conditioned Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/61b1bb801d03a9b0da5721c6beaabf1dc6cd90c0\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398104959\",\"name\":\"Justin R. Lovelace\"},{\"authorId\":\"144156074\",\"name\":\"Bobak Mortazavi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a554243e6806ac419ffdb19c354686f77ef2b848\",\"title\":\"Learning to Generate Clinically Coherent Chest X-Ray Reports\",\"url\":\"https://www.semanticscholar.org/paper/a554243e6806ac419ffdb19c354686f77ef2b848\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2005.08045\",\"authors\":[{\"authorId\":\"152516150\",\"name\":\"Aniket Agarwal\"},{\"authorId\":\"1703122502\",\"name\":\"Ayush Mangal\"},{\"authorId\":\"80465887\",\"name\":\"Vipul\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac73d0abab68604b9c7a2b98635516eda899c7b3\",\"title\":\"Visual Relationship Detection using Scene Graphs: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/ac73d0abab68604b9c7a2b98635516eda899c7b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47535039\",\"name\":\"Chenchen Liu\"},{\"authorId\":\"152804227\",\"name\":\"Y. Jin\"},{\"authorId\":\"46321208\",\"name\":\"K. Xu\"},{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/cvpr42600.2020.01085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72e10d154869adbe98c0f7301ad50d92fbf69420\",\"title\":\"Beyond Short-Term Snippet: Video Relation Detection With Spatio-Temporal Global Context\",\"url\":\"https://www.semanticscholar.org/paper/72e10d154869adbe98c0f7301ad50d92fbf69420\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":\"2003.07449\",\"authors\":[{\"authorId\":\"8118056\",\"name\":\"Tristan Sylvain\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"198333f1f426224de2f36a3ee2aa48e54cf4ba3e\",\"title\":\"Object-Centric Image Generation from Layouts\",\"url\":\"https://www.semanticscholar.org/paper/198333f1f426224de2f36a3ee2aa48e54cf4ba3e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50025815\",\"name\":\"Yongzhi Li\"},{\"authorId\":\"47845273\",\"name\":\"D. Zhang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/cvpr42600.2020.01280\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"title\":\"Visual-Semantic Matching by Exploring High-Order Attention and Distraction\",\"url\":\"https://www.semanticscholar.org/paper/a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.08081\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"1390788836\",\"name\":\"Guangxiang Zhao\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ba3190eb0dca6344e43c3eced1788324c169388\",\"title\":\"Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/4ba3190eb0dca6344e43c3eced1788324c169388\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08897\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49051904\",\"name\":\"P. Yao\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"833560cd68a3e3d1be1bc650756dd6c679798551\",\"title\":\"Normalized and Geometry-Aware Self-Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/833560cd68a3e3d1be1bc650756dd6c679798551\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2012.05545\",\"authors\":[{\"authorId\":\"67333377\",\"name\":\"Zeliang Song\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"title\":\"Image Captioning with Context-Aware Auxiliary Guidance\",\"url\":\"https://www.semanticscholar.org/paper/6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.04448\",\"authors\":[{\"authorId\":\"1471378474\",\"name\":\"Qian Huang\"},{\"authorId\":\"46350295\",\"name\":\"Horace He\"},{\"authorId\":\"50286275\",\"name\":\"Abhay Singh\"},{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"3245681\",\"name\":\"Austin R. Benson\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"79e454ea58417a93dda211cbc27a781547a710f9\",\"title\":\"Better Set Representations For Relational Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/79e454ea58417a93dda211cbc27a781547a710f9\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2009.13331\",\"authors\":[{\"authorId\":\"1510729710\",\"name\":\"He Huang\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"},{\"authorId\":\"144142812\",\"name\":\"Yuta Kikuchi\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"},{\"authorId\":\"2914452\",\"name\":\"W. Tang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"276d7cdf89658734b30eec55f33a7e4786eb63c7\",\"title\":\"Addressing Class Imbalance in Scene Graph Parsing by Learning to Contrast and Score\",\"url\":\"https://www.semanticscholar.org/paper/276d7cdf89658734b30eec55f33a7e4786eb63c7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49336997\",\"name\":\"W. Wang\"},{\"authorId\":\"12287885\",\"name\":\"R. Liu\"},{\"authorId\":\"4820214\",\"name\":\"Mingle Wang\"},{\"authorId\":\"49184528\",\"name\":\"Sen Wang\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1145/3394171.3413507\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00075d654178c2641b779d28235c85877f475858\",\"title\":\"Memory-Based Network for Scene Graph with Unbalanced Relations\",\"url\":\"https://www.semanticscholar.org/paper/00075d654178c2641b779d28235c85877f475858\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2615648\",\"name\":\"Xudong Hong\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"153786091\",\"name\":\"Asad Sayeed\"},{\"authorId\":\"52406707\",\"name\":\"Khushboo Mehra\"},{\"authorId\":\"2869436\",\"name\":\"V. Demberg\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.18653/v1/2020.conll-1.34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8504fe99ba36088b36623441eb468adae67a9b51\",\"title\":\"Diverse and Relevant Visual Storytelling with Scene Graph Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/8504fe99ba36088b36623441eb468adae67a9b51\",\"venue\":\"CoNLL\",\"year\":2020},{\"arxivId\":\"2004.14231\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"title\":\"Image Captioning through Image Transformer\",\"url\":\"https://www.semanticscholar.org/paper/657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.02314\",\"authors\":[{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1007/978-3-030-58592-1_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9cf1b1c1aef71c1487272943edf62dd51703ff31\",\"title\":\"Bridging Knowledge Graphs to Generate Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/9cf1b1c1aef71c1487272943edf62dd51703ff31\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2005.08230\",\"authors\":[{\"authorId\":\"49934559\",\"name\":\"Boris Knyazev\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"51906624\",\"name\":\"Catalina Cangea\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f2d1f5f0fa79daab734bb326feb41d68c1ebccd5\",\"title\":\"Graph Density-Aware Losses for Novel Compositions in Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/f2d1f5f0fa79daab734bb326feb41d68c1ebccd5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145523333\",\"name\":\"Peng Yao\"},{\"authorId\":\"102227937\",\"name\":\"J. Li\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/ICME46284.2020.9102935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59d65f0719287512f3f605615f64b7eda27db97b\",\"title\":\"Modeling Local and Global Contexts for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59d65f0719287512f3f605615f64b7eda27db97b\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.06077\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"51510489\",\"name\":\"Marius Mosbach\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c6d4f0afbe3a7d6ba8e94f446878977721a21eb\",\"title\":\"Sparse Graph to Sequence Learning for Vision Conditioned Long Textual Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/7c6d4f0afbe3a7d6ba8e94f446878977721a21eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6731\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4df184d6a74f1ffd84b644735c9afb5060552770\",\"title\":\"Joint Commonsense and Relation Reasoning for Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4df184d6a74f1ffd84b644735c9afb5060552770\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.12313\",\"authors\":[{\"authorId\":\"32556011\",\"name\":\"Victor Milewski\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"},{\"authorId\":\"2338197\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"b89e002625b0703f08b7590a1763ca7c8be66ad4\",\"title\":\"Are scene graphs good enough to improve Image Captioning?\",\"url\":\"https://www.semanticscholar.org/paper/b89e002625b0703f08b7590a1763ca7c8be66ad4\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145269477\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1492126621\",\"name\":\"Y. Rao\"},{\"authorId\":\"49279687\",\"name\":\"Lianwei Wu\"},{\"authorId\":\"1978658363\",\"name\":\"Cong Feng\"}],\"doi\":\"10.1007/978-3-030-63823-8_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b686455c59af63ccd45b73b5445465bbd282bfd\",\"title\":\"Image Captioning Algorithm Based on Sufficient Visual Information and Text Information\",\"url\":\"https://www.semanticscholar.org/paper/0b686455c59af63ccd45b73b5445465bbd282bfd\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90779411\",\"name\":\"Y. Li\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1007/978-3-030-37734-2_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c8b0898e280e4fa92cfd1d50e7d041bbf6a2da4\",\"title\":\"Structured Neural Motifs: Scene Graph Parsing via Enhanced Context\",\"url\":\"https://www.semanticscholar.org/paper/7c8b0898e280e4fa92cfd1d50e7d041bbf6a2da4\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"2009.09809\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"151478793\",\"name\":\"S. Dey\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b67759f193e2c39877723424df0b3d5f91c0bf0b\",\"title\":\"Multi-Modal Reasoning Graph for Scene-Text Based Fine-Grained Image Classification and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b67759f193e2c39877723424df0b3d5f91c0bf0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490659630\",\"name\":\"Yi Dong\"},{\"authorId\":\"9401670\",\"name\":\"C. Liu\"},{\"authorId\":\"49019678\",\"name\":\"Z. Shen\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"50855055\",\"name\":\"P. Wang\"},{\"authorId\":\"7923976\",\"name\":\"Changgong Zhang\"},{\"authorId\":\"3246404\",\"name\":\"P. Ren\"},{\"authorId\":\"65863521\",\"name\":\"Xuansong Xie\"},{\"authorId\":\"46493397\",\"name\":\"Han Yu\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3338533.3366603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"329b8e635e641648860b3ead887a8ecb4990b2e1\",\"title\":\"Domain Specific and Idiom Adaptive Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/329b8e635e641648860b3ead887a8ecb4990b2e1\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"1930660\",\"name\":\"Bo Qu\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/JSTARS.2019.2959208\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fbdb53c100005ac890989beb3d78e208ba9acda\",\"title\":\"Retrieval Topic Recurrent Memory Network for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fbdb53c100005ac890989beb3d78e208ba9acda\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50031180\",\"name\":\"Xiaofeng Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"2753987\",\"name\":\"Fengmao Lv\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"}],\"doi\":\"10.1007/978-3-030-58589-1_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"title\":\"TRRNet: Tiered Relation Reasoning for Compositional Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.16934\",\"authors\":[{\"authorId\":\"40471592\",\"name\":\"Fei Yu\"},{\"authorId\":\"11713158\",\"name\":\"Jiji Tang\"},{\"authorId\":\"2318321\",\"name\":\"Weichong Yin\"},{\"authorId\":\"144825828\",\"name\":\"Y. Sun\"},{\"authorId\":null,\"name\":\"Hao Tian\"},{\"authorId\":\"120155201\",\"name\":\"Hua Wu\"},{\"authorId\":\"144270729\",\"name\":\"Haifeng Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e34cf702b9c90889e268380572bec782280b59c3\",\"title\":\"ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/e34cf702b9c90889e268380572bec782280b59c3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1993631009\",\"name\":\"Haizhou Shi\"},{\"authorId\":\"1490931889\",\"name\":\"Haochen Shi\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"49336516\",\"name\":\"W. Wang\"}],\"doi\":\"10.1145/3394171.3413746\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa8f78e665c037da28a7e35a98c4d2521e3f12e\",\"title\":\"Relational Graph Learning for Grounded Video Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/9fa8f78e665c037da28a7e35a98c4d2521e3f12e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2002.11566\",\"authors\":[{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\"},{\"authorId\":\"37198550\",\"name\":\"Yaya Shi\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"39397292\",\"name\":\"Peijin Wang\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1109/cvpr42600.2020.01329\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1dd557a8839733a5ee06d19989a265e61f603c1\",\"title\":\"Object Relational Graph With Teacher-Recommended Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1dd557a8839733a5ee06d19989a265e61f603c1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.02918\",\"authors\":[{\"authorId\":\"1864097171\",\"name\":\"Xubin Zhong\"},{\"authorId\":\"144116132\",\"name\":\"Changxing Ding\"},{\"authorId\":\"50123957\",\"name\":\"Xian Qu\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"title\":\"Polysemy Deciphering Network for Robust Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2001.02359\",\"authors\":[{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/cvpr42600.2020.00379\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fd806e4d9a0340e7436afcf1e64029887070e61\",\"title\":\"Weakly Supervised Visual Semantic Parsing\",\"url\":\"https://www.semanticscholar.org/paper/5fd806e4d9a0340e7436afcf1e64029887070e61\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.02206\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"47621053\",\"name\":\"A. Gholami\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"title\":\"Scan2Cap: Context-aware Dense Captioning in RGB-D Scans\",\"url\":\"https://www.semanticscholar.org/paper/7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09742\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"title\":\"AutoCaption: Image Captioning with Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100818163\",\"name\":\"Chen-chen Jing\"},{\"authorId\":\"145558278\",\"name\":\"Y. Wu\"},{\"authorId\":\"144315453\",\"name\":\"Mingtao Pei\"},{\"authorId\":\"46972595\",\"name\":\"Yao Hu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1145/3394171.3413902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc24a5a8d6629eec5c8d87d48ab891bc17e862ff\",\"title\":\"Visual-Semantic Graph Matching for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/cc24a5a8d6629eec5c8d87d48ab891bc17e862ff\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.08012\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"1882516497\",\"name\":\"Kancheti Sai Srinivas\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"title\":\"Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09144\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8185538174d9f751125407cad3687994ff08fadb\",\"title\":\"Transformer Reasoning Network for Image-Text Matching and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8185538174d9f751125407cad3687994ff08fadb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10496\",\"authors\":[{\"authorId\":\"3167894\",\"name\":\"Jiaxin Qi\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"title\":\"Two Causal Principles for Improving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.04448\",\"authors\":[{\"authorId\":\"1471378474\",\"name\":\"Qian Huang\"},{\"authorId\":\"46350295\",\"name\":\"Horace He\"},{\"authorId\":\"47264639\",\"name\":\"Ashutosh Kumar Singh\"},{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"3245681\",\"name\":\"Austin R. Benson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1bc97162e25661a17bd871bd389720c6b7dd474\",\"title\":\"Set-Structured Latent Representations\",\"url\":\"https://www.semanticscholar.org/paper/e1bc97162e25661a17bd871bd389720c6b7dd474\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.03107\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"1411260673\",\"name\":\"Luke Melas-Kyriazi\"}],\"doi\":\"10.1109/cvpr42600.2020.00486\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9419436682726232e1b37a04c53bba919b12025\",\"title\":\"Show, Edit and Tell: A Framework for Editing Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/e9419436682726232e1b37a04c53bba919b12025\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2678541\",\"name\":\"Md. Fazle Elahi Khan\"},{\"authorId\":\"145263914\",\"name\":\"X. Luo\"},{\"authorId\":\"2490119\",\"name\":\"R. Tian\"}],\"doi\":\"10.1007/978-3-030-59987-4_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5162be8911e8fc8da2d551451e251fd440c6e4fe\",\"title\":\"A Framework for Modeling Knowledge Graphs via Processing Natural Descriptions of Vehicle-Pedestrian Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5162be8911e8fc8da2d551451e251fd440c6e4fe\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924571\",\"name\":\"Jing Wang\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413753\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"021d50ba5ae1c66e9175428f546976798126dd9f\",\"title\":\"Multimodal Attention with Image Text Spatial Relationship for OCR-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/021d50ba5ae1c66e9175428f546976798126dd9f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.14080\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/cvpr42600.2020.01098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"title\":\"X-Linear Attention Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.00560\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"145527705\",\"name\":\"Zhe Lin\"},{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2059515\",\"name\":\"Mingyang Ling\"}],\"doi\":\"10.1109/CVPR.2019.00207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"740db108d536a8b6f53111407898f4ecaecf80ea\",\"title\":\"Scene Graph Generation With External Knowledge and Image Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/740db108d536a8b6f53111407898f4ecaecf80ea\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39290858e39fb6e2a7d8b9685cbb854fa7da222f\",\"title\":\"Combining NLP and Computer Vision to Help Blind People\",\"url\":\"https://www.semanticscholar.org/paper/39290858e39fb6e2a7d8b9685cbb854fa7da222f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.07061\",\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"46491945\",\"name\":\"Yunpeng Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"40366236\",\"name\":\"Yue Gao\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"title\":\"Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1694585\",\"name\":\"Fanglin Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"title\":\"Referring Expression Grounding by Marginalizing Scene Graph Likelihood\",\"url\":\"https://www.semanticscholar.org/paper/4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.05175\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"87784755\",\"name\":\"A. Thapliyal\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"title\":\"Weakly Supervised Content Selection for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03848\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03598364626c419d3a2578b5c22403f0dd246e99\",\"title\":\"Spatio-Temporal Scene Graphs for Video Dialog\",\"url\":\"https://www.semanticscholar.org/paper/03598364626c419d3a2578b5c22403f0dd246e99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.02347\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/ICCV.2019.00471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"title\":\"Counterfactual Critic Multi-Agent Training for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.08543\",\"authors\":[{\"authorId\":\"152601809\",\"name\":\"Minh Thu Nguyen\"},{\"authorId\":\"6195410\",\"name\":\"D. Phung\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"2008200586\",\"name\":\"Thien Huu Nguyen\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.411\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"title\":\"Structural and Functional Decomposition for Personality Image Captioning in a Communication Game\",\"url\":\"https://www.semanticscholar.org/paper/28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1906.01290\",\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"097981245eb3c66cc10a3164275d0bd52f5ae22a\",\"title\":\"Relational Reasoning using Prior Knowledge for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/097981245eb3c66cc10a3164275d0bd52f5ae22a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.06651\",\"authors\":[{\"authorId\":\"46307726\",\"name\":\"Li-chang Chen\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"47672928\",\"name\":\"S. Wang\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"}],\"doi\":\"10.1007/978-3-030-58529-7_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf1aa76529cdf25bfb13a787f9a6763e7e89b6a1\",\"title\":\"Graph Edit Distance Reward: Learning to Edit Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/bf1aa76529cdf25bfb13a787f9a6763e7e89b6a1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.09971\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b57c9a293934b7434b99807c82d6146634cafa61\",\"title\":\"A Better Variant of Self-Critical Sequence Training\",\"url\":\"https://www.semanticscholar.org/paper/b57c9a293934b7434b99807c82d6146634cafa61\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12204\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":\"10.1109/cvpr42600.2020.01077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"title\":\"Visual Commonsense R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41097744\",\"name\":\"Kai Shen\"},{\"authorId\":\"3008832\",\"name\":\"Lingfei Wu\"},{\"authorId\":\"11541418\",\"name\":\"F. Xu\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.24963/ijcai.2020/131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41f10434eba89d27c83764619b067f9db492d98b\",\"title\":\"Hierarchical Attention Based Spatial-Temporal Graph-to-Sequence Learning for Grounded Video Description\",\"url\":\"https://www.semanticscholar.org/paper/41f10434eba89d27c83764619b067f9db492d98b\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9073332\",\"name\":\"J. Li\"},{\"authorId\":\"1923156\",\"name\":\"P. Yao\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"49039585\",\"name\":\"Wei-Cun Zhang\"}],\"doi\":\"10.3390/APP9163260\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"title\":\"Boosted Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"31126576\",\"name\":\"Zheng Xiong\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"40534966\",\"name\":\"Longcun Jin\"},{\"authorId\":\"9245443\",\"name\":\"Xinyi Peng\"}],\"doi\":\"10.3390/app10010391\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"945ffeb90e538214e3063407db8e094469ec877a\",\"title\":\"Panoptic Segmentation-Based Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/945ffeb90e538214e3063407db8e094469ec877a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.08335\",\"authors\":[{\"authorId\":\"1750913684\",\"name\":\"Bofan Xue\"},{\"authorId\":\"1774825\",\"name\":\"D. Chan\"},{\"authorId\":\"1729041\",\"name\":\"J. Canny\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ca80f5097b6ad4f4537d913c48abc470fb37342\",\"title\":\"A Dataset and Benchmarks for Multimedia Social Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5ca80f5097b6ad4f4537d913c48abc470fb37342\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.09060\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"312799645adfafb886f156708a7a36f2db459c62\",\"title\":\"Adaptively Aligned Image Captioning via Adaptive Attention Time\",\"url\":\"https://www.semanticscholar.org/paper/312799645adfafb886f156708a7a36f2db459c62\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2010.01288\",\"authors\":[{\"authorId\":\"144407296\",\"name\":\"J. Gao\"},{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"2721708\",\"name\":\"P. Yu\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8405576136062ea661febeeedbc5076235d5eb42\",\"title\":\"Unsupervised Cross-lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8405576136062ea661febeeedbc5076235d5eb42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07585\",\"authors\":[{\"authorId\":\"50259110\",\"name\":\"T. He\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"},{\"authorId\":\"4495301\",\"name\":\"Yuan-Fang Li\"}],\"doi\":\"10.24963/ijcai.2020/82\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f55ce65f4bf8d173bb44947276bd0c9f9d7c5ee3\",\"title\":\"Learning from the Scene and Borrowing from the Rich: Tackling the Long Tail in Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/f55ce65f4bf8d173bb44947276bd0c9f9d7c5ee3\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50591162\",\"name\":\"P. Xu\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"145886051\",\"name\":\"L. Guo\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"153773877\",\"name\":\"Xiaojiang Chen\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51a36db5ff0df3211994816ae66f20de92a2a3b3\",\"title\":\"A Survey of Scene Graph: Generation and Application\",\"url\":\"https://www.semanticscholar.org/paper/51a36db5ff0df3211994816ae66f20de92a2a3b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.08608\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/ICCV.2019.00435\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"45f9856d418527d23dc7c89197627fa1f3b215f9\",\"title\":\"Learning to Collocate Neural Modules for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9856d418527d23dc7c89197627fa1f3b215f9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.02104\",\"authors\":[{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1111986f5f9e069ba18c34ff0051b6172e9a0f92\",\"title\":\"Target-Tailored Source-Transformation for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/1111986f5f9e069ba18c34ff0051b6172e9a0f92\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153297544\",\"name\":\"X. Yang\"},{\"authorId\":\"118565563\",\"name\":\"Chong-Yang Gao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1145/3394171.3413859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"title\":\"Hierarchical Scene Graph Encoder-Decoder for Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2001.04735\",\"authors\":[{\"authorId\":\"1485514734\",\"name\":\"Cong Yuren\"},{\"authorId\":\"46782042\",\"name\":\"Hanno Ackermann\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"}],\"doi\":\"10.1007/978-3-030-58565-5_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb4281cc809f86d2f45e34a4da9e70d027fc29ca\",\"title\":\"NODIS: Neural Ordinary Differential Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/eb4281cc809f86d2f45e34a4da9e70d027fc29ca\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1879303113\",\"name\":\"Depeng Wang\"},{\"authorId\":\"7690231\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"1877859275\",\"name\":\"Yuanen Zhou\"},{\"authorId\":\"1390610633\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"152318056\",\"name\":\"L. Wu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/icmew46912.2020.9106007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61cc97db488acc841cc31ffe046957829c366b53\",\"title\":\"A Text-Guided Graph Structure for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/61cc97db488acc841cc31ffe046957829c366b53\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"1910.02974\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICRA40945.2020.9196653\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe6f2a08cb8911d52533a413b071638d0463f10a\",\"title\":\"SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability\",\"url\":\"https://www.semanticscholar.org/paper/fe6f2a08cb8911d52533a413b071638d0463f10a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2009.14352\",\"authors\":[{\"authorId\":\"8668622\",\"name\":\"Xiangxi Shi\"},{\"authorId\":\"1410092701\",\"name\":\"Xu Yang\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":\"10.1007/978-3-030-58568-6_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b41882903384ef849688a325d747fdaad8ecee82\",\"title\":\"Finding It at Another Side: A Viewpoint-Adapted Matching Encoder for Change Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b41882903384ef849688a325d747fdaad8ecee82\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.10731\",\"authors\":[{\"authorId\":\"151253861\",\"name\":\"Weixin Liang\"},{\"authorId\":\"7650020\",\"name\":\"Feiyang Niu\"},{\"authorId\":\"8856206\",\"name\":\"Aishwarya N. Reganti\"},{\"authorId\":\"2028300167\",\"name\":\"Govind Thattai\"},{\"authorId\":\"1748051\",\"name\":\"G. T\\u00fcr\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86fdbc4540d146b0a2d7d61bf9f0109fa1331dac\",\"title\":\"LRTA: A Transparent Neural-Symbolic Reasoning Framework with Modular Supervision for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86fdbc4540d146b0a2d7d61bf9f0109fa1331dac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.09530\",\"authors\":[{\"authorId\":\"153769937\",\"name\":\"H. Akbari\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"120157163\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1845230025\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"37409035\",\"name\":\"R. Fernandez\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"title\":\"Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2010.02591\",\"authors\":[{\"authorId\":\"50045528\",\"name\":\"Xuanli He\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2561045\",\"name\":\"Gholamreza Haffari\"},{\"authorId\":\"50310099\",\"name\":\"W. Chang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"35520711\",\"name\":\"Nhan Dam\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.87\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b21fd64502205bdb5134f13157283c52b701cde\",\"title\":\"Scene Graph Modification Based on Natural Language Commands\",\"url\":\"https://www.semanticscholar.org/paper/6b21fd64502205bdb5134f13157283c52b701cde\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.08565\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"150353841\",\"name\":\"Yinan Zhao\"},{\"authorId\":\"1409765557\",\"name\":\"Meng Zhang\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"}],\"doi\":\"10.1007/978-3-030-58520-4_25\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c936d878003254cdab662a966cecd29e8be652d0\",\"title\":\"Captioning Images Taken by People Who Are Blind\",\"url\":\"https://www.semanticscholar.org/paper/c936d878003254cdab662a966cecd29e8be652d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":54460890,\"doi\":\"10.1109/CVPR.2019.01094\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":15,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1609.05600\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.344\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7d007ba376faddf0046930ea7375ed59600cee9\",\"title\":\"Graph-Structured Representations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c7d007ba376faddf0046930ea7375ed59600cee9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.04080\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1723876\",\"name\":\"Charles Blundell\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6\",\"title\":\"Matching Networks for One Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1812.02347\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/ICCV.2019.00471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"title\":\"Counterfactual Critic Multi-Agent Training for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"title\":\"End-To-End Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1801.00868\",\"authors\":[{\"authorId\":\"144843400\",\"name\":\"Alexander Kirillov\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/CVPR.2019.00963\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dce916351ef589afa7a63452648dd8acba931e92\",\"title\":\"Panoptic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/dce916351ef589afa7a63452648dd8acba931e92\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1806.01261\",\"authors\":[{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"},{\"authorId\":\"2158860\",\"name\":\"Jessica B. Hamrick\"},{\"authorId\":\"2603033\",\"name\":\"V. Bapst\"},{\"authorId\":\"144282558\",\"name\":\"A. Sanchez-Gonzalez\"},{\"authorId\":\"3133079\",\"name\":\"V. Zambaldi\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2844530\",\"name\":\"Andrea Tacchetti\"},{\"authorId\":\"143724694\",\"name\":\"D. Raposo\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"48627702\",\"name\":\"R. Faulkner\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"143745193\",\"name\":\"H. Song\"},{\"authorId\":\"5055381\",\"name\":\"A. Ballard\"},{\"authorId\":\"2058362\",\"name\":\"J. Gilmer\"},{\"authorId\":\"35188630\",\"name\":\"G. Dahl\"},{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"145254624\",\"name\":\"Kelsey R. Allen\"},{\"authorId\":\"143868183\",\"name\":\"C. Nash\"},{\"authorId\":\"40293188\",\"name\":\"V. Langston\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"46378362\",\"name\":\"M. Botvinick\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1980990\",\"name\":\"Y. Li\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b7769dab4e6092aa4b7eeb8aa078a7b725c9b4\",\"title\":\"Relational inductive biases, deep learning, and graph networks\",\"url\":\"https://www.semanticscholar.org/paper/19b7769dab4e6092aa4b7eeb8aa078a7b725c9b4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1803.09189\",\"authors\":[{\"authorId\":\"24874138\",\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"1751476\",\"name\":\"Xiaohui Zeng\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.18653/v1/N18-1037\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0c3c6197037ec92de044b3068c57e26815dd6c76\",\"title\":\"Scene Graph Parsing as Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/0c3c6197037ec92de044b3068c57e26815dd6c76\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1808.05864\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1145/3240508.3240632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"title\":\"Context-Aware Visual Policy Network for Sequence-Level Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1812.01880\",\"authors\":[{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe\",\"title\":\"Learning to Compose Dynamic Tree Structures for Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.01855\",\"authors\":[{\"authorId\":\"2522647\",\"name\":\"Jiaxin Shi\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"8549842\",\"name\":\"Juan-Zi Li\"}],\"doi\":\"10.1109/CVPR.2019.00857\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca1a2b86d39495be5524a0e39b663f7c423a0397\",\"title\":\"Explainable and Explicit Visual Reasoning Over Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/ca1a2b86d39495be5524a0e39b663f7c423a0397\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1612.08242\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2017.690\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d39d69b23424446f0400ef603b2e3e22d0309d6\",\"title\":\"YOLO9000: Better, Faster, Stronger\",\"url\":\"https://www.semanticscholar.org/paper/7d39d69b23424446f0400ef603b2e3e22d0309d6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.03299\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"51239188\",\"name\":\"Fengcheng Wu\"}],\"doi\":\"10.1109/ICCV.2019.00477\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e504843bfd3ca81b859895439bbe19efc1f3dc61\",\"title\":\"Learning to Assemble Neural Module Tree Networks for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/e504843bfd3ca81b859895439bbe19efc1f3dc61\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"16282696\",\"name\":\"Marisa A Stark\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298990\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85ae705ef4353c6854f5be4a4664269d6317c66b\",\"title\":\"Image retrieval using scene graphs\",\"url\":\"https://www.semanticscholar.org/paper/85ae705ef4353c6854f5be4a4664269d6317c66b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144246983\",\"name\":\"H. Barlow\"}],\"doi\":\"10.1016/0022-2496(83)90030-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4c74862e9b0011ea922e3ee171ebd06af568bf5\",\"title\":\"Vision: A computational investigation into the human representation and processing of visual information: David Marr. San Francisco: W. H. Freeman, 1982. pp. xvi + 397\",\"url\":\"https://www.semanticscholar.org/paper/d4c74862e9b0011ea922e3ee171ebd06af568bf5\",\"venue\":\"\",\"year\":1983},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1804.01622\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"25445698\",\"name\":\"Agrim Gupta\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2018.00133\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"46b5d408d950287637dd21ce04772d9b2bacfd14\",\"title\":\"Image Generation from Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/46b5d408d950287637dd21ce04772d9b2bacfd14\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1808.00191\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/978-3-030-01246-5_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fad7fe0a7a90a8470a0688ad26bab6ceb8a85b7\",\"title\":\"Graph R-CNN for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/1fad7fe0a7a90a8470a0688ad26bab6ceb8a85b7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/1075096.1075150\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a600850ac0120cb09a0b7de7da80bb6a7a76de06\",\"title\":\"Accurate Unlexicalized Parsing\",\"url\":\"https://www.semanticscholar.org/paper/a600850ac0120cb09a0b7de7da80bb6a7a76de06\",\"venue\":\"ACL\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145157639\",\"name\":\"Sebastian Schuster\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145830541\",\"name\":\"Angel X. Chang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/W15-2812\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2606e6a5759c030e259ebf3f4261b9c04a36a609\",\"title\":\"Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2606e6a5759c030e259ebf3f4261b9c04a36a609\",\"venue\":\"VL@EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1811.11389\",\"authors\":[{\"authorId\":\"143946810\",\"name\":\"Bo Zhao\"},{\"authorId\":\"48153708\",\"name\":\"L. Meng\"},{\"authorId\":\"2167686\",\"name\":\"Weidong Yin\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2019.00878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4704d8698b9e50aee53a5970172bd046af58ec6\",\"title\":\"Image Generation From Layout\",\"url\":\"https://www.semanticscholar.org/paper/f4704d8698b9e50aee53a5970172bd046af58ec6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"},{\"authorId\":\"1630291637\",\"name\":\"Delle Scienze Umane\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630311779\",\"name\":\"Profilo IN Uscita\"},{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"}],\"doi\":\"10.1515/9783111413426-013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"title\":\"L\",\"url\":\"https://www.semanticscholar.org/paper/5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.04826\",\"authors\":[{\"authorId\":\"2022957\",\"name\":\"Diego Marcheggiani\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"}],\"doi\":\"10.18653/v1/D17-1159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3a3c163f25b9181f1fb7e71a32482a7393d2088\",\"title\":\"Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling\",\"url\":\"https://www.semanticscholar.org/paper/c3a3c163f25b9181f1fb7e71a32482a7393d2088\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1802.05766\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30a3eee5e9302108416f6234d739373dde68d373\",\"title\":\"Learning to Count Objects in Natural Images for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/30a3eee5e9302108416f6234d739373dde68d373\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1808.00171\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1007/978-3-030-01258-8_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8164ebc07f51c9e0db4902980b5ac3f5a8d8d48c\",\"title\":\"Shuffle-Then-Assemble: Learning Object-Agnostic Visual Relationship Features\",\"url\":\"https://www.semanticscholar.org/paper/8164ebc07f51c9e0db4902980b5ac3f5a8d8d48c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1702.08319\",\"authors\":[{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"26538630\",\"name\":\"Z. Kyaw\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"996901b08a6b6f401146204f2db0d54aaf8749c8\",\"title\":\"Visual Translation Embedding Network for Visual Relation Detection\",\"url\":\"https://www.semanticscholar.org/paper/996901b08a6b6f401146204f2db0d54aaf8749c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Redmon\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Yolo9000: Better\",\"url\":\"\",\"venue\":\"faster, stronger. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 6517\\u20136525. IEEE\",\"year\":2017},{\"arxivId\":\"1711.06640\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"38094552\",\"name\":\"Sam Thomson\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2018.00611\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"title\":\"Neural Motifs: Scene Graph Parsing with Global Context\",\"url\":\"https://www.semanticscholar.org/paper/0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.10370\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2018.00445\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccd99008d942b890cecd308a31ba61240eac9e54\",\"title\":\"Learning to Segment Every Thing\",\"url\":\"https://www.semanticscholar.org/paper/ccd99008d942b890cecd308a31ba61240eac9e54\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1411.1792\",\"authors\":[{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1747909\",\"name\":\"Hod Lipson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"081651b38ff7533550a3adfc1c00da333a8fe86c\",\"title\":\"How transferable are features in deep neural networks?\",\"url\":\"https://www.semanticscholar.org/paper/081651b38ff7533550a3adfc1c00da333a8fe86c\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1701.02426\",\"authors\":[{\"authorId\":\"2068265\",\"name\":\"Danfei Xu\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"15239369\",\"name\":\"Christopher B. Choy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34b73c1aa158b892bbe41705b4ae5bf01ecaea86\",\"title\":\"Scene Graph Generation by Iterative Message Passing\",\"url\":\"https://www.semanticscholar.org/paper/34b73c1aa158b892bbe41705b4ae5bf01ecaea86\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1604.00289\",\"authors\":[{\"authorId\":\"2373318\",\"name\":\"B. Lake\"},{\"authorId\":\"1387974690\",\"name\":\"Tomer D. Ullman\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"116975806\",\"name\":\"Samuel Gershman\"}],\"doi\":\"10.1017/S0140525X16001837\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7260c0692f8d265e11c4e9c4c8ef4c185bd587ad\",\"title\":\"Building Machines That Learn and Think Like People\",\"url\":\"https://www.semanticscholar.org/paper/7260c0692f8d265e11c4e9c4c8ef4c185bd587ad\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Teney\"},{\"authorId\":null,\"name\":\"L. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"van den Hengel. Graph-structured representations for visual question answering. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3233\\u20133241. IEEE\",\"year\":2017},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1511.05493\",\"authors\":[{\"authorId\":\"1980990\",\"name\":\"Y. Li\"},{\"authorId\":\"1725299\",\"name\":\"Daniel Tarlow\"},{\"authorId\":\"2107692\",\"name\":\"Marc Brockschmidt\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"492f57ee9ceb61fb5a47ad7aebfec1121887a175\",\"title\":\"Gated Graph Sequence Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/492f57ee9ceb61fb5a47ad7aebfec1121887a175\",\"venue\":\"ICLR\",\"year\":2016}],\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"topics\":[{\"topic\":\"Scene graph\",\"topicId\":\"382302\",\"url\":\"https://www.semanticscholar.org/topic/382302\"},{\"topic\":\"Inductive bias\",\"topicId\":\"170484\",\"url\":\"https://www.semanticscholar.org/topic/170484\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Directed graph\",\"topicId\":\"592\",\"url\":\"https://www.semanticscholar.org/topic/592\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Dictionary\",\"topicId\":\"2618\",\"url\":\"https://www.semanticscholar.org/topic/2618\"},{\"topic\":\"Collocation\",\"topicId\":\"17001\",\"url\":\"https://www.semanticscholar.org/topic/17001\"},{\"topic\":\"Natural language generation\",\"topicId\":\"6196\",\"url\":\"https://www.semanticscholar.org/topic/6196\"},{\"topic\":\"Overfitting\",\"topicId\":\"70499\",\"url\":\"https://www.semanticscholar.org/topic/70499\"},{\"topic\":\"Network interface device\",\"topicId\":\"353029\",\"url\":\"https://www.semanticscholar.org/topic/353029\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Data science\",\"topicId\":\"89193\",\"url\":\"https://www.semanticscholar.org/topic/89193\"},{\"topic\":\"Graph (abstract data type)\",\"topicId\":\"199434\",\"url\":\"https://www.semanticscholar.org/topic/199434\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"Server (computing)\",\"topicId\":\"6042\",\"url\":\"https://www.semanticscholar.org/topic/6042\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Ensemble forecasting\",\"topicId\":\"74321\",\"url\":\"https://www.semanticscholar.org/topic/74321\"}],\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"