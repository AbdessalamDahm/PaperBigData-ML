"{\"abstract\":\"Temporally localizing actions in a video is a fundamental challenge in video understanding. Most existing approaches have often drawn inspiration from image object detection and extended the advances, e.g., SSD and Faster R-CNN, to produce temporal locations of an action in a 1D sequence. Nevertheless, the results can suffer from robustness problem due to the design of predetermined temporal scales, which overlooks the temporal structure of an action and limits the utility on detecting actions with complex variations. In this paper, we propose to address the problem by introducing Gaussian kernels to dynamically optimize temporal scale of each action proposal. Specifically, we present Gaussian Temporal Awareness Networks (GTAN) --- a new architecture that novelly integrates the exploitation of temporal structure into an one-stage action localization framework. Technically, GTAN models the temporal structure through learning a set of Gaussian kernels, each for a cell in the feature maps. Each Gaussian kernel corresponds to a particular interval of an action proposal and a mixture of Gaussian kernels could further characterize action proposals with various length. Moreover, the values in each Gaussian curve reflect the contextual contributions to the localization of an action proposal. Extensive experiments are conducted on both THUMOS14 and ActivityNet v1.3 datasets, and superior results are reported when comparing to state-of-the-art approaches. More remarkably, GTAN achieves 1.9% and 1.1% improvements in mAP on testing set of the two datasets.\",\"arxivId\":\"1909.03877\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\",\"url\":\"https://www.semanticscholar.org/author/34779291\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\",\"url\":\"https://www.semanticscholar.org/author/145690248\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\",\"url\":\"https://www.semanticscholar.org/author/3430743\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\",\"url\":\"https://www.semanticscholar.org/author/40434674\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\",\"url\":\"https://www.semanticscholar.org/author/33642939\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\",\"url\":\"https://www.semanticscholar.org/author/144025741\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2871170\",\"name\":\"Huifen Xia\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/ACCESS.2020.2986861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"title\":\"A Survey on Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123331898\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"title\":\"Refinement of Boundary Regression Using Uncertainty in Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"93768847\",\"name\":\"Xinghan Wang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00984\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"title\":\"Learning Temporal Co-Attention Models for Unsupervised Video Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2038266421\",\"name\":\"Philip H.S. Torr Huazhong University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"2038266423\",\"name\":\"Alibaba Group\"},{\"authorId\":\"51909023\",\"name\":\"U. O. Oxford\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TMM.2019.2943204\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"881103d13eda11f231f88205b7ed2c6f6c8eea1b\",\"title\":\"Coarse-to-Fine Localization of Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/881103d13eda11f231f88205b7ed2c6f6c8eea1b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1910.08250\",\"authors\":[{\"authorId\":\"2724075\",\"name\":\"Yiping Tang\"},{\"authorId\":\"51431831\",\"name\":\"Chuang Niu\"},{\"authorId\":\"35182090\",\"name\":\"Minghao Dong\"},{\"authorId\":\"10648494\",\"name\":\"Shenghan Ren\"},{\"authorId\":\"145157018\",\"name\":\"J. Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6bfb4ef35fd5e9820e23e130aff6c09aa2c6b75c\",\"title\":\"AFO-TAD: Anchor-free One-Stage Detector for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6bfb4ef35fd5e9820e23e130aff6c09aa2c6b75c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9304398\",\"name\":\"Jiawei Zuo\"},{\"authorId\":\"16098412\",\"name\":\"Y. Chen\"},{\"authorId\":\"40476136\",\"name\":\"L. Wang\"},{\"authorId\":\"51018452\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"1917497790\",\"name\":\"Ting Yao\"},{\"authorId\":\"78646416\",\"name\":\"K. Wang\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3394171.3414453\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"title\":\"iDirector: An Intelligent Directing System for Live Broadcast\",\"url\":\"https://www.semanticscholar.org/paper/506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2019.00191\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"22031c69356c35909082613b84fe86b682291b8a\",\"title\":\"Enhancing Temporal Action Localization with Transfer Learning from Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/22031c69356c35909082613b84fe86b682291b8a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2003.12424\",\"authors\":[{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"152464732\",\"name\":\"Qi Dai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.00109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"title\":\"Weakly-Supervised Action Localization by Generative Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.03270\",\"authors\":[{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1007/978-3-030-60639-8_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"title\":\"Multi-level Temporal Pyramid Network for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":\"1904.07442\",\"authors\":[{\"authorId\":\"102665943\",\"name\":\"Yupan Huang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"35150586\",\"name\":\"Yutong Lu\"}],\"doi\":\"10.1109/ICME.2019.00224\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"785bc0ad262a51c5b66d36e19628f00dec22dcd2\",\"title\":\"Decoupling Localization and Classification in Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/785bc0ad262a51c5b66d36e19628f00dec22dcd2\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"153146470\",\"name\":\"Dan Yang\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":\"10.1016/J.PATCOG.2020.107686\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc5af1aff1839364b448a29dedd06e43bd133ea2\",\"title\":\"Deep snippet selective network for weakly supervised temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/fc5af1aff1839364b448a29dedd06e43bd133ea2\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29850862\",\"name\":\"He-Yen Hsieh\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190975\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8d0a1105f231ffc200d7b299fb962d8b673369be\",\"title\":\"Temporal Action Proposal Generation Via Deep Feature Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1105f231ffc200d7b299fb962d8b673369be\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2008.11254\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"1694090\",\"name\":\"Christos Tzelepis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"title\":\"Temporal Action Localization with Variance-Aware Networks\",\"url\":\"https://www.semanticscholar.org/paper/ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.09392\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TPAMI.2020.2980824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"title\":\"Comprehensive Instructional Video Analysis: The COIN Dataset and Performance Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2007.06643\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/978-3-030-58568-6_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"title\":\"Adversarial Background-Aware Loss for Weakly-supervised Temporal Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35723063\",\"name\":\"Md. Jamil-Ur Rahman\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CRV50864.2020.00035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"title\":\"Single-Stage End-to-End Temporal Activity Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"venue\":\"2020 17th Conference on Computer and Robot Vision (CRV)\",\"year\":2020},{\"arxivId\":\"1906.08547\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"48141156\",\"name\":\"Qi Cai\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2596486\",\"name\":\"Zhijian Hou\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"714d6ca486fe5347571052e8049d77920c6e5e07\",\"title\":\"vireoJD-MM at Activity Detection in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/714d6ca486fe5347571052e8049d77920c6e5e07\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.11462\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/cvpr42600.2020.01017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"title\":\"G-TAD: Sub-Graph Localization for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.01598\",\"authors\":[{\"authorId\":\"151504088\",\"name\":\"X. Ding\"},{\"authorId\":\"151488319\",\"name\":\"N. Wang\"},{\"authorId\":\"49779747\",\"name\":\"Xinbo Gao\"},{\"authorId\":\"1492114961\",\"name\":\"Jie Li\"},{\"authorId\":\"72541556\",\"name\":\"X. Wang\"},{\"authorId\":\"121698214\",\"name\":\"Tongliang Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"title\":\"Weakly Supervised Temporal Action Localization with Segment-Level Labels\",\"url\":\"https://www.semanticscholar.org/paper/5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.13705\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1007/978-3-030-58580-8_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ae9cea622f68e1e32b7e6ae5a3c92213e192bf8\",\"title\":\"Learning to Localize Actions from Moments\",\"url\":\"https://www.semanticscholar.org/paper/2ae9cea622f68e1e32b7e6ae5a3c92213e192bf8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.11170\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"1694090\",\"name\":\"Christos Tzelepis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"14bbd0a4ba94fa495de38dfaf78db5e82b8b7629\",\"title\":\"Boundary Uncertainty in a Single-Stage Temporal Action Localization Network\",\"url\":\"https://www.semanticscholar.org/paper/14bbd0a4ba94fa495de38dfaf78db5e82b8b7629\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.07016\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"46515076\",\"name\":\"D. Li\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"48141156\",\"name\":\"Qi Cai\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38791e8ca76e1bb44e7123ec92f97299d7d19d15\",\"title\":\"Trimmed Action Recognition, Dense-Captioning Events in Videos, and Spatio-temporal Action Localization with Focus on ActivityNet Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/38791e8ca76e1bb44e7123ec92f97299d7d19d15\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.07915\",\"authors\":[{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"144742695\",\"name\":\"D. Xu\"},{\"authorId\":\"1491152801\",\"name\":\"Jinhu Dong\"},{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"152948808\",\"name\":\"A. Knoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"title\":\"LAP-Net: Adaptive Features Sampling via Learning Action Progression for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50290191\",\"name\":\"Tianyu Li\"},{\"authorId\":\"2004641888\",\"name\":\"Bing Bing\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/s11042-020-09703-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a14f6a0222385bf0173c0737b47a0cce0c9b036\",\"title\":\"Boundary discrimination and proposal evaluation for temporal action proposal generation\",\"url\":\"https://www.semanticscholar.org/paper/7a14f6a0222385bf0173c0737b47a0cce0c9b036\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.09220\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4673e744d0ded47fe6df3b6314f79a41359578b\",\"title\":\"MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b4673e744d0ded47fe6df3b6314f79a41359578b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657264680\",\"name\":\"Cece Jin\"},{\"authorId\":\"1500522440\",\"name\":\"T. Zhang\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053319\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"title\":\"Regression Before Classification for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2006.07006\",\"authors\":[{\"authorId\":\"1429148175\",\"name\":\"Pilhyeon Lee\"},{\"authorId\":\"49605749\",\"name\":\"J. Wang\"},{\"authorId\":\"1500380529\",\"name\":\"Y. Lu\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cb8bb50e4b84739b9d3477eead0707d8c3a84cd8\",\"title\":\"Background Modeling via Uncertainty Estimation for Weakly-supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/cb8bb50e4b84739b9d3477eead0707d8c3a84cd8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.08548\",\"authors\":[{\"authorId\":\"47792983\",\"name\":\"J. Ma\"},{\"authorId\":\"46227885\",\"name\":\"Satya Krishna Gorti\"},{\"authorId\":\"1765951\",\"name\":\"Maksims Volkovs\"},{\"authorId\":\"93169948\",\"name\":\"Ilya Stanevich\"},{\"authorId\":\"46546800\",\"name\":\"Guangwei Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8283f38f9e027a38c454957297d4a685b453575\",\"title\":\"Cross-Class Relevance Learning for Temporal Concept Localization\",\"url\":\"https://www.semanticscholar.org/paper/d8283f38f9e027a38c454957297d4a685b453575\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.06845\",\"authors\":[{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"38896301\",\"name\":\"G. Kundu\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1007/978-3-030-58548-8_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84d710727a9a5775ab4691a969f52bc3062325e2\",\"title\":\"SF-Net: Single-Frame Supervision for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/84d710727a9a5775ab4691a969f52bc3062325e2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.03560\",\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/tmm.2020.2990070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57c38661af2d1ac5ac79cc51a443f5f1cca4b03b\",\"title\":\"Single Shot Video Object Detector\",\"url\":\"https://www.semanticscholar.org/paper/57c38661af2d1ac5ac79cc51a443f5f1cca4b03b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09748\",\"authors\":[{\"authorId\":\"1685519\",\"name\":\"Ahmed Taha\"},{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-030-58520-4_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"300003fea535027cadf45603c9329cf966ecc7c3\",\"title\":\"A Generic Visualization Approach for Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/300003fea535027cadf45603c9329cf966ecc7c3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"145429878\",\"name\":\"Hui Yu\"},{\"authorId\":\"47591280\",\"name\":\"Feiyu Chen\"},{\"authorId\":\"144485153\",\"name\":\"D. Yang\"}],\"doi\":\"10.1109/LSP.2020.3018914\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc27658c8db517561c77de3a8cd2cdee08a547bf\",\"title\":\"Spatial Enhancement and Temporal Constraint for Weakly Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/dc27658c8db517561c77de3a8cd2cdee08a547bf\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"1911.04127\",\"authors\":[{\"authorId\":\"51266875\",\"name\":\"Chuming Lin\"},{\"authorId\":\"50683988\",\"name\":\"J. Li\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"20595955\",\"name\":\"Zhipeng Cui\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1609/AAAI.V34I07.6815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2534a3c894c93053341d514967c45c78657969c\",\"title\":\"Fast Learning of Temporal Action Proposal via Dense Boundary Generator\",\"url\":\"https://www.semanticscholar.org/paper/e2534a3c894c93053341d514967c45c78657969c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.11594\",\"authors\":[{\"authorId\":\"3191371\",\"name\":\"Yuanhao Zhai\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"2914452\",\"name\":\"W. Tang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-58539-6_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"title\":\"Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.07728\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Tao Zhao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c065821de73b6bb87a2a2376134ac9c28008486\",\"title\":\"Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/1c065821de73b6bb87a2a2376134ac9c28008486\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.09963\",\"authors\":[{\"authorId\":\"1429148175\",\"name\":\"Pilhyeon Lee\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1609/AAAI.V34I07.6793\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89d28af38b1993d2cb3ab04d2c5e9aeaaf383286\",\"title\":\"Background Suppression Network for Weakly-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/89d28af38b1993d2cb3ab04d2c5e9aeaaf383286\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.08465\",\"authors\":[{\"authorId\":\"71777904\",\"name\":\"H. Zhang\"},{\"authorId\":\"2884662\",\"name\":\"Xuemiao Xu\"},{\"authorId\":\"2823769\",\"name\":\"G. Han\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1109/cvpr42600.2020.00075\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d29fc735af090ac33d986d129daf022268839096\",\"title\":\"Context-Aware and Scale-Insensitive Temporal Repetition Counting\",\"url\":\"https://www.semanticscholar.org/paper/d29fc735af090ac33d986d129daf022268839096\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405030052\",\"name\":\"Gibran Benitez-Garcia\"},{\"authorId\":\"153735678\",\"name\":\"Muhammad Haris\"},{\"authorId\":\"1490667000\",\"name\":\"Yoshiyuki Tsuda\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.3390/s20020528\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d56868869c29540998eb04e50614f20eeb1575c\",\"title\":\"Finger Gesture Spotting from Long Sequences Based on Multi-Stream Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2d56868869c29540998eb04e50614f20eeb1575c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1912.01326\",\"authors\":[{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"},{\"authorId\":\"9870507\",\"name\":\"R. Gade\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":\"10.1109/CVPR42600.2020.01314\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"title\":\"A Context-Aware Loss Function for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122572973\",\"name\":\"Md. Moniruzzaman\"},{\"authorId\":\"1993660364\",\"name\":\"Zhaozheng Yin\"},{\"authorId\":\"1700714\",\"name\":\"Z. He\"},{\"authorId\":\"2777406\",\"name\":\"R. Qin\"},{\"authorId\":\"2281499\",\"name\":\"Ming C. Leu\"}],\"doi\":\"10.1145/3394171.3413687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"393aaa45767018e184499556f078640fb016475b\",\"title\":\"Action Completeness Modeling with Background Aware Networks for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/393aaa45767018e184499556f078640fb016475b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.14598\",\"authors\":[{\"authorId\":\"1753647133\",\"name\":\"Chen Zhao\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b19e442f6d313c211b522a791252de2c2468063b\",\"title\":\"Video Self-Stitching Graph Network for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b19e442f6d313c211b522a791252de2c2468063b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09837\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2020.3016486\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"086057656b94de8bfd0d50ebe935e3d433f593d3\",\"title\":\"Revisiting Anchor Mechanisms for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/086057656b94de8bfd0d50ebe935e3d433f593d3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020}],\"corpusId\":196183677,\"doi\":\"10.1109/CVPR.2019.00043\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"38748749\",\"name\":\"Wayner Barrios\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2017.338\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"551cddb9a5e20861b491ec39f3ced933f6364a17\",\"title\":\"SCC: Semantic Context Cascade for Efficient Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/551cddb9a5e20861b491ec39f3ced933f6364a17\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"50678963\",\"name\":\"D. Koller\"}],\"doi\":\"10.1109/ICCV.2013.335\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a81719f9248ab89887af68833fbad9d9a85a526\",\"title\":\"Combining the Right Features for Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1a81719f9248ab89887af68833fbad9d9a85a526\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145182602\",\"name\":\"Dong Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01231-1_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"title\":\"Recurrent Tubelet Proposal and Recognition Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1512.02325\",\"authors\":[{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1007/978-3-319-46448-0_2\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"title\":\"SSD: Single Shot MultiBox Detector\",\"url\":\"https://www.semanticscholar.org/paper/4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"988470995c4066e1fc0077042ece790b806356ee\",\"title\":\"The LEAR submission at Thumos 2014\",\"url\":\"https://www.semanticscholar.org/paper/988470995c4066e1fc0077042ece790b806356ee\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.04671\",\"authors\":[{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144720255\",\"name\":\"T. Lu\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/CVPR.2017.342\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60ca4a90d751e315a2b143289a5c54488e324949\",\"title\":\"Temporal Action Localization by Structured Maximal Sums\",\"url\":\"https://www.semanticscholar.org/paper/60ca4a90d751e315a2b143289a5c54488e324949\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"}],\"doi\":\"10.1109/CVPR.2016.216\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"title\":\"A Multi-stream Bi-directional Recurrent Neural Network for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1807.04821\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-01216-8_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a52d7c53bb0745994e476079bbdea8b8577582a3\",\"title\":\"CTAP: Complementary Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/a52d7c53bb0745994e476079bbdea8b8577582a3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ruxing Wang\"},{\"authorId\":null,\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"UTS at activitynet 2016\",\"url\":\"\",\"venue\":\"In CVPR ActivityNet Challenge Workshop,\",\"year\":2016},{\"arxivId\":\"1806.02964\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"3004751\",\"name\":\"Chongjing Wang\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-030-01225-0_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49e2b4db35a408e91353578764be9085ac1210da\",\"title\":\"BSN: Boundary Sensitive Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/49e2b4db35a408e91353578764be9085ac1210da\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1710.06236\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1145/3123266.3123343\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"title\":\"Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1703.02716\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"title\":\"A Pursuit of Temporal Accuracy in General Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2016.211\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bac994dda1385cd709e08e24170c711d8c573676\",\"title\":\"Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bac994dda1385cd709e08e24170c711d8c573676\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2013.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"title\":\"Temporal Localization of Actions with Actoms\",\"url\":\"https://www.semanticscholar.org/paper/404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1707.06750\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"title\":\"Temporal Convolution Based Action Proposal: Submission to ActivityNet 2017\",\"url\":\"https://www.semanticscholar.org/paper/af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1607.01979\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f85e81f716fe7f8094d84bbe9a5d564b95398a8\",\"title\":\"Untrimmed Video Classification for Activity Detection: submission to ActivityNet Challenge\",\"url\":\"https://www.semanticscholar.org/paper/3f85e81f716fe7f8094d84bbe9a5d564b95398a8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":\"10.1109/CVPR.2016.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"title\":\"Temporal Action Localization with Pyramid of Score Distribution Features\",\"url\":\"https://www.semanticscholar.org/paper/374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.5244/C.31.93\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"title\":\"End-to-End, Single-Stream Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu-Gang Jiang\"},{\"authorId\":null,\"name\":\"Jingen Liu\"},{\"authorId\":null,\"name\":\"Amir R.Zamir\"},{\"authorId\":null,\"name\":\"George Toderici\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"http://crcv.ucf.edu/ THUMOS14,\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b42f83a720bd4156113ba5350add2df2673daf0\",\"title\":\"Action Recognition and Detection by Combining Motion and Appearance Features\",\"url\":\"https://www.semanticscholar.org/paper/2b42f83a720bd4156113ba5350add2df2673daf0\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.05267\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"49447925\",\"name\":\"M. Flynn\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1109/CVPR.2017.113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"title\":\"Temporal Convolutional Networks for Action Segmentation and Detection\",\"url\":\"https://www.semanticscholar.org/paper/210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"title\":\"Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters\",\"url\":\"https://www.semanticscholar.org/paper/aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"venue\":\"AAAI 2017\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08e61adbfa2178e3fa895a7f85a84597c183aede\",\"title\":\"Action and Event Recognition with Fisher Vectors on a Compact Feature Set\",\"url\":\"https://www.semanticscholar.org/paper/08e61adbfa2178e3fa895a7f85a84597c183aede\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1708.02002\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/ICCV.2017.324\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79cfb51a51fc093f66aac8e858afe2e14d4a1f20\",\"title\":\"Focal Loss for Dense Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/79cfb51a51fc093f66aac8e858afe2e14d4a1f20\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58b9332c01f585d2f52accbb249fbea10cc32316\",\"title\":\"Title Learning Latent Subevents in Activity Videos Using Temporal Attention Filters\",\"url\":\"https://www.semanticscholar.org/paper/58b9332c01f585d2f52accbb249fbea10cc32316\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1604.06506\",\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-46454-1_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"574ab231627eadc1056162c38d0895f372121250\",\"title\":\"Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/574ab231627eadc1056162c38d0895f372121250\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"153216896\",\"name\":\"D. Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"title\":\"MSR Asia MSM at ActivityNet Challenge 2017: Trimmed Action Recognition, Temporal Action Proposals and Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2016.341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f3e06ddedd4e6ac799679b65a20e9170a8b753e\",\"title\":\"Temporal Action Detection Using a Statistical Language Model\",\"url\":\"https://www.semanticscholar.org/paper/5f3e06ddedd4e6ac799679b65a20e9170a8b753e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1712.01938\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2018.00556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"title\":\"Learning Latent Super-Events to Detect Multiple Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.04503\",\"authors\":[{\"authorId\":\"9541177\",\"name\":\"Navaneeth Bodla\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2017.593\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53c0aa8d33d240197caff824a6225fb223c1181c\",\"title\":\"Soft-NMS \\u2014 Improving Object Detection with One Line of Code\",\"url\":\"https://www.semanticscholar.org/paper/53c0aa8d33d240197caff824a6225fb223c1181c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Gaussian Temporal Awareness Networks for Action Localization\",\"topics\":[{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"},{\"topic\":\"Object detection\",\"topicId\":\"14349\",\"url\":\"https://www.semanticscholar.org/topic/14349\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Solid-state drive\",\"topicId\":\"30552\",\"url\":\"https://www.semanticscholar.org/topic/30552\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Gaussian blur\",\"topicId\":\"384913\",\"url\":\"https://www.semanticscholar.org/topic/384913\"}],\"url\":\"https://www.semanticscholar.org/paper/10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"