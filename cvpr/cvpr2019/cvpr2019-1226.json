"{\"abstract\":\"Current state-of-the-art approaches for spatio-temporal action detection have achieved impressive results but remain unsatisfactory for temporal extent detection. The main reason comes from that, there are some ambiguous states similar to the real actions which may be treated as target actions even by a well trained network. In this paper, we define these ambiguous samples as \\u201ctransitional states\\u201d, and propose a Transition-Aware Context Network (TACNet) to distinguish transitional states. The proposed TACNet includes two main components, i.e., temporal context detector and transition-aware classifier. The temporal context detector can extract long-term context information with constant time complexity by constructing a recurrent network. The transition-aware classifier can further distinguish transitional states by classifying action and transitional states simultaneously. Therefore, the proposed TACNet can substantially improve the performance of spatio-temporal action detection. We extensively evaluate the proposed TACNet on UCF101-24 and J-HMDB datasets. The experimental results demonstrate that TACNet obtains competitive performance on JHMDB and significantly outperforms the state-of-the-art methods on the untrimmed UCF101 24 in terms of both frame-mAP and video-mAP.\",\"arxivId\":\"1905.13417\",\"authors\":[{\"authorId\":\"143629372\",\"name\":\"L. Song\",\"url\":\"https://www.semanticscholar.org/author/143629372\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\",\"url\":\"https://www.semanticscholar.org/author/50202110\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\",\"url\":\"https://www.semanticscholar.org/author/145015817\"},{\"authorId\":\"144254616\",\"name\":\"Hongbin Sun\",\"url\":\"https://www.semanticscholar.org/author/144254616\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"title\":\"Discovering Multi-Label Actor-Action Association in a Weakly Supervised Setting\",\"url\":\"https://www.semanticscholar.org/paper/1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.08332\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"46961961\",\"name\":\"Cong Yang\"}],\"doi\":\"10.1007/978-3-030-58517-4_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"title\":\"CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.03519\",\"authors\":[{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"1527092320\",\"name\":\"Yanwei Li\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"6000385\",\"name\":\"Zeming Li\"},{\"authorId\":\"144124181\",\"name\":\"Hongbin Sun\"},{\"authorId\":\"49991679\",\"name\":\"Jian Sun\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"63242fbc48fb42fce10fe3ddce677c0fe6444614\",\"title\":\"Fine-Grained Dynamic Head for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/63242fbc48fb42fce10fe3ddce677c0fe6444614\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2004.00180\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2683916\",\"name\":\"Lizhi Yang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"title\":\"Spatio-Temporal Action Detection with Multi-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.03544\",\"authors\":[{\"authorId\":\"46583603\",\"name\":\"J. Wang\"},{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"6000385\",\"name\":\"Zeming Li\"},{\"authorId\":\"144124181\",\"name\":\"Hongbin Sun\"},{\"authorId\":\"2032184078\",\"name\":\"Jian Sun\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c5a9b8eec9edc5a5bc0a600e68a5442e4d7cd6a\",\"title\":\"End-to-End Object Detection with Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/5c5a9b8eec9edc5a5bc0a600e68a5442e4d7cd6a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961634\",\"name\":\"Yutang Wu\"},{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"47672901\",\"name\":\"Shuheng Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054394\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"886653a4a10986596d39c45711f6f1f49b9d4e70\",\"title\":\"Enhanced Action Tubelet Detector for Spatio-Temporal Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/886653a4a10986596d39c45711f6f1f49b9d4e70\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2008.13196\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145527065\",\"name\":\"Tao Wang\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"}],\"doi\":\"10.1609/AAAI.V34I07.6811\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b66ea4e404cc119f2f7970486cee19bc300a198\",\"title\":\"Finding Action Tubes with a Sparse-to-Dense Framework\",\"url\":\"https://www.semanticscholar.org/paper/7b66ea4e404cc119f2f7970486cee19bc300a198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50201744\",\"name\":\"Shengjun Zhang\"},{\"authorId\":\"1471440106\",\"name\":\"W. Meng\"},{\"authorId\":\"4169031\",\"name\":\"Hui-quan Li\"},{\"authorId\":\"8628276\",\"name\":\"Xuehong Cui\"}],\"doi\":\"10.1109/ACCESS.2019.2959206\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"430ee2f6b5a1d4c194e26088ca8e3b58ae571605\",\"title\":\"Multimodal Spatiotemporal Networks for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/430ee2f6b5a1d4c194e26088ca8e3b58ae571605\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2001.04608\",\"authors\":[{\"authorId\":\"1527103472\",\"name\":\"Yixuan Li\"},{\"authorId\":\"50218816\",\"name\":\"Zixu Wang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58517-4_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6e3034cd8855616533d091dc1d70e969c20a42b\",\"title\":\"Actions as Moving Points\",\"url\":\"https://www.semanticscholar.org/paper/e6e3034cd8855616533d091dc1d70e969c20a42b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2871170\",\"name\":\"Huifen Xia\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/ACCESS.2020.2986861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"title\":\"A Survey on Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2012.03482\",\"authors\":[{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"1527092320\",\"name\":\"Yanwei Li\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"6000385\",\"name\":\"Zeming Li\"},{\"authorId\":\"35593490\",\"name\":\"X. Zhang\"},{\"authorId\":\"144124181\",\"name\":\"Hongbin Sun\"},{\"authorId\":\"49991679\",\"name\":\"Jian Sun\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cbd30a67bfb186f5481e048b59c5568fc90cb49\",\"title\":\"Rethinking Learnable Tree Filter for Generic Feature Transform\",\"url\":\"https://www.semanticscholar.org/paper/2cbd30a67bfb186f5481e048b59c5568fc90cb49\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1016/j.patcog.2020.107695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86e69494bfc8e8156a7f4cc42d9052b57b6e4241\",\"title\":\"Temporal filtering networks for online action detection\",\"url\":\"https://www.semanticscholar.org/paper/86e69494bfc8e8156a7f4cc42d9052b57b6e4241\",\"venue\":\"Pattern Recognit.\",\"year\":2021}],\"corpusId\":173188703,\"doi\":\"10.1109/CVPR.2019.01226\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"518512621412fd76d47ef9225a45fcc99d0247d2\",\"references\":[{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1604.07602\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/978-3-319-46454-1_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1ea1e828256feee129eae3497f41e21bce36a34\",\"title\":\"Spot On: Action Localization from Pointly-Supervised Proposals\",\"url\":\"https://www.semanticscholar.org/paper/b1ea1e828256feee129eae3497f41e21bce36a34\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2787367\",\"name\":\"P. Siva\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"}],\"doi\":\"10.5244/C.25.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16fd1875104614d499402b660bc0a8e19d07963c\",\"title\":\"Weakly Supervised Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/16fd1875104614d499402b660bc0a8e19d07963c\",\"venue\":\"BMVC\",\"year\":2011},{\"arxivId\":\"1707.09143\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.5244/C.31.22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"title\":\"Localizing Actions from Video Labels and Pseudo-Annotations\",\"url\":\"https://www.semanticscholar.org/paper/0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1703.10664\",\"authors\":[{\"authorId\":\"151185786\",\"name\":\"R. Hou\"},{\"authorId\":\"145430739\",\"name\":\"C. Chen\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065f55d40d473b63becccc890fe8a57c2f840548\",\"title\":\"Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065f55d40d473b63becccc890fe8a57c2f840548\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1512.02325\",\"authors\":[{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1007/978-3-319-46448-0_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"title\":\"SSD: Single Shot MultiBox Detector\",\"url\":\"https://www.semanticscholar.org/paper/4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/ICCV.2017.619\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44a3e466743add34a34567b4566ebe6c98bd2abf\",\"title\":\"TORNADO: A Spatio-Temporal Convolutional Regression Network for Video Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/44a3e466743add34a34567b4566ebe6c98bd2abf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.01861\",\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.472\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"title\":\"Action Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.04952\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.473\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f91a5b09b50a9118d75ffea672a785a703cd604a\",\"title\":\"AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/f91a5b09b50a9118d75ffea672a785a703cd604a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1706.02677\",\"authors\":[{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"34837514\",\"name\":\"P. Noordhuis\"},{\"authorId\":\"39033676\",\"name\":\"L. Wesolowski\"},{\"authorId\":\"1717990\",\"name\":\"Aapo Kyrola\"},{\"authorId\":\"3609856\",\"name\":\"Andrew Tulloch\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"title\":\"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\",\"url\":\"https://www.semanticscholar.org/paper/0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1701.06659\",\"authors\":[{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"22748016\",\"name\":\"Ananth Ranga\"},{\"authorId\":\"36183106\",\"name\":\"Ambrish Tyagi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e94183191183a368bf07eb544654bae4b3cbf407\",\"title\":\"DSSD : Deconvolutional Single Shot Detector\",\"url\":\"https://www.semanticscholar.org/paper/e94183191183a368bf07eb544654bae4b3cbf407\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2014.309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4420d2c9acaec36fbfea64e7f90c7234895ff982\",\"title\":\"Multi-fold MIL Training for Weakly Supervised Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/4420d2c9acaec36fbfea64e7f90c7234895ff982\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69475315\",\"name\":\"D. E. Bockelman\"},{\"authorId\":\"34049624\",\"name\":\"W. Eisenstadt\"}],\"doi\":\"10.1109/22.392911\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b167f877ac7c5689c735dee9606bda132302ea8c\",\"title\":\"Combined differential and common-mode scattering parameters: theory and simulation\",\"url\":\"https://www.semanticscholar.org/paper/b167f877ac7c5689c735dee9606bda132302ea8c\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2015.7298735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"title\":\"Fast action proposals for human action detection and search\",\"url\":\"https://www.semanticscholar.org/paper/22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018}],\"title\":\"TACNet: Transition-Aware Context Network for Spatio-Temporal Action Detection\",\"topics\":[{\"topic\":\"Time complexity\",\"topicId\":\"3448\",\"url\":\"https://www.semanticscholar.org/topic/3448\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Human Metabolome Database\",\"topicId\":\"214982\",\"url\":\"https://www.semanticscholar.org/topic/214982\"}],\"url\":\"https://www.semanticscholar.org/paper/518512621412fd76d47ef9225a45fcc99d0247d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"