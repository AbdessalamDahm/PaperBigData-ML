"{\"abstract\":\"Blind video decaptioning is a problem of automatically removing text overlays and inpainting the occluded parts in videos without any input masks. While recent deep learning based inpainting methods deal with a single image and mostly assume that the positions of the corrupted pixels are known, we aim at automatic text removal in video sequences without mask information. In this paper, we propose a simple yet effective framework for fast blind video decaptioning. We construct an encoder-decoder model, where the encoder takes multiple source frames that can provide visible pixels revealed from the scene dynamics. These hints are aggregated and fed into the decoder. We apply a residual connection from the input frame to the decoder output to enforce our network to focus on the corrupted regions only. Our proposed model was ranked in the first place in the ECCV Chalearn 2018 LAP Inpainting Competition Track2: Video decaptioning. In addition, we further improve this strong model by applying a recurrent feedback. The recurrent feedback not only enforces temporal coherence but also provides strong clues on where the corrupted pixels are. Both qualitative and quantitative experiments demonstrate that our full model produces accurate and temporally consistent video results in real time (50+ fps).\",\"arxivId\":\"1905.02949\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\",\"url\":\"https://www.semanticscholar.org/author/24028009\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\",\"url\":\"https://www.semanticscholar.org/author/2262209\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\",\"url\":\"https://www.semanticscholar.org/author/1926578\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\",\"url\":\"https://www.semanticscholar.org/author/98758720\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993656953\",\"name\":\"Weijiang Yu\"},{\"authorId\":\"97251476\",\"name\":\"J. Liang\"},{\"authorId\":\"47681435\",\"name\":\"L. Li\"},{\"authorId\":\"1730284\",\"name\":\"N. Xiao\"}],\"doi\":\"10.1145/3394171.3413912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44a47b9660a4cf03b6db99543aecef568b272d0b\",\"title\":\"Single Image De-noising via Staged Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/44a47b9660a4cf03b6db99543aecef568b272d0b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"153362999\",\"name\":\"Y. Jung\"},{\"authorId\":\"2771818\",\"name\":\"Fran\\u00e7ois Rameau\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"153116390\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1145/3343031.3350895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"844c7955f70beee9b4ccf08d27f41cd873d2116d\",\"title\":\"Video Retargeting: Trade-off between Content Preservation and Spatio-temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/844c7955f70beee9b4ccf08d27f41cd873d2116d\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9389320\",\"name\":\"J. Zdenek\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.1109/WACV45572.2020.9093544\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7fecd549152c7f7d7aa1364353cdbcc0e1ea3bc\",\"title\":\"Erasing Scene Text with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/b7fecd549152c7f7d7aa1364353cdbcc0e1ea3bc\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1908.07683\",\"authors\":[{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3343031.3350864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"title\":\"Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation\",\"url\":\"https://www.semanticscholar.org/paper/e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2007.10247\",\"authors\":[{\"authorId\":\"5764695\",\"name\":\"Y. Zeng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1007/978-3-030-58517-4_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7f89feee68b6856c0a980a5888b42d18231be07\",\"title\":\"Learning Joint Spatial-Temporal Transformations for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/f7f89feee68b6856c0a980a5888b42d18231be07\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-58583-9_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e4ae2e88c470975209769abe12c895dcf0b534d5\",\"title\":\"Proposal-Based Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/e4ae2e88c470975209769abe12c895dcf0b534d5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.13066\",\"authors\":[{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"title\":\"Align-and-Attend Network for Globally and Locally Coherent Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000246152\",\"name\":\"Wei Wu\"},{\"authorId\":\"2727357\",\"name\":\"Zizheng Liu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1579769878\",\"name\":\"Shan Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190903\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b51f2b08cf10070a374eda5213a0cfe68f2e84c\",\"title\":\"No-Reference Video Quality Assessment Based On Similarity Map Estimation\",\"url\":\"https://www.semanticscholar.org/paper/1b51f2b08cf10070a374eda5213a0cfe68f2e84c\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020}],\"corpusId\":147703808,\"doi\":\"10.1109/CVPR.2019.00439\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"d6671a8f5c5ed906501f9c441fda64942a682800\",\"references\":[{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.4734\",\"authors\":[{\"authorId\":\"2060028\",\"name\":\"D. Eigen\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1109/ICCV.2015.304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67711d42b77a13a04822ae00620660cef3abf8c4\",\"title\":\"Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-scale Convolutional Architecture\",\"url\":\"https://www.semanticscholar.org/paper/67711d42b77a13a04822ae00620660cef3abf8c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"35130187\",\"name\":\"Xiaolong Zhu\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2017.745\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"title\":\"Real-Time Neural Style Transfer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2810911\",\"name\":\"K. Patwardhan\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"}],\"doi\":\"10.1109/ICIP.2005.1529993\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30cc16168a7a10a35b66bb98787ba9f2babcb655\",\"title\":\"Video inpainting of occluding and occluded objects\",\"url\":\"https://www.semanticscholar.org/paper/30cc16168a7a10a35b66bb98787ba9f2babcb655\",\"venue\":\"IEEE International Conference on Image Processing 2005\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30991253\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"8004695\",\"name\":\"V. Caselles\"},{\"authorId\":\"34688079\",\"name\":\"C. Ballester\"}],\"doi\":\"10.1145/344779.344972\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"title\":\"Image inpainting\",\"url\":\"https://www.semanticscholar.org/paper/4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"venue\":\"SIGGRAPH '00\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702012\",\"name\":\"C. Ballester\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"8004695\",\"name\":\"V. Caselles\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"144959292\",\"name\":\"J. Verdera\"}],\"doi\":\"10.1109/83.935036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75bc9595744b133a86c2f2da9b207b4206b88dd4\",\"title\":\"Filling-in by joint interpolation of vector fields and gray levels\",\"url\":\"https://www.semanticscholar.org/paper/75bc9595744b133a86c2f2da9b207b4206b88dd4\",\"venue\":\"IEEE Trans. Image Process.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2569570\",\"name\":\"Chih-Hung Ling\"},{\"authorId\":\"1685088\",\"name\":\"Chia-Wen Lin\"},{\"authorId\":\"2020273\",\"name\":\"Chih-Wen Su\"},{\"authorId\":\"4769561\",\"name\":\"Y. Chen\"},{\"authorId\":\"1704678\",\"name\":\"H. Liao\"}],\"doi\":\"10.1109/TMM.2010.2095000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd0607aaa15a703e9b0619459d65bd14df510ac4\",\"title\":\"Virtual Contour Guided Video Object Inpainting Using Posture Mapping and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/dd0607aaa15a703e9b0619459d65bd14df510ac4\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782328\",\"name\":\"Y. Pritch\"},{\"authorId\":\"1409080992\",\"name\":\"Eitam Kav-Venaki\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/ICCV.2009.5459159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38fd97e5bd9ae77ee6d9245fad88a18385539691\",\"title\":\"Shift-map image editing\",\"url\":\"https://www.semanticscholar.org/paper/38fd97e5bd9ae77ee6d9245fad88a18385539691\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":\"1804.07723\",\"authors\":[{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01252-6_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a417a16473e2bcb1c98cd7814bc106760925e60\",\"title\":\"Image Inpainting for Irregular Holes Using Partial Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/2a417a16473e2bcb1c98cd7814bc106760925e60\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. A. Efros\"},{\"authorId\":null,\"name\":\"T. K. Leung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":null,\"title\":\"Texture synthesis by nonparametric sampling\",\"url\":\"\",\"venue\":\"iccv, page 1033. IEEE,\",\"year\":1999},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1801.07892\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00577\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"title\":\"Generative Image Inpainting with Contextual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743988\",\"name\":\"Yonatan Wexler\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611618\",\"name\":\"M. Irani\"}],\"doi\":\"10.1109/CVPR.2004.1315022\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ec1e2e0165473dbb8ec52a8eba009968ea915b8d\",\"title\":\"Space-time video completion\",\"url\":\"https://www.semanticscholar.org/paper/ec1e2e0165473dbb8ec52a8eba009968ea915b8d\",\"venue\":\"CVPR 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Shechtman\"},{\"authorId\":null,\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":null,\"title\":\"High - resolution image inpainting using multi - scale neural patch synthesis Semantic image in - painting with deep generative models\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145603921\",\"name\":\"Miguel Granados\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"1763640\",\"name\":\"O. Grau\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/j.1467-8659.2012.03000.x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b09ea83a2c84150477ca85a6a0da0920ce64ef32\",\"title\":\"How Not to Be Seen \\u2014 Object Removal from Videos of Crowded Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b09ea83a2c84150477ca85a6a0da0920ce64ef32\",\"venue\":\"Comput. Graph. Forum\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2810911\",\"name\":\"K. Patwardhan\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"}],\"doi\":\"10.1109/TIP.2006.888343\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56210467fe8e222e3b1d5fb940d466bb983cf66a\",\"title\":\"Video Inpainting Under Constrained Camera Motion\",\"url\":\"https://www.semanticscholar.org/paper/56210467fe8e222e3b1d5fb940d466bb983cf66a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2007},{\"arxivId\":\"1706.09138\",\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"2482345\",\"name\":\"C. Wang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2018.2836316\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"732fa3c6d17e6c8a857afd441ec2f43f028b07d0\",\"title\":\"Perceptual Adversarial Networks for Image-to-Image Transformation\",\"url\":\"https://www.semanticscholar.org/paper/732fa3c6d17e6c8a857afd441ec2f43f028b07d0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1806.03589\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2019.00457\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a997f1ecd85e1467d11252741d188fac8db22722\",\"title\":\"Free-Form Image Inpainting With Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/a997f1ecd85e1467d11252741d188fac8db22722\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1611.09969\",\"authors\":[{\"authorId\":\"143702938\",\"name\":\"C. Yang\"},{\"authorId\":\"144834702\",\"name\":\"X. Lu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"2733405\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2017.434\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b\",\"title\":\"High-Resolution Image Inpainting Using Multi-scale Neural Patch Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"38824925\",\"name\":\"A. Finkelstein\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"}],\"doi\":\"10.1145/1576246.1531330\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"title\":\"PatchMatch: a randomized correspondence algorithm for structural image editing\",\"url\":\"https://www.semanticscholar.org/paper/744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145081747\",\"name\":\"M. Venkatesh\"},{\"authorId\":\"2074615\",\"name\":\"S. Cheung\"},{\"authorId\":null,\"name\":\"Jian Zhao\"}],\"doi\":\"10.1016/j.patrec.2008.03.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07fb50bbdd4ade4687eccb70a805e31cb3b334fa\",\"title\":\"Efficient Object-Based Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/07fb50bbdd4ade4687eccb70a805e31cb3b334fa\",\"venue\":\"2006 International Conference on Image Processing\",\"year\":2006},{\"arxivId\":\"1503.05528\",\"authors\":[{\"authorId\":\"1902919\",\"name\":\"A. Newson\"},{\"authorId\":\"1713633\",\"name\":\"Andr\\u00e9s Almansa\"},{\"authorId\":\"3284350\",\"name\":\"M. Fradet\"},{\"authorId\":\"1796594\",\"name\":\"Y. Gousseau\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1137/140954933\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a57afd150ab309f868c9030cddfc0fd896f67308\",\"title\":\"Video Inpainting of Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/a57afd150ab309f868c9030cddfc0fd896f67308\",\"venue\":\"SIAM J. Imaging Sci.\",\"year\":2014},{\"arxivId\":\"1808.00449\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01267-0_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"title\":\"Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Sapiro\"},{\"authorId\":null,\"name\":\"M. Bertalmio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":null,\"title\":\"Video in - painting of occluding and occluded objects . In Image Processing , 2005 . ICIP 2005\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39990338\",\"name\":\"S. Iizuka\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/3072959.3073659\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d21ebaab3f715dc7178966ff146711882e6a6fee\",\"title\":\"Globally and locally consistent image completion\",\"url\":\"https://www.semanticscholar.org/paper/d21ebaab3f715dc7178966ff146711882e6a6fee\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1607.07539\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1696291\",\"name\":\"Chen Chen\"},{\"authorId\":\"33494814\",\"name\":\"Teck-Yian Lim\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/CVPR.2017.728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"title\":\"Semantic Image Inpainting with Deep Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"},{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"}],\"doi\":\"10.1145/2980179.2982398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"title\":\"Temporally coherent completion of dynamic video\",\"url\":\"https://www.semanticscholar.org/paper/cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2369548\",\"name\":\"Junyuan Xie\"},{\"authorId\":\"2230211\",\"name\":\"Linli Xu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2017ec2c60d542af5e9993176ba68f89529dbce\",\"title\":\"Image Denoising and Inpainting with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a2017ec2c60d542af5e9993176ba68f89529dbce\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"1817118\",\"name\":\"Tai-Pang Wu\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":\"10.1109/TPAMI.2006.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56ddd9127ffb99279838088347d15cf97cb8f2e2\",\"title\":\"Video repairing under variable illumination using cyclic motions\",\"url\":\"https://www.semanticscholar.org/paper/56ddd9127ffb99279838088347d15cf97cb8f2e2\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1501.00092\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2015.2439281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"title\":\"Image Super-Resolution Using Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2598948\",\"name\":\"Xiao-Jiao Mao\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2020008\",\"name\":\"Yubin Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18168aea48a22f6fe2fe407c0ff70083cba225a7\",\"title\":\"Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections\",\"url\":\"https://www.semanticscholar.org/paper/18168aea48a22f6fe2fe407c0ff70083cba225a7\",\"venue\":\"NIPS\",\"year\":2016}],\"title\":\"Deep Blind Video Decaptioning by Temporal Aggregation and Recurrence\",\"topics\":[{\"topic\":\"Inpainting\",\"topicId\":\"146260\",\"url\":\"https://www.semanticscholar.org/topic/146260\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"European Conference on Computer Vision\",\"topicId\":\"551185\",\"url\":\"https://www.semanticscholar.org/topic/551185\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Loss function\",\"topicId\":\"3650\",\"url\":\"https://www.semanticscholar.org/topic/3650\"},{\"topic\":\"Real-time computing\",\"topicId\":\"172684\",\"url\":\"https://www.semanticscholar.org/topic/172684\"},{\"topic\":\"Network model\",\"topicId\":\"20353\",\"url\":\"https://www.semanticscholar.org/topic/20353\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Autostereogram\",\"topicId\":\"99453\",\"url\":\"https://www.semanticscholar.org/topic/99453\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Circuit restoration\",\"topicId\":\"346947\",\"url\":\"https://www.semanticscholar.org/topic/346947\"},{\"topic\":\"Aggregate data\",\"topicId\":\"54317\",\"url\":\"https://www.semanticscholar.org/topic/54317\"},{\"topic\":\"Apache Axis\",\"topicId\":\"24270\",\"url\":\"https://www.semanticscholar.org/topic/24270\"}],\"url\":\"https://www.semanticscholar.org/paper/d6671a8f5c5ed906501f9c441fda64942a682800\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"