"{\"abstract\":\"How much can we infer about a person\\u2019s looks from the way they speak? In this paper, we study the task of reconstructing a facial image of a person from a short audio recording of that person speaking. We design and train a deep neural network to perform this task using millions of natural Internet/Youtube videos of people speaking. During training, our model learns voice-face correlations that allow it to produce images that capture various physical attributes of the speakers such as age, gender and ethnicity. This is done in a self-supervised manner, by utilizing the natural co-occurrence of faces and speech in Internet videos, without the need to model attributes explicitly. We evaluate and numerically quantify how\\u2013-and in what manner\\u2013-our Speech2Face reconstructions, obtained directly from audio, resemble the true face images of the speakers.\",\"arxivId\":\"1905.09773\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\",\"url\":\"https://www.semanticscholar.org/author/66808667\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\",\"url\":\"https://www.semanticscholar.org/author/2112779\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\",\"url\":\"https://www.semanticscholar.org/author/9340074\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\",\"url\":\"https://www.semanticscholar.org/author/2138834\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\",\"url\":\"https://www.semanticscholar.org/author/1768236\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\",\"url\":\"https://www.semanticscholar.org/author/144544291\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\",\"url\":\"https://www.semanticscholar.org/author/1752521\"}],\"citationVelocity\":18,\"citations\":[{\"arxivId\":\"2002.10137\",\"authors\":[{\"authorId\":\"50488872\",\"name\":\"R. Yi\"},{\"authorId\":\"7818093\",\"name\":\"Zipeng Ye\"},{\"authorId\":\"2938279\",\"name\":\"J. Zhang\"},{\"authorId\":\"1679542\",\"name\":\"H. Bao\"},{\"authorId\":\"46398687\",\"name\":\"Yongjin Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bec253e82076dc363b8fd72d5c8fadf8f5b7e475\",\"title\":\"Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose\",\"url\":\"https://www.semanticscholar.org/paper/bec253e82076dc363b8fd72d5c8fadf8f5b7e475\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.05888\",\"authors\":[{\"authorId\":\"115358722\",\"name\":\"Yeqi Bai\"},{\"authorId\":\"145855564\",\"name\":\"Tao Ma\"},{\"authorId\":\"48169625\",\"name\":\"L. Wang\"},{\"authorId\":\"1723364\",\"name\":\"Z. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7a27c9aca97915feb61a189d7a351083a7336b1\",\"title\":\"Speech Fusion to Face: Bridging the Gap Between Human's Vocal Characteristics and Facial Imaging\",\"url\":\"https://www.semanticscholar.org/paper/c7a27c9aca97915feb61a189d7a351083a7336b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14569\",\"authors\":[{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"88579203\",\"name\":\"Zhucun Xue\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9052977\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e538538d6b211e23aa85538ce8cf0645eeff43a2\",\"title\":\"APB2FACE: Audio-Guided Face Reenactment with Auxiliary Pose and Blink Signals\",\"url\":\"https://www.semanticscholar.org/paper/e538538d6b211e23aa85538ce8cf0645eeff43a2\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2001.04463\",\"authors\":[{\"authorId\":\"151500851\",\"name\":\"K. Deng\"},{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"title\":\"Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07984\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"title\":\"Separating Sounds from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.03478\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866ba646300961747ddc29ce57153858e2be588a\",\"title\":\"Multi-Instrumentalist Net: Unsupervised Generation of Music from Body Movements\",\"url\":\"https://www.semanticscholar.org/paper/866ba646300961747ddc29ce57153858e2be588a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14348\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6127cceb5847551cc09814a0d00cf63ba21b546\",\"title\":\"Audeo: Audio Generation for a Silent Performance Video\",\"url\":\"https://www.semanticscholar.org/paper/c6127cceb5847551cc09814a0d00cf63ba21b546\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2005.07074\",\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"46239142\",\"name\":\"Soyeon Choe\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"153579825\",\"name\":\"Hong-Goo Kang\"}],\"doi\":\"10.21437/Interspeech.2020-1065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7abd42a3f9319873384138283ed71279044601b7\",\"title\":\"FaceFilter: Audio-visual speech separation using still images\",\"url\":\"https://www.semanticscholar.org/paper/7abd42a3f9319873384138283ed71279044601b7\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2007.04536\",\"authors\":[{\"authorId\":\"1698935666\",\"name\":\"Jianrong Wang\"},{\"authorId\":\"48539418\",\"name\":\"Xiao-sheng Hu\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"46641911\",\"name\":\"W. Liu\"},{\"authorId\":\"1504684472\",\"name\":\"Mei Yu\"},{\"authorId\":\"145340953\",\"name\":\"T. Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"01b654d90f4670b4cc49a18283b5d2844e5d5048\",\"title\":\"Attention-based Residual Speech Portrait Model for Speech to Face Generation\",\"url\":\"https://www.semanticscholar.org/paper/01b654d90f4670b4cc49a18283b5d2844e5d5048\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.06968\",\"authors\":[{\"authorId\":\"1519970315\",\"name\":\"Xinsheng Wang\"},{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"1492210844\",\"name\":\"Alan Hanjalic\"},{\"authorId\":\"144951859\",\"name\":\"O. Scharenborg\"}],\"doi\":\"10.21437/interspeech.2020-1759\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a204f659b53e5fe8829562353a19eaebd6f87a4\",\"title\":\"S2IGAN: Speech-to-Image Generation via Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/3a204f659b53e5fe8829562353a19eaebd6f87a4\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2006.01943\",\"authors\":[{\"authorId\":\"23981209\",\"name\":\"Dogucan Yaman\"},{\"authorId\":\"19325009\",\"name\":\"Fevziye Irem Eyiokur\"},{\"authorId\":\"3025777\",\"name\":\"H. K. Ekenel\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc5bcf3951370d094101539f8abef4b6fba5ef0a\",\"title\":\"Ear2Face: Deep Biometric Modality Mapping\",\"url\":\"https://www.semanticscholar.org/paper/cc5bcf3951370d094101539f8abef4b6fba5ef0a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98291940\",\"name\":\"S. H. Lim\"},{\"authorId\":\"152782270\",\"name\":\"L. T. Giorgini\"},{\"authorId\":\"50247851\",\"name\":\"W. Moon\"},{\"authorId\":\"3458936\",\"name\":\"J. Wettlaufer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c635b654863a7b0badf843bc90489bf40e0d87b\",\"title\":\"Predicting Rare Events in Multiscale Dynamical Systems using Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/7c635b654863a7b0badf843bc90489bf40e0d87b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.13017\",\"authors\":[{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"22248940\",\"name\":\"X. Zeng\"},{\"authorId\":\"145194966\",\"name\":\"Chao Xu\"},{\"authorId\":\"50762378\",\"name\":\"Jun Chen\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"},{\"authorId\":\"122376816\",\"name\":\"Yunliang Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61dd5d814c82f2b1a2be416f859b7c426ac35cc2\",\"title\":\"APB2FaceV2: Real-Time Audio-Guided Multi-Face Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/61dd5d814c82f2b1a2be416f859b7c426ac35cc2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07710\",\"authors\":[{\"authorId\":\"1976753\",\"name\":\"Roman V Yampolskiy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2ea115933c094582d374e623ff67c74ad24fe3\",\"title\":\"Human $\\\\neq$ AGI.\",\"url\":\"https://www.semanticscholar.org/paper/bf2ea115933c094582d374e623ff67c74ad24fe3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.14326\",\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"9299637\",\"name\":\"Hong-Goo Kang\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"}],\"doi\":\"10.21437/Interspeech.2020-1113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6ec232e30ae03c1f97981fb00c84195f9f9bff3\",\"title\":\"Seeing voices and hearing voices: learning discriminative embeddings using cross-modal self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/d6ec232e30ae03c1f97981fb00c84195f9f9bff3\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2010.01464\",\"authors\":[{\"authorId\":\"40061203\",\"name\":\"Sandipan Banerjee\"},{\"authorId\":\"1702222\",\"name\":\"Ajjen Joshi\"},{\"authorId\":\"1564230554\",\"name\":\"Prashant Mahajan\"},{\"authorId\":\"7149487\",\"name\":\"Sneha Bhattacharya\"},{\"authorId\":\"2164893\",\"name\":\"Survi Kyal\"},{\"authorId\":\"144848710\",\"name\":\"Taniya Mishra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c34e05c9eac4c843ab59c38efe8ad098b17e0f69\",\"title\":\"LEGAN: Disentangled Manipulation of Directional Lighting and Facial Expressions by Leveraging Human Perceptual Judgements\",\"url\":\"https://www.semanticscholar.org/paper/c34e05c9eac4c843ab59c38efe8ad098b17e0f69\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.01826\",\"authors\":[{\"authorId\":\"144083220\",\"name\":\"Bin Duan\"},{\"authorId\":\"86955149\",\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Hao Tang\"},{\"authorId\":\"3422205\",\"name\":\"Hugo Latapie\"},{\"authorId\":\"144761059\",\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9587ba9ac12d3cc3e03f398dac1b97fc1a85621d\",\"title\":\"Cascade Attention Guided Residue Learning GAN for Cross-Modal Translation\",\"url\":\"https://www.semanticscholar.org/paper/9587ba9ac12d3cc3e03f398dac1b97fc1a85621d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.02541\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":\"10.21437/interspeech.2020-1026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0d2dc8123277cf3c894a10121272207dc39413\",\"title\":\"Vocoder-Based Speech Synthesis from Silent Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a0d2dc8123277cf3c894a10121272207dc39413\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50488872\",\"name\":\"R. Yi\"},{\"authorId\":\"7818093\",\"name\":\"Zipeng Ye\"},{\"authorId\":\"2938279\",\"name\":\"J. Zhang\"},{\"authorId\":\"1679542\",\"name\":\"H. Bao\"},{\"authorId\":\"46398687\",\"name\":\"Yongjin Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d76d7102edb5668cf425af1e806375b5a01dab33\",\"title\":\"Audio-driven Talking Face Video Generation with Natural Head Pose\",\"url\":\"https://www.semanticscholar.org/paper/d76d7102edb5668cf425af1e806375b5a01dab33\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49507095\",\"name\":\"Haoming Xu\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"1443732549\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1145/3394171.3413581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"title\":\"Cross-Modal Relation-Aware Networks for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.12780\",\"authors\":[{\"authorId\":\"41016678\",\"name\":\"Givi Meishvili\"},{\"authorId\":\"5641221\",\"name\":\"S. Jenni\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1109/cvpr42600.2020.00144\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b073e91f84ab59e482c2f1e22918f46ef606a531\",\"title\":\"Learning to Have an Ear for Face Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/b073e91f84ab59e482c2f1e22918f46ef606a531\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50446158\",\"name\":\"S. Goto\"},{\"authorId\":\"5848263\",\"name\":\"Kotaro Onishi\"},{\"authorId\":\"145784089\",\"name\":\"Y. Saito\"},{\"authorId\":\"2940047\",\"name\":\"Kentaro Tachibana\"},{\"authorId\":\"49810982\",\"name\":\"Koichiro Mori\"}],\"doi\":\"10.21437/interspeech.2020-2136\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b96f42659acbe92bba23dfad70c82d54e594b3f6\",\"title\":\"Face2Speech: Towards Multi-Speaker Text-to-Speech Synthesis Using an Embedding Vector Predicted from a Face Image\",\"url\":\"https://www.semanticscholar.org/paper/b96f42659acbe92bba23dfad70c82d54e594b3f6\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2007.07710\",\"authors\":[{\"authorId\":\"1976753\",\"name\":\"Roman V Yampolskiy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42e742de2455c4ea4f9563b273539b088c0334e5\",\"title\":\"Human \\u2260 AGI\",\"url\":\"https://www.semanticscholar.org/paper/42e742de2455c4ea4f9563b273539b088c0334e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04758\",\"authors\":[{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"100602595\",\"name\":\"Mandi Luo\"},{\"authorId\":\"77886607\",\"name\":\"Rui Wang\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"title\":\"Deep Audio-Visual Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.08335\",\"authors\":[{\"authorId\":\"3404049\",\"name\":\"Leyuan Qu\"},{\"authorId\":\"1798067\",\"name\":\"Cornelius Weber\"},{\"authorId\":\"50313481\",\"name\":\"Stefan Wermter\"}],\"doi\":\"10.21437/interspeech.2020-1697\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bc8a42ed4e6537063a4d20fc285e33bd47c1baa\",\"title\":\"Multimodal Target Speech Separation with Voice and Face References\",\"url\":\"https://www.semanticscholar.org/paper/3bc8a42ed4e6537063a4d20fc285e33bd47c1baa\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2006.07931\",\"authors\":[{\"authorId\":\"134192555\",\"name\":\"J. F. Montesinos\"},{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":\"10.1109/MMSP48831.2020.9287124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"title\":\"Solos: A Dataset for Audio-Visual Music Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.05830\",\"authors\":[{\"authorId\":\"81678900\",\"name\":\"Hyeong-Seok Choi\"},{\"authorId\":\"24100383\",\"name\":\"Chang-Dae Park\"},{\"authorId\":\"34674393\",\"name\":\"K. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"b44c4d94d2b1ce39ccf94677d69085a3bf5b2ff3\",\"title\":\"From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech\",\"url\":\"https://www.semanticscholar.org/paper/b44c4d94d2b1ce39ccf94677d69085a3bf5b2ff3\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2007.04687\",\"authors\":[{\"authorId\":\"2678268\",\"name\":\"P. Wu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"9754502\",\"name\":\"Yujia Shi\"},{\"authorId\":\"5264927\",\"name\":\"Yujia Sun\"},{\"authorId\":\"1802542506\",\"name\":\"Fangtao Shao\"},{\"authorId\":\"48551946\",\"name\":\"Zhaoyang Wu\"},{\"authorId\":\"40615725\",\"name\":\"Zhiwei Yang\"}],\"doi\":\"10.1007/978-3-030-58577-8_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f28873be3601c5a2736996eba543cf51950a381\",\"title\":\"Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/8f28873be3601c5a2736996eba543cf51950a381\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49865106\",\"name\":\"Z. Chen\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"152328117\",\"name\":\"Bo Yuan\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.01353\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d5a05bd182e27df36a115a10ebba766962653fc\",\"title\":\"PuppeteerGAN: Arbitrary Portrait Animation With Semantic-Aware Appearance Transformation\",\"url\":\"https://www.semanticscholar.org/paper/0d5a05bd182e27df36a115a10ebba766962653fc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.03894\",\"authors\":[{\"authorId\":\"1866636284\",\"name\":\"Ruijie Tao\"},{\"authorId\":\"2127436\",\"name\":\"Rohan Kumar Das\"},{\"authorId\":\"71200803\",\"name\":\"H. Li\"}],\"doi\":\"10.21437/interspeech.2020-1814\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7232c88607067648ec726caaa4c02f58a9808424\",\"title\":\"Audio-Visual Speaker Recognition with a Cross-Modal Discriminative Network\",\"url\":\"https://www.semanticscholar.org/paper/7232c88607067648ec726caaa4c02f58a9808424\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7816749\",\"name\":\"Santiago Pascual de la Puente\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb6d51a68cc8bd53a515d8f23893e9fd76005fbc\",\"title\":\"Efficient, end-to-end and self-supervised methods for speech processing and generation\",\"url\":\"https://www.semanticscholar.org/paper/fb6d51a68cc8bd53a515d8f23893e9fd76005fbc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.03413\",\"authors\":[{\"authorId\":\"1865748\",\"name\":\"Jiguo Li\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"3366824\",\"name\":\"Chuanmin Jia\"},{\"authorId\":\"1697982\",\"name\":\"Jizheng Xu\"},{\"authorId\":\"48459110\",\"name\":\"Li Zhang\"},{\"authorId\":\"49417698\",\"name\":\"Y. Wang\"},{\"authorId\":\"14104497\",\"name\":\"Siwei Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/JSTSP.2020.2987417\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1f127ef1ad0ca9d261bc40137fb7e84e6152410c\",\"title\":\"Direct Speech-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/1f127ef1ad0ca9d261bc40137fb7e84e6152410c\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"153915824\",\"name\":\"Rita Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d97a12a443d1238ac2f02b3e47619fff33c8430f\",\"title\":\"Face Reconstruction from Voice using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d97a12a443d1238ac2f02b3e47619fff33c8430f\",\"venue\":\"NeurIPS\",\"year\":2019}],\"corpusId\":162183917,\"doi\":\"10.1109/CVPR.2019.00772\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"references\":[{\"arxivId\":\"1901.10436\",\"authors\":[{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"47733712\",\"name\":\"N. Ratha\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":null,\"name\":\"John R. Smith\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e1b0f50417867317a8cb8fe35c6b2617ad9641e\",\"title\":\"Diversity in Faces\",\"url\":\"https://www.semanticscholar.org/paper/9e1b0f50417867317a8cb8fe35c6b2617ad9641e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144598072\",\"name\":\"D. King\"}],\"doi\":\"10.1145/1577069.1755843\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ea6a93199c9227fa0c1c7de13725f918c9be3a4\",\"title\":\"Dlib-ml: A Machine Learning Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2ea6a93199c9227fa0c1c7de13725f918c9be3a4\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2009},{\"arxivId\":\"1805.00833\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"title\":\"Learnable PINs: Cross-Modal Embeddings for Person Identity\",\"url\":\"https://www.semanticscholar.org/paper/a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153144262\",\"name\":\"H. M. Smith\"}],\"doi\":\"10.3758/s13414-015-1045-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a22c71a446e37283007139a9da366cb1ddb4550\",\"title\":\"Matching novel face and voice identity using static and dynamic facial images\",\"url\":\"https://www.semanticscholar.org/paper/8a22c71a446e37283007139a9da366cb1ddb4550\",\"venue\":\"Attention, perception & psychophysics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144270764\",\"name\":\"J. Hansen\"},{\"authorId\":\"9864076\",\"name\":\"Keri A. Williams\"},{\"authorId\":\"3319398\",\"name\":\"H. Boril\"}],\"doi\":\"10.1121/1.4927554\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9549c0128a101db6bac83691122eca741a7ed914\",\"title\":\"Speaker height estimation from speech: Fusing spectral regression and statistical acoustic models.\",\"url\":\"https://www.semanticscholar.org/paper/9549c0128a101db6bac83691122eca741a7ed914\",\"venue\":\"The Journal of the Acoustical Society of America\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143636342\",\"name\":\"Sarah L. Taylor\"},{\"authorId\":\"2066626\",\"name\":\"T. Kim\"},{\"authorId\":\"1740159\",\"name\":\"Yisong Yue\"},{\"authorId\":\"30303590\",\"name\":\"M. Mahler\"},{\"authorId\":\"1988242\",\"name\":\"James Krahe\"},{\"authorId\":\"36969558\",\"name\":\"Anastasio Garcia Rodriguez\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"}],\"doi\":\"10.1145/3072959.3073699\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc63b9cf84b1fb0b3eca84372919f74a40b7c132\",\"title\":\"A deep learning approach for generalized speech animation\",\"url\":\"https://www.semanticscholar.org/paper/cc63b9cf84b1fb0b3eca84372919f74a40b7c132\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1503.02531\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c908739fbff75f03469d13d4a1a07de3414ee19\",\"title\":\"Distilling the Knowledge in a Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3984021\",\"name\":\"Ruben Zazo\"},{\"authorId\":\"1414161764\",\"name\":\"Phani Sankar Nidadavolu\"},{\"authorId\":\"34507928\",\"name\":\"Nanxin Chen\"},{\"authorId\":\"1402317819\",\"name\":\"J. Gonz\\u00e1lez-Rodr\\u00edguez\"},{\"authorId\":\"49278419\",\"name\":\"Najim Dehak\"}],\"doi\":\"10.1109/ACCESS.2018.2816163\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fb40940a0814125c72ef7dfc18390f64521efa4\",\"title\":\"Age Estimation in Short Speech Utterances Based on LSTM Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4fb40940a0814125c72ef7dfc18390f64521efa4\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1706.00079\",\"authors\":[{\"authorId\":\"19320851\",\"name\":\"Ken Hoover\"},{\"authorId\":\"1680841\",\"name\":\"S. Chaudhuri\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"},{\"authorId\":\"145428577\",\"name\":\"Ian Sturdy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77ccb02b7d65b6cae80081c78c3fb35e878aca28\",\"title\":\"Putting a Face to the Voice: Fusing Audio and Visual Signals Across a Video to Determine Speakers\",\"url\":\"https://www.semanticscholar.org/paper/77ccb02b7d65b6cae80081c78c3fb35e878aca28\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.10550\",\"authors\":[{\"authorId\":\"8792285\",\"name\":\"Olivia Wiles\"},{\"authorId\":\"32445716\",\"name\":\"A. Koepke\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ea992f009492888c482d5f4006281eaa8b758e7\",\"title\":\"X2Face: A network for controlling face generation by using images, audio, and pose codes\",\"url\":\"https://www.semanticscholar.org/paper/9ea992f009492888c482d5f4006281eaa8b758e7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1808.05561\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1145/3240508.3240578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"540831094fd9b80469c8dacb9320b7e342b50e03\",\"title\":\"Emotion Recognition in Speech using Cross-Modal Transfer in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/540831094fd9b80469c8dacb9320b7e342b50e03\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Arandjelovic\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Look\",\"url\":\"\",\"venue\":\"listen and learn. In IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1606.07536\",\"authors\":[{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"372bc106c61e7eb004835e85bbfee997409f176a\",\"title\":\"Coupled Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/372bc106c61e7eb004835e85bbfee997409f176a\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1712.09382\",\"authors\":[{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1411184751\",\"name\":\"Hayden Schoen\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1109/CVPR.2018.00790\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6d60aaad68fa78c914ee34c26bceab033a88622\",\"title\":\"Audio to Body Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/c6d60aaad68fa78c914ee34c26bceab033a88622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144339350\",\"name\":\"G. Andrew\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6\",\"title\":\"Deep Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152823345\",\"name\":\"M. Sol\\u00e8r\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"153243248\",\"name\":\"A. Krause\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1007/978-3-319-48881-3_59\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"title\":\"Suggesting Sounds for Images from Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1709.07902\",\"authors\":[{\"authorId\":\"2957796\",\"name\":\"Wei-Ning Hsu\"},{\"authorId\":\"46207379\",\"name\":\"Yu Zhang\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c955f0a5a70ae458084998ceee20e402ecc6504a\",\"title\":\"Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data\",\"url\":\"https://www.semanticscholar.org/paper/c955f0a5a70ae458084998ceee20e402ecc6504a\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144331537\",\"name\":\"P. B. Denes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1188d477bb192ec731806c33e0a2a412b19b6ca5\",\"title\":\"The Speech Chain\",\"url\":\"https://www.semanticscholar.org/paper/1188d477bb192ec731806c33e0a2a412b19b6ca5\",\"venue\":\"\",\"year\":1963},{\"arxivId\":\"1807.04836\",\"authors\":[{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"144727980\",\"name\":\"M. Ismail\"},{\"authorId\":\"36326884\",\"name\":\"Weiyang Liu\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"1798727\",\"name\":\"R. Singh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4188f289eb85bb047dbbc15acbd79fae6abe25f5\",\"title\":\"Disjoint Mapping Network for Cross-modal Matching of Voices and Faces\",\"url\":\"https://www.semanticscholar.org/paper/4188f289eb85bb047dbbc15acbd79fae6abe25f5\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1512.00570\",\"authors\":[{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1007/978-3-319-46493-0_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d0363a3ebda56d91d704d5ff5458a527775b609\",\"title\":\"Attribute2Image: Conditional Image Generation from Visual Attributes\",\"url\":\"https://www.semanticscholar.org/paper/2d0363a3ebda56d91d704d5ff5458a527775b609\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7180730\",\"name\":\"Shota Horiguchi\"},{\"authorId\":\"1833359\",\"name\":\"N. Kanda\"},{\"authorId\":\"2694044\",\"name\":\"K. Nagamatsu\"}],\"doi\":\"10.1145/3240508.3240601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b4da93fbdf7ae520fa00d39ffa694e850b85162\",\"title\":\"Face-Voice Matching using Cross-modal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/3b4da93fbdf7ae520fa00d39ffa694e850b85162\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"3468872\",\"name\":\"Antti Herva\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":\"10.1145/3072959.3073658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95b803d07c37e8349bd7b1318367d8237c76cbc0\",\"title\":\"Audio-driven facial animation by joint end-to-end learning of pose and emotion\",\"url\":\"https://www.semanticscholar.org/paper/95b803d07c37e8349bd7b1318367d8237c76cbc0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780015\",\"name\":\"V. R. D. Sa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45b55bc4cbb124cc8f91f658871904be5f65b35f\",\"title\":\"Minimizing Disagreement for Self-Supervised Classification\",\"url\":\"https://www.semanticscholar.org/paper/45b55bc4cbb124cc8f91f658871904be5f65b35f\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1804.00326\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2018.00879\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c75658b080a9baaac20db39af86016ffa36f6f0\",\"title\":\"Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching\",\"url\":\"https://www.semanticscholar.org/paper/2c75658b080a9baaac20db39af86016ffa36f6f0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1701.04851\",\"authors\":[{\"authorId\":\"39578349\",\"name\":\"F. Cole\"},{\"authorId\":\"2636941\",\"name\":\"D. Belanger\"},{\"authorId\":\"1707347\",\"name\":\"Dilip Krishnan\"},{\"authorId\":\"8707513\",\"name\":\"Aaron Sarna\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2017.361\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"559b12257d56725fbef5790e2dfdec8751919ef1\",\"title\":\"Synthesizing Normalized Faces from Facial Identity Features\",\"url\":\"https://www.semanticscholar.org/paper/559b12257d56725fbef5790e2dfdec8751919ef1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"4738460\",\"name\":\"Mingyu Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"title\":\"Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"O. Wiles\"},{\"authorId\":null,\"name\":\"A. S. Koepke\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"X2Face: A network for controlling face generation using images\",\"url\":\"\",\"venue\":\"audio, and pose codes. In European Conference on Computer Vision (ECCV), Springer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3188342\",\"name\":\"Omkar M. Parkhi\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.29.41\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"162ea969d1929ed180cc6de9f0bf116993ff6e06\",\"title\":\"Deep Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/162ea969d1929ed180cc6de9f0bf116993ff6e06\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":\"1712.07271\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/s11263-018-1083-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"046111bd2dfc057182e0b995110a5705b572c819\",\"title\":\"Learning Sight from Sound: Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/046111bd2dfc057182e0b995110a5705b572c819\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1805.05553\",\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-20873-8_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"title\":\"On Learning Associations of Faces and Voices\",\"url\":\"https://www.semanticscholar.org/paper/1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1611.05358\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"title\":\"Lip Reading Sentences in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37016781\",\"name\":\"Supasorn Suwajanakorn\"},{\"authorId\":\"1396612598\",\"name\":\"Steven M. Seitz\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1145/3072959.3073640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"title\":\"Synthesizing Obama\",\"url\":\"https://www.semanticscholar.org/paper/7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1706.08612\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2017-950\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a26431833b0ea8659ef1d24bff3ac9e56dcfcd0\",\"title\":\"VoxCeleb: A Large-Scale Speaker Identification Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8a26431833b0ea8659ef1d24bff3ac9e56dcfcd0\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1607.07295\",\"authors\":[{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e64992091458256f438fbe1bd44fffcc197b76c\",\"title\":\"Learning Aligned Cross-Modal Representations from Weakly Aligned Data\",\"url\":\"https://www.semanticscholar.org/paper/7e64992091458256f438fbe1bd44fffcc197b76c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Merler\"},{\"authorId\":null,\"name\":\"N. Ratha\"},{\"authorId\":null,\"name\":\"R. S. Feris\"},{\"authorId\":null,\"name\":\"S. Albanie A. Nagrani\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Cross - modal embeddings for person identity\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems ( NIPS )\",\"year\":2016},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50473499\",\"name\":\"M. Kamachi\"},{\"authorId\":\"144240600\",\"name\":\"H. Hill\"},{\"authorId\":\"2283386\",\"name\":\"K. Lander\"},{\"authorId\":\"1404217694\",\"name\":\"E. Vatikiotis-Bateson\"}],\"doi\":\"10.1016/j.cub.2003.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd4d6ee3aed9f5e3f63b1bce29e8706c3c5917dd\",\"title\":\"`Putting the Face to the Voice' Matching Identity across Modality\",\"url\":\"https://www.semanticscholar.org/paper/fd4d6ee3aed9f5e3f63b1bce29e8706c3c5917dd\",\"venue\":\"Current Biology\",\"year\":2003},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.10195\",\"authors\":[{\"authorId\":\"144404308\",\"name\":\"Amanda Duarte\"},{\"authorId\":\"153738374\",\"name\":\"Francisco Roldan\"},{\"authorId\":\"118129922\",\"name\":\"Miquel Tubau\"},{\"authorId\":\"115672881\",\"name\":\"Janna Escur\"},{\"authorId\":\"144077573\",\"name\":\"S. Pascual\"},{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"145470863\",\"name\":\"K. McGuinness\"},{\"authorId\":\"144345280\",\"name\":\"J. Torres\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":\"10.1109/ICASSP.2019.8682970\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d68ae09863d3ec1831392204f7a062ebebaacff9\",\"title\":\"Wav2Pix: Speech-conditioned Face Generation Using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d68ae09863d3ec1831392204f7a062ebebaacff9\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73dd716522b0b99880b1c002e8ad1ed6eddf6334\",\"title\":\"The Discovery of perceptual structure from visual co-occurrences in space and time\",\"url\":\"https://www.semanticscholar.org/paper/73dd716522b0b99880b1c002e8ad1ed6eddf6334\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1811.10813\",\"authors\":[{\"authorId\":\"2927349\",\"name\":\"S. Shon\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ICASSP.2019.8683477\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac545258eb99e8ee83787903ce74b37cddf00e4e\",\"title\":\"Noise-tolerant Audio-visual Online Person Verification Using an Attention-based Neural Network Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ac545258eb99e8ee83787903ce74b37cddf00e4e\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35771704\",\"name\":\"Israel D. Gebru\"},{\"authorId\":\"1684507\",\"name\":\"Sileye O. Ba\"},{\"authorId\":\"33890734\",\"name\":\"Georgios D. Evangelidis\"},{\"authorId\":\"1794229\",\"name\":\"R. Horaud\"}],\"doi\":\"10.1109/ICCVW.2015.96\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef7d38f5a8bf2490345d31ad73aeeb8263c624c3\",\"title\":\"Tracking the Active Speaker Based on a Joint Audio-Visual Observation Model\",\"url\":\"https://www.semanticscholar.org/paper/ef7d38f5a8bf2490345d31ad73aeeb8263c624c3\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":\"1806.00154\",\"authors\":[{\"authorId\":\"50178247\",\"name\":\"Najmeh Sadoughi\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"}],\"doi\":\"10.1109/TAFFC.2019.2916031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b0e2250a2eb250682cfef8e369742cf10d0dfa2\",\"title\":\"Speech-Driven Expressive Talking Lips with Conditional Sequential Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b0e2250a2eb250682cfef8e369742cf10d0dfa2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145506659\",\"name\":\"M. Feld\"},{\"authorId\":\"1763455\",\"name\":\"F. Burkhardt\"},{\"authorId\":\"33662760\",\"name\":\"C. Mueller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d07fe80d707da04de691e6559292ee284494b67c\",\"title\":\"Automatic speaker age and gender recognition in the car for tailoring dialog and mobile services\",\"url\":\"https://www.semanticscholar.org/paper/d07fe80d707da04de691e6559292ee284494b67c\",\"venue\":\"INTERSPEECH\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2160086\",\"name\":\"M. H. Bahari\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"}],\"doi\":\"10.1109/BIOMS.2011.6052385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e998cced21d6a2d43f53d3d2c75e0141287cd8c2\",\"title\":\"Speaker age estimation and gender detection based on supervised Non-Negative Matrix Factorization\",\"url\":\"https://www.semanticscholar.org/paper/e998cced21d6a2d43f53d3d2c75e0141287cd8c2\",\"venue\":\"2011 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS)\",\"year\":2011}],\"title\":\"Speech2Face: Learning the Face Behind a Voice\",\"topics\":[{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Face (geometry)\",\"topicId\":\"14212\",\"url\":\"https://www.semanticscholar.org/topic/14212\"},{\"topic\":\"Biometrics\",\"topicId\":\"3710\",\"url\":\"https://www.semanticscholar.org/topic/3710\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Numerical analysis\",\"topicId\":\"5413\",\"url\":\"https://www.semanticscholar.org/topic/5413\"},{\"topic\":\"Align (company)\",\"topicId\":\"439709\",\"url\":\"https://www.semanticscholar.org/topic/439709\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"}],\"url\":\"https://www.semanticscholar.org/paper/e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"