"{\"abstract\":\"Time-lapse videos usually contain visually appealing content but are often difficult and costly to create. In this paper, we present an end-to-end solution to synthesize a time-lapse video from a single outdoor image using deep neural networks. Our key idea is to train a conditional generative adversarial network based on existing datasets of time-lapse videos and image sequences. We propose a multi-frame joint conditional generation framework to effectively learn the correlation between the illumination change of an outdoor scene and the time of the day. We further present a multi-domain training scheme for robust training of our generative models from two datasets with different distributions and missing timestamp labels. Compared to alternative time-lapse video synthesis algorithms, our method uses the timestamp as the control variable and does not require a reference video to guide the synthesis of the final output. We conduct ablation studies to validate our algorithm and compare with state-of-the-art techniques both qualitatively and quantitatively.\",\"arxivId\":\"1904.00680\",\"authors\":[{\"authorId\":\"7532506\",\"name\":\"Seonghyeon Nam\",\"url\":\"https://www.semanticscholar.org/author/7532506\"},{\"authorId\":\"1797422\",\"name\":\"Chongyang Ma\",\"url\":\"https://www.semanticscholar.org/author/1797422\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\",\"url\":\"https://www.semanticscholar.org/author/1752091\"},{\"authorId\":\"48858384\",\"name\":\"William Brendel\",\"url\":\"https://www.semanticscholar.org/author/48858384\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\",\"url\":\"https://www.semanticscholar.org/author/145857599\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\",\"url\":\"https://www.semanticscholar.org/author/1754380\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":\"2001.01026\",\"authors\":[{\"authorId\":\"46917346\",\"name\":\"Amy Zhao\"},{\"authorId\":\"47231927\",\"name\":\"G. Balakrishnan\"},{\"authorId\":\"40649030\",\"name\":\"Kathleen M. Lewis\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1724429\",\"name\":\"J. Guttag\"},{\"authorId\":\"3046516\",\"name\":\"Adrian V. Dalca\"}],\"doi\":\"10.1109/cvpr42600.2020.00846\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"title\":\"Painting Many Pasts: Synthesizing Time Lapse Videos of Paintings\",\"url\":\"https://www.semanticscholar.org/paper/5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98716326\",\"name\":\"Y. Chen\"},{\"authorId\":\"3257136\",\"name\":\"X. Liu\"},{\"authorId\":\"80578084\",\"name\":\"C. Wang\"}],\"doi\":\"10.1117/12.2574416\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd920b4a748747a045067f335280e08d00d481ab\",\"title\":\"Research of road scene object detection algorithm based on mobile platform\",\"url\":\"https://www.semanticscholar.org/paper/fd920b4a748747a045067f335280e08d00d481ab\",\"venue\":\"International Workshop on Pattern Recognition\",\"year\":2020},{\"arxivId\":\"2003.08791\",\"authors\":[{\"authorId\":\"1585846601\",\"name\":\"Ivan Anokhin\"},{\"authorId\":\"52021869\",\"name\":\"P. Solovev\"},{\"authorId\":\"51931029\",\"name\":\"Denis Korzhenkov\"},{\"authorId\":\"2168093\",\"name\":\"A. Kharlamov\"},{\"authorId\":\"51110175\",\"name\":\"Taras Khakhulin\"},{\"authorId\":\"1585846605\",\"name\":\"Alexey Silvestrov\"},{\"authorId\":\"1742235\",\"name\":\"S. Nikolenko\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"},{\"authorId\":\"51434572\",\"name\":\"Gleb Sterkin\"}],\"doi\":\"10.1109/cvpr42600.2020.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4c4a647d6a55bc35bdf5210cfb257c913618990\",\"title\":\"High-Resolution Daytime Translation Without Domain Labels\",\"url\":\"https://www.semanticscholar.org/paper/c4c4a647d6a55bc35bdf5210cfb257c913618990\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.04776\",\"authors\":[{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"145194966\",\"name\":\"Chao Xu\"},{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1490938675\",\"name\":\"Xia Wu\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"},{\"authorId\":\"122376816\",\"name\":\"Yunliang Jiang\"}],\"doi\":\"10.1007/978-3-030-58558-7_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1847cbb4064ca05593f7b408783e9f183953488\",\"title\":\"DTVNet: Dynamic Time-lapse Video Generation via Single Still Image\",\"url\":\"https://www.semanticscholar.org/paper/c1847cbb4064ca05593f7b408783e9f183953488\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.10704\",\"authors\":[{\"authorId\":\"145411379\",\"name\":\"R. Rakhimov\"},{\"authorId\":\"9937997\",\"name\":\"Denis Volkhonskiy\"},{\"authorId\":\"145235439\",\"name\":\"A. Artemov\"},{\"authorId\":\"145516498\",\"name\":\"D. Zorin\"},{\"authorId\":\"51139941\",\"name\":\"Evgeny Burnaev\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef25fe928b5a9f53296a938339dff5aeffcf6e7b\",\"title\":\"Latent Video Transformer\",\"url\":\"https://www.semanticscholar.org/paper/ef25fe928b5a9f53296a938339dff5aeffcf6e7b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393157266\",\"name\":\"Ken\\u2019ich Morooka\"},{\"authorId\":\"40460824\",\"name\":\"X. Zhang\"},{\"authorId\":\"1915539\",\"name\":\"Shoko Miyauchi\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"},{\"authorId\":\"3979815\",\"name\":\"E. Ohno\"}],\"doi\":\"10.1007/978-3-030-39770-8_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e11d273299945ba943e0c1094628142a148bd40\",\"title\":\"GAN-Based Method for Synthesizing Multi-focus Cell Images\",\"url\":\"https://www.semanticscholar.org/paper/7e11d273299945ba943e0c1094628142a148bd40\",\"venue\":\"PSIVT Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48623302\",\"name\":\"Ye Yu\"},{\"authorId\":\"1953101\",\"name\":\"Abhimitra Meka\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"123810991\",\"name\":\"Christian\"},{\"authorId\":\"2026670485\",\"name\":\"Theobalt\"},{\"authorId\":\"145242734\",\"name\":\"W. Smith\"}],\"doi\":\"10.1007/978-3-030-58542-6_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f26995f08f965caea1a459645c21e0b80170b09\",\"title\":\"Self-supervised Outdoor Scene Relighting\",\"url\":\"https://www.semanticscholar.org/paper/2f26995f08f965caea1a459645c21e0b80170b09\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.00362\",\"authors\":[{\"authorId\":\"39737792\",\"name\":\"Zili Yi\"},{\"authorId\":\"144212122\",\"name\":\"Qiang Tang\"},{\"authorId\":\"1850236751\",\"name\":\"Vishnu Sanjay Ramiya Srinivasan\"},{\"authorId\":\"47047818\",\"name\":\"Zhan Xu\"}],\"doi\":\"10.1145/3394171.3413926\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af443225ec5813afa669353564957e295b0471a9\",\"title\":\"Animating Through Warping: An Efficient Method for High-Quality Facial Expression Animation\",\"url\":\"https://www.semanticscholar.org/paper/af443225ec5813afa669353564957e295b0471a9\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103664864\",\"name\":\"Chia-chi Cheng\"},{\"authorId\":\"40846050\",\"name\":\"Hungyu Chen\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":\"10.1109/cvpr42600.2020.00568\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"title\":\"Time Flies: Animating a Still Image With Time-Lapse Video As Reference\",\"url\":\"https://www.semanticscholar.org/paper/4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84209943\",\"name\":\"J. Cho\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"2065130\",\"name\":\"D. Min\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/TIP.2020.3000612\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8d44fa9912f88c526230747b3e06f5df6ddadd7\",\"title\":\"Single Image Deraining Using Time-Lapse Data\",\"url\":\"https://www.semanticscholar.org/paper/b8d44fa9912f88c526230747b3e06f5df6ddadd7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49107901\",\"name\":\"Albert Pumarola\"},{\"authorId\":\"144003484\",\"name\":\"A. Agudo\"},{\"authorId\":\"145358414\",\"name\":\"A. Mart\\u00ednez\"},{\"authorId\":\"1791054\",\"name\":\"A. Sanfeliu\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"}],\"doi\":\"10.1007/s11263-019-01210-3\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"9c41d7cd81c3af37ac68a4f348122aead4f53962\",\"title\":\"GANimation: One-Shot Anatomically Consistent Facial Animation\",\"url\":\"https://www.semanticscholar.org/paper/9c41d7cd81c3af37ac68a4f348122aead4f53962\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019}],\"corpusId\":90246895,\"doi\":\"10.1109/CVPR.2019.00150\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"54efdd4c03e47a11db7ef710b8dc87c70d34e529\",\"references\":[{\"arxivId\":\"1608.07724\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46484-8_16\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5bf3b2a5591f2a2f0c648dc5a1f4ff3bd6b9102a\",\"title\":\"Learning Temporal Transformations from Time-Lapse Videos\",\"url\":\"https://www.semanticscholar.org/paper/5bf3b2a5591f2a2f0c648dc5a1f4ff3bd6b9102a\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1802.06474\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2816471\",\"name\":\"Xueting Li\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1007/978-3-030-01219-9_28\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eadac91600c67ee2343e7ce76934e92b1796e60e\",\"title\":\"A Closed-form Solution to Photorealistic Image Stylization\",\"url\":\"https://www.semanticscholar.org/paper/eadac91600c67ee2343e7ce76934e92b1796e60e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"39763785\",\"name\":\"K. Zheng\"},{\"authorId\":\"143800609\",\"name\":\"Brian Curless\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1145/1186822.1073273\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97cf26976f50578a65fc6714a234469f52030aca\",\"title\":\"Animating pictures with stochastic motion textures\",\"url\":\"https://www.semanticscholar.org/paper/97cf26976f50578a65fc6714a234469f52030aca\",\"venue\":\"ACM Trans. Graph.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145801672\",\"name\":\"Nathan Jacobs\"},{\"authorId\":\"145964443\",\"name\":\"Nathaniel Roman\"},{\"authorId\":\"143857761\",\"name\":\"Robert Pless\"}],\"doi\":\"10.1109/CVPR.2007.383258\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9d4648c9ce8f9d62b941b57615450f6f434a609a\",\"title\":\"Consistent Temporal Variations in Many Outdoor Scenes\",\"url\":\"https://www.semanticscholar.org/paper/9d4648c9ce8f9d62b941b57615450f6f434a609a\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.11714\",\"authors\":[{\"authorId\":\"3022958\",\"name\":\"H. Kim\"},{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"9102722\",\"name\":\"A. Tewari\"},{\"authorId\":\"9765909\",\"name\":\"Weipeng Xu\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/3197517.3201283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efb0a4574736a976b6dc3c23be45e5fc0ac6fe41\",\"title\":\"Deep video portraits\",\"url\":\"https://www.semanticscholar.org/paper/efb0a4574736a976b6dc3c23be45e5fc0ac6fe41\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1804.00582\",\"authors\":[{\"authorId\":\"8763474\",\"name\":\"Z. Li\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1109/CVPR.2018.00942\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70cefe655a7f9dae0948b2102871661666dc1be8\",\"title\":\"Learning Intrinsic Image Decomposition from Watching the World\",\"url\":\"https://www.semanticscholar.org/paper/70cefe655a7f9dae0948b2102871661666dc1be8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.07511\",\"authors\":[{\"authorId\":\"13981526\",\"name\":\"Fu-jun Luan\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144374926\",\"name\":\"K. Bala\"}],\"doi\":\"10.1109/CVPR.2017.740\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b5253c8159ffa7cca12901af26a0a0897b45cda\",\"title\":\"Deep Photo Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/8b5253c8159ffa7cca12901af26a0a0897b45cda\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2469774\",\"name\":\"Wei-Cih Jhou\"},{\"authorId\":\"1711298\",\"name\":\"W. Cheng\"}],\"doi\":\"10.1109/TMM.2015.2500031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71ca74f55147d641358d0609e13d2bfcfaa3f5f7\",\"title\":\"Animating Still Landscape Photographs Through Cloud Motion Creation\",\"url\":\"https://www.semanticscholar.org/paper/71ca74f55147d641358d0609e13d2bfcfaa3f5f7\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"150426657\",\"name\":\"\\u62d3\\u6d77 \\u6749\\u5c71\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8a5f27e7805f8de84ea008d59452ff864271696\",\"title\":\"\\u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\u201d\\u306e\\u5b66\\u7fd2\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/e8a5f27e7805f8de84ea008d59452ff864271696\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34872975\",\"name\":\"Yi-Chang Shih\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1145/2508363.2508419\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8a44b6b3511073c1c0f8cb86f3848f3a7390d875\",\"title\":\"Data-driven hallucination of different times of day from a single outdoor photo\",\"url\":\"https://www.semanticscholar.org/paper/8a44b6b3511073c1c0f8cb86f3848f3a7390d875\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1704.02510\",\"authors\":[{\"authorId\":\"39737792\",\"name\":\"Zili Yi\"},{\"authorId\":\"39497427\",\"name\":\"Hao Zhang\"},{\"authorId\":\"145604260\",\"name\":\"Ping Tan\"},{\"authorId\":\"34077629\",\"name\":\"Minglun Gong\"}],\"doi\":\"10.1109/ICCV.2017.310\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef3c1f6c177e37f1d0d2a61702b60c766971700b\",\"title\":\"DualGAN: Unsupervised Dual Learning for Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/ef3c1f6c177e37f1d0d2a61702b60c766971700b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1905.01270\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"143963461\",\"name\":\"Hung-Yu Tseng\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"144688398\",\"name\":\"Maneesh Kumar Singh\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01246-5_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d5d9d8e74b215609eabba80ef79a35ebf460e49\",\"title\":\"Diverse Image-to-Image Translation via Disentangled Representations\",\"url\":\"https://www.semanticscholar.org/paper/3d5d9d8e74b215609eabba80ef79a35ebf460e49\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1411.1784\",\"authors\":[{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"title\":\"Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2167259\",\"name\":\"P. Laffont\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"}],\"doi\":\"10.1109/ICCV.2015.57\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1879306d3f410e3c9e3bb0af9c92b0a021b423e9\",\"title\":\"Intrinsic Decomposition of Image Sequences from Local Temporal Variations\",\"url\":\"https://www.semanticscholar.org/paper/1879306d3f410e3c9e3bb0af9c92b0a021b423e9\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Manzil Zaheer\"},{\"authorId\":null,\"name\":\"Satwik Kottur Ruslan\"},{\"authorId\":null,\"name\":\"R Salakhutdinov\"},{\"authorId\":null,\"name\":\"Alexander J Smola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Siamak Ravanbakhsh, Barnabas Poczos\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"143872936\",\"name\":\"Xavier Puig\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"3081640\",\"name\":\"Adela Barriuso\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.544\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d\",\"title\":\"Scene Parsing through ADE20K Dataset\",\"url\":\"https://www.semanticscholar.org/paper/2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"},{\"authorId\":\"7723706\",\"name\":\"S. Rusinkiewicz\"}],\"doi\":\"10.1145/1276377.1276504\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a465ecb70d83cc04208ad338fd9d9a6d32037c25\",\"title\":\"Factored time-lapse video\",\"url\":\"https://www.semanticscholar.org/paper/a465ecb70d83cc04208ad338fd9d9a6d32037c25\",\"venue\":\"SIGGRAPH 2007\",\"year\":2007},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1703.06114\",\"authors\":[{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"2111187\",\"name\":\"Siamak Ravanbakhsh\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a456265138c088a894301c0433dae938705a9bec\",\"title\":\"Deep Sets\",\"url\":\"https://www.semanticscholar.org/paper/a456265138c088a894301c0433dae938705a9bec\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1710.00756\",\"authors\":[{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9fea96a88d9a390d0a51d25022ca73b90f801b4\",\"title\":\"Neural Color Transfer between Images\",\"url\":\"https://www.semanticscholar.org/paper/b9fea96a88d9a390d0a51d25022ca73b90f801b4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145476994\",\"name\":\"V. Bychkovsky\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"121028414\",\"name\":\"E. Chan\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/CVPR.2011.5995332\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ee57b18a7be2b671ffc6f5ce5dbbe92112ee0fb\",\"title\":\"Learning photographic global tonal adjustment with a database of input/output image pairs\",\"url\":\"https://www.semanticscholar.org/paper/5ee57b18a7be2b671ffc6f5ce5dbbe92112ee0fb\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1709.07592\",\"authors\":[{\"authorId\":\"39272336\",\"name\":\"W. Xiong\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2018.00251\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"87a818723a2ada66a1193baf17b0383d9766781b\",\"title\":\"Learning to Generate Time-Lapse Videos Using Multi-stage Dynamic Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/87a818723a2ada66a1193baf17b0383d9766781b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1706.08033\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"title\":\"Decomposing Motion and Content for Natural Video Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1707.09405\",\"authors\":[{\"authorId\":\"143832240\",\"name\":\"Qifeng Chen\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1109/ICCV.2017.168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28eceb438da0b841bbd3d02684dbfa263838ed60\",\"title\":\"Photographic Image Synthesis with Cascaded Refinement Networks\",\"url\":\"https://www.semanticscholar.org/paper/28eceb438da0b841bbd3d02684dbfa263838ed60\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1612.00215\",\"authors\":[{\"authorId\":\"2045768\",\"name\":\"Levent Karacan\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e4a0ee35f5e5eef7feab42bb693ef23b163ae8a\",\"title\":\"Learning to Generate Images of Outdoor Scenes from Attributes and Semantic Layouts\",\"url\":\"https://www.semanticscholar.org/paper/9e4a0ee35f5e5eef7feab42bb693ef23b163ae8a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"2409115\",\"name\":\"M. Loper\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":\"10.2312/EGWR/EGSR04/299-308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"074f913be001b817e72047804a2807b5575448d1\",\"title\":\"Progressively-Refined Reflectance Functions from natural Illumination\",\"url\":\"https://www.semanticscholar.org/paper/074f913be001b817e72047804a2807b5575448d1\",\"venue\":\"Rendering Techniques\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2884662\",\"name\":\"Xuemiao Xu\"},{\"authorId\":\"47537489\",\"name\":\"L. Wan\"},{\"authorId\":\"3260708\",\"name\":\"Xiaopei Liu\"},{\"authorId\":\"1720633\",\"name\":\"T. Wong\"},{\"authorId\":\"40585254\",\"name\":\"L. Wang\"},{\"authorId\":\"66036597\",\"name\":\"Chi-Sing Leung\"}],\"doi\":\"10.1145/1409060.1409070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db62e0de5710788c55f7e5c22589901b6c840ee1\",\"title\":\"Animating animal motion from still\",\"url\":\"https://www.semanticscholar.org/paper/db62e0de5710788c55f7e5c22589901b6c840ee1\",\"venue\":\"SIGGRAPH 2008\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"123371831\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2017.2723009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f986968735459e789890f24b6b277b0920a9725d\",\"title\":\"Places: A 10 Million Image Database for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f986968735459e789890f24b6b277b0920a9725d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1707.04993\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00165\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"title\":\"MoCoGAN: Decomposing Motion and Content for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.09767\",\"authors\":[{\"authorId\":\"9480437\",\"name\":\"Asha Anoosheh\"},{\"authorId\":\"1959475\",\"name\":\"Torsten Sattler\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICRA.2019.8794387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"153f7aefd862b53d2eeef9c813443fb32998757f\",\"title\":\"Night-to-Day Image Translation for Retrieval-based Localization\",\"url\":\"https://www.semanticscholar.org/paper/153f7aefd862b53d2eeef9c813443fb32998757f\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"1808.05174\",\"authors\":[{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1007/978-3-030-01228-1_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ad3c383a79e85159098112127300dfd08c21319\",\"title\":\"Recycle-GAN: Unsupervised Video Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/8ad3c383a79e85159098112127300dfd08c21319\",\"venue\":\"ECCV\",\"year\":2018}],\"title\":\"End-To-End Time-Lapse Video Synthesis From a Single Outdoor Image\",\"topics\":[{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"End-to-end encryption\",\"topicId\":\"854929\",\"url\":\"https://www.semanticscholar.org/topic/854929\"},{\"topic\":\"Microsoft Windows\",\"topicId\":\"4539\",\"url\":\"https://www.semanticscholar.org/topic/4539\"},{\"topic\":\"Master of Science in Information Technology\",\"topicId\":\"1418216\",\"url\":\"https://www.semanticscholar.org/topic/1418216\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Frame language\",\"topicId\":\"224664\",\"url\":\"https://www.semanticscholar.org/topic/224664\"},{\"topic\":\"NAM\",\"topicId\":\"481072\",\"url\":\"https://www.semanticscholar.org/topic/481072\"}],\"url\":\"https://www.semanticscholar.org/paper/54efdd4c03e47a11db7ef710b8dc87c70d34e529\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"