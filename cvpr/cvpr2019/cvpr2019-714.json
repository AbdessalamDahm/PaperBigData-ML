"{\"abstract\":\"Obtaining deep networks that are robust against adversarial examples and generalize well is an open problem. A recent hypothesis even states that both robust and accurate models are impossible, i.e., adversarial robustness and generalization are conflicting goals. In an effort to clarify the relationship between robustness and generalization, we assume an underlying, low-dimensional data manifold and show that: 1. regular adversarial examples leave the manifold; 2. adversarial examples constrained to the manifold, i.e., on-manifold adversarial examples, exist; 3. on-manifold adversarial examples are generalization errors, and on-manifold adversarial training boosts generalization; 4. regular robustness and generalization are not necessarily contradicting goals. These assumptions imply that both robust and accurate models are possible. However, different models (architectures, training strategies etc.) can exhibit different robustness and generalization characteristics. To confirm our claims, we present extensive experiments on synthetic data (with known manifold) as well as on EMNIST, Fashion-MNIST and CelebA.\",\"arxivId\":\"1812.00740\",\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\",\"url\":\"https://www.semanticscholar.org/author/145177088\"},{\"authorId\":\"143610806\",\"name\":\"M. Hein\",\"url\":\"https://www.semanticscholar.org/author/143610806\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\",\"url\":\"https://www.semanticscholar.org/author/48920094\"}],\"citationVelocity\":30,\"citations\":[{\"arxivId\":\"2012.13628\",\"authors\":[{\"authorId\":\"1515531906\",\"name\":\"Ahmadreza Jeddi\"},{\"authorId\":\"35371895\",\"name\":\"M. Shafiee\"},{\"authorId\":\"50381441\",\"name\":\"Alexander Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fccfd63590564038a4f7235b7ce5c4eddb9b33c\",\"title\":\"A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via Adversarial Fine-tuning\",\"url\":\"https://www.semanticscholar.org/paper/3fccfd63590564038a4f7235b7ce5c4eddb9b33c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.03712\",\"authors\":[{\"authorId\":\"31896097\",\"name\":\"V. Krishnan\"},{\"authorId\":\"152746662\",\"name\":\"Abed AlRahman Al Makdah\"},{\"authorId\":\"2476273\",\"name\":\"F. Pasqualetti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97667dbc4538e97143ba1f8fe257b8e97dfee2de\",\"title\":\"Lipschitz Bounds and Provably Robust Training by Laplacian Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/97667dbc4538e97143ba1f8fe257b8e97dfee2de\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1912.00888\",\"authors\":[{\"authorId\":\"79993101\",\"name\":\"Nils Lukas\"},{\"authorId\":\"46868456\",\"name\":\"Yuxuan Zhang\"},{\"authorId\":\"1682949\",\"name\":\"F. Kerschbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7f04ba1d0d141d0452193727df26860ab7a721\",\"title\":\"Deep Neural Network Fingerprinting by Conferrable Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/1f7f04ba1d0d141d0452193727df26860ab7a721\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.07458\",\"authors\":[{\"authorId\":\"51290549\",\"name\":\"Kanil Patel\"},{\"authorId\":\"52020792\",\"name\":\"William H. Beluch\"},{\"authorId\":\"40232936\",\"name\":\"D. Zhang\"},{\"authorId\":\"34474312\",\"name\":\"M. Pfeiffer\"},{\"authorId\":\"1409956321\",\"name\":\"Bin Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d4a20d1762590d00efd11a0f463a679da97c71\",\"title\":\"On-manifold Adversarial Data Augmentation Improves Uncertainty Calibration\",\"url\":\"https://www.semanticscholar.org/paper/f3d4a20d1762590d00efd11a0f463a679da97c71\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2209082\",\"name\":\"Quan-Xin Zhang\"},{\"authorId\":\"2084690\",\"name\":\"Xiaohui Kuang\"}],\"doi\":\"10.1016/j.patcog.2020.107309\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da418706f2d08ce388895d7917a19a5ea30f406c\",\"title\":\"Adaptive iterative attack towards explainable adversarial robustness\",\"url\":\"https://www.semanticscholar.org/paper/da418706f2d08ce388895d7917a19a5ea30f406c\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8392935\",\"name\":\"M. Li\"},{\"authorId\":\"121720851\",\"name\":\"Yingyi Ma\"},{\"authorId\":\"49469336\",\"name\":\"Xin-hua Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b6ccd6203219915b8eee88596ea8f5526ebf772\",\"title\":\"Meta-Learning of Structured Representation by Proximal Mapping\",\"url\":\"https://www.semanticscholar.org/paper/3b6ccd6203219915b8eee88596ea8f5526ebf772\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"ING BEYOND\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fac8d2bd19f3a82f92a344d758007cff499b7725\",\"title\":\"CONFIDENCE-CALIBRATED ADVERSARIAL TRAINING and Detection: MORE ROBUST MODELS GENERALIZ-\",\"url\":\"https://www.semanticscholar.org/paper/fac8d2bd19f3a82f92a344d758007cff499b7725\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.09685\",\"authors\":[{\"authorId\":\"48479348\",\"name\":\"Yang He\"},{\"authorId\":\"1470468158\",\"name\":\"Shadi Rahimian\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/978-3-030-58592-1_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b58563fafc69c2d5886d4ab588dfab9d591b992f\",\"title\":\"Segmentations-Leak: Membership Inference Attacks and Defenses in Semantic Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b58563fafc69c2d5886d4ab588dfab9d591b992f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.09405\",\"authors\":[{\"authorId\":\"145780943\",\"name\":\"A. Elliott\"},{\"authorId\":\"145700630\",\"name\":\"Stephen Law\"},{\"authorId\":\"145485796\",\"name\":\"C. Russell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a9c99775f1acbffa3c5bd6d9cf9b13d74929144\",\"title\":\"Adversarial Perturbations on the Perceptual Ball\",\"url\":\"https://www.semanticscholar.org/paper/6a9c99775f1acbffa3c5bd6d9cf9b13d74929144\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46453234\",\"name\":\"Hongwei Jin\"},{\"authorId\":\"49469336\",\"name\":\"Xin-hua Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"89d502f4f92535f964e6552c4f9d4a8f52844884\",\"title\":\"Robust Training of Graph Convolutional Networks via Latent Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/89d502f4f92535f964e6552c4f9d4a8f52844884\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.02658\",\"authors\":[{\"authorId\":\"2463213\",\"name\":\"W. Luo\"},{\"authorId\":\"48251349\",\"name\":\"C. Wu\"},{\"authorId\":\"145094975\",\"name\":\"N. Zhou\"},{\"authorId\":\"23596449\",\"name\":\"L. Ni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83714be281b9a25271e2adad51e27ff61a2ac517\",\"title\":\"Random Directional Attack for Fooling Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/83714be281b9a25271e2adad51e27ff61a2ac517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.09461\",\"authors\":[{\"authorId\":\"49799275\",\"name\":\"Maximilian Augustin\"},{\"authorId\":\"38150565\",\"name\":\"Alexander Meinke\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":\"10.1007/978-3-030-58574-7_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a0d9b212b08abbe812649ecb8f4e54b97d52711\",\"title\":\"Adversarial Robustness on In- and Out-Distribution Improves Explainability\",\"url\":\"https://www.semanticscholar.org/paper/5a0d9b212b08abbe812649ecb8f4e54b97d52711\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145780943\",\"name\":\"A. Elliott\"},{\"authorId\":\"50086226\",\"name\":\"S. Law\"},{\"authorId\":\"145485796\",\"name\":\"C. Russell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87a47415e22b2016715769dec6680a6e9a8b7d6f\",\"title\":\"Perturbations on the Perceptual Ball.\",\"url\":\"https://www.semanticscholar.org/paper/87a47415e22b2016715769dec6680a6e9a8b7d6f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.09665\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"120805419\",\"name\":\"Mingxing Tan\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"152924487\",\"name\":\"Jiang Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":\"10.1109/cvpr42600.2020.00090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9deb882768d5e78f3dbbbdf6d24666c9793736a7\",\"title\":\"Adversarial Examples Improve Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9deb882768d5e78f3dbbbdf6d24666c9793736a7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.02494\",\"authors\":[{\"authorId\":\"145356288\",\"name\":\"Yujun Shi\"},{\"authorId\":\"102925442\",\"name\":\"B. Liao\"},{\"authorId\":\"2653181\",\"name\":\"Guangyong Chen\"},{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"674b8a44c80cd35aca14dbbba0a6b01a58438d85\",\"title\":\"Understanding Adversarial Behavior of DNNs by Disentangling Non-Robust and Robust Components in Performance Metric\",\"url\":\"https://www.semanticscholar.org/paper/674b8a44c80cd35aca14dbbba0a6b01a58438d85\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.11828\",\"authors\":[{\"authorId\":\"113727681\",\"name\":\"Haotao Wang\"},{\"authorId\":\"2648459\",\"name\":\"Tianlong Chen\"},{\"authorId\":\"3631339\",\"name\":\"Shupeng Gui\"},{\"authorId\":\"3236115\",\"name\":\"Ting-Kuei Hu\"},{\"authorId\":\"102551205\",\"name\":\"J. Liu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6218de58c9191acb49e106059fa9e3b1ecc502d9\",\"title\":\"Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness and Accuracy for Free\",\"url\":\"https://www.semanticscholar.org/paper/6218de58c9191acb49e106059fa9e3b1ecc502d9\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2005.11626\",\"authors\":[{\"authorId\":\"2208511\",\"name\":\"Kibok Lee\"},{\"authorId\":\"2240134\",\"name\":\"Zhuoyuan Chen\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"c8da73d44c448378db616e66c661f18712ba0f6c\",\"title\":\"ShapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/c8da73d44c448378db616e66c661f18712ba0f6c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.10703\",\"authors\":[{\"authorId\":\"1473184915\",\"name\":\"Xiaodong Qi\"},{\"authorId\":\"2256602\",\"name\":\"Lansheng Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0aa0e4179bc14d2011fb1a7e5785835c8cb9fef7\",\"title\":\"G\\u00f6del's Sentence Is An Adversarial Example But Unsolvable\",\"url\":\"https://www.semanticscholar.org/paper/0aa0e4179bc14d2011fb1a7e5785835c8cb9fef7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07849\",\"authors\":[{\"authorId\":\"40245480\",\"name\":\"H. Wang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"144799773\",\"name\":\"Xiaobai Liu\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/TPAMI.2020.3032061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e7bc6ea46f0ccb3c86c7795af95a33799f71883\",\"title\":\"A Hamiltonian Monte Carlo Method for Probabilistic Adversarial Attack and Learning\",\"url\":\"https://www.semanticscholar.org/paper/8e7bc6ea46f0ccb3c86c7795af95a33799f71883\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2009.02470\",\"authors\":[{\"authorId\":\"3329881\",\"name\":\"Wei-An Lin\"},{\"authorId\":\"2048281\",\"name\":\"Chun Pong Lau\"},{\"authorId\":\"39593895\",\"name\":\"A. Levine\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"34389431\",\"name\":\"S. Feizi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2e165871bdfe21fe8389087696030ac33edd7f17\",\"title\":\"Dual Manifold Adversarial Robustness: Defense against Lp and non-Lp Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/2e165871bdfe21fe8389087696030ac33edd7f17\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2003.00883\",\"authors\":[{\"authorId\":\"1515315817\",\"name\":\"Camilo Pestana\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46641911\",\"name\":\"W. Liu\"},{\"authorId\":\"47400552\",\"name\":\"David Glance\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47bbe8c5d5bb184e293129705b6a0e15e744a289\",\"title\":\"Adversarial Perturbations Prevail in the Y-Channel of the YCbCr Color Space\",\"url\":\"https://www.semanticscholar.org/paper/47bbe8c5d5bb184e293129705b6a0e15e744a289\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143785036\",\"name\":\"Liuwan Zhu\"},{\"authorId\":\"46265979\",\"name\":\"Rui Ning\"},{\"authorId\":\"50097090\",\"name\":\"C. Wang\"},{\"authorId\":\"40089292\",\"name\":\"C. Xin\"},{\"authorId\":\"1725092\",\"name\":\"Hongyi Wu\"}],\"doi\":\"10.1145/3394171.3413546\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"228e0f752acd88cadc1ac146143f8d4763d22007\",\"title\":\"GangSweep: Sweep out Neural Backdoors by GAN\",\"url\":\"https://www.semanticscholar.org/paper/228e0f752acd88cadc1ac146143f8d4763d22007\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.13216\",\"authors\":[{\"authorId\":\"35790820\",\"name\":\"F. Qiao\"},{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152343\",\"name\":\"Xi Peng\"}],\"doi\":\"10.1109/CVPR42600.2020.01257\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89b95fb53727ee45be440045efef656718517c4c\",\"title\":\"Learning to Learn Single Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/89b95fb53727ee45be440045efef656718517c4c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.12914\",\"authors\":[{\"authorId\":\"80316080\",\"name\":\"H. B. Lee\"},{\"authorId\":\"47418323\",\"name\":\"Taewook Nam\"},{\"authorId\":\"1720494\",\"name\":\"E. Yang\"},{\"authorId\":\"35788904\",\"name\":\"Sung Ju Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf5fba0919014bc740b0a72ea0fa87783f4f2f4b\",\"title\":\"Meta Dropout: Learning to Perturb Features for Generalization\",\"url\":\"https://www.semanticscholar.org/paper/cf5fba0919014bc740b0a72ea0fa87783f4f2f4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.03824\",\"authors\":[{\"authorId\":\"40138789\",\"name\":\"S. Liu\"},{\"authorId\":\"145101451\",\"name\":\"A. A. A. Setio\"},{\"authorId\":\"2562046\",\"name\":\"Florin C. Ghesu\"},{\"authorId\":\"145720674\",\"name\":\"E. Gibson\"},{\"authorId\":\"1764071\",\"name\":\"S. Grbic\"},{\"authorId\":\"1388066189\",\"name\":\"B. Georgescu\"},{\"authorId\":\"1685020\",\"name\":\"D. Comaniciu\"}],\"doi\":\"10.1109/TMI.2020.3026261\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0601f7e5cb996669c4f0295da8fcd94e456182d\",\"title\":\"No Surprises: Training Robust Lung Nodule Detection for Low-Dose CT Scans by Augmenting with Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/b0601f7e5cb996669c4f0295da8fcd94e456182d\",\"venue\":\"IEEE transactions on medical imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-030-58536-5_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f176d108578af18d209defc8ff9633942f7b794b\",\"title\":\"Towards Automated Testing and Robustification by Semantic Adversarial Data Generation\",\"url\":\"https://www.semanticscholar.org/paper/f176d108578af18d209defc8ff9633942f7b794b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.02540\",\"authors\":[{\"authorId\":\"71770366\",\"name\":\"Hyeong-ji Kim\"},{\"authorId\":\"2721172\",\"name\":\"K. Malde\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87b0893619ce33af4467217d109f13162a0dd4e5\",\"title\":\"Proper measure for adversarial robustness\",\"url\":\"https://www.semanticscholar.org/paper/87b0893619ce33af4467217d109f13162a0dd4e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117880583\",\"name\":\"David Abele\"},{\"authorId\":\"1403594377\",\"name\":\"Sara D'Onofrio\"}],\"doi\":\"10.1007/978-3-658-27941-7_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"473652d204582ab02ab8ab32a576bbabc5a82a29\",\"title\":\"Artificial Intelligence \\u2013 The Big Picture\",\"url\":\"https://www.semanticscholar.org/paper/473652d204582ab02ab8ab32a576bbabc5a82a29\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029648342\",\"name\":\"Xinshuai Dong\"},{\"authorId\":\"2802283\",\"name\":\"H. Liu\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58601-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b716dcc220d26af9e7d5b76978dc2d5b265386b\",\"title\":\"API-Net: Robust Generative Classifier via a Single Discriminator\",\"url\":\"https://www.semanticscholar.org/paper/5b716dcc220d26af9e7d5b76978dc2d5b265386b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.04871\",\"authors\":[{\"authorId\":\"153755145\",\"name\":\"L. Wang\"},{\"authorId\":\"114464327\",\"name\":\"H. Zhang\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"3310983\",\"name\":\"C. Hsieh\"},{\"authorId\":\"1390651072\",\"name\":\"Yuan Jiang\"}],\"doi\":\"10.1007/s10994-020-05916-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6380ce0df46ab95bd068e8009295fa97685d8e2\",\"title\":\"Spanning Attack: Reinforce Black-box Attacks with Unlabeled Data\",\"url\":\"https://www.semanticscholar.org/paper/c6380ce0df46ab95bd068e8009295fa97685d8e2\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":\"1909.08072\",\"authors\":[{\"authorId\":\"143794311\",\"name\":\"H. Xu\"},{\"authorId\":\"144268845\",\"name\":\"Yao Ma\"},{\"authorId\":\"66442354\",\"name\":\"Haochen Liu\"},{\"authorId\":\"9250292\",\"name\":\"D. Deb\"},{\"authorId\":\"98114925\",\"name\":\"H. Liu\"},{\"authorId\":\"1736632\",\"name\":\"Jiliang Tang\"},{\"authorId\":\"1739705\",\"name\":\"A. Jain\"}],\"doi\":\"10.1007/s11633-019-1211-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ad5f1d88534715051c6aba7436d60bdf65337e8\",\"title\":\"Adversarial Attacks and Defenses in Images, Graphs and Text: A Review\",\"url\":\"https://www.semanticscholar.org/paper/6ad5f1d88534715051c6aba7436d60bdf65337e8\",\"venue\":\"Int. J. Autom. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80316080\",\"name\":\"H. B. Lee\"},{\"authorId\":\"47418323\",\"name\":\"Taewook Nam\"},{\"authorId\":\"1720494\",\"name\":\"E. Yang\"},{\"authorId\":\"35788904\",\"name\":\"Sung Ju Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1518d8af2eca9829093bcbb6f71fb4afcfd4e2ba\",\"title\":\"Meta Dropout: Learning to Perturb Latent Features for Generalization\",\"url\":\"https://www.semanticscholar.org/paper/1518d8af2eca9829093bcbb6f71fb4afcfd4e2ba\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2004.13344\",\"authors\":[{\"authorId\":\"1486303443\",\"name\":\"Shufei Zhang\"},{\"authorId\":\"11229948\",\"name\":\"Zhuang Qian\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"},{\"authorId\":\"2825865\",\"name\":\"J. Xiao\"},{\"authorId\":\"143605211\",\"name\":\"Yuan He\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1c57e9807835eba3d6b7991e8b371e9df5ec77\",\"title\":\"Robust Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/9f1c57e9807835eba3d6b7991e8b371e9df5ec77\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.02313\",\"authors\":[{\"authorId\":\"40897453\",\"name\":\"Sukrut Rao\"},{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"5b7d8bee7f666326925f0933ca5a52b16ba1ff8f\",\"title\":\"Adversarial Training against Location-Optimized Adversarial Patches\",\"url\":\"https://www.semanticscholar.org/paper/5b7d8bee7f666326925f0933ca5a52b16ba1ff8f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.04935\",\"authors\":[{\"authorId\":\"1741114742\",\"name\":\"Maryna Karpusha\"},{\"authorId\":\"66863417\",\"name\":\"Sunghee Yun\"},{\"authorId\":\"1728063\",\"name\":\"Istv\\u00e1n Feh\\u00e9rv\\u00e1ri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eed22f2734c6d42748c990b92d342b78437d1c44\",\"title\":\"Calibrated neighborhood aware confidence measure for deep metric learning\",\"url\":\"https://www.semanticscholar.org/paper/eed22f2734c6d42748c990b92d342b78437d1c44\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.05720\",\"authors\":[{\"authorId\":\"143610806\",\"name\":\"M. Hein\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"},{\"authorId\":\"52215534\",\"name\":\"Julian Bitterwolf\"}],\"doi\":\"10.1109/CVPR.2019.00013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a25b63a6a0071d7d88ff4671c1fd40f320a08533\",\"title\":\"Why ReLU Networks Yield High-Confidence Predictions Far Away From the Training Data and How to Mitigate the Problem\",\"url\":\"https://www.semanticscholar.org/paper/a25b63a6a0071d7d88ff4671c1fd40f320a08533\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.14352\",\"authors\":[{\"authorId\":\"66307436\",\"name\":\"J. Vadillo\"},{\"authorId\":\"145585784\",\"name\":\"Roberto Santana\"},{\"authorId\":\"144762651\",\"name\":\"J. Lozano\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"602a63984481ca60ddd392bca3f296275cd536c5\",\"title\":\"Analysis of Dominant Classes in Universal Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/602a63984481ca60ddd392bca3f296275cd536c5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.11122\",\"authors\":[{\"authorId\":\"3380463\",\"name\":\"Alessandro Tibo\"},{\"authorId\":\"94378548\",\"name\":\"M. Jaeger\"},{\"authorId\":\"50130104\",\"name\":\"Kim G. Larsen\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"c0b46a3fb8cfb7d4fa2db169dfc4d92a059b83ec\",\"title\":\"A general framework for defining and optimizing robustness\",\"url\":\"https://www.semanticscholar.org/paper/c0b46a3fb8cfb7d4fa2db169dfc4d92a059b83ec\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46453234\",\"name\":\"Hongwei Jin\"},{\"authorId\":\"46448625\",\"name\":\"Xinhua Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"837d221b5e5c612e3667174b65c81fa1239247b7\",\"title\":\"Latent Adversarial Training of Graph Convolution Networks\",\"url\":\"https://www.semanticscholar.org/paper/837d221b5e5c612e3667174b65c81fa1239247b7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.06259\",\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"604dc3c7ad3736e58d7fd8a5839f8d8ba63e63b6\",\"title\":\"Confidence-Calibrated Adversarial Training: Generalizing to Unseen Attacks\",\"url\":\"https://www.semanticscholar.org/paper/604dc3c7ad3736e58d7fd8a5839f8d8ba63e63b6\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2006.13977\",\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"2916636\",\"name\":\"N. Chandramoorthy\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf4d01f6db964cf9101702a32ca8db1b9b2b06d0\",\"title\":\"Bit Error Robustness for Energy-Efficient DNN Accelerators\",\"url\":\"https://www.semanticscholar.org/paper/cf4d01f6db964cf9101702a32ca8db1b9b2b06d0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"2916636\",\"name\":\"N. Chandramoorthy\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"a1db46169a8c6ab333ae36d1223c70cc7a1490b3\",\"title\":\"On Mitigating Random and Adversarial Bit Errors\",\"url\":\"https://www.semanticscholar.org/paper/a1db46169a8c6ab333ae36d1223c70cc7a1490b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02beef8baeb674c764071cd60da86c4a03f1fa78\",\"title\":\"CONFIDENCE-CALIBRATED ADVERSARIAL TRAINING\",\"url\":\"https://www.semanticscholar.org/paper/02beef8baeb674c764071cd60da86c4a03f1fa78\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.04725\",\"authors\":[{\"authorId\":\"144871753\",\"name\":\"L. Chen\"},{\"authorId\":\"51270420\",\"name\":\"Y. Min\"},{\"authorId\":\"50495516\",\"name\":\"Mingrui Zhang\"},{\"authorId\":\"1697131\",\"name\":\"Amin Karbasi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f31fdc30a24f2f50ade1b4786dedec5c79774668\",\"title\":\"More Data Can Expand the Generalization Gap Between Adversarially Robust and Standard Models\",\"url\":\"https://www.semanticscholar.org/paper/f31fdc30a24f2f50ade1b4786dedec5c79774668\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2004.08994\",\"authors\":[{\"authorId\":\"2687150\",\"name\":\"X. Liu\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"50462546\",\"name\":\"Pengcheng He\"},{\"authorId\":\"47482448\",\"name\":\"W. Chen\"},{\"authorId\":\"72682749\",\"name\":\"Yu Wang\"},{\"authorId\":\"1759772\",\"name\":\"Hoifung Poon\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ffcf8352223c95ae8cef4daaec995525ecc926b\",\"title\":\"Adversarial Training for Large Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2ffcf8352223c95ae8cef4daaec995525ecc926b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cc267b9e3ed940e5eb53951f527f964038b6506\",\"title\":\"Confidence-Calibrated Adversarial Training: Towards Robust Models Generalizing Beyond the Attack Used During Training\",\"url\":\"https://www.semanticscholar.org/paper/1cc267b9e3ed940e5eb53951f527f964038b6506\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.11486\",\"authors\":[{\"authorId\":\"2281855\",\"name\":\"L. Darlow\"},{\"authorId\":null,\"name\":\"Stanislaw Jastrzebski\"},{\"authorId\":\"1728216\",\"name\":\"A. Storkey\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c540cc769ea14ad3f844ee28542949fec03cc143\",\"title\":\"Latent Adversarial Debiasing: Mitigating Collider Bias in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c540cc769ea14ad3f844ee28542949fec03cc143\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.11626\",\"authors\":[{\"authorId\":\"3332270\",\"name\":\"Beomsu Kim\"},{\"authorId\":\"11027268\",\"name\":\"Junghoon Seo\"},{\"authorId\":\"48629004\",\"name\":\"Taegyun Jeon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0af9d2ce78e873a17e8fa5a6dcc3a790e227a9e1\",\"title\":\"Bridging Adversarial Robustness and Gradient Interpretability\",\"url\":\"https://www.semanticscholar.org/paper/0af9d2ce78e873a17e8fa5a6dcc3a790e227a9e1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.01855\",\"authors\":[{\"authorId\":\"145735687\",\"name\":\"Ehsan Kazemi\"},{\"authorId\":\"40900821\",\"name\":\"T. Kerdreux\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"59e6200bf81fc7765c83b2809d49f99f4e66d3b4\",\"title\":\"Trace-Norm Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/59e6200bf81fc7765c83b2809d49f99f4e66d3b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02896\",\"authors\":[{\"authorId\":\"86941640\",\"name\":\"W. Woods\"},{\"authorId\":\"50763007\",\"name\":\"J. Chen\"},{\"authorId\":\"48486159\",\"name\":\"C. Teuscher\"}],\"doi\":\"10.1038/s42256-019-0104-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79f2371557f6cd8e69e3b9cde873bf36981424c5\",\"title\":\"Adversarial Explanations for Understanding Image Classification Decisions and Improved Neural Network Robustness\",\"url\":\"https://www.semanticscholar.org/paper/79f2371557f6cd8e69e3b9cde873bf36981424c5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1902.00577\",\"authors\":[{\"authorId\":\"3467930\",\"name\":\"S. Saralajew\"},{\"authorId\":\"52221725\",\"name\":\"Lars Holdijk\"},{\"authorId\":\"52219028\",\"name\":\"Maike Rees\"},{\"authorId\":\"9320960\",\"name\":\"T. Villmann\"}],\"doi\":\"10.1007/978-3-030-19642-4_19\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"b822f0c524a717e332793ebe7686af28d4f0d371\",\"title\":\"Robustness of Generalized Learning Vector Quantization Models against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/b822f0c524a717e332793ebe7686af28d4f0d371\",\"venue\":\"WSOM+\",\"year\":2019},{\"arxivId\":\"1905.02175\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"78730080\",\"name\":\"B. Tran\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":\"10.23915/DISTILL.00019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd\",\"title\":\"Adversarial Examples Are Not Bugs, They Are Features\",\"url\":\"https://www.semanticscholar.org/paper/1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2005.10190\",\"authors\":[{\"authorId\":\"1388725932\",\"name\":\"Zeyuan Allen-Zhu\"},{\"authorId\":\"2205248\",\"name\":\"Y. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a73dcfe62f33ae595efd5d20658c915af995acc9\",\"title\":\"Feature Purification: How Adversarial Training Performs Robust Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a73dcfe62f33ae595efd5d20658c915af995acc9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48128472\",\"name\":\"J. Zhou\"},{\"authorId\":\"143869239\",\"name\":\"Chao Liang\"},{\"authorId\":\"47740797\",\"name\":\"J. Chen\"}],\"doi\":\"10.1007/978-3-030-58577-8_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"078ac3d05afb953585ae17e914c6b4d0571f6421\",\"title\":\"Manifold Projection for Adversarial Defense on Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/078ac3d05afb953585ae17e914c6b4d0571f6421\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11506\",\"authors\":[{\"authorId\":\"2865034\",\"name\":\"Lingkai Kong\"},{\"authorId\":\"5795999\",\"name\":\"Haoming Jiang\"},{\"authorId\":\"8103389\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"23119946\",\"name\":\"J. Lyu\"},{\"authorId\":\"36345161\",\"name\":\"Tuo Zhao\"},{\"authorId\":\"145657505\",\"name\":\"C. Zhang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.102\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05ef3566499e24888a8c500944336616f8f418a4\",\"title\":\"Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution Data\",\"url\":\"https://www.semanticscholar.org/paper/05ef3566499e24888a8c500944336616f8f418a4\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1812.09010\",\"authors\":[{\"authorId\":\"3387470\",\"name\":\"Klemen Grm\"},{\"authorId\":\"115771744\",\"name\":\"Martin Pernus\"},{\"authorId\":\"114864059\",\"name\":\"Leo Cluzel\"},{\"authorId\":\"2613438\",\"name\":\"W. Scheirer\"},{\"authorId\":\"1704880\",\"name\":\"S. Dobrisek\"},{\"authorId\":\"2011218\",\"name\":\"V. \\u0160truc\"}],\"doi\":\"10.1109/CVPRW.2019.00295\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4ef6edfc233bf6a47e44de5a570462e9bdecc2f5\",\"title\":\"Face Hallucination Revisited: An Exploratory Study on Dataset Bias\",\"url\":\"https://www.semanticscholar.org/paper/4ef6edfc233bf6a47e44de5a570462e9bdecc2f5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2011.02675\",\"authors\":[{\"authorId\":\"1515315817\",\"name\":\"Camilo Pestana\"},{\"authorId\":\"40584023\",\"name\":\"Wei Liu\"},{\"authorId\":\"47400552\",\"name\":\"David Glance\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7702d9175917fe27884a471d08803755a5d2c55c\",\"title\":\"Defense-friendly Images in Adversarial Attacks: Dataset and Metrics for Perturbation Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/7702d9175917fe27884a471d08803755a5d2c55c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03680\",\"authors\":[{\"authorId\":\"3396987\",\"name\":\"Sharon Zhou\"},{\"authorId\":\"49456763\",\"name\":\"Eric Zelikman\"},{\"authorId\":\"36206455\",\"name\":\"F. Lu\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"928abdc0b6a2b5bc274f20228c7f74728263996f\",\"title\":\"Evaluating the Disentanglement of Deep Generative Models through Manifold Topology\",\"url\":\"https://www.semanticscholar.org/paper/928abdc0b6a2b5bc274f20228c7f74728263996f\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":54439061,\"doi\":\"10.1109/CVPR.2019.00714\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8bcd98bd5a451c2bbde4a22a4d1affe3c6407af0\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"30137838\",\"name\":\"M. Augustin\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-030-28954-6_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8b9fa6f9e0b606ff335a0557a838dea2696b084\",\"title\":\"Towards Reverse-Engineering Black-Box Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e8b9fa6f9e0b606ff335a0557a838dea2696b084\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1512.09300\",\"authors\":[{\"authorId\":\"46560485\",\"name\":\"Anders Boesen Lindbo Larsen\"},{\"authorId\":\"1388358166\",\"name\":\"S\\u00f8ren Kaae S\\u00f8nderby\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1724252\",\"name\":\"O. Winther\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e8b8a7778ace2a02f8db6fe321a54520c6b283ca\",\"title\":\"Autoencoding beyond pixels using a learned similarity metric\",\"url\":\"https://www.semanticscholar.org/paper/e8b8a7778ace2a02f8db6fe321a54520c6b283ca\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1607.04311\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"975b6ec05f04662a967af8c7504b7f552a0ee0bd\",\"title\":\"Defensive Distillation is Not Robust to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/975b6ec05f04662a967af8c7504b7f552a0ee0bd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1610.05820\",\"authors\":[{\"authorId\":\"2520493\",\"name\":\"R. Shokri\"},{\"authorId\":\"34828439\",\"name\":\"Marco Stronati\"},{\"authorId\":\"3469125\",\"name\":\"Congzheng Song\"},{\"authorId\":\"1723945\",\"name\":\"Vitaly Shmatikov\"}],\"doi\":\"10.1109/SP.2017.41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d\",\"title\":\"Membership Inference Attacks Against Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1702.02284\",\"authors\":[{\"authorId\":\"2064588\",\"name\":\"Sandy H. Huang\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8c16a56d2a9520197da9a1546f517db5f19b204\",\"title\":\"Adversarial Attacks on Neural Network Policies\",\"url\":\"https://www.semanticscholar.org/paper/c8c16a56d2a9520197da9a1546f517db5f19b204\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1708.01697\",\"authors\":[{\"authorId\":\"2974221\",\"name\":\"Andras Rozsa\"},{\"authorId\":\"38636666\",\"name\":\"M. G\\u00fcnther\"},{\"authorId\":\"32163276\",\"name\":\"T. Boult\"}],\"doi\":\"10.5244/C.31.156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"853272e90e9b9c05eaa60fbb02fad4f2a83f031a\",\"title\":\"Adversarial Robustness: Softmax versus Openmax\",\"url\":\"https://www.semanticscholar.org/paper/853272e90e9b9c05eaa60fbb02fad4f2a83f031a\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1804.07729\",\"authors\":[{\"authorId\":\"3040023\",\"name\":\"Rima Alaifari\"},{\"authorId\":\"32833939\",\"name\":\"Giovanni S. Alberti\"},{\"authorId\":\"41016193\",\"name\":\"Tandri Gauksson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ecda636a99ec93acc941c0217a65c9a3af9562f\",\"title\":\"ADef: an Iterative Algorithm to Construct Adversarial Deformations\",\"url\":\"https://www.semanticscholar.org/paper/3ecda636a99ec93acc941c0217a65c9a3af9562f\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1611.01331\",\"authors\":[{\"authorId\":\"7200137\",\"name\":\"Leon Sixt\"},{\"authorId\":\"35091806\",\"name\":\"Benjamin Wild\"},{\"authorId\":\"1748047\",\"name\":\"Tim Landgraf\"}],\"doi\":\"10.3389/frobt.2018.00066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a2c82a5d46822e1c9a6c05cb93d3fc7b927bed1\",\"title\":\"RenderGAN: Generating Realistic Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/6a2c82a5d46822e1c9a6c05cb93d3fc7b927bed1\",\"venue\":\"Front. Robot. AI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":\"1511.05432\",\"authors\":[{\"authorId\":\"1762788\",\"name\":\"Uri Shaham\"},{\"authorId\":\"23552524\",\"name\":\"Yutaro Yamada\"},{\"authorId\":\"145537739\",\"name\":\"Sahand N. Negahban\"}],\"doi\":\"10.1016/j.neucom.2018.04.027\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"24529bffa95f07c01ccf6f02eb4dc9d859430159\",\"title\":\"Understanding adversarial training: Increasing local stability of supervised models through robust optimization\",\"url\":\"https://www.semanticscholar.org/paper/24529bffa95f07c01ccf6f02eb4dc9d859430159\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1710.08864\",\"authors\":[{\"authorId\":\"1730754\",\"name\":\"Jiawei Su\"},{\"authorId\":\"145197293\",\"name\":\"Danilo Vasconcellos Vargas\"},{\"authorId\":\"145106127\",\"name\":\"K. Sakurai\"}],\"doi\":\"10.1109/TEVC.2019.2890858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"title\":\"One Pixel Attack for Fooling Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019},{\"arxivId\":\"1704.01547\",\"authors\":[{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb0ef63e7886c1f3da8174a81df256cebc133f6\",\"title\":\"Comment on \\\"Biologically inspired protection of deep networks from adversarial attacks\\\"\",\"url\":\"https://www.semanticscholar.org/paper/0eb0ef63e7886c1f3da8174a81df256cebc133f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1710.10766\",\"authors\":[{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"3307885\",\"name\":\"Taesup Kim\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"1684887\",\"name\":\"Nate Kushman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"title\":\"PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1706.04701\",\"authors\":[{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"145604979\",\"name\":\"J. Wei\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"title\":\"Adversarial Example Defense: Ensembles of Weak Defenses are not Strong\",\"url\":\"https://www.semanticscholar.org/paper/6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"venue\":\"WOOT\",\"year\":2017},{\"arxivId\":\"1411.7766\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/ICCV.2015.425\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4\",\"title\":\"Deep Learning Face Attributes in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1709.01643\",\"authors\":[{\"authorId\":\"50003118\",\"name\":\"Alexander J. Ratner\"},{\"authorId\":\"33918804\",\"name\":\"Henry R. Ehrenberg\"},{\"authorId\":\"8815003\",\"name\":\"Zeshan Hussain\"},{\"authorId\":\"12322385\",\"name\":\"Jared A Dunnmon\"},{\"authorId\":\"144988097\",\"name\":\"C. R\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ae265be8ccf396115ef06405f3b8421851998a9\",\"title\":\"Learning to Compose Domain-Specific Transformations for Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/1ae265be8ccf396115ef06405f3b8421851998a9\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2701535\",\"name\":\"Nina Narodytska\"},{\"authorId\":\"7993151\",\"name\":\"S. Kasiviswanathan\"}],\"doi\":\"10.1109/CVPRW.2017.172\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f174af2842fcd9878d460007d476482b1b1c8579\",\"title\":\"Simple Black-Box Adversarial Attacks on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f174af2842fcd9878d460007d476482b1b1c8579\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1801.02774\",\"authors\":[{\"authorId\":\"2058362\",\"name\":\"J. Gilmer\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"2601641\",\"name\":\"S. Schoenholz\"},{\"authorId\":\"40297238\",\"name\":\"M. Raghu\"},{\"authorId\":\"145233583\",\"name\":\"M. Wattenberg\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e77171024bf7dc2ff33db89710f1184543c694e5\",\"title\":\"Adversarial Spheres\",\"url\":\"https://www.semanticscholar.org/paper/e77171024bf7dc2ff33db89710f1184543c694e5\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1804.07998\",\"authors\":[{\"authorId\":\"3030212\",\"name\":\"Moustafa Alzantot\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"143718836\",\"name\":\"Ahmed Elgohary\"},{\"authorId\":\"33386728\",\"name\":\"Bo-Jhang Ho\"},{\"authorId\":\"1702254\",\"name\":\"M. Srivastava\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":\"10.18653/v1/D18-1316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c68fbc1f4aa72d30974f8a3071054e3b227137fd\",\"title\":\"Generating Natural Language Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/c68fbc1f4aa72d30974f8a3071054e3b227137fd\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00957\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e37a3b227b68953f8067215828dc8b8714cb21b\",\"title\":\"Boosting Adversarial Attacks with Momentum\",\"url\":\"https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1710.11342\",\"authors\":[{\"authorId\":\"2708739\",\"name\":\"Zhengli Zhao\"},{\"authorId\":\"33546336\",\"name\":\"Dheeru Dua\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3502b5ef1afb16f76bcae33db17179195bbcdaae\",\"title\":\"Generating Natural Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/3502b5ef1afb16f76bcae33db17179195bbcdaae\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1703.01101\",\"authors\":[{\"authorId\":\"47092548\",\"name\":\"Volker Fischer\"},{\"authorId\":\"34996529\",\"name\":\"Mummadi Chaithanya Kumar\"},{\"authorId\":\"2708564\",\"name\":\"J. H. Metzen\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c4454aa7a2a244c678f507a982fe8827ba419bb\",\"title\":\"Adversarial Examples for Semantic Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/4c4454aa7a2a244c678f507a982fe8827ba419bb\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1703.09202\",\"authors\":[{\"authorId\":\"40637388\",\"name\":\"Aran Nayebi\"},{\"authorId\":\"25769960\",\"name\":\"S. Ganguli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"600a5d60cb96eda2a9849413e747547d70dfb00a\",\"title\":\"Biologically inspired protection of deep networks from adversarial attacks\",\"url\":\"https://www.semanticscholar.org/paper/600a5d60cb96eda2a9849413e747547d70dfb00a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andras Rozsa\"},{\"authorId\":null,\"name\":\"Manuel G\\u00fcnther\"},{\"authorId\":null,\"name\":\"E Terrance\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Boult . Adversarial robustness : Softmax versus openmax\",\"url\":\"\",\"venue\":\"In BMVC\",\"year\":null},{\"arxivId\":\"1611.02770\",\"authors\":[{\"authorId\":\"1887192\",\"name\":\"Y. Liu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"title\":\"Delving into Transferable Adversarial Examples and Black-box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2635549\",\"name\":\"A. Sinha\"},{\"authorId\":\"40281109\",\"name\":\"Hongseok Namkoong\"},{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"818c52f4ba56cb8cf152ad614f2f4803057a5cfe\",\"title\":\"Certifying Some Distributional Robustness with Principled Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/818c52f4ba56cb8cf152ad614f2f4803057a5cfe\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1608.07690\",\"authors\":[{\"authorId\":\"3451382\",\"name\":\"T. Tanay\"},{\"authorId\":\"1682458\",\"name\":\"Lewis D. Griffin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d9d79bcf26ebfebaf48ba83ebdb2f5d9fd95c222\",\"title\":\"A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/d9d79bcf26ebfebaf48ba83ebdb2f5d9fd95c222\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1711.09404\",\"authors\":[{\"authorId\":\"50683297\",\"name\":\"A. Ross\"},{\"authorId\":\"1388372395\",\"name\":\"Finale Doshi-Velez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"title\":\"Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients\",\"url\":\"https://www.semanticscholar.org/paper/ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1703.00410\",\"authors\":[{\"authorId\":\"40285565\",\"name\":\"Reuben Feinman\"},{\"authorId\":\"34658148\",\"name\":\"Ryan R. Curtin\"},{\"authorId\":\"9371478\",\"name\":\"S. Shintre\"},{\"authorId\":\"39283183\",\"name\":\"Andrew B. Gardner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"405b6ff2ea2ec9a7c7d6b18ac951dc778892ffcf\",\"title\":\"Detecting Adversarial Samples from Artifacts\",\"url\":\"https://www.semanticscholar.org/paper/405b6ff2ea2ec9a7c7d6b18ac951dc778892ffcf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1805.09190\",\"authors\":[{\"authorId\":\"36873987\",\"name\":\"Lukas Schott\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd7789de401811fd8692466b8d49230e7184655f\",\"title\":\"Towards the first adversarially robust neural network model on MNIST\",\"url\":\"https://www.semanticscholar.org/paper/fd7789de401811fd8692466b8d49230e7184655f\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1712.00673\",\"authors\":[{\"authorId\":\"23979212\",\"name\":\"Xuanqing Liu\"},{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1007/978-3-030-01234-2_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cf361d02f5ad84567e48754f1a8f895653bc701\",\"title\":\"Towards Robust Neural Networks via Random Self-ensemble\",\"url\":\"https://www.semanticscholar.org/paper/1cf361d02f5ad84567e48754f1a8f895653bc701\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.08598\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"32815692\",\"name\":\"Jessy Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"title\":\"Black-box Adversarial Attacks with Limited Queries and Information\",\"url\":\"https://www.semanticscholar.org/paper/b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Rosca\"},{\"authorId\":null,\"name\":\"B. Lakshminarayanan\"},{\"authorId\":null,\"name\":\"D. Warde-Farley\"},{\"authorId\":null,\"name\":\"S. Mohamed\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Variational approaches for autoencoding generative adversarial\",\"url\":\"\",\"venue\":\"networks. arXiv.org,\",\"year\":2017},{\"arxivId\":\"1707.01159\",\"authors\":[{\"authorId\":\"40599829\",\"name\":\"Sayantan Sarkar\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"3152615\",\"name\":\"U. Mahbub\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"defdab5b6a3ca1ac1d2bfa472c5a1cd69fc84d68\",\"title\":\"UPSET and ANGRI : Breaking High Performance Image Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/defdab5b6a3ca1ac1d2bfa472c5a1cd69fc84d68\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1801.02612\",\"authors\":[{\"authorId\":\"2723309\",\"name\":\"Chaowei Xiao\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"39037167\",\"name\":\"M. Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3c071dbbb4520ed5875f7e064a9da87240534db\",\"title\":\"Spatially Transformed Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/d3c071dbbb4520ed5875f7e064a9da87240534db\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":\"1511.07528\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"2623167\",\"name\":\"Matt Fredrikson\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/EuroSP.2016.36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"819167ace2f0caae7745d2f25a803979be5fbfae\",\"title\":\"The Limitations of Deep Learning in Adversarial Settings\",\"url\":\"https://www.semanticscholar.org/paper/819167ace2f0caae7745d2f25a803979be5fbfae\",\"venue\":\"2016 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":\"1507.00677\",\"authors\":[{\"authorId\":\"3213400\",\"name\":\"Takeru Miyato\"},{\"authorId\":\"35647224\",\"name\":\"S. Maeda\"},{\"authorId\":\"2877296\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"1966945\",\"name\":\"Ken Nakae\"},{\"authorId\":\"145516720\",\"name\":\"S. Ishii\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d450b0f12ae0437048e4047a630c31d902002d0c\",\"title\":\"Distributional Smoothing with Virtual Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/d450b0f12ae0437048e4047a630c31d902002d0c\",\"venue\":\"ICLR 2016\",\"year\":2015},{\"arxivId\":\"1704.03976\",\"authors\":[{\"authorId\":\"3213400\",\"name\":\"Takeru Miyato\"},{\"authorId\":\"35647224\",\"name\":\"S. Maeda\"},{\"authorId\":\"2877296\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"145516720\",\"name\":\"S. Ishii\"}],\"doi\":\"10.1109/TPAMI.2018.2858821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b1c6f6521da545892f3f5dc39461584d4a27ec0\",\"title\":\"Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/4b1c6f6521da545892f3f5dc39461584d4a27ec0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"1756353\",\"name\":\"Horst Samulowitz\"},{\"authorId\":\"1727257\",\"name\":\"D. Turaga\"},{\"authorId\":\"1703189\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/ICIP.2016.7533048\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c652d2ace44dfb006505ae68aa4c2299fca86236\",\"title\":\"Adaptive data augmentation for image classification\",\"url\":\"https://www.semanticscholar.org/paper/c652d2ace44dfb006505ae68aa4c2299fca86236\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1801.04693\",\"authors\":[{\"authorId\":\"145607083\",\"name\":\"B. Luo\"},{\"authorId\":\"2146767\",\"name\":\"Y. Liu\"},{\"authorId\":\"2337781\",\"name\":\"Lingxiao Wei\"},{\"authorId\":\"144239164\",\"name\":\"Q. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"516afc7d5a427f0b53ca459fe2624a1aae2ee00d\",\"title\":\"Towards Imperceptible and Robust Adversarial Example Attacks against Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/516afc7d5a427f0b53ca459fe2624a1aae2ee00d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"2727584\",\"name\":\"Y. Adi\"},{\"authorId\":\"2759569\",\"name\":\"N. Neverova\"},{\"authorId\":\"1771345\",\"name\":\"Joseph Keshet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3837f81524286ed5f9142d245743733766aa4017\",\"title\":\"Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/3837f81524286ed5f9142d245743733766aa4017\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1803.00940\",\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":\"33072734\",\"name\":\"N. Moran\"},{\"authorId\":\"50304331\",\"name\":\"Solomon Garber\"},{\"authorId\":\"39432646\",\"name\":\"Antonella DiLillo\"},{\"authorId\":\"1770857\",\"name\":\"J. Storer\"}],\"doi\":\"10.1109/DCC.2018.00022\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"804763091199e262179ae50ae7e6f88e5522f123\",\"title\":\"Protecting JPEG Images Against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/804763091199e262179ae50ae7e6f88e5522f123\",\"venue\":\"2018 Data Compression Conference\",\"year\":2018},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1511.03034\",\"authors\":[{\"authorId\":\"2136577\",\"name\":\"Ruitong Huang\"},{\"authorId\":\"48310008\",\"name\":\"B. Xu\"},{\"authorId\":\"1714772\",\"name\":\"Dale Schuurmans\"},{\"authorId\":\"40868287\",\"name\":\"Csaba Szepesvari\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d87422549a4e7596c6b6b59458d1a52f69d9fa33\",\"title\":\"Learning with a Strong Adversary\",\"url\":\"https://www.semanticscholar.org/paper/d87422549a4e7596c6b6b59458d1a52f69d9fa33\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1804.11285\",\"authors\":[{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"35210462\",\"name\":\"Kunal Talwar\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"804fb9542f4f56e264dd2df57c255a9a2011c00f\",\"title\":\"Adversarially Robust Generalization Requires More Data\",\"url\":\"https://www.semanticscholar.org/paper/804fb9542f4f56e264dd2df57c255a9a2011c00f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1608.08967\",\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"637c25f7e8f37226f829cd9264d4eeea50f75e7b\",\"title\":\"Robustness of classifiers: from adversarial to random noise\",\"url\":\"https://www.semanticscholar.org/paper/637c25f7e8f37226f829cd9264d4eeea50f75e7b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1712.09196\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"2021902\",\"name\":\"A. Jalal\"},{\"authorId\":\"32222530\",\"name\":\"Eirini Asteri\"},{\"authorId\":\"3806712\",\"name\":\"C. Daskalakis\"},{\"authorId\":\"1718469\",\"name\":\"A. Dimakis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2d015c62f258eaad5b578a3d9bef762e7943ec47\",\"title\":\"The Robust Manifold Defense: Adversarial Training using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/2d015c62f258eaad5b578a3d9bef762e7943ec47\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1805.09501\",\"authors\":[{\"authorId\":\"8132903\",\"name\":\"E. Cubuk\"},{\"authorId\":\"2368067\",\"name\":\"Barret Zoph\"},{\"authorId\":\"30415265\",\"name\":\"Dandelion Man\\u00e9\"},{\"authorId\":\"38062095\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f723eb3e7159f07b97464c8d947d15e78612abe4\",\"title\":\"AutoAugment: Learning Augmentation Policies from Data\",\"url\":\"https://www.semanticscholar.org/paper/f723eb3e7159f07b97464c8d947d15e78612abe4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1802.05351\",\"authors\":[{\"authorId\":\"1789625\",\"name\":\"Binghui Wang\"},{\"authorId\":\"144516687\",\"name\":\"N. Gong\"}],\"doi\":\"10.1109/SP.2018.00038\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f5476c9629f8093e8ba8c6a41868415c6a7f2f1\",\"title\":\"Stealing Hyperparameters in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/0f5476c9629f8093e8ba8c6a41868415c6a7f2f1\",\"venue\":\"2018 IEEE Symposium on Security and Privacy (SP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":\"10.1145/3243734.3264418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"570cd3a4f2353c7391410d567a1615b7284d412d\",\"title\":\"Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/570cd3a4f2353c7391410d567a1615b7284d412d\",\"venue\":\"CCS\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10754103\",\"name\":\"A. Bhagoji\"},{\"authorId\":\"3007016\",\"name\":\"Daniel Cullina\"},{\"authorId\":\"143615345\",\"name\":\"P. Mittal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10bd926253cbf5829ee92e927127641b69546e65\",\"title\":\"Dimensionality Reduction as a Defense against Evasion Attacks on Machine Learning Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/10bd926253cbf5829ee92e927127641b69546e65\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1702.05373\",\"authors\":[{\"authorId\":\"145334576\",\"name\":\"G. Cohen\"},{\"authorId\":\"143876162\",\"name\":\"S. Afshar\"},{\"authorId\":\"145380118\",\"name\":\"J. Tapson\"},{\"authorId\":\"1738347\",\"name\":\"A. Schaik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c2a9f6c7721d3f39ed13be8ef1bb80670ed2282\",\"title\":\"EMNIST: an extension of MNIST to handwritten letters\",\"url\":\"https://www.semanticscholar.org/paper/8c2a9f6c7721d3f39ed13be8ef1bb80670ed2282\",\"venue\":\"CVPR 2017\",\"year\":2017},{\"arxivId\":\"1705.08475\",\"authors\":[{\"authorId\":\"143610806\",\"name\":\"M. Hein\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"title\":\"Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andras Rozsa\"},{\"authorId\":null,\"name\":\"Manuel G\\u00fcnther\"},{\"authorId\":null,\"name\":\"E Terrance\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Boult . Are accuracy and robustness correlated\",\"url\":\"\",\"venue\":\"In ICMLA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Stutz\"},{\"authorId\":null,\"name\":\"M. Hein\"},{\"authorId\":null,\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Disentangling adversarial robustness and generalization\",\"url\":\"\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1702.06832\",\"authors\":[{\"authorId\":\"36426383\",\"name\":\"J. Kos\"},{\"authorId\":\"144358712\",\"name\":\"I. Fischer\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/SPW.2018.00014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e5d0c73eb29e3da8d6d3a0c8560b23680122bb2\",\"title\":\"Adversarial Examples for Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/8e5d0c73eb29e3da8d6d3a0c8560b23680122bb2\",\"venue\":\"2018 IEEE Security and Privacy Workshops (SPW)\",\"year\":2018},{\"arxivId\":\"1609.02943\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"47191084\",\"name\":\"F. Zhang\"},{\"authorId\":\"1687161\",\"name\":\"A. Juels\"},{\"authorId\":\"1746214\",\"name\":\"M. Reiter\"},{\"authorId\":\"1707461\",\"name\":\"T. Ristenpart\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d15b21bdd117877c2d0e865b17d6a336737aea99\",\"title\":\"Stealing Machine Learning Models via Prediction APIs\",\"url\":\"https://www.semanticscholar.org/paper/d15b21bdd117877c2d0e865b17d6a336737aea99\",\"venue\":\"USENIX Security Symposium\",\"year\":2016},{\"arxivId\":\"1706.03922\",\"authors\":[{\"authorId\":\"46395288\",\"name\":\"Yizhen Wang\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"38120884\",\"name\":\"K. Chaudhuri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"299a6815b8bb46355f8b8194b5705e62d753aed1\",\"title\":\"Analyzing the Robustness of Nearest Neighbors to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/299a6815b8bb46355f8b8194b5705e62d753aed1\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1708.07747\",\"authors\":[{\"authorId\":\"145642373\",\"name\":\"H. Xiao\"},{\"authorId\":\"4565995\",\"name\":\"K. Rasul\"},{\"authorId\":\"2742129\",\"name\":\"Roland Vollgraf\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\"title\":\"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1802.01421\",\"authors\":[{\"authorId\":\"1405241841\",\"name\":\"Carl-Johann Simon-Gabriel\"},{\"authorId\":\"1734570\",\"name\":\"Y. Ollivier\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1401804750\",\"name\":\"David Lopez-Paz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"57a1b24ae34abce49f319809009f65f1642fa16a\",\"title\":\"Adversarial Vulnerability of Neural Networks Increases With Input Dimension\",\"url\":\"https://www.semanticscholar.org/paper/57a1b24ae34abce49f319809009f65f1642fa16a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1801.02613\",\"authors\":[{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":null,\"name\":\"Yisen Wang\"},{\"authorId\":\"144757691\",\"name\":\"S. Erfani\"},{\"authorId\":\"2825361\",\"name\":\"S. Wijewickrema\"},{\"authorId\":\"4480560\",\"name\":\"M. E. Houle\"},{\"authorId\":\"1710013\",\"name\":\"Grant Schoenebeck\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a18ada04d93981178234d9c8907fb99ea92fddcb\",\"title\":\"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality\",\"url\":\"https://www.semanticscholar.org/paper/a18ada04d93981178234d9c8907fb99ea92fddcb\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19597437\",\"name\":\"A. Antoniou\"},{\"authorId\":\"1728216\",\"name\":\"A. Storkey\"},{\"authorId\":\"144632352\",\"name\":\"H. Edwards\"}],\"doi\":\"10.1007/978-3-030-01424-7_58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ef296ae607ca441b4fd50fec30aa28f517eb09e\",\"title\":\"Augmenting Image Classifiers Using Data Augmentation Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/0ef296ae607ca441b4fd50fec30aa28f517eb09e\",\"venue\":\"ICANN\",\"year\":2018},{\"arxivId\":\"1706.04987\",\"authors\":[{\"authorId\":\"35578586\",\"name\":\"Mihaela Rosca\"},{\"authorId\":\"40627523\",\"name\":\"Balaji Lakshminarayanan\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"14594344\",\"name\":\"S. Mohamed\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"39d08fa8b028217384daeb3e622848451809a422\",\"title\":\"Variational Approaches for Auto-Encoding Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/39d08fa8b028217384daeb3e622848451809a422\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1801.01944\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SPW.2018.00009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a5704ac5fdacb7121a0c02a9be4de2bdc5a40fc\",\"title\":\"Audio Adversarial Examples: Targeted Attacks on Speech-to-Text\",\"url\":\"https://www.semanticscholar.org/paper/6a5704ac5fdacb7121a0c02a9be4de2bdc5a40fc\",\"venue\":\"2018 IEEE Security and Privacy Workshops (SPW)\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1707.05474\",\"authors\":[{\"authorId\":\"66053599\",\"name\":\"Guoqing Jin\"},{\"authorId\":\"46495138\",\"name\":\"S. Shen\"},{\"authorId\":\"49357199\",\"name\":\"Dongming Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/ICASSP.2019.8683044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c08233528d14e4bcca6c3524f5f7e5a5808dffb0\",\"title\":\"APE-GAN: Adversarial Perturbation Elimination with GAN\",\"url\":\"https://www.semanticscholar.org/paper/c08233528d14e4bcca6c3524f5f7e5a5808dffb0\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1610.04563\",\"authors\":[{\"authorId\":\"2974221\",\"name\":\"Andras Rozsa\"},{\"authorId\":\"38636666\",\"name\":\"M. G\\u00fcnther\"},{\"authorId\":\"32163276\",\"name\":\"T. Boult\"}],\"doi\":\"10.1109/ICMLA.2016.0045\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b3139012b29462f1f2585949a94ef9a2a0ac0b21\",\"title\":\"Are Accuracy and Robustness Correlated\",\"url\":\"https://www.semanticscholar.org/paper/b3139012b29462f1f2585949a94ef9a2a0ac0b21\",\"venue\":\"2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2016},{\"arxivId\":\"1506.02025\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"title\":\"Spatial Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1709.03423\",\"authors\":[{\"authorId\":\"24420945\",\"name\":\"Thilo Strauss\"},{\"authorId\":\"41205558\",\"name\":\"Markus Hanselmann\"},{\"authorId\":\"49614557\",\"name\":\"Andrej Junginger\"},{\"authorId\":\"34008309\",\"name\":\"Holger Ulmer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eccd39db20a0caae8dbcf7f64d04280e62cabf65\",\"title\":\"Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/eccd39db20a0caae8dbcf7f64d04280e62cabf65\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1802.09653\",\"authors\":[{\"authorId\":\"36301492\",\"name\":\"Mahmood Sharif\"},{\"authorId\":\"41224057\",\"name\":\"L. Bauer\"},{\"authorId\":\"1746214\",\"name\":\"M. Reiter\"}],\"doi\":\"10.1109/CVPRW.2018.00211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"578c891983e2fb02693b748879112d7f8a9add46\",\"title\":\"On the Suitability of Lp-Norms for Creating and Preventing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/578c891983e2fb02693b748879112d7f8a9add46\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1804.03286\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"06b98537324dbf11c7de2040e519b4d110f5d622\",\"title\":\"On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses\",\"url\":\"https://www.semanticscholar.org/paper/06b98537324dbf11c7de2040e519b4d110f5d622\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.02485\",\"authors\":[{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"1737610\",\"name\":\"Jonathan Binas\"},{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"50324141\",\"name\":\"Sandeep Subramanian\"},{\"authorId\":\"3168518\",\"name\":\"Ioannis Mitliagkas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"184851f76d7210dea87646648fea196a0071d1d0\",\"title\":\"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations\",\"url\":\"https://www.semanticscholar.org/paper/184851f76d7210dea87646648fea196a0071d1d0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1712.02976\",\"authors\":[{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"151483845\",\"name\":\"Ming Liang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"48566726\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/CVPR.2018.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"title\":\"Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser\",\"url\":\"https://www.semanticscholar.org/paper/ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1702.06280\",\"authors\":[{\"authorId\":\"39221858\",\"name\":\"Kathrin Grosse\"},{\"authorId\":\"144278515\",\"name\":\"P. Manoharan\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144588806\",\"name\":\"M. Backes\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a77313fa10a864e14f538c73d417d7b4d6f320e\",\"title\":\"On the (Statistical) Detection of Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/0a77313fa10a864e14f538c73d417d7b4d6f320e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.02628\",\"authors\":[{\"authorId\":\"2464929\",\"name\":\"Mika Juuti\"},{\"authorId\":\"46230864\",\"name\":\"Sebastian Szyller\"},{\"authorId\":\"30075519\",\"name\":\"A. Dmitrenko\"},{\"authorId\":\"34810365\",\"name\":\"S. Marchal\"},{\"authorId\":\"144836615\",\"name\":\"N. Asokan\"}],\"doi\":\"10.1109/EuroSP.2019.00044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4582e2350e4822834dcf266522690722dd4430d4\",\"title\":\"PRADA: Protecting Against DNN Model Stealing Attacks\",\"url\":\"https://www.semanticscholar.org/paper/4582e2350e4822834dcf266522690722dd4430d4\",\"venue\":\"2019 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2019},{\"arxivId\":\"1811.00525\",\"authors\":[{\"authorId\":\"5911421\",\"name\":\"Marc Khoury\"},{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"00f9e7f7c83a70829da876ffffcedeaeba0f7a55\",\"title\":\"On the Geometry of Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/00f9e7f7c83a70829da876ffffcedeaeba0f7a55\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1710.10571\",\"authors\":[{\"authorId\":\"2635549\",\"name\":\"A. Sinha\"},{\"authorId\":\"40281109\",\"name\":\"Hongseok Namkoong\"},{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a295f76c2afb7f79a970ccf086f16168d976bb93\",\"title\":\"Certifiable Distributional Robustness with Principled Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/a295f76c2afb7f79a970ccf086f16168d976bb93\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1705.03387\",\"authors\":[{\"authorId\":\"13621686\",\"name\":\"Hyeungill Lee\"},{\"authorId\":\"14417003\",\"name\":\"Sungyeob Han\"},{\"authorId\":\"49684730\",\"name\":\"J. Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"398713c17e55558deb03d638f82bfd8d00ec470f\",\"title\":\"Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN\",\"url\":\"https://www.semanticscholar.org/paper/398713c17e55558deb03d638f82bfd8d00ec470f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47619311\",\"name\":\"J. Buckman\"},{\"authorId\":\"39788470\",\"name\":\"Aurko Roy\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"title\":\"Thermometer Encoding: One Hot Way To Resist Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1712.09491\",\"authors\":[{\"authorId\":\"10754103\",\"name\":\"A. Bhagoji\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9da084097986f30897f3722febc70631fe2251d7\",\"title\":\"Exploring the Space of Black-box Attacks on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9da084097986f30897f3722febc70631fe2251d7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1710.10733\",\"authors\":[{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8451075110e8dde43b3640549cc3de4cfd327c49\",\"title\":\"Attacking the Madry Defense Model with L1-based Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8451075110e8dde43b3640549cc3de4cfd327c49\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Battista Biggio\"},{\"authorId\":null,\"name\":\"Fabio Roli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Storkey , and Harrison Edwards . Augmenting image classifiers using data augmentation generative adversarial networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1803.06373\",\"authors\":[{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"title\":\"Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"145602558\",\"name\":\"O. Fawzi\"},{\"authorId\":\"1703189\",\"name\":\"P. Frossard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10eeeca03909bd44af5a5b5791e1b1ef36ff5c9e\",\"title\":\"Fundamental limits on adversarial robustness\",\"url\":\"https://www.semanticscholar.org/paper/10eeeca03909bd44af5a5b5791e1b1ef36ff5c9e\",\"venue\":\"ICML 2015\",\"year\":2015},{\"arxivId\":\"1803.06978\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"title\":\"Improving Transferability of Adversarial Examples With Input Diversity\",\"url\":\"https://www.semanticscholar.org/paper/f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778357\",\"name\":\"L. Amsaleg\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"35401996\",\"name\":\"D. Barbe\"},{\"authorId\":\"144757691\",\"name\":\"S. Erfani\"},{\"authorId\":\"4480560\",\"name\":\"M. E. Houle\"},{\"authorId\":\"144913250\",\"name\":\"Vinh Nguyen\"},{\"authorId\":\"143651750\",\"name\":\"M. Radovanovi\\u0107\"}],\"doi\":\"10.1109/WIFS.2017.8267651\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b8c326ab3ec7d96149a02148ff65f0f9f12981b\",\"title\":\"The vulnerability of learning to adversarial perturbation increases with intrinsic dimensionality\",\"url\":\"https://www.semanticscholar.org/paper/8b8c326ab3ec7d96149a02148ff65f0f9f12981b\",\"venue\":\"2017 IEEE Workshop on Information Forensics and Security (WIFS)\",\"year\":2017},{\"arxivId\":\"1612.00155\",\"authors\":[{\"authorId\":\"2728925\",\"name\":\"Pedro Tabacof\"},{\"authorId\":\"145544654\",\"name\":\"Julia Tavares\"},{\"authorId\":\"145487017\",\"name\":\"E. Valle\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4db188284236d36a77cc0e1f69e5973eddac864a\",\"title\":\"Adversarial Images for Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/4db188284236d36a77cc0e1f69e5973eddac864a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1808.01688\",\"authors\":[{\"authorId\":\"144473414\",\"name\":\"D. Su\"},{\"authorId\":\"1768312\",\"name\":\"Huan Zhang\"},{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"}],\"doi\":\"10.1007/978-3-030-01258-8_39\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"821fd5bed14d6d06c25fbf44123fd7be382f7b4e\",\"title\":\"Is Robustness the Cost of Accuracy? - A Comprehensive Study on the Robustness of 18 Deep Image Classification Models\",\"url\":\"https://www.semanticscholar.org/paper/821fd5bed14d6d06c25fbf44123fd7be382f7b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1707.06728\",\"authors\":[{\"authorId\":\"3393449\",\"name\":\"Valentina Zantedeschi\"},{\"authorId\":\"2378427\",\"name\":\"Maria-Irina Nicolae\"},{\"authorId\":\"22261698\",\"name\":\"Ambrish Rawat\"}],\"doi\":\"10.1145/3128572.3140449\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c16dd87e39472f94c8510ddc7d6954dc6981bcd\",\"title\":\"Efficient Defenses Against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/1c16dd87e39472f94c8510ddc7d6954dc6981bcd\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1803.08680\",\"authors\":[{\"authorId\":\"40896844\",\"name\":\"Daniel Jakubovitz\"},{\"authorId\":\"2711839\",\"name\":\"Raja Giryes\"}],\"doi\":\"10.1007/978-3-030-01258-8_32\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba6bc847a6ece8448ff492d0639a93d736427903\",\"title\":\"Improving DNN Robustness to Adversarial Attacks using Jacobian Regularization\",\"url\":\"https://www.semanticscholar.org/paper/ba6bc847a6ece8448ff492d0639a93d736427903\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.07978\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ab21b120e305b6d3cbf81c5a906d36521152f1\",\"title\":\"Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors\",\"url\":\"https://www.semanticscholar.org/paper/10ab21b120e305b6d3cbf81c5a906d36521152f1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1805.12152\",\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b9c6022598085dd892f360122c0fa4c630b3f18\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1b9c6022598085dd892f360122c0fa4c630b3f18\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1712.02779\",\"authors\":[{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afa0d49c1399c752d6f4665d75ecec640c000468\",\"title\":\"A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations\",\"url\":\"https://www.semanticscholar.org/paper/afa0d49c1399c752d6f4665d75ecec640c000468\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1703.06748\",\"authors\":[{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"33317877\",\"name\":\"Zhang-Wei Hong\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"9944380\",\"name\":\"Meng-Li Shih\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.24963/ijcai.2017/525\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"236b40f3144b95cd84779484c8269092122920aa\",\"title\":\"Tactics of Adversarial Attack on Deep Reinforcement Learning Agents\",\"url\":\"https://www.semanticscholar.org/paper/236b40f3144b95cd84779484c8269092122920aa\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Uri Shaham\"},{\"authorId\":null,\"name\":\"Yutaro Yamada\"},{\"authorId\":null,\"name\":\"Sahand Negahban\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"derstanding adversarial training : Increasing local stability of supervised models through robust optimization Membership inference attacks against machine learning models\",\"url\":\"\",\"venue\":\"\",\"year\":null}],\"title\":\"Disentangling Adversarial Robustness and Generalization\",\"topics\":[{\"topic\":\"Generalization (Psychology)\",\"topicId\":\"167\",\"url\":\"https://www.semanticscholar.org/topic/167\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Robustness (computer science)\",\"topicId\":\"879\",\"url\":\"https://www.semanticscholar.org/topic/879\"},{\"topic\":\"manifold\",\"topicId\":\"12796\",\"url\":\"https://www.semanticscholar.org/topic/12796\"},{\"topic\":\"Synthetic data\",\"topicId\":\"16840\",\"url\":\"https://www.semanticscholar.org/topic/16840\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"MNIST database\",\"topicId\":\"211771\",\"url\":\"https://www.semanticscholar.org/topic/211771\"},{\"topic\":\"101 Mouse\",\"topicId\":\"21905\",\"url\":\"https://www.semanticscholar.org/topic/21905\"},{\"topic\":\"Conflict (Psychology)\",\"topicId\":\"2704\",\"url\":\"https://www.semanticscholar.org/topic/2704\"},{\"topic\":\"Architecture as Topic\",\"topicId\":\"46677\",\"url\":\"https://www.semanticscholar.org/topic/46677\"}],\"url\":\"https://www.semanticscholar.org/paper/8bcd98bd5a451c2bbde4a22a4d1affe3c6407af0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"