"{\"abstract\":\"We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages Visual Genome scene graph structures to create 22M diverse reasoning questions, which all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate question biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. A careful analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains a mere 42.1%, and strong VQA models achieve 54.1%, human performance tops at 89.3%, offering ample opportunity for new research to explore. We hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding of vision and language.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\",\"url\":\"https://www.semanticscholar.org/author/152951058\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\",\"url\":\"https://www.semanticscholar.org/author/144783904\"}],\"citationVelocity\":56,\"citations\":[{\"arxivId\":\"2012.04726\",\"authors\":[{\"authorId\":\"1380616323\",\"name\":\"Jeff Da\"},{\"authorId\":\"39191185\",\"name\":\"M. Forbes\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"90390316\",\"name\":\"Anthony Zheng\"},{\"authorId\":\"2012510\",\"name\":\"Jena D. Hwang\"},{\"authorId\":\"2691021\",\"name\":\"Antoine Bosselut\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c5d597e5f34a01809f1bf4fd6e0f3475f59fb4d\",\"title\":\"Edited Media Understanding: Reasoning About Implications of Manipulated Images\",\"url\":\"https://www.semanticscholar.org/paper/7c5d597e5f34a01809f1bf4fd6e0f3475f59fb4d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.00330\",\"authors\":[{\"authorId\":\"51479145\",\"name\":\"Shailaja Keyur Sampat\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.413\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"5e0b3a58bf6e89e3756aaf0ad97ae8a8ec8f0955\",\"title\":\"Visuo-Lingustic Question Answering (VLQA) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5e0b3a58bf6e89e3756aaf0ad97ae8a8ec8f0955\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1912.03063\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":\"10.3233/FAIA200412\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e9336a1be4fc269a987656aab16d2791515917f\",\"title\":\"Weak Supervision helps Emergence of Word-Object Alignment and improves Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/3e9336a1be4fc269a987656aab16d2791515917f\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.06193\",\"authors\":[{\"authorId\":\"10774714\",\"name\":\"Rajat Koner\"},{\"authorId\":\"98755209\",\"name\":\"Poulami Sinhamahapatra\"},{\"authorId\":\"1700754\",\"name\":\"Volker Tresp\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fc60ce53d8fb9711c5c2cd9206f7578ebc5d9df\",\"title\":\"Relation Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/1fc60ce53d8fb9711c5c2cd9206f7578ebc5d9df\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.04913\",\"authors\":[{\"authorId\":\"47043894\",\"name\":\"Ruixue Tang\"},{\"authorId\":\"1684762080\",\"name\":\"Chao Ma\"}],\"doi\":\"10.1007/978-3-030-60636-7_8\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f65f90c41aafd40449edc8e2c2c80a63bc767e6d\",\"title\":\"Interpretable Neural Computation for Real-World Compositional Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f65f90c41aafd40449edc8e2c2c80a63bc767e6d\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":\"1905.12008\",\"authors\":[{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"},{\"authorId\":\"145882781\",\"name\":\"D. Rajan\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"80893448\",\"name\":\"Alexis Asseman\"},{\"authorId\":\"50192121\",\"name\":\"A. Ozcan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2074ecfe2c7e2d2f7fdfb5c0480adb8c398cdf0b\",\"title\":\"Leveraging Medical Visual Question Answering with Supporting Facts\",\"url\":\"https://www.semanticscholar.org/paper/2074ecfe2c7e2d2f7fdfb5c0480adb8c398cdf0b\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"1907.12133\",\"authors\":[{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"113737386\",\"name\":\"D. Xuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"title\":\"An Empirical Study on Leveraging Scene Graphs for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2006.15631\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"title\":\"Improving VQA and its Explanations by Comparing Competing Explanations\",\"url\":\"https://www.semanticscholar.org/paper/f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.09954\",\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":\"10.24963/ijcai.2019/873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2f02d8817a8fac2a2dda7359353712f8ff85aaa\",\"title\":\"Integrating Knowledge and Reasoning in Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a2f02d8817a8fac2a2dda7359353712f8ff85aaa\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1906.03952\",\"authors\":[{\"authorId\":\"96817905\",\"name\":\"R. Suzuki\"},{\"authorId\":\"3486313\",\"name\":\"Hitomi Yanaka\"},{\"authorId\":\"7906966\",\"name\":\"Masashi Yoshikawa\"},{\"authorId\":\"2106670\",\"name\":\"Koji Mineshima\"},{\"authorId\":\"2520156\",\"name\":\"D. Bekki\"}],\"doi\":\"10.18653/v1/P19-2054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e59b5dedafb4f647f9cf5976b1f99eb1de12b77\",\"title\":\"Multimodal Logical Inference System for Visual-Textual Entailment\",\"url\":\"https://www.semanticscholar.org/paper/5e59b5dedafb4f647f9cf5976b1f99eb1de12b77\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2001.11770\",\"authors\":[{\"authorId\":\"51174907\",\"name\":\"Tomer Wolfson\"},{\"authorId\":\"22245981\",\"name\":\"Mor Geva\"},{\"authorId\":\"145520321\",\"name\":\"Ankit Gupta\"},{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"79775260\",\"name\":\"Y. Goldberg\"},{\"authorId\":\"1682639\",\"name\":\"D. Deutch\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"}],\"doi\":\"10.1162/tacl_a_00309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71c908529b12ef6ee8d735127a63d48b1fc5c43c\",\"title\":\"Break It Down: A Question Understanding Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/71c908529b12ef6ee8d735127a63d48b1fc5c43c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8536519\",\"name\":\"Eunsol Kim\"},{\"authorId\":\"21152168\",\"name\":\"Woo Young Kang\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01459\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1888f86aa78a2a538ad68a8bba1dd6b01492c77\",\"title\":\"Hypergraph Attention Networks for Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/d1888f86aa78a2a538ad68a8bba1dd6b01492c77\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.03343\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"1388031809\",\"name\":\"Antoine Maiorca\"},{\"authorId\":\"1388031811\",\"name\":\"Nathan Hubens\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd8e7ed46ca883e7e6f897f25715d50220eaca30\",\"title\":\"Modulated Self-attention Convolutional Network for VQA\",\"url\":\"https://www.semanticscholar.org/paper/fd8e7ed46ca883e7e6f897f25715d50220eaca30\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49116303\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"144410256\",\"name\":\"Ryota Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"}],\"doi\":\"10.1007/978-3-030-50334-5_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee2dc587ff68e353fc47e0b2ad25e402fe87c57f\",\"title\":\"Multi-view Visual Question Answering Dataset for Real Environment Applications\",\"url\":\"https://www.semanticscholar.org/paper/ee2dc587ff68e353fc47e0b2ad25e402fe87c57f\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145296409\",\"name\":\"A. Potapov\"},{\"authorId\":\"144336979\",\"name\":\"A. Belikov\"},{\"authorId\":\"48649198\",\"name\":\"V. Bogdanov\"},{\"authorId\":\"150031580\",\"name\":\"Alexander Scherbatiy\"}],\"doi\":\"10.1007/978-3-030-27005-6_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34b5098b5fc6021059f89247d03ef7e84969b752\",\"title\":\"Cognitive Module Networks for Grounded Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/34b5098b5fc6021059f89247d03ef7e84969b752\",\"venue\":\"AGI\",\"year\":2019},{\"arxivId\":\"1908.04950\",\"authors\":[{\"authorId\":\"51906624\",\"name\":\"Catalina Cangea\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"},{\"authorId\":\"144269589\",\"name\":\"P. Li\\u00f2\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad732e16296b62ba1de9a22bd01452590b52a2fc\",\"title\":\"VideoNavQA: Bridging the Gap between Visual and Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad732e16296b62ba1de9a22bd01452590b52a2fc\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"3055431\",\"name\":\"Marco T\\u00falio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":\"10.1109/CVPR42600.2020.01002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cea494961a45d6a0687c75248fd078999d9a43\",\"title\":\"SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/27cea494961a45d6a0687c75248fd078999d9a43\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.05054\",\"authors\":[{\"authorId\":\"114577307\",\"name\":\"C. Alberti\"},{\"authorId\":\"50602231\",\"name\":\"Jeffrey Ling\"},{\"authorId\":\"123052390\",\"name\":\"Michael Collins\"},{\"authorId\":\"1781409\",\"name\":\"D. Reitter\"}],\"doi\":\"10.18653/v1/D19-1219\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"title\":\"Fusion of Detected Objects in Text for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48079662\",\"name\":\"Sungho Park\"},{\"authorId\":\"145864562\",\"name\":\"Sunhee Hwang\"},{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1109/ACCESS.2020.3041503\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"title\":\"Fair-VQA: Fairness-Aware Visual Question Answering Through Sensitive Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ashish Vaswani\"},{\"authorId\":null,\"name\":\"Noam Shazeer\"},{\"authorId\":null,\"name\":\"Niki Parmar\"},{\"authorId\":null,\"name\":\"Jakob\"},{\"authorId\":null,\"name\":\"Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"title\":\"Words aren\\u2019t enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22225752\",\"name\":\"F. Brad\"}],\"doi\":\"10.1109/ICCVW.2019.00560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"title\":\"Scene Graph Contextualization in Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2012.06946\",\"authors\":[{\"authorId\":\"46583603\",\"name\":\"J. Wang\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41171e9024d0082c2a57f4887bac93131669b881\",\"title\":\"MiniVLM: A Smaller and Faster Vision-Language Model\",\"url\":\"https://www.semanticscholar.org/paper/41171e9024d0082c2a57f4887bac93131669b881\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Weifeng Zhang\"},{\"authorId\":null,\"name\":\"Jing Yu\"},{\"authorId\":null,\"name\":\"Yuxia Wang\"},{\"authorId\":null,\"name\":\"Wei Wang\"}],\"doi\":\"10.1016/j.knosys.2020.106639\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63ca298bcb66f3bd7eb2dfdced0bcb475de83809\",\"title\":\"Multimodal deep fusion for image question answering\",\"url\":\"https://www.semanticscholar.org/paper/63ca298bcb66f3bd7eb2dfdced0bcb475de83809\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.15124\",\"authors\":[{\"authorId\":\"83574123\",\"name\":\"Emanuele Bugliarello\"},{\"authorId\":\"1750769\",\"name\":\"Ryan Cotterell\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"title\":\"Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs\",\"url\":\"https://www.semanticscholar.org/paper/82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.06927\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"title\":\"SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.02481\",\"authors\":[{\"authorId\":\"49308062\",\"name\":\"Y. Yang\"},{\"authorId\":\"1779453\",\"name\":\"L. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"569033d6e2c758f469c648be7a1cf83f5ede1598\",\"title\":\"Learn to Explain Efficiently via Neural Logic Inductive Learning\",\"url\":\"https://www.semanticscholar.org/paper/569033d6e2c758f469c648be7a1cf83f5ede1598\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395925001\",\"name\":\"Bj\\u00f6rn Wahle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"title\":\"Grounding semantics in robots for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.02111\",\"authors\":[{\"authorId\":\"46867626\",\"name\":\"Y. Zhang\"},{\"authorId\":\"66273798\",\"name\":\"Xinshi Chen\"},{\"authorId\":\"103401813\",\"name\":\"Y. Yang\"},{\"authorId\":\"145699745\",\"name\":\"A. Ramamurthy\"},{\"authorId\":\"38620893\",\"name\":\"B. Li\"},{\"authorId\":\"40612590\",\"name\":\"Yuan Qi\"},{\"authorId\":\"1779453\",\"name\":\"L. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fc076ab06e2213c9fb104459d92c87e34f66ae1\",\"title\":\"Can Graph Neural Networks Help Logic Reasoning?\",\"url\":\"https://www.semanticscholar.org/paper/7fc076ab06e2213c9fb104459d92c87e34f66ae1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"title\":\"AiR: Attention with Reasoning Capability (Supplementary Materials)\",\"url\":\"https://www.semanticscholar.org/paper/456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":\"10.18653/v1/2020.acl-main.643\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e600553fe2f21630f2a272c80de4ce0e0363cb9c\",\"title\":\"Multimodal Neural Graph Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e600553fe2f21630f2a272c80de4ce0e0363cb9c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"title\":\"Learning Latent Graph Representations for Relational VQA\",\"url\":\"https://www.semanticscholar.org/paper/6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1909.07459\",\"authors\":[{\"authorId\":\"103393695\",\"name\":\"C. Jiang\"},{\"authorId\":\"3560734\",\"name\":\"Steven Weikai Lu\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3467c9977b875544221abbd8153facf2cb176759\",\"title\":\"Constructing Dynamic Knowledge Graph for Visual Semantic Understanding and Applications in Autonomous Robotics\",\"url\":\"https://www.semanticscholar.org/paper/3467c9977b875544221abbd8153facf2cb176759\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"1388031809\",\"name\":\"Antoine Maiorca\"},{\"authorId\":\"1388031811\",\"name\":\"Nathan Hubens\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2960fd63507253d1d6a19802068666de478bfc0\",\"title\":\"C V ] 8 O ct 2 01 9 Modulated Self-attention Convolutional Network for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b2960fd63507253d1d6a19802068666de478bfc0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144638992\",\"name\":\"Xinzhe Han\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153645460\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58545-7_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"title\":\"Interpretable Visual Reasoning via Probabilistic Formulation Under Natural Supervision\",\"url\":\"https://www.semanticscholar.org/paper/2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.05704\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/2020.acl-main.727\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4a012aa325cdee5a5c779fe2133e146616a5d5\",\"title\":\"A negative case analysis of visual grounding methods for VQA\",\"url\":\"https://www.semanticscholar.org/paper/2f4a012aa325cdee5a5c779fe2133e146616a5d5\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.10731\",\"authors\":[{\"authorId\":\"151253861\",\"name\":\"Weixin Liang\"},{\"authorId\":\"7650020\",\"name\":\"Feiyang Niu\"},{\"authorId\":\"8856206\",\"name\":\"Aishwarya N. Reganti\"},{\"authorId\":\"2028300167\",\"name\":\"Govind Thattai\"},{\"authorId\":\"1748051\",\"name\":\"G. T\\u00fcr\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86fdbc4540d146b0a2d7d61bf9f0109fa1331dac\",\"title\":\"LRTA: A Transparent Neural-Symbolic Reasoning Framework with Modular Supervision for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86fdbc4540d146b0a2d7d61bf9f0109fa1331dac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10802\",\"authors\":[{\"authorId\":\"2239880\",\"name\":\"I. Gat\"},{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da5dde64865d7620079e0f50ef27b32bbebef7af\",\"title\":\"Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies\",\"url\":\"https://www.semanticscholar.org/paper/da5dde64865d7620079e0f50ef27b32bbebef7af\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2012.12871\",\"authors\":[{\"authorId\":\"1751661088\",\"name\":\"Phillip Lippe\"},{\"authorId\":\"1661217828\",\"name\":\"Nithin Holla\"},{\"authorId\":\"1879340965\",\"name\":\"Shantanu Chandra\"},{\"authorId\":\"1723418777\",\"name\":\"Santhosh Rajamanickam\"},{\"authorId\":\"33537528\",\"name\":\"G. Antoniou\"},{\"authorId\":\"2362276\",\"name\":\"Ekaterina Shutova\"},{\"authorId\":\"2169553\",\"name\":\"H. Yannakoudakis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"76e266d5220f963886cf30ae747d72fdf8c84378\",\"title\":\"A Multimodal Framework for the Detection of Hateful Memes\",\"url\":\"https://www.semanticscholar.org/paper/76e266d5220f963886cf30ae747d72fdf8c84378\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.08566\",\"authors\":[{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.63\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cf4e64566252b3a342ba344e8a123c2b209766f2\",\"title\":\"MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf4e64566252b3a342ba344e8a123c2b209766f2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2006.09437\",\"authors\":[{\"authorId\":\"2652016\",\"name\":\"Tim Klinger\"},{\"authorId\":\"21493167\",\"name\":\"D. Adjodah\"},{\"authorId\":\"79805467\",\"name\":\"Vincent Marois\"},{\"authorId\":\"47263059\",\"name\":\"J. Joseph\"},{\"authorId\":\"40497459\",\"name\":\"M. Riemer\"},{\"authorId\":\"144994681\",\"name\":\"Alex 'Sandy' Pentland\"},{\"authorId\":\"143903370\",\"name\":\"Murray Campbell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c103f1903e6cb9904729e65fb167a18dbfe3b129\",\"title\":\"A Study of Compositional Generalization in Neural Models\",\"url\":\"https://www.semanticscholar.org/paper/c103f1903e6cb9904729e65fb167a18dbfe3b129\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145296409\",\"name\":\"A. Potapov\"},{\"authorId\":\"6374907\",\"name\":\"O. Scherbakov\"},{\"authorId\":\"48649198\",\"name\":\"V. Bogdanov\"},{\"authorId\":\"39086684\",\"name\":\"V. Potapova\"},{\"authorId\":\"144336979\",\"name\":\"A. Belikov\"},{\"authorId\":\"143860556\",\"name\":\"S. Rodionov\"},{\"authorId\":\"1804542874\",\"name\":\"Artem Yashenko\"}],\"doi\":\"10.1007/978-3-030-52152-3_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b375748f0abbf56154615568d7cefb7fd404dd6f\",\"title\":\"Analyzing Elementary School Olympiad Math Tasks as a Benchmark for AGI\",\"url\":\"https://www.semanticscholar.org/paper/b375748f0abbf56154615568d7cefb7fd404dd6f\",\"venue\":\"AGI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c10383189c118465f8b40e8dba9213f57fa570\",\"title\":\"UNITER: Learning UNiversal Image-TExt Representations\",\"url\":\"https://www.semanticscholar.org/paper/33c10383189c118465f8b40e8dba9213f57fa570\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.09713\",\"authors\":[{\"authorId\":\"51027911\",\"name\":\"Daniel Keysers\"},{\"authorId\":\"1474228495\",\"name\":\"Nathanael Sch\\u00e4rli\"},{\"authorId\":\"1471909492\",\"name\":\"Nathan Scales\"},{\"authorId\":\"2836674\",\"name\":\"H. Buisman\"},{\"authorId\":\"2362932\",\"name\":\"Daniel Furrer\"},{\"authorId\":\"1471005695\",\"name\":\"Sergii Kashubin\"},{\"authorId\":\"1470531643\",\"name\":\"Nikola Momchev\"},{\"authorId\":\"1470524352\",\"name\":\"Danila Sinopalnikov\"},{\"authorId\":\"3140227\",\"name\":\"Lukasz Stafiniak\"},{\"authorId\":\"1470473803\",\"name\":\"Tibor Tihon\"},{\"authorId\":\"3045792\",\"name\":\"D. Tsarkov\"},{\"authorId\":null,\"name\":\"Xiao Wang\"},{\"authorId\":\"2807540\",\"name\":\"Marc van Zee\"},{\"authorId\":\"49513540\",\"name\":\"O. Bousquet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b\",\"title\":\"Measuring Compositional Generalization: A Comprehensive Method on Realistic Data\",\"url\":\"https://www.semanticscholar.org/paper/5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1908.10285\",\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"113457342\",\"name\":\"Raquel Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/D19-1285\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"67c6e842ceafda5b31626c773b380f9e97423cd2\",\"title\":\"Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/67c6e842ceafda5b31626c773b380f9e97423cd2\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1905.11666\",\"authors\":[{\"authorId\":\"47902700\",\"name\":\"Wonjae Kim\"},{\"authorId\":\"5076961\",\"name\":\"Y. Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fc594c1ced000ea6ae36d28242cf50b4aec502f\",\"title\":\"Learning Dynamics of Attention: Human Prior for Interpretable Machine Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/4fc594c1ced000ea6ae36d28242cf50b4aec502f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1907.03950\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"title\":\"Learning by Abstraction: The Neural State Machine\",\"url\":\"https://www.semanticscholar.org/paper/136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"467ac47b2e01ce6ae74e8d70561ca0f8f66c7b8c\",\"title\":\"Probing Text Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/467ac47b2e01ce6ae74e8d70561ca0f8f66c7b8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.09655\",\"authors\":[{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":\"10.1109/TASLP.2020.3010650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfa437129daef8533708924c395c3fd0c5c3bf81\",\"title\":\"Temporal Reasoning via Audio Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bfa437129daef8533708924c395c3fd0c5c3bf81\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.09073\",\"authors\":[{\"authorId\":\"49869982\",\"name\":\"J. Kruk\"},{\"authorId\":\"104128958\",\"name\":\"Jonah Lubin\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.18653/v1/D19-1469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75e40feb1d09c9bcfe8e6b080f40e6a6ffd03800\",\"title\":\"Integrating Text and Image: Determining Multimodal Document Intent in Instagram Posts\",\"url\":\"https://www.semanticscholar.org/paper/75e40feb1d09c9bcfe8e6b080f40e6a6ffd03800\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2004.11883\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c7faa44bde54f017e164ad8e687bd1963005988\",\"title\":\"Revisiting Modulated Convolutions for Visual Counting and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/6c7faa44bde54f017e164ad8e687bd1963005988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.09796\",\"authors\":[{\"authorId\":\"145868671\",\"name\":\"M. Crawshaw\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"title\":\"Multi-Task Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03875\",\"authors\":[{\"authorId\":\"49887423\",\"name\":\"Jiaxin Shi\"},{\"authorId\":\"1712738522\",\"name\":\"Shulin Cao\"},{\"authorId\":\"3470231\",\"name\":\"Liangming Pan\"},{\"authorId\":\"83271938\",\"name\":\"Yutong Xiang\"},{\"authorId\":\"145779862\",\"name\":\"Lei Hou\"},{\"authorId\":\"8549226\",\"name\":\"Juan-Zi Li\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1631386300\",\"name\":\"Bin He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"94312d7df647ba62bb542a8a19c69f3e5c4a32bb\",\"title\":\"KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over Knowledge Base\",\"url\":\"https://www.semanticscholar.org/paper/94312d7df647ba62bb542a8a19c69f3e5c4a32bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14025\",\"authors\":[{\"authorId\":\"79778234\",\"name\":\"Sungjin Park\"},{\"authorId\":\"89016637\",\"name\":\"T. Whang\"},{\"authorId\":\"3037023\",\"name\":\"Y. Yoon\"},{\"authorId\":\"1450703435\",\"name\":\"Hueiseok Lim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"title\":\"Multi-View Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152176221\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"33201965\",\"name\":\"Satyananda Kashyap\"},{\"authorId\":\"1410148565\",\"name\":\"Karina Kanjaria\"},{\"authorId\":\"1388126424\",\"name\":\"Adam Coy\"},{\"authorId\":\"13403287\",\"name\":\"D. Ballah\"},{\"authorId\":\"2230103\",\"name\":\"Yufan Guo\"},{\"authorId\":\"33348864\",\"name\":\"J. Wu\"},{\"authorId\":\"46474962\",\"name\":\"A. Karargyris\"},{\"authorId\":\"1740300\",\"name\":\"D. Beymer\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"},{\"authorId\":\"80257800\",\"name\":\"Vandana Mukherjee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc71a905ca132999a158857823606cd979b9080e\",\"title\":\"Visual Dialog for Radiology: Data Curation and FirstSteps\",\"url\":\"https://www.semanticscholar.org/paper/cc71a905ca132999a158857823606cd979b9080e\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"1911.03705\",\"authors\":[{\"authorId\":\"51583409\",\"name\":\"Bill Yuchen Lin\"},{\"authorId\":\"153150499\",\"name\":\"Ming Shen\"},{\"authorId\":\"97953933\",\"name\":\"Y. Xing\"},{\"authorId\":\"144032123\",\"name\":\"P. Zhou\"},{\"authorId\":\"145201126\",\"name\":\"X. Ren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"727c9d3846ebd80a9138d0e6c9e995d9afc1d312\",\"title\":\"CommonGen: A Constrained Text Generation Dataset Towards Generative Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/727c9d3846ebd80a9138d0e6c9e995d9afc1d312\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.01239\",\"authors\":[{\"authorId\":\"114180826\",\"name\":\"Violetta Shevchenko\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8a3c338551f9c512868bc89217f95bbce69b1a8\",\"title\":\"Visual Question Answering with Prior Class Semantics\",\"url\":\"https://www.semanticscholar.org/paper/b8a3c338551f9c512868bc89217f95bbce69b1a8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065332\",\"name\":\"H. Lee\"},{\"authorId\":\"144517919\",\"name\":\"Seunghyun Yoon\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"153586399\",\"name\":\"Doo Soon Kim\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"27582486\",\"name\":\"Joongbo Shin\"},{\"authorId\":\"1731707\",\"name\":\"K. Jung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"76d7f84fc94dfbe41b16fed2775b1705cc6d9da9\",\"title\":\"KPQA: A Metric for Generative Question Answering Using Word Weights\",\"url\":\"https://www.semanticscholar.org/paper/76d7f84fc94dfbe41b16fed2775b1705cc6d9da9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.13471\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"title\":\"On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints\",\"url\":\"https://www.semanticscholar.org/paper/1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.08970\",\"authors\":[{\"authorId\":\"2362932\",\"name\":\"Daniel Furrer\"},{\"authorId\":\"2807540\",\"name\":\"Marc van Zee\"},{\"authorId\":\"1471909492\",\"name\":\"Nathan Scales\"},{\"authorId\":\"1821614764\",\"name\":\"Nathanael Scharli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"323c417eaa2958f10fa543d1963c2ac5c04fac98\",\"title\":\"Compositional Generalization in Semantic Parsing: Pre-training vs. Specialized Architectures\",\"url\":\"https://www.semanticscholar.org/paper/323c417eaa2958f10fa543d1963c2ac5c04fac98\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06195\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50580345\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"title\":\"Large-Scale Adversarial Training for Vision-and-Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"113720743\",\"name\":\"Amin Parvaneh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR42600.2020.01006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"title\":\"Counterfactual Vision and Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.14435\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdabd8bc1009e3ef2764a4e1dde20938aecad84\",\"title\":\"Towards Ecologically Valid Research on Language User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/6bdabd8bc1009e3ef2764a4e1dde20938aecad84\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.11894\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"title\":\"Unshuffling Data for Improved Generalization\",\"url\":\"https://www.semanticscholar.org/paper/fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.02347\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/ICCV.2019.00471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"title\":\"Counterfactual Critic Multi-Agent Training for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.12770\",\"authors\":[{\"authorId\":\"1659695668\",\"name\":\"Cristobal Eyzaguirre\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/cvpr42600.2020.01283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2732b5a501870e20e77cd6cde81b33ae017ba206\",\"title\":\"Differentiable Adaptive Computation Time for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2732b5a501870e20e77cd6cde81b33ae017ba206\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379579811\",\"name\":\"Terufumi Morishita\"},{\"authorId\":\"29347584\",\"name\":\"G. Morio\"},{\"authorId\":\"7180730\",\"name\":\"Shota Horiguchi\"},{\"authorId\":\"36904068\",\"name\":\"Hiroaki Ozaki\"},{\"authorId\":\"2468213\",\"name\":\"T. Miyoshi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3eb7b0a43afdb5ec8296409a3ffd2412d1806656\",\"title\":\"Hitachi at SemEval-2020 Task 8: Simple but Effective Modality Ensemble for Meme Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3eb7b0a43afdb5ec8296409a3ffd2412d1806656\",\"venue\":\"SemEval@COLING\",\"year\":2020},{\"arxivId\":\"2008.06651\",\"authors\":[{\"authorId\":\"46307726\",\"name\":\"Li-chang Chen\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"47672928\",\"name\":\"S. Wang\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"}],\"doi\":\"10.1007/978-3-030-58529-7_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf1aa76529cdf25bfb13a787f9a6763e7e89b6a1\",\"title\":\"Graph Edit Distance Reward: Learning to Edit Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/bf1aa76529cdf25bfb13a787f9a6763e7e89b6a1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.03705\",\"authors\":[{\"authorId\":\"51583409\",\"name\":\"Bill Yuchen Lin\"},{\"authorId\":\"143977316\",\"name\":\"M. Shen\"},{\"authorId\":\"150341221\",\"name\":\"Wangchunshu Zhou\"},{\"authorId\":\"1557324013\",\"name\":\"Pei Zhou\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1384550891\",\"name\":\"X. Ren\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.165\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc366c5a6e6aaf3fe718be09d9b6fb8924f1a7bf\",\"title\":\"CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/fc366c5a6e6aaf3fe718be09d9b6fb8924f1a7bf\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50535362\",\"name\":\"Jiani Huang\"},{\"authorId\":\"48475775\",\"name\":\"C. Smith\"},{\"authorId\":\"1697444\",\"name\":\"Osbert Bastani\"},{\"authorId\":\"50631599\",\"name\":\"Rishabh Singh\"},{\"authorId\":\"1893193\",\"name\":\"Aws Albarghouthi\"},{\"authorId\":\"145835621\",\"name\":\"M. Naik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30600e3a97875009eac0f79be527fe393b55ad29\",\"title\":\"Generating Programmatic Referring Expressions via Program Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/30600e3a97875009eac0f79be527fe393b55ad29\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dzmitry Bahdanau\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2eb710b446570f48377b25eb279295648d05f65d\",\"title\":\"On sample efficiency and systematic generalization of grounded language understanding with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/2eb710b446570f48377b25eb279295648d05f65d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.11524\",\"authors\":[{\"authorId\":\"1961237\",\"name\":\"S. Amizadeh\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"2636739\",\"name\":\"Oleksandr Polozov\"},{\"authorId\":\"153268415\",\"name\":\"Y. Huang\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"fb62c82e469a265d986a164ba56d96d130937fd7\",\"title\":\"Neuro-Symbolic Visual Reasoning: Disentangling \\\"Visual\\\" from \\\"Reasoning\\\"\",\"url\":\"https://www.semanticscholar.org/paper/fb62c82e469a265d986a164ba56d96d130937fd7\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2002.11949\",\"authors\":[{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"1508668394\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"49887423\",\"name\":\"Jiaxin Shi\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00377\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10874b307d89f1ff9e049f2464afa6d91237ce4c\",\"title\":\"Unbiased Scene Graph Generation From Biased Training\",\"url\":\"https://www.semanticscholar.org/paper/10874b307d89f1ff9e049f2464afa6d91237ce4c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.14034\",\"authors\":[{\"authorId\":\"48637335\",\"name\":\"Wenyu Han\"},{\"authorId\":\"1754258\",\"name\":\"Siyuan Xiang\"},{\"authorId\":\"47535312\",\"name\":\"C. Liu\"},{\"authorId\":\"1443735578\",\"name\":\"Ruoyu Wang\"},{\"authorId\":\"104267768\",\"name\":\"C. Feng\"}],\"doi\":\"10.1109/cvpr42600.2020.01470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e038f227508c0b816f80f82115cf0536db65f978\",\"title\":\"SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings\",\"url\":\"https://www.semanticscholar.org/paper/e038f227508c0b816f80f82115cf0536db65f978\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2190934\",\"name\":\"Parisa Kordjamshidi\"},{\"authorId\":\"1707726\",\"name\":\"J. Pustejovsky\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.18653/v1/2020.emnlp-tutorials.5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7c56ca5453b37e68b3bbc38112fb0306a175037\",\"title\":\"Representation, Learning and Reasoning on Spatial Language for Downstream NLP Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c7c56ca5453b37e68b3bbc38112fb0306a175037\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.13161\",\"authors\":[{\"authorId\":\"7655033\",\"name\":\"G\\u00f6zde G\\u00fcl Sahin\"},{\"authorId\":\"51208524\",\"name\":\"Yova Kementchedjhieva\"},{\"authorId\":\"1660797358\",\"name\":\"P. Rust\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"}],\"doi\":\"10.18653/v1/2020.acl-main.115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e0fab543b49b315d29b0d81e8f958707456f69e\",\"title\":\"PuzzLing Machines: A Challenge on Learning From Small Data\",\"url\":\"https://www.semanticscholar.org/paper/2e0fab543b49b315d29b0d81e8f958707456f69e\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1909.11291\",\"authors\":[{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"12371246\",\"name\":\"Alon Talmor\"},{\"authorId\":\"48872685\",\"name\":\"Sewon Min\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e914370a043fd626e172d55816952bc477bd582\",\"title\":\"Question Answering is a Format; When is it Useful?\",\"url\":\"https://www.semanticscholar.org/paper/8e914370a043fd626e172d55816952bc477bd582\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.12902\",\"authors\":[{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"1410913697\",\"name\":\"Russ Howes\"},{\"authorId\":\"8277405\",\"name\":\"Brian Dolhansky\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdfcb7a9de6a0cb37bf2110bef619555a96258bc\",\"title\":\"Adversarial Evaluation of Multimodal Models under Realistic Gray Box Assumption\",\"url\":\"https://www.semanticscholar.org/paper/cdfcb7a9de6a0cb37bf2110bef619555a96258bc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.13262\",\"authors\":[{\"authorId\":\"39209233\",\"name\":\"Siwen Luo\"},{\"authorId\":\"2046142\",\"name\":\"S. Han\"},{\"authorId\":\"33053279\",\"name\":\"Kaiyuan Sun\"},{\"authorId\":\"48422087\",\"name\":\"Josiah Poon\"}],\"doi\":\"10.1007/978-3-030-63830-6_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"title\":\"REXUP: I REason, I EXtract, I UPdate with Structured Compositional Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2012.14700\",\"authors\":[{\"authorId\":\"7748443\",\"name\":\"Sangwoong Yoon\"},{\"authorId\":\"21152168\",\"name\":\"Woo Young Kang\"},{\"authorId\":\"97519074\",\"name\":\"Sungwook Jeon\"},{\"authorId\":\"50112156\",\"name\":\"Seong-Eun Lee\"},{\"authorId\":\"118727697\",\"name\":\"Changjin Han\"},{\"authorId\":\"30664924\",\"name\":\"Jonghun Park\"},{\"authorId\":\"1845794808\",\"name\":\"Eun-Sol Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2e0570df4e56d51be58b53166e853d848ef767af\",\"title\":\"Image-to-Image Retrieval by Learning Similarity between Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/2e0570df4e56d51be58b53166e853d848ef767af\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.03230\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"152876475\",\"name\":\"William W. J. Wang\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0bbae624efbfeee01bd38185c6d754c08417de7\",\"title\":\"Meta Module Network for Compositional Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/d0bbae624efbfeee01bd38185c6d754c08417de7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49303626\",\"name\":\"K. Su\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"104545113\",\"name\":\"J. Li\"},{\"authorId\":\"1557387379\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.3389/frobt.2020.00109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22e2a19bef88c30a37402da5b54fac34655d77ea\",\"title\":\"Toward Accurate Visual Reasoning With Dual-Path Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/22e2a19bef88c30a37402da5b54fac34655d77ea\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86df3250b3c5218d76076e46662ac17a2650c611\",\"title\":\"3 Discussion : Knowledge Integration in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/86df3250b3c5218d76076e46662ac17a2650c611\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.08230\",\"authors\":[{\"authorId\":\"49934559\",\"name\":\"Boris Knyazev\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"51906624\",\"name\":\"Catalina Cangea\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f2d1f5f0fa79daab734bb326feb41d68c1ebccd5\",\"title\":\"Graph Density-Aware Losses for Novel Compositions in Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/f2d1f5f0fa79daab734bb326feb41d68c1ebccd5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13681\",\"authors\":[{\"authorId\":\"20657367\",\"name\":\"A. Mani\"},{\"authorId\":\"116122080\",\"name\":\"William Hinthorn\"},{\"authorId\":\"2029244392\",\"name\":\"Nobline Yoo\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"title\":\"Point and Ask: Incorporating Pointing into Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.04957\",\"authors\":[{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"1925969\",\"name\":\"M. Murray\"},{\"authorId\":\"49258625\",\"name\":\"Maya Cakmak\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b9ce27801c077433245ad0f9e43e3c38441cecd\",\"title\":\"Vision-and-Dialog Navigation\",\"url\":\"https://www.semanticscholar.org/paper/1b9ce27801c077433245ad0f9e43e3c38441cecd\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":\"1911.11230\",\"authors\":[{\"authorId\":\"38826848\",\"name\":\"Michelle Shu\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1609/AAAI.V34I07.6876\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0d3c0fc3c87c801ce3667eec4987fd0901e19d\",\"title\":\"Identifying Model Weakness with Adversarial Examiner\",\"url\":\"https://www.semanticscholar.org/paper/1a0d3c0fc3c87c801ce3667eec4987fd0901e19d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2005.00619\",\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"title\":\"Probing Contextual Language Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2764826\",\"name\":\"H. Degen\"},{\"authorId\":\"1399251774\",\"name\":\"L. Reinerman-Jones\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50334-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e82d446b3bfcbded4a212bf25db36bea9b62dad7\",\"title\":\"Artificial Intelligence in HCI: First International Conference, AI-HCI 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19\\u201324, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/e82d446b3bfcbded4a212bf25db36bea9b62dad7\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"2004.08814\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/cvpr42600.2020.00997\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"434bccb2743fbb918b5666000c839b390cb209ae\",\"title\":\"Graph-Structured Referring Expression Reasoning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/434bccb2743fbb918b5666000c839b390cb209ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.10226\",\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46433486\",\"name\":\"Yanzhao Zhou\"},{\"authorId\":\"103515844\",\"name\":\"Gen Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"39483833\",\"name\":\"Duyu Tang\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cda975be6f9fb55813bb6813b8c7c417331de7bd\",\"title\":\"Deep Reason: A Strong Baseline for Real-World Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cda975be6f9fb55813bb6813b8c7c417331de7bd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.11587\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"title\":\"Object-Centric Diagnosis of Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.14558\",\"authors\":[{\"authorId\":\"146096525\",\"name\":\"Achiya Jerbi\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe840c573c2c0e6f76270e1054bb699627b0f470\",\"title\":\"Learning Object Detection from Captions via Textual Scene Attributes\",\"url\":\"https://www.semanticscholar.org/paper/fe840c573c2c0e6f76270e1054bb699627b0f470\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01725\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1859082176\",\"name\":\"Salman Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"title\":\"Attention Guided Semantic Relationship Parsing for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05756\",\"authors\":[{\"authorId\":\"49934559\",\"name\":\"Boris Knyazev\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"1491746775\",\"name\":\"Cuatualina Cangea\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a582140e2e27b68673e891c52d4b3742b0453ddb\",\"title\":\"Generative Graph Perturbations for Scene Graph Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a582140e2e27b68673e891c52d4b3742b0453ddb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1909.04696\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"}],\"doi\":\"10.18653/v1/D19-1596\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"title\":\"Sunny and Dark Outside?! Improving Answer Consistency in VQA through Entailed Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2012.07192\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"title\":\"Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding\",\"url\":\"https://www.semanticscholar.org/paper/e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1912.03098\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/978-3-030-58558-7_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"title\":\"Connecting Vision and Language with Localized Narratives\",\"url\":\"https://www.semanticscholar.org/paper/439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50031180\",\"name\":\"Xiaofeng Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"2753987\",\"name\":\"Fengmao Lv\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"}],\"doi\":\"10.1007/978-3-030-58589-1_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"title\":\"TRRNet: Tiered Relation Reasoning for Compositional Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.00724\",\"authors\":[{\"authorId\":\"17097887\",\"name\":\"Sanjay Subramanian\"},{\"authorId\":\"50757607\",\"name\":\"Ben Bogin\"},{\"authorId\":\"2285178\",\"name\":\"Nitish Gupta\"},{\"authorId\":\"51174907\",\"name\":\"Tomer Wolfson\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"}],\"doi\":\"10.18653/v1/2020.acl-main.495\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0416fda32c39fc9531e87bab6a8a1a552bf9ada0\",\"title\":\"Obtaining Faithful Interpretations from Compositional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0416fda32c39fc9531e87bab6a8a1a552bf9ada0\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2007.01072\",\"authors\":[{\"authorId\":\"1491246679\",\"name\":\"M. Hildebrandt\"},{\"authorId\":\"47892918\",\"name\":\"H. Li\"},{\"authorId\":\"10774714\",\"name\":\"Rajat Koner\"},{\"authorId\":\"1742501819\",\"name\":\"Volker Tresp\"},{\"authorId\":\"3075189\",\"name\":\"Stephan G\\u00fcnnemann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"59f14747ef7ba486fd45664f3902e3ad7b395a0d\",\"title\":\"Scene Graph Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/59f14747ef7ba486fd45664f3902e3ad7b395a0d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.07251\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15586721\",\"name\":\"Yingying Zhuang\"},{\"authorId\":\"47958013\",\"name\":\"Xingxing Zhang\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6769\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b42cb7889053f5c89380c82604aa33fd6270894\",\"title\":\"DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0b42cb7889053f5c89380c82604aa33fd6270894\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2012.04446\",\"authors\":[{\"authorId\":\"2018337565\",\"name\":\"Jia Guo\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"46316984\",\"name\":\"Yilun Zhao\"},{\"authorId\":\"3405101\",\"name\":\"He-Da Wang\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"101131295\",\"name\":\"Xiaofei He\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6695d3b92e7cd7f2359f698a09c7b3dc37996329\",\"title\":\"LAMP: Label Augmented Multimodal Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/6695d3b92e7cd7f2359f698a09c7b3dc37996329\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1997954506\",\"name\":\"Yevhen Romaniak\"},{\"authorId\":\"1997944494\",\"name\":\"Anastasiia Smielova\"},{\"authorId\":\"1380224734\",\"name\":\"Yevhenii Yakishyn\"},{\"authorId\":\"1380224706\",\"name\":\"Valerii Dziubliuk\"},{\"authorId\":\"1380224713\",\"name\":\"Mykhailo Zlotnyk\"},{\"authorId\":\"1380224917\",\"name\":\"Oleksandr Viatchaninov\"}],\"doi\":\"10.1145/3379350.3416153\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7444f34dd62067823dcf58b1ffdf03a7047e1a96\",\"title\":\"Nimble: Mobile Interface for a Visual Question Answering Augmented by Gestures\",\"url\":\"https://www.semanticscholar.org/paper/7444f34dd62067823dcf58b1ffdf03a7047e1a96\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"49617533\",\"name\":\"P. Allen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"189b518d70ad34c8de6f613bf3bd5051077608bc\",\"title\":\"Probing Language Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/189b518d70ad34c8de6f613bf3bd5051077608bc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"2005221955\",\"name\":\"Ali Movaghar\"}],\"doi\":\"10.36227/techrxiv.12928544.v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b678835c5de86ebe2031da902957aead8de931aa\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/b678835c5de86ebe2031da902957aead8de931aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"292d6cbab27ba35c825d75130311a4b27f291af2\",\"title\":\"Visual Question Answering with Annotation-Efficient Zero Shot Learning under Linguistic Domain Shift\",\"url\":\"https://www.semanticscholar.org/paper/292d6cbab27ba35c825d75130311a4b27f291af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.01499\",\"authors\":[{\"authorId\":\"90475778\",\"name\":\"Qing Li\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"151261268\",\"name\":\"Yining Hong\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58536-5_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2d6fee1cc06354fdb3811aaa06910f4e34cd4a7\",\"title\":\"A Competence-aware Curriculum for Visual Concepts Learning via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2d6fee1cc06354fdb3811aaa06910f4e34cd4a7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.10354\",\"authors\":[{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc4598d636b599c4752a376cc074541c5a0ec97a\",\"title\":\"Unsupervised Keyword Extraction for Full-sentence VQA\",\"url\":\"https://www.semanticscholar.org/paper/fc4598d636b599c4752a376cc074541c5a0ec97a\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2009.03793\",\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1397911258\",\"name\":\"Ali Movaghar-Rahimabadi\"}],\"doi\":\"10.36227/techrxiv.12928544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f097e32ea304a14c8e26648b05f944d530b016\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/46f097e32ea304a14c8e26648b05f944d530b016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1908.02962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"title\":\"From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense\",\"url\":\"https://www.semanticscholar.org/paper/06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66593666\",\"name\":\"Soohyeong Lee\"},{\"authorId\":\"2584081\",\"name\":\"Ju-Whan Kim\"},{\"authorId\":\"1564629398\",\"name\":\"Youngmin Oh\"},{\"authorId\":\"2796960\",\"name\":\"Joo Hyuk Jeon\"}],\"doi\":\"10.1109/GC46384.2019.00015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7448d1f37d70cf75d57113da35a539f3f7f51c00\",\"title\":\"Visual Question Answering over Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/7448d1f37d70cf75d57113da35a539f3f7f51c00\",\"venue\":\"2019 First International Conference on Graph Computing (GC)\",\"year\":2019},{\"arxivId\":\"2005.00955\",\"authors\":[{\"authorId\":\"2467508\",\"name\":\"Tal Linzen\"}],\"doi\":\"10.18653/v1/2020.acl-main.465\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0cda85c030711aaa5383c80d5928a4d22f8d3bf\",\"title\":\"How Can We Accelerate Progress Towards Human-like Linguistic Generalization?\",\"url\":\"https://www.semanticscholar.org/paper/d0cda85c030711aaa5383c80d5928a4d22f8d3bf\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2005.00891\",\"authors\":[{\"authorId\":\"1382048113\",\"name\":\"Giovanni Campagna\"},{\"authorId\":\"1491516389\",\"name\":\"Agata Foryciarz\"},{\"authorId\":\"40879549\",\"name\":\"M. Moradshahi\"},{\"authorId\":\"39682108\",\"name\":\"M. Lam\"}],\"doi\":\"10.18653/v1/2020.acl-main.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3d5bdfda2c5c841c2481f5da123b2c086e6f5c\",\"title\":\"Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking\",\"url\":\"https://www.semanticscholar.org/paper/ec3d5bdfda2c5c841c2481f5da123b2c086e6f5c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7c75b16563d07069505cd07dd6466d86f6958f9\",\"title\":\"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/e7c75b16563d07069505cd07dd6466d86f6958f9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.13160\",\"authors\":[{\"authorId\":\"145251354\",\"name\":\"Xin Hong\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"48537499\",\"name\":\"Liang Pang\"},{\"authorId\":\"70414094\",\"name\":\"J. Guo\"},{\"authorId\":\"30857876\",\"name\":\"Xueqi Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"825363a518902f3e44d61bd9a10262d0e527be60\",\"title\":\"Transformation Driven Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/825363a518902f3e44d61bd9a10262d0e527be60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.11278\",\"authors\":[{\"authorId\":\"2706729\",\"name\":\"Jaemin Cho\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.707\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"title\":\"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2006.05726\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7454abbee8f92dd0fd893c8039c03d66e9a5f032\",\"title\":\"Estimating semantic structure for the VQA answer space\",\"url\":\"https://www.semanticscholar.org/paper/7454abbee8f92dd0fd893c8039c03d66e9a5f032\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362476\",\"name\":\"Liming Zhan\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"145451510\",\"name\":\"L. Fan\"},{\"authorId\":\"145905368\",\"name\":\"Jiaxin Chen\"},{\"authorId\":\"1772198\",\"name\":\"X. Wu\"}],\"doi\":\"10.1145/3394171.3413761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8d5b853f2212cbb48a43f1edec9b96d76d388ec\",\"title\":\"Medical Visual Question Answering via Conditional Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/b8d5b853f2212cbb48a43f1edec9b96d76d388ec\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48499775\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.01246\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7147091d3ce4f2e766fe57700fd891bd01d8ae40\",\"title\":\"Webly Supervised Knowledge Embedding Model for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7147091d3ce4f2e766fe57700fd891bd01d8ae40\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29072828\",\"name\":\"Seungwhan Moon\"},{\"authorId\":\"2162189\",\"name\":\"Pararth Shah\"},{\"authorId\":\"48822822\",\"name\":\"A. Kumar\"},{\"authorId\":\"1751070\",\"name\":\"Rajen Subba\"}],\"doi\":\"10.18653/v1/K19-1068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1ef6cc7800ea33a7527956363a46e95efc57fc5\",\"title\":\"Memory Graph Networks for Explainable Memory-grounded Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e1ef6cc7800ea33a7527956363a46e95efc57fc5\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"1803054\",\"name\":\"Shujie Liu\"},{\"authorId\":\"70362337\",\"name\":\"Heung-Yeung Shum\"}],\"doi\":\"10.1016/j.eng.2019.12.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3410e91c55ec78e4ec94b6a56897945e136d7cd8\",\"title\":\"Progress in Neural NLP: Modeling, Learning, and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/3410e91c55ec78e4ec94b6a56897945e136d7cd8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b01bc15919f72929d36fc0443395e97b632c81b8\",\"title\":\"CapWAP: Image Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/b01bc15919f72929d36fc0443395e97b632c81b8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.04264\",\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8ca71f61139c69131ab200368a30a3dc72fa6785\",\"title\":\"CapWAP: Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/8ca71f61139c69131ab200368a30a3dc72fa6785\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.06351\",\"authors\":[{\"authorId\":\"17866105\",\"name\":\"Fuli Luo\"},{\"authorId\":\"46709826\",\"name\":\"Pengcheng Yang\"},{\"authorId\":\"50341802\",\"name\":\"S. Li\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9b7620f9b9653ada1a7ce36b0d6617f5979fff2\",\"title\":\"CAPT: Contrastive Pre-Training for Learning Denoised Sequence Representations\",\"url\":\"https://www.semanticscholar.org/paper/d9b7620f9b9653ada1a7ce36b0d6617f5979fff2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47002278\",\"name\":\"Yikuan Li\"},{\"authorId\":\"51464971\",\"name\":\"Hanyin Wang\"},{\"authorId\":\"1830568527\",\"name\":\"Yuan Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"title\":\"A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports\",\"url\":\"https://www.semanticscholar.org/paper/ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06666\",\"authors\":[{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1932edb4e5b2aae30ec1e7344b16d6110f52ef4\",\"title\":\"VirTex: Learning Visual Representations from Textual Annotations\",\"url\":\"https://www.semanticscholar.org/paper/b1932edb4e5b2aae30ec1e7344b16d6110f52ef4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.05121\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221\",\"title\":\"Roses Are Red, Violets Are Blue... but Should Vqa Expect Them To?\",\"url\":\"https://www.semanticscholar.org/paper/95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.01655\",\"authors\":[{\"authorId\":\"2947115\",\"name\":\"Arjun Reddy Akula\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"1403907739\",\"name\":\"Yaser Al-Onaizan\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"},{\"authorId\":\"145732771\",\"name\":\"Siva Reddy\"}],\"doi\":\"10.18653/v1/2020.acl-main.586\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"title\":\"Words aren't enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4009206\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"33201965\",\"name\":\"Satyananda Kashyap\"},{\"authorId\":\"1410148565\",\"name\":\"Karina Kanjaria\"},{\"authorId\":\"40346984\",\"name\":\"Joy T. Wu\"},{\"authorId\":\"13403287\",\"name\":\"D. Ballah\"},{\"authorId\":\"1388126424\",\"name\":\"Adam Coy\"},{\"authorId\":\"2308391\",\"name\":\"Alexandros Karargyris\"},{\"authorId\":\"2230103\",\"name\":\"Yufan Guo\"},{\"authorId\":\"1768272818\",\"name\":\"David James Beymer\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"},{\"authorId\":\"80257800\",\"name\":\"Vandana Mukherjee\"}],\"doi\":\"10.18653/v1/2020.bionlp-1.6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"title\":\"Towards Visual Dialog for Radiology\",\"url\":\"https://www.semanticscholar.org/paper/6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"venue\":\"BioNLP\",\"year\":2020},{\"arxivId\":\"1908.08530\",\"authors\":[{\"authorId\":\"145499378\",\"name\":\"Weijie Su\"},{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"47746274\",\"name\":\"Y. Cao\"},{\"authorId\":\"48218753\",\"name\":\"B. Li\"},{\"authorId\":\"152309485\",\"name\":\"Lewei Lu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2527626c11a84f15709e943fbfa2356e19930e3b\",\"title\":\"VL-BERT: Pre-training of Generic Visual-Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/2527626c11a84f15709e943fbfa2356e19930e3b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bill Yuchen Lin\"},{\"authorId\":\"143977316\",\"name\":\"M. Shen\"},{\"authorId\":\"145303641\",\"name\":\"Yu Xing\"},{\"authorId\":\"1557324013\",\"name\":\"Pei Zhou\"},{\"authorId\":\"145201124\",\"name\":\"Xiang Ren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b7cb2e9d884427ef50b564d97d3fd403953afa6\",\"title\":\"COMMONGEN: Towards Generative Commonsense Reasoning via A Constrained Text Generation Challenge\",\"url\":\"https://www.semanticscholar.org/paper/8b7cb2e9d884427ef50b564d97d3fd403953afa6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.02174\",\"authors\":[{\"authorId\":\"3444866\",\"name\":\"Alessandro Suglia\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"34742006\",\"name\":\"Andrea Vanzo\"},{\"authorId\":\"2972920\",\"name\":\"E. Bastianelli\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143873430\",\"name\":\"S. Frank\"},{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"}],\"doi\":\"10.18653/V1/2020.ACL-MAIN.682\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"title\":\"CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2002.09758\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"145222654\",\"name\":\"Patrick Lewis\"},{\"authorId\":\"144105277\",\"name\":\"Wen-tau Yih\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55a3b36fd21dbbe9384ab3ba1bcf901235d95f47\",\"title\":\"Unsupervised Question Decomposition for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/55a3b36fd21dbbe9384ab3ba1bcf901235d95f47\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1912.07538\",\"authors\":[{\"authorId\":\"48189355\",\"name\":\"V. Agarwal\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/cvpr42600.2020.00971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"title\":\"Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing\",\"url\":\"https://www.semanticscholar.org/paper/d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.10094\",\"authors\":[{\"authorId\":\"2027617785\",\"name\":\"Anh-Cat Le-Ngo\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"},{\"authorId\":\"2867032\",\"name\":\"S. Rana\"},{\"authorId\":\"119971153\",\"name\":\"Sunil Gupta\"},{\"authorId\":\"49337894\",\"name\":\"S. Venkatesh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"684e40bc390a9478a325995ea360267d77e4ddaa\",\"title\":\"Logically Consistent Loss for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/684e40bc390a9478a325995ea360267d77e4ddaa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.13135\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"47527626\",\"name\":\"Peng Su\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"2011378\",\"name\":\"Z. Fu\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"title\":\"Contrastive Visual-Linguistic Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03755\",\"authors\":[{\"authorId\":\"27549522\",\"name\":\"Goonmeet Bajaj\"},{\"authorId\":\"153100367\",\"name\":\"B. Bandyopadhyay\"},{\"authorId\":\"144545992\",\"name\":\"D. Schmidt\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"32264523\",\"name\":\"Christopher W. Myers\"},{\"authorId\":\"143724543\",\"name\":\"S. Parthasarathy\"}],\"doi\":\"10.1109/CVPRW50498.2020.00201\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"title\":\"Understanding Knowledge Gaps in Visual Question Answering: Implications for Gap Identification and Testing\",\"url\":\"https://www.semanticscholar.org/paper/e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TIP.2020.3034494\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"title\":\"Learning Dual Encoding Model for Adaptive Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102052663\",\"name\":\"V. Ng\"},{\"authorId\":\"49113957\",\"name\":\"X. Wan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfba0ff16edfcca0a509a3ddf2d91445a563b81f\",\"title\":\"Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/bfba0ff16edfcca0a509a3ddf2d91445a563b81f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.01629\",\"authors\":[{\"authorId\":\"145498819\",\"name\":\"P. Wang\"},{\"authorId\":\"47417383\",\"name\":\"Dongyang Liu\"},{\"authorId\":\"144462039\",\"name\":\"H. Li\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1145/3394171.3413905\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a08274632296de2f98d11180ce3e2b06776a3a0\",\"title\":\"Give Me Something to Eat: Referring Expression Comprehension with Commonsense Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3a08274632296de2f98d11180ce3e2b06776a3a0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.13962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01276\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"title\":\"Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text\",\"url\":\"https://www.semanticscholar.org/paper/c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.11475\",\"authors\":[{\"authorId\":\"48729196\",\"name\":\"Weijiang Yu\"},{\"authorId\":\"150167685\",\"name\":\"Jingwen Zhou\"},{\"authorId\":\"23476952\",\"name\":\"Weihao Yu\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"1730284\",\"name\":\"N. Xiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef318e7ff0883e72d853c75736d20cc123b556d5\",\"title\":\"Heterogeneous Graph Learning for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/ef318e7ff0883e72d853c75736d20cc123b556d5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51126032\",\"name\":\"Zhuoqian Yang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"119883554\",\"name\":\"J. Yu\"},{\"authorId\":null,\"name\":\"Zengchang Qin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"490a9ee7c995140136d2c5054081c08429ebc171\",\"title\":\"Scene Graph Reasoning with Prior Visual Relationship for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/490a9ee7c995140136d2c5054081c08429ebc171\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.02315\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.01045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"title\":\"12-in-1: Multi-Task Vision and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.08539\",\"authors\":[{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"152462956\",\"name\":\"D. Gordon\"},{\"authorId\":\"151492449\",\"name\":\"T. Nguyen\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d27eca39a42d1bf618c827f5472d58a8423c5568\",\"title\":\"What Can You Learn from Your Muscles? Learning Visual Representation from Human Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d27eca39a42d1bf618c827f5472d58a8423c5568\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.13406\",\"authors\":[{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"97671685\",\"name\":\"H. Wu\"},{\"authorId\":\"51135899\",\"name\":\"Yi Ren Fung\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1904c5389a70a905019d5429f09bc7f669bdc898\",\"title\":\"Learning from Lexical Perturbations for Consistent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1904c5389a70a905019d5429f09bc7f669bdc898\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.04790\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"152422011\",\"name\":\"Aravind Mohan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"1389630028\",\"name\":\"Davide Testuggine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51b461040c381cb1489e55ea4b9686c709818b10\",\"title\":\"The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes\",\"url\":\"https://www.semanticscholar.org/paper/51b461040c381cb1489e55ea4b9686c709818b10\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2004.00436\",\"authors\":[{\"authorId\":\"51222844\",\"name\":\"Sherif Abdelkarim\"},{\"authorId\":\"22199114\",\"name\":\"Panos Achlioptas\"},{\"authorId\":\"34060310\",\"name\":\"Jiaji Huang\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"2244184\",\"name\":\"Kenneth Ward Church\"},{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5dfbc9692bff0d3252d6de51435b889786e0f541\",\"title\":\"Long-tail Visual Relationship Recognition with a Visiolinguistic Hubless Loss\",\"url\":\"https://www.semanticscholar.org/paper/5dfbc9692bff0d3252d6de51435b889786e0f541\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":152282269,\"doi\":\"10.1109/CVPR.2019.00686\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":40,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"references\":[{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1701.02426\",\"authors\":[{\"authorId\":\"2068265\",\"name\":\"Danfei Xu\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"15239369\",\"name\":\"Christopher B. Choy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.330\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"34b73c1aa158b892bbe41705b4ae5bf01ecaea86\",\"title\":\"Scene Graph Generation by Iterative Message Passing\",\"url\":\"https://www.semanticscholar.org/paper/34b73c1aa158b892bbe41705b4ae5bf01ecaea86\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1803.03067\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"289fb3709475f5c87df8d97f129af54029d27fee\",\"title\":\"Compositional Attention Networks for Machine Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/289fb3709475f5c87df8d97f129af54029d27fee\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2427104\",\"name\":\"M. Huzak\"}],\"doi\":\"10.1007/978-3-642-04898-2_637\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"865739fded6d2902aeb5d1fce4579e9ff083353e\",\"title\":\"Chi-Square Distribution\",\"url\":\"https://www.semanticscholar.org/paper/865739fded6d2902aeb5d1fce4579e9ff083353e\",\"venue\":\"International Encyclopedia of Statistical Science\",\"year\":2011},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2011.5995347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0302bb2d5476540cfb21467473f5eca843caf90b\",\"title\":\"Unbiased look at dataset bias\",\"url\":\"https://www.semanticscholar.org/paper/0302bb2d5476540cfb21467473f5eca843caf90b\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1802.08129\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2018.00915\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"title\":\"Multimodal Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145835048\",\"name\":\"Y. Attali\"},{\"authorId\":\"1402109386\",\"name\":\"Maya Bar-Hillel\"}],\"doi\":\"10.1111/J.1745-3984.2003.TB01099.X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb272ea7d7b998914d75f47711a41f2b6bc3a670\",\"title\":\"Guess Where: The Position of Correct Answers in Multiple-Choice Test Items as a Psychometric Variable\",\"url\":\"https://www.semanticscholar.org/paper/eb272ea7d7b998914d75f47711a41f2b6bc3a670\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1603.06059\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.18653/v1/P16-1170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"title\":\"Generating Natural Questions About an Image\",\"url\":\"https://www.semanticscholar.org/paper/8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4445815\",\"name\":\"Jeffery J. Mondak\"},{\"authorId\":\"36705464\",\"name\":\"B. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f1a8acc43cf09b184c15f5f2b6dea2309ecf7a2\",\"title\":\"Asked and Answered: Knowledge Levels When We Won\\u2019t Take \\u201cDon\\u2019t Know\\u201d for an Answer\",\"url\":\"https://www.semanticscholar.org/paper/8f1a8acc43cf09b184c15f5f2b6dea2309ecf7a2\",\"venue\":\"\",\"year\":2000},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144194300\",\"name\":\"J. Millman\"},{\"authorId\":\"33976457\",\"name\":\"C. Bishop\"},{\"authorId\":\"30200176\",\"name\":\"Robert L. Ebel\"}],\"doi\":\"10.1177/001316446502500304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2dd6cbcdcbab554b4f1a98d29c892bdedc08a58\",\"title\":\"An Analysis of Test-Wiseness\",\"url\":\"https://www.semanticscholar.org/paper/a2dd6cbcdcbab554b4f1a98d29c892bdedc08a58\",\"venue\":\"\",\"year\":1965},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Anderson\"},{\"authorId\":null,\"name\":\"X. He\"},{\"authorId\":null,\"name\":\"C. Buehler\"},{\"authorId\":null,\"name\":\"D. Teney\"},{\"authorId\":null,\"name\":\"M. Johnson\"},{\"authorId\":null,\"name\":\"S. Gould\"},{\"authorId\":null,\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VQA : Visual question answer\",\"url\":\"\",\"venue\":\"International Journal of Computer Vision\",\"year\":null},{\"arxivId\":\"1612.06530\",\"authors\":[{\"authorId\":\"144738967\",\"name\":\"S. Zhang\"},{\"authorId\":\"14564042\",\"name\":\"Lizhen Qu\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"2881049\",\"name\":\"Zhenglu Yang\"},{\"authorId\":\"8214269\",\"name\":\"Jiawan Zhang\"}],\"doi\":\"10.24963/ijcai.2017/592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0f61fa2ae931eb001214b60c6391966ddb41123\",\"title\":\"Automatic Generation of Grounded Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/b0f61fa2ae931eb001214b60c6391966ddb41123\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Is the fence behind the gate both brown and metallic? no VQA 1. What are the yellow lines called? 2\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Lu\"},{\"authorId\":null,\"name\":\"S. Antol\"},{\"authorId\":null,\"name\":\"M. Mitchell\"},{\"authorId\":null,\"name\":\"C. L. Zitnick\"},{\"authorId\":null,\"name\":\"D. Parikh\"},{\"authorId\":null,\"name\":\"D. Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VQA : Visual question answer\",\"url\":\"\",\"venue\":\"International Journal of Computer Vision\",\"year\":null},{\"arxivId\":\"1705.00601\",\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.18653/v1/D17-1097\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"title\":\"The Promise of Premise: Harnessing Question Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"16282696\",\"name\":\"Marisa A Stark\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85ae705ef4353c6854f5be4a4664269d6317c66b\",\"title\":\"Image retrieval using scene graphs\",\"url\":\"https://www.semanticscholar.org/paper/85ae705ef4353c6854f5be4a4664269d6317c66b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1609.05600\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.344\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7d007ba376faddf0046930ea7375ed59600cee9\",\"title\":\"Graph-Structured Representations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c7d007ba376faddf0046930ea7375ed59600cee9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Teney\"},{\"authorId\":null,\"name\":\"L. Liu\"},{\"authorId\":null,\"name\":\"A. van den Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graphstructured representations for visual question answering\",\"url\":\"\",\"venue\":\"arXiv preprint,\",\"year\":2017},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1829696\",\"name\":\"Y. Rubner\"},{\"authorId\":\"145086151\",\"name\":\"Carlo Tomasi\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1023/A:1026543900054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d13a04844e4a781e5180987118f732d93aa9f398\",\"title\":\"The Earth Mover's Distance as a Metric for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d13a04844e4a781e5180987118f732d93aa9f398\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D Teney\"},{\"authorId\":null,\"name\":\"P Anderson\"},{\"authorId\":null,\"name\":\"X He\"},{\"authorId\":null,\"name\":\"A Van Den\"},{\"authorId\":null,\"name\":\"Hengel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Tips and tricks for visual question answering\",\"url\":\"\",\"venue\":\"Learnings from the 2017 challenge\",\"year\":2017},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1503.01817\",\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"118220290\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/2812802\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"title\":\"YFCC100M: the new data in multimedia research\",\"url\":\"https://www.semanticscholar.org/paper/354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"venue\":\"Commun. ACM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6e695ddd07aad719001c0fc1129328452385949\",\"title\":\"The New Data and New Challenges in Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/a6e695ddd07aad719001c0fc1129328452385949\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144096985\",\"name\":\"G. Miller\"}],\"doi\":\"10.1145/219717.219748\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68c03788224000794d5491ab459be0b2a2c38677\",\"title\":\"WordNet: a lexical database for English\",\"url\":\"https://www.semanticscholar.org/paper/68c03788224000794d5491ab459be0b2a2c38677\",\"venue\":\"CACM\",\"year\":1995},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016}],\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Silo (dataset)\",\"topicId\":\"130506\",\"url\":\"https://www.semanticscholar.org/topic/130506\"},{\"topic\":\"Scene graph\",\"topicId\":\"382302\",\"url\":\"https://www.semanticscholar.org/topic/382302\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"Next-generation network\",\"topicId\":\"40718\",\"url\":\"https://www.semanticscholar.org/topic/40718\"},{\"topic\":\"Plausibility structure\",\"topicId\":\"294239\",\"url\":\"https://www.semanticscholar.org/topic/294239\"},{\"topic\":\"Reasoning - publishing subsection\",\"topicId\":\"450845\",\"url\":\"https://www.semanticscholar.org/topic/450845\"},{\"topic\":\"Smoothing (statistical technique)\",\"topicId\":\"561463\",\"url\":\"https://www.semanticscholar.org/topic/561463\"}],\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"