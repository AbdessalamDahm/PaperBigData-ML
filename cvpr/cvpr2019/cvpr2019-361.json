"{\"abstract\":\"Human speech is often accompanied by hand and arm gestures. We present a method for cross-modal translation from \\\"in-the-wild\\\" monologue speech of a single speaker to their conversational gesture motion. We train on unlabeled videos for which we only have noisy pseudo ground truth from an automatic pose detection system. Our proposed model significantly outperforms baseline methods in a quantitative comparison. To support research toward obtaining a computational understanding of the relationship between gesture and speech, we release a large video dataset of person-specific gestures.\",\"arxivId\":\"1906.04160\",\"authors\":[{\"authorId\":\"2361255\",\"name\":\"Shiry Ginosar\",\"url\":\"https://www.semanticscholar.org/author/2361255\"},{\"authorId\":\"48319922\",\"name\":\"A. Bar\",\"url\":\"https://www.semanticscholar.org/author/48319922\"},{\"authorId\":\"51169014\",\"name\":\"Gefen Kohavi\",\"url\":\"https://www.semanticscholar.org/author/51169014\"},{\"authorId\":\"1715365\",\"name\":\"C. Chan\",\"url\":\"https://www.semanticscholar.org/author/1715365\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\",\"url\":\"https://www.semanticscholar.org/author/144956994\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\",\"url\":\"https://www.semanticscholar.org/author/143751119\"}],\"citationVelocity\":24,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717035\",\"name\":\"Simon Alexanderson\"},{\"authorId\":\"2763884\",\"name\":\"G. Henter\"},{\"authorId\":\"145372964\",\"name\":\"Taras Kucherenko\"},{\"authorId\":\"1826819\",\"name\":\"J. Beskow\"}],\"doi\":\"10.1111/cgf.13946\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b48f1a8a99a64346232e4ebb9e4105aeb62a81a2\",\"title\":\"Style\\u2010Controllable Speech\\u2010Driven Gesture Synthesis Using Normalising Flows\",\"url\":\"https://www.semanticscholar.org/paper/b48f1a8a99a64346232e4ebb9e4105aeb62a81a2\",\"venue\":\"Comput. Graph. Forum\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48946664\",\"name\":\"G. Ali\"},{\"authorId\":\"1647576304\",\"name\":\"Myungho Lee\"},{\"authorId\":\"2151594\",\"name\":\"Jae-In Hwang\"}],\"doi\":\"10.1002/cav.1944\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46fadc2f4fe1e65527c9e5969a1e32ca32ecb72f\",\"title\":\"Automatic text\\u2010to\\u2010gesture rule generation for embodied conversational agents\",\"url\":\"https://www.semanticscholar.org/paper/46fadc2f4fe1e65527c9e5969a1e32ca32ecb72f\",\"venue\":\"Comput. Animat. Virtual Worlds\",\"year\":2020},{\"arxivId\":\"2008.12405\",\"authors\":[{\"authorId\":\"119739494\",\"name\":\"Ben Saunders\"},{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61ff9694321710cac36b3822bcc08a28df6240c\",\"title\":\"Adversarial Training for Multi-Channel Sign Language Production\",\"url\":\"https://www.semanticscholar.org/paper/e61ff9694321710cac36b3822bcc08a28df6240c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14874\",\"authors\":[{\"authorId\":\"119739494\",\"name\":\"Ben Saunders\"},{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1007/978-3-030-58621-8_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0384839a338dee011dab5fe6de3805e17121b0f\",\"title\":\"Progressive Transformers for End-to-End Sign Language Production\",\"url\":\"https://www.semanticscholar.org/paper/c0384839a338dee011dab5fe6de3805e17121b0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.05070\",\"authors\":[{\"authorId\":\"2966240\",\"name\":\"Jianren Wang\"},{\"authorId\":\"152922969\",\"name\":\"Z. Fang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"}],\"doi\":\"10.1109/WACV45572.2020.9093345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b646b1845152652f3665bfdeb2f87448d4acc19b\",\"title\":\"AlignNet: A Unifying Approach to Audio-Visual Alignment\",\"url\":\"https://www.semanticscholar.org/paper/b646b1845152652f3665bfdeb2f87448d4acc19b\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430725\",\"name\":\"Ylva Ferstl\"},{\"authorId\":\"143687087\",\"name\":\"M. Neff\"},{\"authorId\":\"145795454\",\"name\":\"R. McDonnell\"}],\"doi\":\"10.1145/3359566.3360053\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e08f7b8ea538639afda07cc9caa2ded2c933b099\",\"title\":\"Multi-objective adversarial gesture generation\",\"url\":\"https://www.semanticscholar.org/paper/e08f7b8ea538639afda07cc9caa2ded2c933b099\",\"venue\":\"MIG\",\"year\":2019},{\"arxivId\":\"2011.01114\",\"authors\":[{\"authorId\":\"73771369\",\"name\":\"Prateek Manocha\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6873eb283ff1349db303dd79cc4bbb20fea99296\",\"title\":\"Facial Keypoint Sequence Generation from Audio\",\"url\":\"https://www.semanticscholar.org/paper/6873eb283ff1349db303dd79cc4bbb20fea99296\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.07011\",\"authors\":[{\"authorId\":\"144810140\",\"name\":\"J. H. Christensen\"},{\"authorId\":\"3013806\",\"name\":\"Sascha Hornauer\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"}],\"doi\":\"10.1109/ICRA40945.2020.9196934\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d041600fa596a7d63c633cd976f01b16587fbdb1\",\"title\":\"BatVision: Learning to See 3D Spatial Layout with Two Ears\",\"url\":\"https://www.semanticscholar.org/paper/d041600fa596a7d63c633cd976f01b16587fbdb1\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2007.04687\",\"authors\":[{\"authorId\":\"2678268\",\"name\":\"P. Wu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"9754502\",\"name\":\"Yujia Shi\"},{\"authorId\":\"5264927\",\"name\":\"Yujia Sun\"},{\"authorId\":\"1802542506\",\"name\":\"Fangtao Shao\"},{\"authorId\":\"48551946\",\"name\":\"Zhaoyang Wu\"},{\"authorId\":\"40615725\",\"name\":\"Zhiwei Yang\"}],\"doi\":\"10.1007/978-3-030-58577-8_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f28873be3601c5a2736996eba543cf51950a381\",\"title\":\"Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/8f28873be3601c5a2736996eba543cf51950a381\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978787902\",\"name\":\"Victor G. O. M. Nicola\"},{\"authorId\":\"2520689\",\"name\":\"R. B. Madeo\"},{\"authorId\":\"2125066\",\"name\":\"S. M. Peres\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206743\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34fbfe942311d112822b49c58dc8ca60c254380a\",\"title\":\"Systematic study on dimensionality reduction in the gesture phase segmentation problem\",\"url\":\"https://www.semanticscholar.org/paper/34fbfe942311d112822b49c58dc8ca60c254380a\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2010.06194\",\"authors\":[{\"authorId\":\"1789820\",\"name\":\"N. Wake\"},{\"authorId\":\"9000389\",\"name\":\"M. Sato\"},{\"authorId\":\"1882605\",\"name\":\"Kazuhiro Sasabuchi\"},{\"authorId\":\"1500391189\",\"name\":\"Minako Nakamura\"},{\"authorId\":\"66117417\",\"name\":\"K. Ikeuchi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65497441b0d644e6b09c4cad768fd0b7781301e6\",\"title\":\"Labeling the Phrase Set of the Conversation Agent, Rinna\",\"url\":\"https://www.semanticscholar.org/paper/65497441b0d644e6b09c4cad768fd0b7781301e6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.03201\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"4942685\",\"name\":\"G. Cui\"},{\"authorId\":\"16132631\",\"name\":\"Z. Kou\"},{\"authorId\":\"2743695\",\"name\":\"Haitian Zheng\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b63a9dc18baf645b4766b2b2ec8461c2c843275a\",\"title\":\"What comprises a good talking-head video generation?: A Survey and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/b63a9dc18baf645b4766b2b2ec8461c2c843275a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR42600.2020.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"title\":\"Music Gesture for Visual Sound Separation\",\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.03478\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"866ba646300961747ddc29ce57153858e2be588a\",\"title\":\"Multi-Instrumentalist Net: Unsupervised Generation of Music from Body Movements\",\"url\":\"https://www.semanticscholar.org/paper/866ba646300961747ddc29ce57153858e2be588a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202217\",\"name\":\"I. Habibie\"},{\"authorId\":\"2470018\",\"name\":\"WeiPeng Xu\"},{\"authorId\":\"39503308\",\"name\":\"Dushyant Mehta\"},{\"authorId\":\"46458089\",\"name\":\"Lingjie Liu\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"1403428213\",\"name\":\"Gerard Pons-Moll\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1afeacdae33129e84406ee2ed635fd81ae6efa7\",\"title\":\"Learning Speech-driven 3D Conversational Gestures from Video\",\"url\":\"https://www.semanticscholar.org/paper/b1afeacdae33129e84406ee2ed635fd81ae6efa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.12287\",\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"7996087\",\"name\":\"Hanbyul Joo\"},{\"authorId\":\"2361255\",\"name\":\"Shiry Ginosar\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1384c31c9b2780eee16b1ef6bb66cfdeac88cf1\",\"title\":\"Body2Hands: Learning to Infer 3D Hands from Conversational Gesture Body Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/a1384c31c9b2780eee16b1ef6bb66cfdeac88cf1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09198\",\"authors\":[{\"authorId\":\"46840906\",\"name\":\"Miao Liao\"},{\"authorId\":\"144268595\",\"name\":\"Sibo Zhang\"},{\"authorId\":\"1585288737\",\"name\":\"Peng Wang\"},{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"a0b4f6f589a4e37d5d652968110b43816574175a\",\"title\":\"Personalized Speech2Video with 3D Skeleton Regularization and Expressive Body Poses\",\"url\":\"https://www.semanticscholar.org/paper/a0b4f6f589a4e37d5d652968110b43816574175a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.07816\",\"authors\":[{\"authorId\":\"51038715\",\"name\":\"Y. Lin\"},{\"authorId\":\"8665310\",\"name\":\"H. Kao\"},{\"authorId\":\"1944621645\",\"name\":\"Yih-Chih Tseng\"},{\"authorId\":\"144090142\",\"name\":\"M. Tsai\"},{\"authorId\":\"2448188\",\"name\":\"Li Su\"}],\"doi\":\"10.1145/3394171.3413921\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1e36672c791f79d674acefe9d7dfeb827697db5\",\"title\":\"A Human-Computer Duet System for Music Performance\",\"url\":\"https://www.semanticscholar.org/paper/f1e36672c791f79d674acefe9d7dfeb827697db5\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736448\",\"name\":\"Ryo Ishii\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"1718158\",\"name\":\"Yukiko I. Nakano\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3383652.3423908\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97bcea32979ed602fd404448a4e4cedad4171d79\",\"title\":\"Impact of Personality on Nonverbal Behavior Generation\",\"url\":\"https://www.semanticscholar.org/paper/97bcea32979ed602fd404448a4e4cedad4171d79\",\"venue\":\"IVA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028615681\",\"name\":\"Swapna Agarwal\"},{\"authorId\":\"143790066\",\"name\":\"Dipanjan Das\"},{\"authorId\":\"3262263\",\"name\":\"B. Bhowmick\"}],\"doi\":\"10.23919/Eusipco47968.2020.9287778\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0389de79f650ee66f891cb7070478f4e80a9cc33\",\"title\":\"Realistic Lip Animation from Speech for Unseen Subjects using Few-shot Cross-modal Learning\",\"url\":\"https://www.semanticscholar.org/paper/0389de79f650ee66f891cb7070478f4e80a9cc33\",\"venue\":\"2020 28th European Signal Processing Conference (EUSIPCO)\",\"year\":2021},{\"arxivId\":\"2001.04463\",\"authors\":[{\"authorId\":\"151500851\",\"name\":\"K. Deng\"},{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"title\":\"Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12999\",\"authors\":[{\"authorId\":\"143778670\",\"name\":\"J. P. Ferreira\"},{\"authorId\":\"2029248405\",\"name\":\"Thiago M. Coutinho\"},{\"authorId\":\"144012660\",\"name\":\"Thiago L. Gomes\"},{\"authorId\":\"35151106\",\"name\":\"J. F. Neto\"},{\"authorId\":\"2599699\",\"name\":\"R. Azevedo\"},{\"authorId\":\"144190194\",\"name\":\"Renato Martins\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1016/j.cag.2020.09.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"833b66d4636636b79ef86ed7b27733a88f4e0c3e\",\"title\":\"Learning to dance: A graph convolutional adversarial network to generate realistic dance motions from audio\",\"url\":\"https://www.semanticscholar.org/paper/833b66d4636636b79ef86ed7b27733a88f4e0c3e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.15327\",\"authors\":[{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"122024152\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"title\":\"Compositional Video Synthesis with Action Graphs\",\"url\":\"https://www.semanticscholar.org/paper/cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"1576511129\",\"name\":\"Zhong Cao\"},{\"authorId\":\"2782958\",\"name\":\"Weishen Pan\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1724003\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/TMM.2019.2960700\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd47c05f454a3c3980a6c623201db45acb08a70c\",\"title\":\"Deep Gesture Video Generation With Learning on Regions of Interest\",\"url\":\"https://www.semanticscholar.org/paper/dd47c05f454a3c3980a6c623201db45acb08a70c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2002.03761\",\"authors\":[{\"authorId\":\"51053524\",\"name\":\"W. Zhuang\"},{\"authorId\":\"50096299\",\"name\":\"C. Wang\"},{\"authorId\":\"50019156\",\"name\":\"Si-Yu Xia\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"},{\"authorId\":null,\"name\":\"Yangang Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4e98221a5d14d30618d1b15295261cf6123cc907\",\"title\":\"Music2Dance: DanceNet for Music-driven Dance Generation\",\"url\":\"https://www.semanticscholar.org/paper/4e98221a5d14d30618d1b15295261cf6123cc907\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"152496368\",\"name\":\"Dong Won Lee\"},{\"authorId\":\"1500659510\",\"name\":\"Ryo Ishii\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.170\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d5924c8cdef6270a955ba82c2b07a8282d869744\",\"title\":\"No Gestures Left Behind: Learning Relationships between Spoken Language and Freeform Gestures\",\"url\":\"https://www.semanticscholar.org/paper/d5924c8cdef6270a955ba82c2b07a8282d869744\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"70659697\",\"name\":\"M. Mendiratta\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"9102722\",\"name\":\"A. Tewari\"},{\"authorId\":\"2019625111\",\"name\":\"Vladislav Golyanik\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/3414685.3417808\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0024d00985ed1e64b274cec37dbfc81f03a23d1b\",\"title\":\"Egocentric videoconferencing\",\"url\":\"https://www.semanticscholar.org/paper/0024d00985ed1e64b274cec37dbfc81f03a23d1b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2007.09170\",\"authors\":[{\"authorId\":\"145372964\",\"name\":\"Taras Kucherenko\"},{\"authorId\":\"1745025\",\"name\":\"D. Hasegawa\"},{\"authorId\":\"6965816\",\"name\":\"N. Kaneko\"},{\"authorId\":\"2763884\",\"name\":\"G. Henter\"},{\"authorId\":\"9167315\",\"name\":\"Hedvig Kjellstrom\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"992572fcdd4f637972319816d2b0fb707f6852ec\",\"title\":\"Moving fast and slow: Analysis of representations and post-processing in speech-driven automatic gesture generation\",\"url\":\"https://www.semanticscholar.org/paper/992572fcdd4f637972319816d2b0fb707f6852ec\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430725\",\"name\":\"Ylva Ferstl\"},{\"authorId\":\"143687087\",\"name\":\"M. Neff\"},{\"authorId\":\"145795454\",\"name\":\"R. McDonnell\"}],\"doi\":\"10.1016/j.cag.2020.04.007\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6819ccbff6ac78ad15329726cb7649dc245f0a87\",\"title\":\"Adversarial gesture generation with realistic gesture phasing\",\"url\":\"https://www.semanticscholar.org/paper/6819ccbff6ac78ad15329726cb7649dc245f0a87\",\"venue\":\"Comput. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"1734731\",\"name\":\"P. Kumaraguru\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a593bf44e46bd4cb426c658ed87f4fce43f13aa\",\"title\":\"Lip-syncing Videos In The Wild\",\"url\":\"https://www.semanticscholar.org/paper/8a593bf44e46bd4cb426c658ed87f4fce43f13aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.14348\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6127cceb5847551cc09814a0d00cf63ba21b546\",\"title\":\"Audeo: Audio Generation for a Silent Performance Video\",\"url\":\"https://www.semanticscholar.org/paper/c6127cceb5847551cc09814a0d00cf63ba21b546\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2001.09326\",\"authors\":[{\"authorId\":\"145372964\",\"name\":\"Taras Kucherenko\"},{\"authorId\":\"2824339\",\"name\":\"Patrik Jonell\"},{\"authorId\":\"71582095\",\"name\":\"S. V. Waveren\"},{\"authorId\":\"2763884\",\"name\":\"G. Henter\"},{\"authorId\":\"1717035\",\"name\":\"Simon Alexanderson\"},{\"authorId\":\"39799707\",\"name\":\"I. Leite\"},{\"authorId\":\"9167315\",\"name\":\"Hedvig Kjellstrom\"}],\"doi\":\"10.1145/3382507.3418815\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"44789c64150f5fe0745bba51386edc3052a6ebac\",\"title\":\"Gesticulator: A framework for semantically-aware speech-driven gesture generation\",\"url\":\"https://www.semanticscholar.org/paper/44789c64150f5fe0745bba51386edc3052a6ebac\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"2004.12992\",\"authors\":[{\"authorId\":\"32025363\",\"name\":\"Yang Zhou\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"1399909799\",\"name\":\"Xintong Han\"},{\"authorId\":\"2808670\",\"name\":\"E. Kalogerakis\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"80452718\",\"name\":\"J. Echevarria\"}],\"doi\":\"10.1145/3414685.3417774\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"739497ec657d2c1e6ed7eb424951e0affe117be4\",\"title\":\"MakeItTalk: Speaker-Aware Talking Head Animation\",\"url\":\"https://www.semanticscholar.org/paper/739497ec657d2c1e6ed7eb424951e0affe117be4\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9acdb181238c3e8cc58ec6886cf0943519ccad2f\",\"title\":\"2D to 3D body pose estimation for sign language with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/9acdb181238c3e8cc58ec6886cf0943519ccad2f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"}],\"doi\":\"10.1145/3340555.3356090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae77189921ffade5ee4c4d4a0e93e879d7280b80\",\"title\":\"Coalescing Narrative and Dialogue for Grounded Pose Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/ae77189921ffade5ee4c4d4a0e93e879d7280b80\",\"venue\":\"ICMI\",\"year\":2019},{\"arxivId\":\"2010.00995\",\"authors\":[{\"authorId\":\"3430725\",\"name\":\"Ylva Ferstl\"},{\"authorId\":\"143687087\",\"name\":\"M. Neff\"},{\"authorId\":\"145795454\",\"name\":\"R. McDonnell\"}],\"doi\":\"10.1145/3383652.3423882\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1b0e07cd93332b64541118e66e5fb32ecd214c3\",\"title\":\"Understanding the Predictability of Gesture Parameters from Speech and their Perceptual Importance\",\"url\":\"https://www.semanticscholar.org/paper/d1b0e07cd93332b64541118e66e5fb32ecd214c3\",\"venue\":\"IVA\",\"year\":2020},{\"arxivId\":\"2009.08015\",\"authors\":[{\"authorId\":\"8665310\",\"name\":\"H. Kao\"},{\"authorId\":\"2448188\",\"name\":\"Li Su\"}],\"doi\":\"10.1145/3394171.3413848\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"daa00c142fdf25aa454d8ca52e4d20f5d0605964\",\"title\":\"Temporally Guided Music-to-Body-Movement Generation\",\"url\":\"https://www.semanticscholar.org/paper/daa00c142fdf25aa454d8ca52e4d20f5d0605964\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146372255\",\"name\":\"Caglar Gulcehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"83138063\",\"name\":\"Fethi\"},{\"authorId\":null,\"name\":\"Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425c8668e0add6a8966242a24da58bf2bb4aa5\",\"title\":\"Adversarial Training for Multi-Channel Sign Language Production\",\"url\":\"https://www.semanticscholar.org/paper/5f425c8668e0add6a8966242a24da58bf2bb4aa5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.12553\",\"authors\":[{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"52605659\",\"name\":\"Dong Won Lee\"},{\"authorId\":\"1718158\",\"name\":\"Yukiko I. Nakano\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1007/978-3-030-58523-5_15\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"6e78e32481218e9391a88e6d0e30c0062ae71bec\",\"title\":\"Style Transfer for Co-Speech Gesture Animation: A Multi-Speaker Conditional-Mixture Approach\",\"url\":\"https://www.semanticscholar.org/paper/6e78e32481218e9391a88e6d0e30c0062ae71bec\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3436376\",\"name\":\"Wim Pouw\"},{\"authorId\":\"1639322804\",\"name\":\"Alexandra Paxton\"},{\"authorId\":\"3462161\",\"name\":\"S. Harrison\"},{\"authorId\":\"3225718\",\"name\":\"J. Dixon\"}],\"doi\":\"10.1073/pnas.2004163117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ae93fd3580f7b5ecf0c04e02a546882906ba647\",\"title\":\"Acoustic information about upper limb movement in voicing\",\"url\":\"https://www.semanticscholar.org/paper/7ae93fd3580f7b5ecf0c04e02a546882906ba647\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46998556\",\"name\":\"Jens Nirme\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09422ad7788c00ed5df305c53910393877344df7\",\"title\":\"Understanding virtual speakers\",\"url\":\"https://www.semanticscholar.org/paper/09422ad7788c00ed5df305c53910393877344df7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.07643\",\"authors\":[{\"authorId\":\"32783220\",\"name\":\"Fajrian Yunus\"},{\"authorId\":\"153544348\",\"name\":\"C. Clavel\"},{\"authorId\":\"1703084\",\"name\":\"C. Pelachaud\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a9b07fc446dbb40e9d2ea00ab1ce5f94f94884f\",\"title\":\"Sequence-to-Sequence Predictive Model: From Prosody To Communicative Gestures\",\"url\":\"https://www.semanticscholar.org/paper/9a9b07fc446dbb40e9d2ea00ab1ce5f94f94884f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07931\",\"authors\":[{\"authorId\":\"134192555\",\"name\":\"J. F. Montesinos\"},{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":\"10.1109/MMSP48831.2020.9287124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"title\":\"Solos: A Dataset for Audio-Visual Music Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"2009.02119\",\"authors\":[{\"authorId\":\"145215929\",\"name\":\"Youngwoo Yoon\"},{\"authorId\":\"1658637513\",\"name\":\"Bok Cha\"},{\"authorId\":\"1520033283\",\"name\":\"Joo-Haeng Lee\"},{\"authorId\":\"145416765\",\"name\":\"M. Jang\"},{\"authorId\":\"51453783\",\"name\":\"Jaeyeon Lee\"},{\"authorId\":\"47964259\",\"name\":\"Jae-Hong Kim\"},{\"authorId\":\"1717371\",\"name\":\"Geehyuk Lee\"}],\"doi\":\"10.1145/3414685.3417838\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbaae3188aed31df77272c9f30d2b8faaa407939\",\"title\":\"Speech gesture generation from the trimodal context of text, audio, and speaker identity\",\"url\":\"https://www.semanticscholar.org/paper/bbaae3188aed31df77272c9f30d2b8faaa407939\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2007.08547\",\"authors\":[{\"authorId\":\"152875073\",\"name\":\"Lele Chen\"},{\"authorId\":\"4942685\",\"name\":\"G. Cui\"},{\"authorId\":\"9585133\",\"name\":\"Celong Liu\"},{\"authorId\":\"49969600\",\"name\":\"Z. Li\"},{\"authorId\":\"16132631\",\"name\":\"Z. Kou\"},{\"authorId\":\"92413558\",\"name\":\"Yi Xu\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58545-7_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7e40f631825034e474be5640e6ac9ed7a6917c7\",\"title\":\"Talking-head Generation with Rhythmic Head Motion\",\"url\":\"https://www.semanticscholar.org/paper/f7e40f631825034e474be5640e6ac9ed7a6917c7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09198\",\"authors\":[{\"authorId\":\"46840906\",\"name\":\"Miao Liao\"},{\"authorId\":\"144268595\",\"name\":\"Sibo Zhang\"},{\"authorId\":\"1585288737\",\"name\":\"Peng Wang\"},{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"2407738\",\"name\":\"Xinxin Zuo\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab58561f2646091e8f7dac5020fabfed9e74eab7\",\"title\":\"Speech2Video Synthesis with 3D Skeleton Regularization and Expressive Body Poses\",\"url\":\"https://www.semanticscholar.org/paper/ab58561f2646091e8f7dac5020fabfed9e74eab7\",\"venue\":\"\",\"year\":2020}],\"corpusId\":182952539,\"doi\":\"10.1109/CVPR.2019.00361\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e609684188c842092ae7bcae81429471e422df4d\",\"references\":[{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1145/1618452.1618518\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3878d1e9b4f6521b035388f5871bbcac6c44a008\",\"title\":\"Real-time prosody-driven synthesis of body language\",\"url\":\"https://www.semanticscholar.org/paper/3878d1e9b4f6521b035388f5871bbcac6c44a008\",\"venue\":\"SIGGRAPH 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104775158\",\"name\":\"Chet A. Creider\"}],\"doi\":\"10.1525/JLIN.1994.4.1.81\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d8740bbc94bdc1581d393d031addbb69e64065a1\",\"title\":\"Hand and Mind: What Gestures Reveal about Thought\",\"url\":\"https://www.semanticscholar.org/paper/d8740bbc94bdc1581d393d031addbb69e64065a1\",\"venue\":\"\",\"year\":1994},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"144867807\",\"name\":\"S. Thrun\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1145/1778765.1778861\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa6dac4ddb75f360f2925eb7a9a0719e05bbe3d4\",\"title\":\"Gesture controllers\",\"url\":\"https://www.semanticscholar.org/paper/fa6dac4ddb75f360f2925eb7a9a0719e05bbe3d4\",\"venue\":\"SIGGRAPH 2010\",\"year\":2010},{\"arxivId\":\"1712.09382\",\"authors\":[{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1411184751\",\"name\":\"Hayden Schoen\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1109/CVPR.2018.00790\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c6d60aaad68fa78c914ee34c26bceab033a88622\",\"title\":\"Audio to Body Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/c6d60aaad68fa78c914ee34c26bceab033a88622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145431806\",\"name\":\"J. Cassell\"}],\"doi\":\"10.7551/mitpress/2697.001.0001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7482fa49be14224dbe5297ee6b428810b589741\",\"title\":\"Embodied conversational agents\",\"url\":\"https://www.semanticscholar.org/paper/d7482fa49be14224dbe5297ee6b428810b589741\",\"venue\":\"\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"1739671\",\"name\":\"D. L. James\"}],\"doi\":\"10.1145/2601097.2601178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8795ec68ea209933f742a138c2b6fd8b18dff129\",\"title\":\"Inverse-Foley animation\",\"url\":\"https://www.semanticscholar.org/paper/8795ec68ea209933f742a138c2b6fd8b18dff129\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/TPAMI.2012.261\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9f04d907ba87261d4e46ed03dd7de0ec7a1a125f\",\"title\":\"Articulated Human Detection with Flexible Mixtures of Parts\",\"url\":\"https://www.semanticscholar.org/paper/9f04d907ba87261d4e46ed03dd7de0ec7a1a125f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/CVPR.2016.412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f56d232921fe7255beedd961a557007d54e31f0\",\"title\":\"Deep Hand: How to Train a CNN on 1 Million Hand Images When Your Data is Continuous and Weakly Labelled\",\"url\":\"https://www.semanticscholar.org/paper/3f56d232921fe7255beedd961a557007d54e31f0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"},{\"authorId\":\"1800748\",\"name\":\"M. Covell\"},{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"}],\"doi\":\"10.1145/258734.258880\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"title\":\"Video Rewrite: driving visual speech with audio\",\"url\":\"https://www.semanticscholar.org/paper/3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"venue\":\"SIGGRAPH '97\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145267380\",\"name\":\"P. Buehler\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"}],\"doi\":\"10.1109/CVPR.2009.5206523\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8876813ecffb5dbe92b3f781cb35a4fb822b871d\",\"title\":\"Learning sign language by watching TV (using weakly aligned subtitles)\",\"url\":\"https://www.semanticscholar.org/paper/8876813ecffb5dbe92b3f781cb35a4fb822b871d\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2096971\",\"name\":\"M. Thi\\u00e9baux\"},{\"authorId\":\"1788771\",\"name\":\"S. Marsella\"},{\"authorId\":\"2979549\",\"name\":\"A. N. Marshall\"},{\"authorId\":\"1682684\",\"name\":\"Marcelo Kallmann\"}],\"doi\":\"10.1145/1402383.1402409\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd3db64cb99c139aabb25a8bfa2770ac86c0a92\",\"title\":\"SmartBody: behavior realization for embodied conversational agents\",\"url\":\"https://www.semanticscholar.org/paper/abd3db64cb99c139aabb25a8bfa2770ac86c0a92\",\"venue\":\"AAMAS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"2417546\",\"name\":\"S. Hadfield\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/CVPR.2018.00812\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"644602c65a5d8f30e62be027eb7b47f7c335191a\",\"title\":\"Neural Sign Language Translation\",\"url\":\"https://www.semanticscholar.org/paper/644602c65a5d8f30e62be027eb7b47f7c335191a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3116662\",\"name\":\"J. Gemmeke\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"36794621\",\"name\":\"Dylan Freedman\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"39965499\",\"name\":\"W. Lawrence\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"39687627\",\"name\":\"M. Ritter\"}],\"doi\":\"10.1109/ICASSP.2017.7952261\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ba2218b708ca64ab556e39d5997202e012717d5\",\"title\":\"Audio Set: An ontology and human-labeled dataset for audio events\",\"url\":\"https://www.semanticscholar.org/paper/5ba2218b708ca64ab556e39d5997202e012717d5\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"145682405\",\"name\":\"J. Charles\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-16865-4_35\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5df5cd86d69a65c981494b5bd416c85038b473a\",\"title\":\"Deep Convolutional Neural Networks for Efficient Pose Estimation in Gesture Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5df5cd86d69a65c981494b5bd416c85038b473a\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145039780\",\"name\":\"Chung-Cheng Chiu\"},{\"authorId\":\"1788771\",\"name\":\"S. Marsella\"}],\"doi\":\"10.1007/978-3-642-23974-8_14\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"73aa64024b6311ecae5292e16d5538632f5d2c77\",\"title\":\"How to Train Your Avatar: A Data Driven Approach to Gesture Generation\",\"url\":\"https://www.semanticscholar.org/paper/73aa64024b6311ecae5292e16d5538632f5d2c77\",\"venue\":\"IVA\",\"year\":2011},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740663\",\"name\":\"Francis K. H. Quek\"},{\"authorId\":\"145493778\",\"name\":\"D. McNeill\"},{\"authorId\":\"2387793\",\"name\":\"R. Bryll\"},{\"authorId\":\"144346436\",\"name\":\"Susan Duncan\"},{\"authorId\":\"3073990\",\"name\":\"X. Ma\"},{\"authorId\":\"2156795\",\"name\":\"C. Kirbas\"},{\"authorId\":\"2660294\",\"name\":\"K. E. McCullough\"},{\"authorId\":\"143806517\",\"name\":\"R. Ansari\"}],\"doi\":\"10.1145/568513.568514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23175b146edaf762c446b245f4b1d82af41ade13\",\"title\":\"Multimodal human discourse: gesture and speech\",\"url\":\"https://www.semanticscholar.org/paper/23175b146edaf762c446b245f4b1d82af41ade13\",\"venue\":\"TCHI\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145572314\",\"name\":\"B. Butterworth\"},{\"authorId\":\"2509147\",\"name\":\"U. Hadar\"}],\"doi\":\"10.1037//0033-295x.96.1.168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0d1368fb0ba66bf2021bf468f0fd85483c24b73\",\"title\":\"Gesture, speech, and computational stages: a reply to McNeill.\",\"url\":\"https://www.semanticscholar.org/paper/d0d1368fb0ba66bf2021bf468f0fd85483c24b73\",\"venue\":\"Psychological review\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50191878\",\"name\":\"W. C. So\"},{\"authorId\":\"2440683\",\"name\":\"S. Kita\"},{\"authorId\":\"115377287\",\"name\":\"S. Goldin-Meadow\"}],\"doi\":\"10.1111/J.1551-6709.2008.01006.X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb58cc404f42281133c0078e37838757c1491e82\",\"title\":\"Using the Hands to Identify Who Does What to Whom: Gesture and Speech Go Hand-in-Hand\",\"url\":\"https://www.semanticscholar.org/paper/bb58cc404f42281133c0078e37838757c1491e82\",\"venue\":\"Cogn. Sci.\",\"year\":2009},{\"arxivId\":\"1609.09430\",\"authors\":[{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"1680841\",\"name\":\"S. Chaudhuri\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"3116662\",\"name\":\"J. Gemmeke\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"47380012\",\"name\":\"D. Platt\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"12812321\",\"name\":\"K. Wilson\"}],\"doi\":\"10.1109/ICASSP.2017.7952132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59d8c68de09da69a608ceb149f40114f5538c5b1\",\"title\":\"CNN architectures for large-scale audio classification\",\"url\":\"https://www.semanticscholar.org/paper/59d8c68de09da69a608ceb149f40114f5538c5b1\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145431806\",\"name\":\"J. Cassell\"},{\"authorId\":\"145493778\",\"name\":\"D. McNeill\"},{\"authorId\":\"145588979\",\"name\":\"K. Mccullough\"}],\"doi\":\"10.1075/PC.7.1.03CAS\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"654f385272f0e1e7d9e4dd0dd56e519421e51668\",\"title\":\"Speech-gesture mismatches: Evidence for one underlying representation of linguistic and nonlinguistic information\",\"url\":\"https://www.semanticscholar.org/paper/654f385272f0e1e7d9e4dd0dd56e519421e51668\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49496994\",\"name\":\"A. Kendon\"}],\"doi\":\"10.5860/choice.42-5687\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fa55b0b6c37558c985331f05a98f320449e8f9d7\",\"title\":\"Gesture: Visible Action as Utterance\",\"url\":\"https://www.semanticscholar.org/paper/fa55b0b6c37558c985331f05a98f320449e8f9d7\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37016781\",\"name\":\"Supasorn Suwajanakorn\"},{\"authorId\":\"1396612598\",\"name\":\"Steven M. Seitz\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1145/3072959.3073640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"title\":\"Synthesizing Obama\",\"url\":\"https://www.semanticscholar.org/paper/7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2520689\",\"name\":\"R. B. Madeo\"},{\"authorId\":\"2125066\",\"name\":\"S. M. Peres\"},{\"authorId\":\"2112108\",\"name\":\"C. A. M. Lima\"}],\"doi\":\"10.1016/j.eswa.2016.02.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6194546b210d84524b1d56cba6732757a05052cc\",\"title\":\"Gesture phase segmentation using support vector machines\",\"url\":\"https://www.semanticscholar.org/paper/6194546b210d84524b1d56cba6732757a05052cc\",\"venue\":\"Expert Syst. Appl.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145431806\",\"name\":\"J. Cassell\"},{\"authorId\":\"2451989\",\"name\":\"H. Vilhj\\u00e1lmsson\"},{\"authorId\":\"1690448\",\"name\":\"T. Bickmore\"}],\"doi\":\"10.1145/383259.383315\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b3b0f715da1d2988d078c53636730fa6a9769ad\",\"title\":\"BEAT: the Behavior Expression Animation Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/1b3b0f715da1d2988d078c53636730fa6a9769ad\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145431806\",\"name\":\"J. Cassell\"},{\"authorId\":\"1703084\",\"name\":\"C. Pelachaud\"},{\"authorId\":\"1699200\",\"name\":\"N. Badler\"},{\"authorId\":\"145332819\",\"name\":\"Mark Steedman\"},{\"authorId\":\"1792667\",\"name\":\"Brett Achorn\"},{\"authorId\":\"2955637\",\"name\":\"Tripp Becket\"},{\"authorId\":\"3024972\",\"name\":\"Brett Douville\"},{\"authorId\":\"35219353\",\"name\":\"S. Prevost\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.1145/192161.192272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3586d02338c87f8a7da08aed18625745fd1b3c46\",\"title\":\"Animated conversation: rule-based generation of facial expression, gesture & spoken intonation for multiple conversational agents\",\"url\":\"https://www.semanticscholar.org/paper/3586d02338c87f8a7da08aed18625745fd1b3c46\",\"venue\":\"SIGGRAPH '94\",\"year\":1994},{\"arxivId\":\"1712.02310\",\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"7987770\",\"name\":\"Weicheng Kuo\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2018.00524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"title\":\"From Lifestyle Vlogs to Everyday Interactions\",\"url\":\"https://www.semanticscholar.org/paper/729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5864138\",\"name\":\"Stefan Kopp\"},{\"authorId\":\"3313648\",\"name\":\"Brigitte Krenn\"},{\"authorId\":\"1788771\",\"name\":\"S. Marsella\"},{\"authorId\":\"2979549\",\"name\":\"A. N. Marshall\"},{\"authorId\":\"1703084\",\"name\":\"C. Pelachaud\"},{\"authorId\":\"1696134\",\"name\":\"H. Pirker\"},{\"authorId\":\"1727838\",\"name\":\"K. Th\\u00f3risson\"},{\"authorId\":\"2451989\",\"name\":\"H. Vilhj\\u00e1lmsson\"}],\"doi\":\"10.1007/11821830_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad72b65ab67ebe502e27b16932ffafd9a69d61ca\",\"title\":\"Towards a Common Framework for Multimodal Generation: The Behavior Markup Language\",\"url\":\"https://www.semanticscholar.org/paper/ad72b65ab67ebe502e27b16932ffafd9a69d61ca\",\"venue\":\"IVA\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guest Editorial\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e64dba5a683789e73a1c29c9a74dd0ef3b74a664\",\"title\":\"Gesture and speech in interaction : An overview\",\"url\":\"https://www.semanticscholar.org/paper/e64dba5a683789e73a1c29c9a74dd0ef3b74a664\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7562120\",\"name\":\"J. P. Ruiter\"},{\"authorId\":\"3179497\",\"name\":\"A. Bangerter\"},{\"authorId\":\"32679588\",\"name\":\"Paula Dings\"}],\"doi\":\"10.1111/j.1756-8765.2012.01183.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"253bb0d18e1f2eae1983c527090871eeea972d86\",\"title\":\"The Interplay Between Gesture and Speech in the Production of Referring Expressions: Investigating the Tradeoff Hypothesis\",\"url\":\"https://www.semanticscholar.org/paper/253bb0d18e1f2eae1983c527090871eeea972d86\",\"venue\":\"Top. Cogn. Sci.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143687087\",\"name\":\"M. Neff\"},{\"authorId\":\"145616714\",\"name\":\"M. Kipp\"},{\"authorId\":\"33578779\",\"name\":\"Irene Albrecht\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"}],\"doi\":\"10.1145/1330511.1330516\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86aae06409f84028697f6aede2e28394d03c8723\",\"title\":\"Gesture modeling and animation based on a probabilistic re-creation of speaker style\",\"url\":\"https://www.semanticscholar.org/paper/86aae06409f84028697f6aede2e28394d03c8723\",\"venue\":\"TOGS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"3171632\",\"name\":\"A. Quattoni\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2007.383299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4d628ea1c03b9f70b1a23a61129aeee91e35062\",\"title\":\"Latent-Dynamic Discriminative Models for Continuous Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e4d628ea1c03b9f70b1a23a61129aeee91e35062\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1812.08008\",\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"2915997\",\"name\":\"T. \\u0160imon\"},{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2017.143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e8db1519245426f3a78752a3d8360484f4626b1\",\"title\":\"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields\",\"url\":\"https://www.semanticscholar.org/paper/9e8db1519245426f3a78752a3d8360484f4626b1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"144994682\",\"name\":\"A. Pentland\"}],\"doi\":\"10.1109/34.546259\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67852293a05e4e9da899e99ba109a81b2af7fca4\",\"title\":\"Task-Specific Gesture Analysis in Real-Time Using Interpolated Views\",\"url\":\"https://www.semanticscholar.org/paper/67852293a05e4e9da899e99ba109a81b2af7fca4\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1705118\",\"name\":\"Arno Hartholt\"},{\"authorId\":\"144518646\",\"name\":\"D. Traum\"},{\"authorId\":\"1788771\",\"name\":\"S. Marsella\"},{\"authorId\":\"145109163\",\"name\":\"Ari Shapiro\"},{\"authorId\":\"2624478\",\"name\":\"Giota Stratou\"},{\"authorId\":\"3201827\",\"name\":\"A. Leuski\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145438097\",\"name\":\"J. Gratch\"}],\"doi\":\"10.1007/978-3-642-40415-3_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf08954f2433149a6e198423597ec8add84d278c\",\"title\":\"All Together Now - Introducing the Virtual Human Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/cf08954f2433149a6e198423597ec8add84d278c\",\"venue\":\"IVA\",\"year\":2013},{\"arxivId\":\"1808.07371\",\"authors\":[{\"authorId\":\"1715365\",\"name\":\"C. Chan\"},{\"authorId\":\"2361255\",\"name\":\"Shiry Ginosar\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2019.00603\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"title\":\"Everybody Dance Now\",\"url\":\"https://www.semanticscholar.org/paper/e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50178247\",\"name\":\"Najmeh Sadoughi\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"}],\"doi\":\"10.1145/2818346.2820750\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5dd7ca121b95ea79800ed8e6f91f64a63ee72045\",\"title\":\"Retrieving Target Gestures Toward Speech Driven Animation with Meaningful Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/5dd7ca121b95ea79800ed8e6f91f64a63ee72045\",\"venue\":\"ICMI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788771\",\"name\":\"S. Marsella\"},{\"authorId\":\"1884967\",\"name\":\"Yuyu Xu\"},{\"authorId\":\"1930380\",\"name\":\"Margot Lhommet\"},{\"authorId\":\"2149730\",\"name\":\"A. Feng\"},{\"authorId\":\"1770312\",\"name\":\"Stefan Scherer\"},{\"authorId\":\"145109163\",\"name\":\"Ari Shapiro\"}],\"doi\":\"10.1145/2485895.2485900\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3f4b2a93e12a34944beafc24077f64dba9b2d48\",\"title\":\"Virtual character performance from speech\",\"url\":\"https://www.semanticscholar.org/paper/e3f4b2a93e12a34944beafc24077f64dba9b2d48\",\"venue\":\"SCA '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145616714\",\"name\":\"M. Kipp\"},{\"authorId\":\"143687087\",\"name\":\"M. Neff\"},{\"authorId\":\"2349057\",\"name\":\"Kerstin H. Kipp\"},{\"authorId\":\"33578779\",\"name\":\"Irene Albrecht\"}],\"doi\":\"10.1007/978-3-540-74997-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47203a18759d6386209a7d4432353cb40758f683\",\"title\":\"Towards Natural Gesture Synthesis: Evaluating Gesture Units in a Data-Driven Approach to Gesture Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/47203a18759d6386209a7d4432353cb40758f683\",\"venue\":\"IVA\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2779846\",\"name\":\"H. Sakoe\"},{\"authorId\":\"35805230\",\"name\":\"Seibi Chiba\"}],\"doi\":\"10.1109/TASSP.1978.1163055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18f355d7ef4aa9f82bf5c00f84e46714efa5fd77\",\"title\":\"Dynamic programming algorithm optimization for spoken word recognition\",\"url\":\"https://www.semanticscholar.org/paper/18f355d7ef4aa9f82bf5c00f84e46714efa5fd77\",\"venue\":\"\",\"year\":1978},{\"arxivId\":\"1705.02966\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.31.109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8632cf6c1ef4319966564328d187876d3bef363\",\"title\":\"You said that?\",\"url\":\"https://www.semanticscholar.org/paper/a8632cf6c1ef4319966564328d187876d3bef363\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"145563607\",\"name\":\"M. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a63c0ae8cb411040a29ad85f2d009a17bf5a9a2\",\"title\":\"Orientation Histograms for Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a63c0ae8cb411040a29ad85f2d009a17bf5a9a2\",\"venue\":\"\",\"year\":1995}],\"title\":\"Learning Individual Styles of Conversational Gesture\",\"topics\":[{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Pitch (music)\",\"topicId\":\"1967371\",\"url\":\"https://www.semanticscholar.org/topic/1967371\"},{\"topic\":\"Dialog system\",\"topicId\":\"83260\",\"url\":\"https://www.semanticscholar.org/topic/83260\"},{\"topic\":\"Humans\",\"topicId\":\"732\",\"url\":\"https://www.semanticscholar.org/topic/732\"},{\"topic\":\"High-level programming language\",\"topicId\":\"212045\",\"url\":\"https://www.semanticscholar.org/topic/212045\"},{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Semantic prosody\",\"topicId\":\"1144412\",\"url\":\"https://www.semanticscholar.org/topic/1144412\"},{\"topic\":\"Hypertext Transfer Protocol\",\"topicId\":\"28225\",\"url\":\"https://www.semanticscholar.org/topic/28225\"},{\"topic\":\"Amazon Web Services\",\"topicId\":\"8552\",\"url\":\"https://www.semanticscholar.org/topic/8552\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"UC Browser\",\"topicId\":\"785037\",\"url\":\"https://www.semanticscholar.org/topic/785037\"},{\"topic\":\"Cyber security standards\",\"topicId\":\"114650\",\"url\":\"https://www.semanticscholar.org/topic/114650\"}],\"url\":\"https://www.semanticscholar.org/paper/e609684188c842092ae7bcae81429471e422df4d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"