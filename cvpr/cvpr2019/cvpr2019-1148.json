"{\"abstract\":\"The vulnerability of machine learning systems to adversarial attacks questions their usage in many applications. In this paper, we propose a randomized diversification as a defense strategy. We introduce a multi-channel architecture in a gray-box scenario, which assumes that the architecture of the classifier and the training data set are known to the attacker. The attacker does not only have access to a secret key and to the internal states of the system at the test time. The defender processes an input in multiple channels. Each channel introduces its own randomization in a special transform domain based on a secret key shared between the training and testing stages. Such a transform based randomization with a shared key preserves the gradients in key-defined sub-spaces for the defender but it prevents gradient back propagation and the creation of various bypass systems for the attacker. An additional benefit of multi-channel randomization is the aggregation that fuses soft-outputs from all channels, thus increasing the reliability of the final score. The sharing of a secret key creates an information advantage to the defender. Experimental evaluation demonstrates an increased robustness of the proposed method to a number of known state-of-the-art attacks.\",\"arxivId\":\"1904.00689\",\"authors\":[{\"authorId\":\"144040982\",\"name\":\"O. Taran\",\"url\":\"https://www.semanticscholar.org/author/144040982\"},{\"authorId\":\"3074253\",\"name\":\"Shideh Rezaeifar\",\"url\":\"https://www.semanticscholar.org/author/3074253\"},{\"authorId\":\"2189106\",\"name\":\"T. Holotyak\",\"url\":\"https://www.semanticscholar.org/author/2189106\"},{\"authorId\":\"9428112\",\"name\":\"S. Voloshynovskiy\",\"url\":\"https://www.semanticscholar.org/author/9428112\"}],\"citationVelocity\":4,\"citations\":[{\"arxivId\":\"1910.12392\",\"authors\":[{\"authorId\":\"144625576\",\"name\":\"M. Barni\"},{\"authorId\":\"26973516\",\"name\":\"E. Nowroozi\"},{\"authorId\":\"2488892\",\"name\":\"B. Tondi\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"151e2dcb920b3629dd2079444e2d4fa0ebb905a2\",\"title\":\"Effectiveness of Random Deep Feature Selection for Securing Image Manipulation Detectors Against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/151e2dcb920b3629dd2079444e2d4fa0ebb905a2\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2010.07542\",\"authors\":[{\"authorId\":\"1753697087\",\"name\":\"Beno\\u00eet Bonnet\"},{\"authorId\":\"1775704\",\"name\":\"T. Furon\"},{\"authorId\":\"144224330\",\"name\":\"P. Bas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5d9cbd083bf1f2073557eab27a0a6e556ba602f\",\"title\":\"Adversarial Images through Stega Glasses\",\"url\":\"https://www.semanticscholar.org/paper/c5d9cbd083bf1f2073557eab27a0a6e556ba602f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12989192\",\"name\":\"Benjamin Appiah\"},{\"authorId\":\"1949051\",\"name\":\"E. Baagyere\"},{\"authorId\":\"1978812715\",\"name\":\"Kwabena Owusu-Agyemang\"},{\"authorId\":\"3267138\",\"name\":\"Zhiguang Qin\"},{\"authorId\":\"1977997973\",\"name\":\"Muhammed Amin Abdullah\"}],\"doi\":\"10.1109/ACCESS.2020.3024244\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb81c640b56168788b25ca1901cd0479290178cc\",\"title\":\"Multi-Class Triplet Loss With Gaussian Noise for Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/bb81c640b56168788b25ca1901cd0479290178cc\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2008.05230\",\"authors\":[{\"authorId\":\"49663528\",\"name\":\"W. Liu\"},{\"authorId\":\"8003001\",\"name\":\"Miaojing Shi\"},{\"authorId\":\"1775704\",\"name\":\"T. Furon\"},{\"authorId\":\"101723127\",\"name\":\"Lianghuan Li\"}],\"doi\":\"10.1145/3394171.3413604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"871e5349c24532174662bf1f553af268e4c36aa9\",\"title\":\"Defending Adversarial Examples via DNN Bottleneck Reinforcement\",\"url\":\"https://www.semanticscholar.org/paper/871e5349c24532174662bf1f553af268e4c36aa9\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1912.02153\",\"authors\":[{\"authorId\":\"2398137\",\"name\":\"H. Zhang\"},{\"authorId\":\"1744904\",\"name\":\"Yannis Avrithis\"},{\"authorId\":\"1775704\",\"name\":\"T. Furon\"},{\"authorId\":\"1778357\",\"name\":\"L. Amsaleg\"}],\"doi\":\"10.1109/TIFS.2020.3021899\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"580305c4bdda4131f4e4b48ca08f473997268bbf\",\"title\":\"Walking on the Edge: Fast, Low-Distortion Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/580305c4bdda4131f4e4b48ca08f473997268bbf\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753696847\",\"name\":\"Tobias Kupek\"},{\"authorId\":\"1574072339\",\"name\":\"Cecilia Pasquini\"},{\"authorId\":\"1394720839\",\"name\":\"Rainer B\\u00f6hme\"}],\"doi\":\"10.1145/3369412.3395076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"349f754b3c7b1ab9068bdd37e93d09bd7fff6477\",\"title\":\"On the Difficulty of Hiding Keys in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/349f754b3c7b1ab9068bdd37e93d09bd7fff6477\",\"venue\":\"IH&MMSec\",\"year\":2020},{\"arxivId\":\"2005.06023\",\"authors\":[{\"authorId\":\"7878359\",\"name\":\"W. Li\"},{\"authorId\":\"2488892\",\"name\":\"B. Tondi\"},{\"authorId\":\"2000167\",\"name\":\"R. Ni\"},{\"authorId\":\"144625575\",\"name\":\"M. Barni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc2418a1cc631967a277997d04d7842f2dd7ac4f\",\"title\":\"Increased-confidence adversarial examples for improved transferability of Counter-Forensic attacks\",\"url\":\"https://www.semanticscholar.org/paper/fc2418a1cc631967a277997d04d7842f2dd7ac4f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040982\",\"name\":\"O. Taran\"},{\"authorId\":\"3074253\",\"name\":\"Shideh Rezaeifar\"},{\"authorId\":\"2189106\",\"name\":\"T. Holotyak\"},{\"authorId\":\"9428112\",\"name\":\"S. Voloshynovskiy\"}],\"doi\":\"10.1186/s13635-020-00106-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2706fd666c955839324ee0b8dee005ab232d52f4\",\"title\":\"Machine learning through cryptographic glasses: combating adversarial attacks by key-based diversified aggregation\",\"url\":\"https://www.semanticscholar.org/paper/2706fd666c955839324ee0b8dee005ab232d52f4\",\"venue\":\"EURASIP J. Inf. Secur.\",\"year\":2020},{\"arxivId\":\"2009.11397\",\"authors\":[{\"authorId\":\"7482585\",\"name\":\"M. Rottmann\"},{\"authorId\":\"1962695793\",\"name\":\"Mathis Peyron\"},{\"authorId\":\"1705189\",\"name\":\"N. Krejic\"},{\"authorId\":\"1765041\",\"name\":\"H. Gottschalk\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f40c0c650f5cd6c20669f3f6388fce2dae856db6\",\"title\":\"Detection of Iterative Adversarial Attacks via Counter Attack\",\"url\":\"https://www.semanticscholar.org/paper/f40c0c650f5cd6c20669f3f6388fce2dae856db6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.11219\",\"authors\":[{\"authorId\":\"50365745\",\"name\":\"C. Xiao\"},{\"authorId\":\"46882430\",\"name\":\"C. Zheng\"}],\"doi\":\"10.1109/cvpr42600.2020.00049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43a8b2fd651c3783723f4265d7641f9601a5a6f4\",\"title\":\"One Man\\u2019s Trash Is Another Man\\u2019s Treasure: Resisting Adversarial Examples by Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/43a8b2fd651c3783723f4265d7641f9601a5a6f4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":90259556,\"doi\":\"10.1109/CVPR.2019.01148\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b1a3dc492c88427a0b6fa253f09c2b19fc6f0d48\",\"references\":[{\"arxivId\":\"1805.08000\",\"authors\":[{\"authorId\":\"46182699\",\"name\":\"Zhonghui You\"},{\"authorId\":\"7173620\",\"name\":\"Jinmian Ye\"},{\"authorId\":\"49243193\",\"name\":\"Kunming Li\"},{\"authorId\":\"48319357\",\"name\":\"P. Wang\"}],\"doi\":\"10.1109/ICIP.2019.8803055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a39149da8f9ec8fc398b9f1506c61e17650e3118\",\"title\":\"Adversarial Noise Layer: Regularize Neural Network by Adding Noise\",\"url\":\"https://www.semanticscholar.org/paper/a39149da8f9ec8fc398b9f1506c61e17650e3118\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1802.06816\",\"authors\":[{\"authorId\":\"3386912\",\"name\":\"N. Das\"},{\"authorId\":\"3290827\",\"name\":\"Madhuri Shanbhogue\"},{\"authorId\":\"1792665\",\"name\":\"Shang-Tse Chen\"},{\"authorId\":\"10735510\",\"name\":\"Fred Hohman\"},{\"authorId\":\"50341101\",\"name\":\"S. Li\"},{\"authorId\":\"144423419\",\"name\":\"L. Chen\"},{\"authorId\":\"2110884\",\"name\":\"Michael E. Kounavis\"},{\"authorId\":\"1793506\",\"name\":\"Duen Horng Chau\"}],\"doi\":\"10.1145/3219819.3219910\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09b971fd40efe6d8a7389b61f15df4a0c264ce60\",\"title\":\"SHIELD: Fast, Practical Defense and Vaccination for Deep Learning using JPEG Compression\",\"url\":\"https://www.semanticscholar.org/paper/09b971fd40efe6d8a7389b61f15df4a0c264ce60\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. LeCun\"},{\"authorId\":null,\"name\":\"C. Cortes\"},{\"authorId\":null,\"name\":\"C. Burges\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Mnist handwritten digit database\",\"url\":\"\",\"venue\":\"AT&T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist,\",\"year\":2010},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1712.07107\",\"authors\":[{\"authorId\":\"152162529\",\"name\":\"Xiaoyong Yuan\"},{\"authorId\":\"50462511\",\"name\":\"Pan He\"},{\"authorId\":\"22317545\",\"name\":\"Qile Zhu\"},{\"authorId\":\"47058258\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2018.2886017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03a507a0876c7e1a26608358b1a9dd39f1eb08e0\",\"title\":\"Adversarial Examples: Attacks and Defenses for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/03a507a0876c7e1a26608358b1a9dd39f1eb08e0\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1802.00573\",\"authors\":[{\"authorId\":\"46842323\",\"name\":\"Z. Chen\"},{\"authorId\":\"2488892\",\"name\":\"B. Tondi\"},{\"authorId\":\"2967870\",\"name\":\"X. Li\"},{\"authorId\":\"143767230\",\"name\":\"R. Ni\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"144625576\",\"name\":\"M. Barni\"}],\"doi\":\"10.1109/TIFS.2019.2901826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"129a89b7645a81e7affe425c6d71443339d99b94\",\"title\":\"Secure Detection of Image Manipulation by Means of Random Feature Selection\",\"url\":\"https://www.semanticscholar.org/paper/129a89b7645a81e7affe425c6d71443339d99b94\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Krizhevsky\"},{\"authorId\":null,\"name\":\"V. Nair\"},{\"authorId\":null,\"name\":\"G. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The cifar-10 dataset\",\"url\":\"\",\"venue\":\"online: http://www. cs. toronto. edu/kriz/cifar. html,\",\"year\":2014},{\"arxivId\":\"1809.01715\",\"authors\":[{\"authorId\":\"144040982\",\"name\":\"O. Taran\"},{\"authorId\":\"3074253\",\"name\":\"Shideh Rezaeifar\"},{\"authorId\":\"9428112\",\"name\":\"S. Voloshynovskiy\"}],\"doi\":\"10.1007/978-3-030-11012-3_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0001739746fe04bc6d9b9a82788d9032e18d0205\",\"title\":\"Bridging machine learning and cryptography in defence against adversarial attacks\",\"url\":\"https://www.semanticscholar.org/paper/0001739746fe04bc6d9b9a82788d9032e18d0205\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817564\",\"name\":\"X. V. Nguyen\"},{\"authorId\":\"144757691\",\"name\":\"S. Erfani\"},{\"authorId\":\"1892724\",\"name\":\"S. Paisitkriangkrai\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"1688394\",\"name\":\"C. Leckie\"},{\"authorId\":\"1720142\",\"name\":\"K. Ramamohanarao\"}],\"doi\":\"10.1109/ICPR.2016.7899688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ea3cb713365e8cde0678875b8bdd787f83b7c42\",\"title\":\"Training robust models using Random Projection\",\"url\":\"https://www.semanticscholar.org/paper/1ea3cb713365e8cde0678875b8bdd787f83b7c42\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1702.04267\",\"authors\":[{\"authorId\":\"2708564\",\"name\":\"J. H. Metzen\"},{\"authorId\":\"3081854\",\"name\":\"Tim Genewein\"},{\"authorId\":\"47092548\",\"name\":\"Volker Fischer\"},{\"authorId\":\"3452473\",\"name\":\"B. Bischoff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"531e3a7b7768f199fdd401b266504db245ca039a\",\"title\":\"On Detecting Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/531e3a7b7768f199fdd401b266504db245ca039a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1708.07747\",\"authors\":[{\"authorId\":\"145642373\",\"name\":\"H. Xiao\"},{\"authorId\":\"4565995\",\"name\":\"K. Rasul\"},{\"authorId\":\"2742129\",\"name\":\"Roland Vollgraf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\"title\":\"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32\",\"venue\":\"ArXiv\",\"year\":2017}],\"title\":\"Defending Against Adversarial Attacks by Randomized Diversification\",\"topics\":[{\"topic\":\"Randomized algorithm\",\"topicId\":\"3442\",\"url\":\"https://www.semanticscholar.org/topic/3442\"},{\"topic\":\"Diversification (finance)\",\"topicId\":\"56436\",\"url\":\"https://www.semanticscholar.org/topic/56436\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Key (cryptography)\",\"topicId\":\"67214\",\"url\":\"https://www.semanticscholar.org/topic/67214\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"Backpropagation\",\"topicId\":\"11998\",\"url\":\"https://www.semanticscholar.org/topic/11998\"},{\"topic\":\"Test set\",\"topicId\":\"24168\",\"url\":\"https://www.semanticscholar.org/topic/24168\"},{\"topic\":\"Symmetric-key algorithm\",\"topicId\":\"11628\",\"url\":\"https://www.semanticscholar.org/topic/11628\"},{\"topic\":\"Software propagation\",\"topicId\":\"2021211\",\"url\":\"https://www.semanticscholar.org/topic/2021211\"},{\"topic\":\"Numerical analysis\",\"topicId\":\"5413\",\"url\":\"https://www.semanticscholar.org/topic/5413\"},{\"topic\":\"Sparse matrix\",\"topicId\":\"126\",\"url\":\"https://www.semanticscholar.org/topic/126\"}],\"url\":\"https://www.semanticscholar.org/paper/b1a3dc492c88427a0b6fa253f09c2b19fc6f0d48\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"