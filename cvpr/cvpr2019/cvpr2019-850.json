"{\"abstract\":\"Current captioning approaches can describe images using black-box architectures whose behavior is hardly controllable and explainable from the exterior. As an image can be described in infinite ways depending on the goal and the context at hand, a higher degree of controllability is needed to apply captioning algorithms in complex scenarios. In this paper, we introduce a novel framework for image captioning which can generate diverse descriptions by allowing both grounding and controllability. Given a control signal in the form of a sequence or set of image regions, we generate the corresponding caption through a recurrent architecture which predicts textual chunks explicitly grounded on regions, following the constraints of the given control. Experiments are conducted on Flickr30k Entities and on COCO Entities, an extended version of COCO in which we add grounding annotations collected in a semi-automatic manner. Results demonstrate that our method achieves state of the art performances on controllable image captioning, in terms of caption quality and diversity. Code and annotations are publicly available at: https://github.com/aimagelab/show-control-and-tell.\",\"arxivId\":\"1811.10652\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\",\"url\":\"https://www.semanticscholar.org/author/3468983\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\",\"url\":\"https://www.semanticscholar.org/author/1843795\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\",\"url\":\"https://www.semanticscholar.org/author/1741922\"}],\"citationVelocity\":22,\"citations\":[{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1476813856\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1016/j.patrec.2019.11.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cc1a8014ab6de2e5ef45f7f2204ba7e73cb10ec\",\"title\":\"Explaining digital humanities by aligning images and textual descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2cc1a8014ab6de2e5ef45f7f2204ba7e73cb10ec\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1909.08745\",\"authors\":[{\"authorId\":\"144060080\",\"name\":\"Giang T. Nguyen\"},{\"authorId\":\"8102722\",\"name\":\"T. Jun\"},{\"authorId\":\"144256269\",\"name\":\"Trung Tran\"},{\"authorId\":\"72657968\",\"name\":\"Daeyoung Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b428979e3b67f40fc307b5b166f9c97adba6a63f\",\"title\":\"ContCap: A comprehensive framework for continual image captioning\",\"url\":\"https://www.semanticscholar.org/paper/b428979e3b67f40fc307b5b166f9c97adba6a63f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.03098\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/978-3-030-58558-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"title\":\"Connecting Vision and Language with Localized Narratives\",\"url\":\"https://www.semanticscholar.org/paper/439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144060080\",\"name\":\"Giang T. Nguyen\"},{\"authorId\":\"8102722\",\"name\":\"Tae Joon Jun\"},{\"authorId\":\"145178790\",\"name\":\"Trung Tran\"},{\"authorId\":\"1729331675\",\"name\":\"Tolcha Yalew\"},{\"authorId\":\"40513516\",\"name\":\"Daeyoung Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b76f2cba712972f068bfb0fffa9b467761fd273\",\"title\":\"ContCap: A scalable framework for continual image captioning.\",\"url\":\"https://www.semanticscholar.org/paper/7b76f2cba712972f068bfb0fffa9b467761fd273\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.03347\",\"authors\":[{\"authorId\":\"10752412\",\"name\":\"L. Cultrera\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"70892589\",\"name\":\"Pietro Pala\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1109/CVPRW50498.2020.00178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bf6619144d3fb32877794edf216b1da89632772\",\"title\":\"Explaining Autonomous Driving by Learning End-to-End Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8bf6619144d3fb32877794edf216b1da89632772\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2011.14901\",\"authors\":[{\"authorId\":\"32236286\",\"name\":\"Annika Lindh\"},{\"authorId\":\"144394786\",\"name\":\"R. Ross\"},{\"authorId\":\"34967075\",\"name\":\"John D. Kelleher\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"027aba2214f6a199d7be75150e94075f3752e27f\",\"title\":\"Language-Driven Region Pointer Advancement for Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/027aba2214f6a199d7be75150e94075f3752e27f\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2004.08070\",\"authors\":[{\"authorId\":\"51163002\",\"name\":\"Alasdair Tran\"},{\"authorId\":\"46953477\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"}],\"doi\":\"10.1109/CVPR42600.2020.01305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"title\":\"Transform and Tell: Entity-Aware News Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.04453\",\"authors\":[{\"authorId\":\"2562211\",\"name\":\"Xiaoyu Shen\"},{\"authorId\":\"144042991\",\"name\":\"Jun Suzuki\"},{\"authorId\":\"3040648\",\"name\":\"Kentaro Inui\"},{\"authorId\":\"46444442\",\"name\":\"H. Su\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"},{\"authorId\":\"1714612\",\"name\":\"S. Sekine\"}],\"doi\":\"10.18653/v1/D19-1054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b618c2d5747379531e313acfde33191deb609c5f\",\"title\":\"Select and Attend: Towards Controllable Content Selection in Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/b618c2d5747379531e313acfde33191deb609c5f\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"title\":\"Attacking Image Captioning Towards Accuracy-Preserving Target Words Removal\",\"url\":\"https://www.semanticscholar.org/paper/0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1910.02974\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICRA40945.2020.9196653\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe6f2a08cb8911d52533a413b071638d0463f10a\",\"title\":\"SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability\",\"url\":\"https://www.semanticscholar.org/paper/fe6f2a08cb8911d52533a413b071638d0463f10a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1912.05730\",\"authors\":[{\"authorId\":\"1456146130\",\"name\":\"Rushi J. Babariya\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"}],\"doi\":\"10.1007/978-3-030-41299-9_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4874d0e044b44ee75d3125b0b8a002596918eeae\",\"title\":\"Meaning guided video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4874d0e044b44ee75d3125b0b8a002596918eeae\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-030-30645-8_66\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f378be13df9e97e15ca240b60a0a0aa16d5eb64\",\"title\":\"Artpedia: A New Visual-Semantic Dataset with Visual and Contextual Sentences in the Artistic Domain\",\"url\":\"https://www.semanticscholar.org/paper/6f378be13df9e97e15ca240b60a0a0aa16d5eb64\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52511039\",\"name\":\"T. Nishimura\"},{\"authorId\":\"29544582\",\"name\":\"S. Tomori\"},{\"authorId\":\"144921213\",\"name\":\"H. Hashimoto\"},{\"authorId\":\"73390405\",\"name\":\"A. Hashimoto\"},{\"authorId\":\"2936312\",\"name\":\"Y. Yamakata\"},{\"authorId\":\"2374821\",\"name\":\"Jun Harashima\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"144873535\",\"name\":\"S. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18a8da86ccc52ee0218c282fa9891a6955973a16\",\"title\":\"Visual Grounding Annotation of Recipe Flow Graph\",\"url\":\"https://www.semanticscholar.org/paper/18a8da86ccc52ee0218c282fa9891a6955973a16\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2012.02339\",\"authors\":[{\"authorId\":\"2031911881\",\"name\":\"Edwin G. Ng\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"title\":\"Understanding Guided Image Captioning Performance across Domains\",\"url\":\"https://www.semanticscholar.org/paper/0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11701\",\"authors\":[{\"authorId\":\"84039136\",\"name\":\"P. Sadler\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b60d6e35891baa34282433546df0449d7422ce98\",\"title\":\"Spatial Attention as an Interface for Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/b60d6e35891baa34282433546df0449d7422ce98\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05175\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"87784755\",\"name\":\"A. Thapliyal\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"title\":\"Weakly Supervised Content Selection for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2005.00908\",\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"122615952\",\"name\":\"Sheng-Jie Li\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"48060050\",\"name\":\"M. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7cc8205ddf8211d6ae2fce03de2953a4b978b66a\",\"title\":\"Clue: Cross-modal Coherence Modeling for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/7cc8205ddf8211d6ae2fce03de2953a4b978b66a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33834231\",\"name\":\"Soojin Jang\"},{\"authorId\":\"1515118694\",\"name\":\"Kyohoon Jin\"},{\"authorId\":\"1516407429\",\"name\":\"Junhyeok An\"},{\"authorId\":\"1687948\",\"name\":\"Young-bin Kim\"}],\"doi\":\"10.1109/ACCESS.2020.2974328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e84a9fdb060b34c7e934735b16c1d2195d009d9\",\"title\":\"Regional Patch-Based Feature Interpolation Method for Effective Regularization\",\"url\":\"https://www.semanticscholar.org/paper/4e84a9fdb060b34c7e934735b16c1d2195d009d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2005.14386\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57ace777e00c0df5d0b729990eed12ed6b0dcfe9\",\"title\":\"Controlling Length in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/57ace777e00c0df5d0b729990eed12ed6b0dcfe9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01156\",\"authors\":[{\"authorId\":\"145841847\",\"name\":\"Michael Burke\"},{\"authorId\":\"2740413\",\"name\":\"K. Subr\"},{\"authorId\":\"47172195\",\"name\":\"S. Ramamoorthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"164458a07d7f33b5b3c7a7b3c2ce24b89c371911\",\"title\":\"Action sequencing using visual permutations\",\"url\":\"https://www.semanticscholar.org/paper/164458a07d7f33b5b3c7a7b3c2ce24b89c371911\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.11782\",\"authors\":[{\"authorId\":\"152584142\",\"name\":\"Zhengxiong Jia\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":\"10.1145/3372278.3390697\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"title\":\"iCap: Interactive Image Captioning with Predictive Text\",\"url\":\"https://www.semanticscholar.org/paper/87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1665150187\",\"name\":\"Xin Qian\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"37298954\",\"name\":\"F. Du\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"73649257\",\"name\":\"J. Chan\"}],\"doi\":\"10.1145/3334480.3382946\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5aab7ee416c0eada217b4ebde9778f26845c8f43\",\"title\":\"A Formative Study on Designing Accurate and Natural Figure Captioning Systems\",\"url\":\"https://www.semanticscholar.org/paper/5aab7ee416c0eada217b4ebde9778f26845c8f43\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":\"1908.04919\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58a77455b1c38afe1eab4bec664bd866eba1573d\",\"title\":\"Towards Diverse and Accurate Image Captions via Reinforcing Determinantal Point Process\",\"url\":\"https://www.semanticscholar.org/paper/58a77455b1c38afe1eab4bec664bd866eba1573d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.11690\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2562211\",\"name\":\"Xiaoyu Shen\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"54a42098b34c2602305b03fe07b7db82b789f5db\",\"title\":\"Integrating Image Captioning with Rule-based Entity Masking\",\"url\":\"https://www.semanticscholar.org/paper/54a42098b34c2602305b03fe07b7db82b789f5db\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05413\",\"authors\":[{\"authorId\":\"51013428\",\"name\":\"Youssef A. Mejjati\"},{\"authorId\":\"1872039960\",\"name\":\"Celso F. Gomez\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-3-030-58592-1_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e03ef52b0f9a0a0742c692e0ecdf04ea609314b3\",\"title\":\"Look here! A parametric learning based approach to redirect visual attention\",\"url\":\"https://www.semanticscholar.org/paper/e03ef52b0f9a0a0742c692e0ecdf04ea609314b3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"51019115\",\"name\":\"S. Li\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.18653/v1/2020.acl-main.583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb05ea53c4bfee60e045d26cc487d20141482949\",\"title\":\"Cross-modal Coherence Modeling for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/bb05ea53c4bfee60e045d26cc487d20141482949\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eccfd6174709c285d62b11fb3da9b68d485ca883\",\"title\":\"Integrating Rule-based Entity Masking into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eccfd6174709c285d62b11fb3da9b68d485ca883\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1911.04365\",\"authors\":[{\"authorId\":\"9457831\",\"name\":\"J. He\"},{\"authorId\":\"1405953764\",\"name\":\"Quan-Jie Cao\"},{\"authorId\":\"39844955\",\"name\":\"L. Zhang\"},{\"authorId\":\"93970041\",\"name\":\"Hui Tao\"}],\"doi\":\"10.1109/ACCESS.2020.2982571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"587e1359d0a54ecf24e2577357abe79d0cd00ab2\",\"title\":\"Conditionally Learn to Pay Attention for Sequential Visual Task\",\"url\":\"https://www.semanticscholar.org/paper/587e1359d0a54ecf24e2577357abe79d0cd00ab2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.02707\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.271\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"title\":\"Sub-Instruction Aware Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":53778132,\"doi\":\"10.1109/CVPR.2019.00850\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8e59cf8c3becbedced0089028a1cddac8b19b251\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"38718108\",\"name\":\"S. B. Needleman\"},{\"authorId\":\"31942395\",\"name\":\"C. Wunsch\"}],\"doi\":\"10.1016/B978-0-12-131200-8.50031-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3c9d483dfc4b78ccf0530b9854a7932aa5469cb\",\"title\":\"A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins\",\"url\":\"https://www.semanticscholar.org/paper/f3c9d483dfc4b78ccf0530b9854a7932aa5469cb\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"venue\":\"ICCV 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3182726\",\"name\":\"Matthew Honnibal\"},{\"authorId\":\"2089067\",\"name\":\"Y. Goldberg\"},{\"authorId\":\"145177145\",\"name\":\"M. Johnson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d32c62d9709a10fc75096246971edc36a5855b53\",\"title\":\"A Non-Monotonic Arc-Eager Transition System for Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/d32c62d9709a10fc75096246971edc36a5855b53\",\"venue\":\"CoNLL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3358971\",\"name\":\"Ashwin K. Vijayakumar\"},{\"authorId\":\"37824829\",\"name\":\"M. Cogswell\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b1e3f7218f1c0f0db56bf2bd9475521454693a1\",\"title\":\"Diverse Beam Search for Improved Description of Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/1b1e3f7218f1c0f0db56bf2bd9475521454693a1\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1711.07068\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"82247c9e74ddebb4dce65560ee69620579358f2d\",\"title\":\"Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space\",\"url\":\"https://www.semanticscholar.org/paper/82247c9e74ddebb4dce65560ee69620579358f2d\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1802.08665\",\"authors\":[{\"authorId\":\"145289462\",\"name\":\"Gonzalo E. Mena\"},{\"authorId\":\"2636941\",\"name\":\"D. Belanger\"},{\"authorId\":\"2342841\",\"name\":\"Scott W. Linderman\"},{\"authorId\":\"144108062\",\"name\":\"Jasper Snoek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"23deae1e548bc055c8920fc8529e59bba0816685\",\"title\":\"Learning Latent Permutations with Gumbel-Sinkhorn Networks\",\"url\":\"https://www.semanticscholar.org/paper/23deae1e548bc055c8920fc8529e59bba0816685\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1805.07030\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2018.00896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"title\":\"SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\",\"url\":\"https://www.semanticscholar.org/paper/beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2089067\",\"name\":\"Y. Goldberg\"},{\"authorId\":\"1720988\",\"name\":\"Joakim Nivre\"}],\"doi\":\"10.1162/tacl_a_00237\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90fc459c305f13b3fab0abf42b8dd1801c59511\",\"title\":\"Training Deterministic Parsers with Non-Deterministic Oracles\",\"url\":\"https://www.semanticscholar.org/paper/f90fc459c305f13b3fab0abf42b8dd1801c59511\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2019.01095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"CHRISTUS\"},{\"authorId\":null,\"name\":\"WUKSCH\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"967f32841955b72f358190436baa5510839d9ab3\",\"title\":\"A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins\",\"url\":\"https://www.semanticscholar.org/paper/967f32841955b72f358190436baa5510839d9ab3\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1805.00314\",\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-1198\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"title\":\"Object Counts! Bringing Explicit Detections Back into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.01033\",\"authors\":[{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"144982160\",\"name\":\"T. Lucas\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.1109/ICCV.2017.140\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"title\":\"Areas of Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"144418438\",\"name\":\"Hinrich Sch\\u00fctze\"}],\"doi\":\"10.1145/601858.601867\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"084c55d6432265785e3ff86a2e900a49d501c00a\",\"title\":\"Foundations of statistical natural language processing\",\"url\":\"https://www.semanticscholar.org/paper/084c55d6432265785e3ff86a2e900a49d501c00a\",\"venue\":\"SGMD\",\"year\":2002},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1808.00265\",\"authors\":[{\"authorId\":\"2373307\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/WACV.2019.00043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"title\":\"Interpretable Visual Question Answering by Visual Grounding From Attention Supervision Mining\",\"url\":\"https://www.semanticscholar.org/paper/b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50536468\",\"name\":\"Danqi Chen\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a14045a751f5d8ed387c8630a86a3a2861b90643\",\"title\":\"A Fast and Accurate Dependency Parser using Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a14045a751f5d8ed387c8630a86a3a2861b90643\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1706.08474\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/3177745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"title\":\"Paying More Attention to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.323\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"24952249\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b2c60061ad32e28eb1e20aff42e062c9160786be\",\"title\":\"Diverse and Controllable Image Captioning with Part-of-Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/b2c60061ad32e28eb1e20aff42e062c9160786be\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2941401\",\"name\":\"H. Kuhn\"}],\"doi\":\"10.1007/978-3-540-68279-0_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6a0f30260302a2001da9999096cfdd89bc1f7fb\",\"title\":\"The Hungarian Method for the Assignment Problem\",\"url\":\"https://www.semanticscholar.org/paper/b6a0f30260302a2001da9999096cfdd89bc1f7fb\",\"venue\":\"50 Years of Integer Programming\",\"year\":2010},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1510.01431\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"title\":\"SentiCap: Generating Image Descriptions with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1611.09312\",\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"153925540\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2017.339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"title\":\"Hierarchical Boundary-Aware Neural Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":\"1612.00576\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/D17-1098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"title\":\"Guided Open Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcella Cornia\"},{\"authorId\":null,\"name\":\"Lorenzo Baraldi\"},{\"authorId\":null,\"name\":\"Rita Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"url\":\"\",\"venue\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2019}],\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"topics\":[{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"},{\"topic\":\"Entity\",\"topicId\":\"6664\",\"url\":\"https://www.semanticscholar.org/topic/6664\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"HTTPS\",\"topicId\":\"48813\",\"url\":\"https://www.semanticscholar.org/topic/48813\"},{\"topic\":\"Semiconductor industry\",\"topicId\":\"76540\",\"url\":\"https://www.semanticscholar.org/topic/76540\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"}],\"url\":\"https://www.semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"