"{\"abstract\":\"Binaural audio provides a listener with 3D sound sensation, allowing a rich perceptual experience of the scene. However, binaural recordings are scarcely available and require nontrivial expertise and equipment to obtain. We propose to convert common monaural audio into binaural audio by leveraging video. The key idea is that visual frames reveal significant spatial cues that, while explicitly lacking in the accompanying single-channel audio, are strongly linked to it. Our multi-modal approach recovers this link from unlabeled video. We devise a deep convolutional neural network that learns to decode the monaural (single-channel) soundtrack into its binaural counterpart by injecting visual information about object and scene configurations. We call the resulting output 2.5D visual sound---the visual stream helps \\\"lift\\\" the flat single channel audio into spatialized sound. In addition to sound generation, we show the self-supervised representation learned by our network benefits audio-visual source separation. Our video results: http://vision.cs.utexas.edu/projects/2.5D_visual_sound/\",\"arxivId\":\"1812.04204\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\",\"url\":\"https://www.semanticscholar.org/author/3387849\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\",\"url\":\"https://www.semanticscholar.org/author/1794409\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e8b99d59e3f077bf1391140bd58a78341b3148a\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation (Supplementary Materials)\",\"url\":\"https://www.semanticscholar.org/paper/3e8b99d59e3f077bf1391140bd58a78341b3148a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145392266\",\"name\":\"Santiago Gonzalez\"},{\"authorId\":\"1686788\",\"name\":\"R. Miikkulainen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15facc065733eb9eb5c037465310c9f56b1e18cb\",\"title\":\"Evolving Loss Functions with Multivariate Taylor Polynomial Parameterizations\",\"url\":\"https://www.semanticscholar.org/paper/15facc065733eb9eb5c037465310c9f56b1e18cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.00059\",\"authors\":[{\"authorId\":\"89213824\",\"name\":\"Santiago Gonzalez\"},{\"authorId\":\"1686788\",\"name\":\"R. Miikkulainen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"787bf3af84ccb025ce279be7ee872e7f63b64d30\",\"title\":\"Optimizing Loss Functions Through Multivariate Taylor Polynomial Parameterization\",\"url\":\"https://www.semanticscholar.org/paper/787bf3af84ccb025ce279be7ee872e7f63b64d30\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.11583\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1941a6e2d4fd61b63d1df518a40cb47cab19c0e6\",\"title\":\"Semantic Audio-Visual Navigation\",\"url\":\"https://www.semanticscholar.org/paper/1941a6e2d4fd61b63d1df518a40cb47cab19c0e6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.04237\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58523-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb79a085e014f129b063199a38fe9945355c137\",\"title\":\"Self-Supervised Learning of Audio-Visual Objects from Video\",\"url\":\"https://www.semanticscholar.org/paper/0eb79a085e014f129b063199a38fe9945355c137\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000431943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4867095c19f6c5827943cc74335b370d4bfcab29\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4867095c19f6c5827943cc74335b370d4bfcab29\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"1904.07750\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00398\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"title\":\"Co-Separating Sounds of Visual Objects\",\"url\":\"https://www.semanticscholar.org/paper/7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.07933\",\"authors\":[{\"authorId\":\"145343013\",\"name\":\"Andr\\u00e9s F. P\\u00e9rez\"},{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/WACV45572.2020.9093307\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"title\":\"Audio-Visual Model Distillation Using Acoustic Images\",\"url\":\"https://www.semanticscholar.org/paper/f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2007.06355\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1500378795\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1007/978-3-030-58565-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"title\":\"Multiple Sound Sources Localization from Coarse to Fine\",\"url\":\"https://www.semanticscholar.org/paper/53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.09805\",\"authors\":[{\"authorId\":\"1491401265\",\"name\":\"Shuang Ma\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7df5dd31f2ce600a4be589dff4d6a758be262324\",\"title\":\"Learning Audio-Visual Representations with Active Contrastive Coding\",\"url\":\"https://www.semanticscholar.org/paper/7df5dd31f2ce600a4be589dff4d6a758be262324\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.09649\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/tpami.2019.2952095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"title\":\"Learning to Localize Sound Sources in Visual Scenes: Analysis and Applications\",\"url\":\"https://www.semanticscholar.org/paper/edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.06175\",\"authors\":[{\"authorId\":\"2806097\",\"name\":\"Karren D. Yang\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"}],\"doi\":\"10.1109/cvpr42600.2020.00995\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"title\":\"Telling Left From Right: Learning Spatial Correspondence of Sight and Sound\",\"url\":\"https://www.semanticscholar.org/paper/7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.04124\",\"authors\":[{\"authorId\":\"40176903\",\"name\":\"Sangho Lee\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"6555176\",\"name\":\"Thomas Breuel\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"title\":\"Parameter Efficient Multimodal Transformers for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"2026650249\",\"name\":\"Niccol\\u00f2 Pozzetti\"},{\"authorId\":\"103150889\",\"name\":\"D. Greco\"},{\"authorId\":\"1723008\",\"name\":\"Marco Cristani\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-58542-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8728049700f949a4731ca9d6de73dee8940592bc\",\"title\":\"Leveraging Acoustic Images for Effective Self-supervised Audio Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8728049700f949a4731ca9d6de73dee8940592bc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.08151\",\"authors\":[{\"authorId\":\"145194507\",\"name\":\"S. Kasaei\"},{\"authorId\":\"1568855068\",\"name\":\"J. Melsen\"},{\"authorId\":\"80009585\",\"name\":\"F. V. Beers\"},{\"authorId\":\"1568979708\",\"name\":\"Christiaan Steenkist\"},{\"authorId\":\"147265747\",\"name\":\"K. Von\\u010dina\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6ea4bbc2d1fcac322e64a190c5ae990d9a9f682\",\"title\":\"The State of Lifelong Learning in Service Robots: Current Bottlenecks in Object Perception and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/f6ea4bbc2d1fcac322e64a190c5ae990d9a9f682\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR42600.2020.01049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"title\":\"Music Gesture for Visual Sound Separation\",\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"title\":\"Audio-Visual Embodied Navigation\",\"url\":\"https://www.semanticscholar.org/paper/6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.11474\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58539-6_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c47ef056ac57e83405f9ee63c32c6a185011d187\",\"title\":\"SoundSpaces: Audio-Visual Navigation in 3D Environments\",\"url\":\"https://www.semanticscholar.org/paper/c47ef056ac57e83405f9ee63c32c6a185011d187\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145194507\",\"name\":\"S. Kasaei\"},{\"authorId\":\"1568855068\",\"name\":\"J. Melsen\"},{\"authorId\":\"80009585\",\"name\":\"F. V. Beers\"},{\"authorId\":\"1568979708\",\"name\":\"Christiaan Steenkist\"},{\"authorId\":\"147265747\",\"name\":\"K. Von\\u010dina\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f05023f7afe019c3a2b00f56d45a9e857c9437ea\",\"title\":\"The State of Service Robots: Current Bottlenecks in Object Perception and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/f05023f7afe019c3a2b00f56d45a9e857c9437ea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10629\",\"authors\":[{\"authorId\":\"1694704\",\"name\":\"Jiasong Wu\"},{\"authorId\":\"47268472\",\"name\":\"T. Li\"},{\"authorId\":\"2461136\",\"name\":\"Youyong Kong\"},{\"authorId\":\"1803944\",\"name\":\"Guanyu Yang\"},{\"authorId\":\"1684465\",\"name\":\"L. Senhadji\"},{\"authorId\":\"144305249\",\"name\":\"H. Shu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fec5ca52ef0ff8ba395077479aef60b9f780b33d\",\"title\":\"SLNSpeech: solving extended speech separation problem by the help of sign language\",\"url\":\"https://www.semanticscholar.org/paper/fec5ca52ef0ff8ba395077479aef60b9f780b33d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.12391\",\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"2073462\",\"name\":\"D. Bull\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3670d55a696dea9234660149b490e22fb5c2a3a5\",\"title\":\"Artificial Intelligence in the Creative Industries: A Review\",\"url\":\"https://www.semanticscholar.org/paper/3670d55a696dea9234660149b490e22fb5c2a3a5\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":54628402,\"doi\":\"10.1109/CVPR.2019.00041\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763888\",\"name\":\"M. Noisternig\"},{\"authorId\":\"1752098\",\"name\":\"A. Sontacchi\"},{\"authorId\":\"48270859\",\"name\":\"T. Musil\"},{\"authorId\":\"1779788\",\"name\":\"R. H\\u00f6ldrich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8789821e38bc9086d5f6e1fb55c15f1e8b9667d\",\"title\":\"A 3D Ambisonic Based Binaural Sound Reproduction System\",\"url\":\"https://www.semanticscholar.org/paper/d8789821e38bc9086d5f6e1fb55c15f1e8b9667d\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31496901\",\"name\":\"John W. Fisher III\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"1731948\",\"name\":\"P. Viola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15674778d14d7f2bf90c323924e8153d5f10fb60\",\"title\":\"Learning Joint Statistical Models for Audio-Visual Fusion and Segregation\",\"url\":\"https://www.semanticscholar.org/paper/15674778d14d7f2bf90c323924e8153d5f10fb60\",\"venue\":\"NIPS\",\"year\":2000},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34303152\",\"name\":\"X. Zhang\"},{\"authorId\":\"1733567\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/TASLP.2017.2687104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ad5d2bbf050b25b3d879ef6940f13d02a54f50d\",\"title\":\"Deep Learning Based Binaural Speech Separation in Reverberant Environments\",\"url\":\"https://www.semanticscholar.org/paper/7ad5d2bbf050b25b3d879ef6940f13d02a54f50d\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthias Kronlachner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Spatial transformations for the alteration of ambisonic recordings\",\"url\":\"\",\"venue\":\"M. Thesis, University of Music and Performing Arts, Graz, Institute of Electronic Music and Acoustics,\",\"year\":2014},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48190580\",\"name\":\"D. Griffin\"},{\"authorId\":\"49719219\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/TASSP.1984.1164317\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"83179cfc937dfd62513282854e357c7f38fecda8\",\"title\":\"Signal estimation from modified short-time Fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/83179cfc937dfd62513282854e357c7f38fecda8\",\"venue\":\"\",\"year\":1984},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":\"10.1109/ICASSP.2017.7951787\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77b5aa4f00a8525893ce3aeb9eea9934a8694b84\",\"title\":\"Motion informed audio source separation\",\"url\":\"https://www.semanticscholar.org/paper/77b5aa4f00a8525893ce3aeb9eea9934a8694b84\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48190580\",\"name\":\"D. Griffin\"},{\"authorId\":\"49719219\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/ICASSP.1983.1172092\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"14bc876fae55faf5669beb01667a4f3bd324a4f1\",\"title\":\"Signal estimation from modified short-time Fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/14bc876fae55faf5669beb01667a4f3bd324a4f1\",\"venue\":\"ICASSP\",\"year\":1983},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"1742319\",\"name\":\"M. Crocco\"},{\"authorId\":\"2157339\",\"name\":\"Samuele Martelli\"},{\"authorId\":\"1700022\",\"name\":\"A. Trucco\"},{\"authorId\":\"8955013\",\"name\":\"A. D. Bue\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/ICCVW.2015.95\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"760240945de3fa26c7651b601440ca8749c1b916\",\"title\":\"Seeing the Sound: A New Multimodal Imaging Device for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/760240945de3fa26c7651b601440ca8749c1b916\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3307172\",\"name\":\"Antoine Deleforge\"},{\"authorId\":\"1794229\",\"name\":\"R. Horaud\"}],\"doi\":\"10.1145/2157689.2157834\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d68d3f9917f12f9ee0b58f50b12e77b1c1a6b7a\",\"title\":\"The cocktail party robot: Sound source separation and localisation with an active binaural head\",\"url\":\"https://www.semanticscholar.org/paper/9d68d3f9917f12f9ee0b58f50b12e77b1c1a6b7a\",\"venue\":\"2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145247805\",\"name\":\"K. Iida\"},{\"authorId\":\"6146557\",\"name\":\"Y. Ishii\"},{\"authorId\":\"31306640\",\"name\":\"Shinsuke Nishioka\"}],\"doi\":\"10.1121/1.4880856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15964a660ed1caeb716470b37c9d0a1cb9a12eb1\",\"title\":\"Personalization of head-related transfer functions in the median plane based on the anthropometry of the listener's pinnae.\",\"url\":\"https://www.semanticscholar.org/paper/15964a660ed1caeb716470b37c9d0a1cb9a12eb1\",\"venue\":\"The Journal of the Acoustical Society of America\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47820818\",\"name\":\"J. Pu\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/ICASSP.2017.7952687\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7d609d978eabf9df940687b8b94ef104d1ef3c\",\"title\":\"Audio-visual object localization and separation using low-rank and sparsity\",\"url\":\"https://www.semanticscholar.org/paper/0d7d609d978eabf9df940687b8b94ef104d1ef3c\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"50363843\",\"name\":\"Michael I. Mandel\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"}],\"doi\":\"10.7916/D8TX3QRG\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11a6279a6c7f34a43dd305dfcaae084c71998eeb\",\"title\":\"Source separation based on binaural cues and source model constraints\",\"url\":\"https://www.semanticscholar.org/paper/11a6279a6c7f34a43dd305dfcaae084c71998eeb\",\"venue\":\"INTERSPEECH\",\"year\":2008},{\"arxivId\":\"1704.08292\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"4037274\",\"name\":\"Sudhanshu Srivastava\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1145/3126686.3126723\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27e8965cc9c166e9afee46e611039f0ce8263e51\",\"title\":\"Deep Cross-Modal Audio-Visual Generation\",\"url\":\"https://www.semanticscholar.org/paper/27e8965cc9c166e9afee46e611039f0ce8263e51\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2177291\",\"name\":\"Beyang Liu\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"1736370\",\"name\":\"D. Koller\"}],\"doi\":\"10.1109/CVPR.2010.5539823\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"893ebdaeb66b2d0c5b5be100e2d19e54a3c0824e\",\"title\":\"Single image depth estimation from predicted semantic labels\",\"url\":\"https://www.semanticscholar.org/paper/893ebdaeb66b2d0c5b5be100e2d19e54a3c0824e\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1809.02587\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"029490920cd736e91d6c57f3cfb850adddcf2725\",\"title\":\"Self-Supervised Generation of Spatial Audio for 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/029490920cd736e91d6c57f3cfb850adddcf2725\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1764429\",\"name\":\"K. Nakadai\"},{\"authorId\":\"1765396\",\"name\":\"K. Hidai\"},{\"authorId\":\"1775800\",\"name\":\"H. Okuno\"},{\"authorId\":\"1742807\",\"name\":\"H. Kitano\"}],\"doi\":\"10.1109/ROBOT.2002.1013493\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cecef48ce9e6997307d7497bb3de91fbe8c1adb\",\"title\":\"Real-time speaker localization and speech separation by audio-visual integration\",\"url\":\"https://www.semanticscholar.org/paper/8cecef48ce9e6997307d7497bb3de91fbe8c1adb\",\"venue\":\"Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292)\",\"year\":2002},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"}],\"doi\":\"10.1109/TASL.2006.885253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe27cac60301c52397c1ce150abd7706afa007cd\",\"title\":\"Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal Continuity and Sparseness Criteria\",\"url\":\"https://www.semanticscholar.org/paper/fe27cac60301c52397c1ce150abd7706afa007cd\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39294084\",\"name\":\"C. Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4f41c8440f88ef2688e131713a92a5f0c9a4ae5\",\"title\":\"Scene-Aware Audio for 360\\\\textdegree{} Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4f41c8440f88ef2688e131713a92a5f0c9a4ae5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1038/014032a0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ffa5b789fea573cb3e882bfc69240c234c23697\",\"title\":\"Our Perception of the Direction of a Source of Sound\",\"url\":\"https://www.semanticscholar.org/paper/8ffa5b789fea573cb3e882bfc69240c234c23697\",\"venue\":\"Nature\",\"year\":1876},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"3215419\",\"name\":\"B. McFee\"},{\"authorId\":\"3268101\",\"name\":\"Eric J. Humphrey\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"1899151\",\"name\":\"O. Nieto\"},{\"authorId\":\"1702877\",\"name\":\"Dawen Liang\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d37fbd2fccaef3ecdf75d34a7aee18ab9519a6f\",\"title\":\"MIR_EVAL: A Transparent Implementation of Common MIR Metrics\",\"url\":\"https://www.semanticscholar.org/paper/6d37fbd2fccaef3ecdf75d34a7aee18ab9519a6f\",\"venue\":\"ISMIR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744069\",\"name\":\"Zohar Barzelay\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"}],\"doi\":\"10.1109/CVPR.2007.383344\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e309dfbae9d123f85223d398d4a400abee3ef393\",\"title\":\"Harmony in Motion\",\"url\":\"https://www.semanticscholar.org/paper/e309dfbae9d123f85223d398d4a400abee3ef393\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1712.04109\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89498817a49d9c349ec9f67375023ead0411b865\",\"title\":\"Im2Flow: Motion Hallucination from Static Images for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89498817a49d9c349ec9f67375023ead0411b865\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2717546\",\"name\":\"Zhoutong Zhang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"12493779\",\"name\":\"Q. Li\"},{\"authorId\":\"25699206\",\"name\":\"Zhengjia Huang\"},{\"authorId\":\"50690309\",\"name\":\"James Traer\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/ICCV.2017.141\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0472a1e41e9ef5b8c619443328d360f88ca34362\",\"title\":\"Generative Modeling of Audible Shapes for Object Perception\",\"url\":\"https://www.semanticscholar.org/paper/0472a1e41e9ef5b8c619443328d360f88ca34362\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Gao\"},{\"authorId\":null,\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"2.5d visual sound\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122315677\",\"name\":\"P. Huang\"},{\"authorId\":\"33752120\",\"name\":\"Minje Kim\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"}],\"doi\":\"10.1109/ICASSP.2014.6853860\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca7f25ac119e2d706e51a63f6178f1547a863bcc\",\"title\":\"Deep learning for monaural speech separation\",\"url\":\"https://www.semanticscholar.org/paper/ca7f25ac119e2d706e51a63f6178f1547a863bcc\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405808215\",\"name\":\"Edgar A. Torres-Gallegos\"},{\"authorId\":\"1403834534\",\"name\":\"Felipe Ordu\\u00f1a-Bustamante\"},{\"authorId\":\"1399626503\",\"name\":\"F. Ar\\u00e1mbula-Cos\\u00edo\"}],\"doi\":\"10.1016/J.APACOUST.2015.04.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53d0533ea56b55573c634da42ef990b0bc3dbe0f\",\"title\":\"Personalization of head-related transfer functions (HRTF) based on automatic photo-anthropometry and inference from a database\",\"url\":\"https://www.semanticscholar.org/paper/53d0533ea56b55573c634da42ef990b0bc3dbe0f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1706.00932\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"title\":\"See, Hear, and Read: Deep Aligned Representations\",\"url\":\"https://www.semanticscholar.org/paper/52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1805.04792\",\"authors\":[{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39294084\",\"name\":\"C. Zheng\"}],\"doi\":\"10.1145/3197517.3201391\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02ba7be40eadfb64a214c3774bf7e3d06d3db095\",\"title\":\"Scene-aware audio for 360\\u00b0 videos\",\"url\":\"https://www.semanticscholar.org/paper/02ba7be40eadfb64a214c3774bf7e3d06d3db095\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144390689\",\"name\":\"W. Koenig\"}],\"doi\":\"10.1121/1.1906578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfd337a0a5cfa29807990450ee74caa46450e3d5\",\"title\":\"Subjective Effects in Binaural Hearing\",\"url\":\"https://www.semanticscholar.org/paper/dfd337a0a5cfa29807990450ee74caa46450e3d5\",\"venue\":\"\",\"year\":1950},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780979\",\"name\":\"\\u00d6. Y\\u0131lmaz\"},{\"authorId\":\"8850109\",\"name\":\"S. Rickard\"}],\"doi\":\"10.1109/TSP.2004.828896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aeab027c39a5b58c7c69addf87332c5b144205f5\",\"title\":\"Blind separation of speech mixtures via time-frequency masking\",\"url\":\"https://www.semanticscholar.org/paper/aeab027c39a5b58c7c69addf87332c5b144205f5\",\"venue\":\"IEEE Transactions on Signal Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W Koenig\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Subjective effects in binaural hearing. The Journal of the\",\"url\":\"\",\"venue\":\"\",\"year\":1950},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40697283\",\"name\":\"J. Strutt\"}],\"doi\":\"10.1017/CBO9780511703966.041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c375bc574011c6d6f26896fb6beccc033fa6611d\",\"title\":\"Scientific Papers: Our Perception of the Direction of a Source of Sound\",\"url\":\"https://www.semanticscholar.org/paper/c375bc574011c6d6f26896fb6beccc033fa6611d\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Nakadai\"},{\"authorId\":null,\"name\":\"K.-i. Hidai\"},{\"authorId\":null,\"name\":\"H. G. Okuno\"},{\"authorId\":null,\"name\":\"H. Kitano\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Realtime speaker localization and speech separation by audiovisual integration\",\"url\":\"\",\"venue\":\"In IEEE International Conference on Robotics and Automation,\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211891\",\"name\":\"Einat Kidron\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"}],\"doi\":\"10.1109/CVPR.2005.274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"title\":\"Pixels that sound\",\"url\":\"https://www.semanticscholar.org/paper/91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2058409\",\"name\":\"Volker Gnann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56456a595bb6d2dea5bfbed0a429f0e53c5a7512\",\"title\":\"SOURCE-FILTER BASED CLUSTERING FOR MONAURAL BLIND SOURCE SEPARATION\",\"url\":\"https://www.semanticscholar.org/paper/56456a595bb6d2dea5bfbed0a429f0e53c5a7512\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"0912.0171\",\"authors\":[{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"1692147\",\"name\":\"E. Vincent\"},{\"authorId\":\"1731535\",\"name\":\"R. Gribonval\"}],\"doi\":\"10.1109/TASL.2010.2050716\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"736a64d2953f78e5145235ce32ff0e6aa240509b\",\"title\":\"Under-Determined Reverberant Audio Source Separation Using a Full-Rank Spatial Covariance Model\",\"url\":\"https://www.semanticscholar.org/paper/736a64d2953f78e5145235ce32ff0e6aa240509b\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"1719943\",\"name\":\"M. Shashanka\"}],\"doi\":\"10.1007/978-3-540-74494-8_52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8338daf3b445fb1b65a203bc60213c09cb537585\",\"title\":\"Supervised and Semi-supervised Separation of Sounds from Single-Channel Mixtures\",\"url\":\"https://www.semanticscholar.org/paper/8338daf3b445fb1b65a203bc60213c09cb537585\",\"venue\":\"ICA\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"},{\"authorId\":\"1734296\",\"name\":\"M. Casey\"},{\"authorId\":\"70773882\",\"name\":\"Northampton Square\"},{\"authorId\":\"1452780437\",\"name\":\"Subspace Projections\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7b47411373a3af57bf7b00ae52cc5443f8b9704\",\"title\":\"AUDIO/VISUAL INDEPENDENT COMPONENTS\",\"url\":\"https://www.semanticscholar.org/paper/d7b47411373a3af57bf7b00ae52cc5443f8b9704\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"1741200\",\"name\":\"J. Movellan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00d1bb817691bb0566bc55fde01d12339625aa1c\",\"title\":\"Audio Vision: Using Audio-Visual Synchrony to Locate Sounds\",\"url\":\"https://www.semanticscholar.org/paper/00d1bb817691bb0566bc55fde01d12339625aa1c\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"27361710\",\"name\":\"K. Dinesh\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"145621177\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/ICASSP.2017.7952688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5545c07fb82934cbe2918ef5ae8550a01efa25ab\",\"title\":\"See and listen: Score-informed association of sound tracks to players in chamber music performance videos\",\"url\":\"https://www.semanticscholar.org/paper/5545c07fb82934cbe2918ef5ae8550a01efa25ab\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1804.04121\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1400\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"title\":\"The Conversation: Deep Audio-Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"153677544\",\"name\":\"Asaph Shamir\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.21437/Interspeech.2018-1955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f997d69d78af086dec4462e4319c6d241f42c0c1\",\"title\":\"Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/f997d69d78af086dec4462e4319c6d241f42c0c1\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1708.07524\",\"authors\":[{\"authorId\":\"46348681\",\"name\":\"D. Wang\"},{\"authorId\":\"49252693\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/TASLP.2018.2842159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae523e2f137fa2a4f5a6cbcc443ba63db2642a96\",\"title\":\"Supervised Speech Separation Based on Deep Learning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/ae523e2f137fa2a4f5a6cbcc443ba63db2642a96\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7491017\",\"name\":\"F. Sedighin\"},{\"authorId\":\"30954170\",\"name\":\"M. Babaie-Zadeh\"},{\"authorId\":\"1744054\",\"name\":\"B. Rivet\"},{\"authorId\":\"1696508\",\"name\":\"C. Jutten\"}],\"doi\":\"10.1109/EUSIPCO.2016.7760220\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dff0935de38fef7c0e591434bd4ca29a6db8047\",\"title\":\"Two multimodal approaches for single microphone source separation\",\"url\":\"https://www.semanticscholar.org/paper/3dff0935de38fef7c0e591434bd4ca29a6db8047\",\"venue\":\"2016 24th European Signal Processing Conference (EUSIPCO)\",\"year\":2016}],\"title\":\"2.5D Visual Sound\",\"topics\":[{\"topic\":\"2.5D\",\"topicId\":\"33594\",\"url\":\"https://www.semanticscholar.org/topic/33594\"},{\"topic\":\"Binaural beats\",\"topicId\":\"611510\",\"url\":\"https://www.semanticscholar.org/topic/611510\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Source separation\",\"topicId\":\"39125\",\"url\":\"https://www.semanticscholar.org/topic/39125\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Surround sound\",\"topicId\":\"1380\",\"url\":\"https://www.semanticscholar.org/topic/1380\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Virtual reality\",\"topicId\":\"4462\",\"url\":\"https://www.semanticscholar.org/topic/4462\"}],\"url\":\"https://www.semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"