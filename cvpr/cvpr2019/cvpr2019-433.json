"{\"abstract\":\"In this paper, we propose an adversarial learning network for the task of multi-style image captioning (MSCap) with a standard factual image caption dataset and a multi-stylized language corpus without paired images. How to learn a single model for multi-stylized image captioning with unpaired data is a challenging and necessary task, whereas rarely studied in previous works. The proposed framework mainly includes four contributive modules following a typical image encoder. First, a style dependent caption generator to output a sentence conditioned on an encoded image and a specified style. Second, a caption discriminator is presented to distinguish the input sentence to be real or not. The discriminator and the generator are trained in an adversarial manner to enable more natural and human-like captions. Third, a style classifier is employed to discriminate the specific style of the input sentence. Besides, a back-translation module is designed to enforce the generated stylized captions are visually grounded, with the intuition of the cycle consistency for factual caption and stylized caption. We enable an end-to-end optimization of the whole model with differentiable softmax approximation.\\u00a0At last, we conduct comprehensive experiments using a combined dataset containing four caption styles to demonstrate the outstanding performance of our proposed method.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\",\"url\":\"https://www.semanticscholar.org/author/26982950\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\",\"url\":\"https://www.semanticscholar.org/author/1749850\"},{\"authorId\":\"145523338\",\"name\":\"Peng Yao\",\"url\":\"https://www.semanticscholar.org/author/145523338\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\",\"url\":\"https://www.semanticscholar.org/author/49298906\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\",\"url\":\"https://www.semanticscholar.org/author/46386029\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":\"2005.04690\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"153003010\",\"name\":\"Xingjian He\"},{\"authorId\":\"1575173011\",\"name\":\"Jie Jiang\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.24963/ijcai.2020/106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9637ae1fbb8aebc8deb6e3c15dd93839e327e1c\",\"title\":\"Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9637ae1fbb8aebc8deb6e3c15dd93839e327e1c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"51019115\",\"name\":\"S. Li\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.18653/v1/2020.acl-main.583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb05ea53c4bfee60e045d26cc487d20141482949\",\"title\":\"Cross-modal Coherence Modeling for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/bb05ea53c4bfee60e045d26cc487d20141482949\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944765097\",\"name\":\"Beigeng Zhao\"}],\"doi\":\"10.1109/ACCESS.2020.3021312\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"title\":\"DrunaliaCap: Image Captioning for Drug-Related Paraphernalia With Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.01894\",\"authors\":[{\"authorId\":\"1715983\",\"name\":\"Oier Lopez de Lacalle\"},{\"authorId\":\"1612386066\",\"name\":\"Ander Salaberria\"},{\"authorId\":\"1786084\",\"name\":\"A. Soroa\"},{\"authorId\":\"2481918\",\"name\":\"Gorka Azkune\"},{\"authorId\":\"1733049\",\"name\":\"Eneko Agirre\"}],\"doi\":\"10.3233/FAIA200319\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b792296bfe5a3b25c5b15d6dd73f5e68314208de\",\"title\":\"Evaluating Multimodal Representations on Visual Semantic Textual Similarity\",\"url\":\"https://www.semanticscholar.org/paper/b792296bfe5a3b25c5b15d6dd73f5e68314208de\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2006.13611\",\"authors\":[{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"47382681\",\"name\":\"Peipei Song\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.24963/ijcai.2020/128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c3f13969af79ce26d584935e8e39a4423a9d63f\",\"title\":\"Recurrent Relational Memory Network for Unsupervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9c3f13969af79ce26d584935e8e39a4423a9d63f\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2007.03877\",\"authors\":[{\"authorId\":\"1826472\",\"name\":\"Dooseop Choi\"},{\"authorId\":\"2197109\",\"name\":\"Seung-Jun Han\"},{\"authorId\":\"97999178\",\"name\":\"K. Min\"},{\"authorId\":\"51428464\",\"name\":\"Jeongdan Choi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"10ad369ae7920f7305417bf26ba33b1b4490f462\",\"title\":\"PathGAN: Local Path Planning with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/10ad369ae7920f7305417bf26ba33b1b4490f462\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.00945\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.219\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"title\":\"Image-Chat: Engaging Grounded Conversations\",\"url\":\"https://www.semanticscholar.org/paper/b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145523333\",\"name\":\"Peng Yao\"},{\"authorId\":\"102227937\",\"name\":\"J. Li\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/ICME46284.2020.9102935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59d65f0719287512f3f605615f64b7eda27db97b\",\"title\":\"Modeling Local and Global Contexts for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59d65f0719287512f3f605615f64b7eda27db97b\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2011.08543\",\"authors\":[{\"authorId\":\"152601809\",\"name\":\"Minh Thu Nguyen\"},{\"authorId\":\"6195410\",\"name\":\"D. Phung\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"2008200586\",\"name\":\"Thien Huu Nguyen\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.411\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"title\":\"Structural and Functional Decomposition for Personality Image Captioning in a Communication Game\",\"url\":\"https://www.semanticscholar.org/paper/28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"1930660\",\"name\":\"Bo Qu\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/JSTARS.2019.2959208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fbdb53c100005ac890989beb3d78e208ba9acda\",\"title\":\"Retrieval Topic Recurrent Memory Network for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fbdb53c100005ac890989beb3d78e208ba9acda\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":\"2005.00908\",\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"122615952\",\"name\":\"Sheng-Jie Li\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"48060050\",\"name\":\"M. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cc8205ddf8211d6ae2fce03de2953a4b978b66a\",\"title\":\"Clue: Cross-modal Coherence Modeling for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/7cc8205ddf8211d6ae2fce03de2953a4b978b66a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.02127\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"145851264\",\"name\":\"Wei Luo\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350943\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"133921bb5e559de464c0078f5fa67409aca27917\",\"title\":\"Aligning Linguistic Words and Visual Semantic Units for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/133921bb5e559de464c0078f5fa67409aca27917\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2009.08899\",\"authors\":[{\"authorId\":\"2533559\",\"name\":\"Dhomas Hatta Fudholi\"},{\"authorId\":\"88823036\",\"name\":\"Yurio Windiatmoko\"},{\"authorId\":\"104526200\",\"name\":\"Nurdi Afrianto\"},{\"authorId\":\"1392876189\",\"name\":\"P. Susanto\"},{\"authorId\":\"80939610\",\"name\":\"Magfirah Suyuti\"},{\"authorId\":\"30726945\",\"name\":\"A. Hidayatullah\"},{\"authorId\":\"2938889\",\"name\":\"R. Rahmadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2291e4f1eb85ec2415aee119c5ca67d8bb64b30f\",\"title\":\"Image Captioning with Attention for Smart Local Tourism using EfficientNet\",\"url\":\"https://www.semanticscholar.org/paper/2291e4f1eb85ec2415aee119c5ca67d8bb64b30f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6998\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9421fa26257e6a8d59bb874cf3b376c6d4c4118b\",\"title\":\"MemCap: Memorizing Style Knowledge for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9421fa26257e6a8d59bb874cf3b376c6d4c4118b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":198117779,\"doi\":\"10.1109/CVPR.2019.00433\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"references\":[{\"arxivId\":\"1801.10121\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"title\":\"Image Captioning at Will: A Versatile Scheme for Effectively Injecting Sentiments into Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.05192\",\"authors\":[{\"authorId\":\"2509132\",\"name\":\"Taeksoo Kim\"},{\"authorId\":\"9959922\",\"name\":\"Moonsu Cha\"},{\"authorId\":\"39280603\",\"name\":\"H. Kim\"},{\"authorId\":\"3088401\",\"name\":\"J. Lee\"},{\"authorId\":\"3968500\",\"name\":\"Jiwon Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7778b2b6ee67df2a0a06fe82e79acfdf714c7399\",\"title\":\"Learning to Discover Cross-Domain Relations with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/7778b2b6ee67df2a0a06fe82e79acfdf714c7399\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.445\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.09137\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1017/S1351324918000098\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"title\":\"Where to put the Image in an Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1508.06615\",\"authors\":[{\"authorId\":\"38367242\",\"name\":\"Yoon Kim\"},{\"authorId\":\"2262249\",\"name\":\"Yacine Jernite\"},{\"authorId\":\"1746662\",\"name\":\"D. Sontag\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"891ce1687e2befddd19f54e4eef1d3f39c8dbaf7\",\"title\":\"Character-Aware Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1408.5882\",\"authors\":[{\"authorId\":\"38367242\",\"name\":\"Yoon Kim\"}],\"doi\":\"10.3115/v1/D14-1181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba\",\"title\":\"Convolutional Neural Networks for Sentence Classification\",\"url\":\"https://www.semanticscholar.org/paper/1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1706.09601\",\"authors\":[{\"authorId\":\"50081790\",\"name\":\"L. Zhang\"},{\"authorId\":\"40497013\",\"name\":\"Flood Sung\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"title\":\"Actor-Critic Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1804.00861\",\"authors\":[{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"title\":\"Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.01925\",\"authors\":[{\"authorId\":\"1940272\",\"name\":\"Matt J. Kusner\"},{\"authorId\":\"2885717\",\"name\":\"Brooks Paige\"},{\"authorId\":\"1388574431\",\"name\":\"Jos\\u00e9 Miguel Hern\\u00e1ndez-Lobato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"222928303a72d1389b0add8032a31abccbba41b3\",\"title\":\"Grammar Variational Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/222928303a72d1389b0add8032a31abccbba41b3\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73327573\",\"name\":\"A. Bell\"}],\"doi\":\"10.1017/S004740450001037X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a3f545b76e23d5b9e5fd98eb2eeaf9fa6438fac\",\"title\":\"Language Style as Audience Design\",\"url\":\"https://www.semanticscholar.org/paper/2a3f545b76e23d5b9e5fd98eb2eeaf9fa6438fac\",\"venue\":\"\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1145/2998574\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"032fb07f1dc510d35529fd302458ae30a1825f2e\",\"title\":\"Generalized Deep Transfer Networks for Knowledge Propagation in Heterogeneous Domains\",\"url\":\"https://www.semanticscholar.org/paper/032fb07f1dc510d35529fd302458ae30a1825f2e\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2016},{\"arxivId\":\"1609.05473\",\"authors\":[{\"authorId\":\"3469209\",\"name\":\"Lantao Yu\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"39055225\",\"name\":\"J. Wang\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"title\":\"SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1704.04131\",\"authors\":[{\"authorId\":\"2496409\",\"name\":\"Z. Shu\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1733732\",\"name\":\"Sunil Hadap\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"}],\"doi\":\"10.1109/CVPR.2017.578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abbe2e8225f5af22ca0b335889f6b4abc7f71d0d\",\"title\":\"Neural Face Editing with Intrinsic Image Disentangling\",\"url\":\"https://www.semanticscholar.org/paper/abbe2e8225f5af22ca0b335889f6b4abc7f71d0d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.05464\",\"authors\":[{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2017.316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"345afa0e85cb2f5cb438ae44027499ff2c392409\",\"title\":\"Adversarial Discriminative Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/345afa0e85cb2f5cb438ae44027499ff2c392409\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1762744\",\"name\":\"A. Stolcke\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"399da68d3b97218b6c80262df7963baa89dcc71b\",\"title\":\"SRILM - an extensible language modeling toolkit\",\"url\":\"https://www.semanticscholar.org/paper/399da68d3b97218b6c80262df7963baa89dcc71b\",\"venue\":\"INTERSPEECH\",\"year\":2002},{\"arxivId\":\"1807.03871\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01249-6_32\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"title\":\"\\\"Factual\\\" or \\\"Emotional\\\": Stylized Image Captioning with Adaptive Learning and Attention\",\"url\":\"https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1510.01431\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"title\":\"SentiCap: Generating Image Descriptions with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Wang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8218640e95bb2d925a617b1c3012eed7d209351\",\"title\":\"Show, Reward and Tell: Automatic Generation of Narrative Paragraph From Photo Stream by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/b8218640e95bb2d925a617b1c3012eed7d209351\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1611.04558\",\"authors\":[{\"authorId\":\"145657834\",\"name\":\"M. Johnson\"},{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"2048712\",\"name\":\"M. Krikun\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"144203200\",\"name\":\"Nikhil Thorat\"},{\"authorId\":\"1765169\",\"name\":\"F. Vi\\u00e9gas\"},{\"authorId\":\"145233583\",\"name\":\"M. Wattenberg\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"48342565\",\"name\":\"Macduff Hughes\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":\"10.1162/tacl_a_00065\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a486e2839291111bb44fa1f07731ada123539f75\",\"title\":\"Google\\u2019s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation\",\"url\":\"https://www.semanticscholar.org/paper/a486e2839291111bb44fa1f07731ada123539f75\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1609.07093\",\"authors\":[{\"authorId\":\"144588497\",\"name\":\"A. Brock\"},{\"authorId\":\"145841951\",\"name\":\"T. Lim\"},{\"authorId\":\"10195154\",\"name\":\"J. M. Ritchie\"},{\"authorId\":\"32233090\",\"name\":\"N. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dcda6ac3fd33bf938574aca9542aec5e5cace26\",\"title\":\"Neural Photo Editing with Introspective Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1dcda6ac3fd33bf938574aca9542aec5e5cace26\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tianlang Chen\"},{\"authorId\":null,\"name\":\"Zhongping Zhang\"},{\"authorId\":null,\"name\":\"Quanzeng You\"},{\"authorId\":null,\"name\":\"Chen Fang\"},{\"authorId\":null,\"name\":\"Zhaowen Wang\"},{\"authorId\":null,\"name\":\"Hailin Jin\"},{\"authorId\":null,\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":null,\"title\":\"factual\\\" or\\\" emotional\",\"url\":\"\",\"venue\":\"Stylized image captioning with adaptive learning and attention\",\"year\":2018},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1805.07030\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2018.00896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"title\":\"SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\",\"url\":\"https://www.semanticscholar.org/paper/beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.09020\",\"authors\":[{\"authorId\":\"30187096\",\"name\":\"Yunjey Choi\"},{\"authorId\":\"8486223\",\"name\":\"Min-Je Choi\"},{\"authorId\":\"30184861\",\"name\":\"Munyoung Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"6098375\",\"name\":\"S. Kim\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"}],\"doi\":\"10.1109/CVPR.2018.00916\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"302207c149bdf7beb6e46e4d4afbd2fa9ac02c64\",\"title\":\"StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144346837\",\"name\":\"Min Yang\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"28106616\",\"name\":\"Yabing Feng\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1145/3132847.3132920\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3844a6cef7960729125722e2d07024058dd9204a\",\"title\":\"Dual Learning for Cross-domain Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3844a6cef7960729125722e2d07024058dd9204a\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1610.09585\",\"authors\":[{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"},{\"authorId\":\"37232298\",\"name\":\"Christopher Olah\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7\",\"title\":\"Conditional Image Synthesis with Auxiliary Classifier GANs\",\"url\":\"https://www.semanticscholar.org/paper/ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"150426657\",\"name\":\"\\u62d3\\u6d77 \\u6749\\u5c71\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8a5f27e7805f8de84ea008d59452ff864271696\",\"title\":\"\\u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\u201d\\u306e\\u5b66\\u7fd2\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/e8a5f27e7805f8de84ea008d59452ff864271696\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christian Ledig\"},{\"authorId\":null,\"name\":\"Lucas Theis\"},{\"authorId\":null,\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":null,\"name\":\"Jose Caballero\"},{\"authorId\":null,\"name\":\"Andrew Cunningham\"},{\"authorId\":null,\"name\":\"Alejandro Acosta\"},{\"authorId\":null,\"name\":\"Andrew P Aitken\"},{\"authorId\":null,\"name\":\"Alykhan Tejani\"},{\"authorId\":null,\"name\":\"Johannes Totz\"},{\"authorId\":null,\"name\":\"Zehan Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":null,\"title\":\"Photorealistic single image super-resolution using a generative adversarial network\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Konstantinos Bousmalis\"},{\"authorId\":null,\"name\":\"Nathan Silberman\"},{\"authorId\":null,\"name\":\"David Dohan\"},{\"authorId\":null,\"name\":\"Dumitru Erhan\"},{\"authorId\":null,\"name\":\"Dilip Krishnan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":null,\"title\":\"Unsupervised pixellevel domain adaptation with generative adversarial networks\",\"url\":\"\",\"venue\":\"In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1703.00955\",\"authors\":[{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2a215755d7548ffc82079ce734c4ac60b62f6f56\",\"title\":\"Toward Controlled Generation of Text\",\"url\":\"https://www.semanticscholar.org/paper/2a215755d7548ffc82079ce734c4ac60b62f6f56\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1109/CVPR.2019.01280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"title\":\"Engaging Image Captioning via Personality\",\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}],\"title\":\"MSCap: Multi-Style Image Captioning With Unpaired Stylized Text\",\"topics\":[{\"topic\":\"Discriminator\",\"topicId\":\"41710\",\"url\":\"https://www.semanticscholar.org/topic/41710\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Statistical classification\",\"topicId\":\"715\",\"url\":\"https://www.semanticscholar.org/topic/715\"},{\"topic\":\"Unified Model\",\"topicId\":\"90488\",\"url\":\"https://www.semanticscholar.org/topic/90488\"},{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"Approximation\",\"topicId\":\"3247\",\"url\":\"https://www.semanticscholar.org/topic/3247\"},{\"topic\":\"Norm (social)\",\"topicId\":\"76329\",\"url\":\"https://www.semanticscholar.org/topic/76329\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Softmax function\",\"topicId\":\"966784\",\"url\":\"https://www.semanticscholar.org/topic/966784\"}],\"url\":\"https://www.semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"