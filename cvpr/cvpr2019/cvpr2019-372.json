"{\"abstract\":\"Temporal action proposal generation is an important task, aiming to localize the video segments containing human actions in an untrimmed video. In this paper, we propose a multi-granularity generator (MGG) to perform the temporal action proposal from different granularity perspectives, relying on the video visual features equipped with the position embedding information. First, we propose to use a bilinear matching model to exploit the rich local information within the video sequence. Afterwards, two components, namely segment proposal producer (SPP) and frame actionness producer (FAP), are combined to perform the task of temporal action proposal at two distinct granularities. SPP considers the whole video in the form of feature pyramid and generates segment proposals from one coarse perspective, while FAP carries out a finer actionness evaluation for each video frame. Our proposed MGG can be trained in an end-to-end fashion. Through temporally adjusting the segment proposals with fine-grained information based on frame actionness, MGG achieves the superior performance over state-of-the-art methods on the public THUMOS-14 and ActivityNet-1.3 datasets. Moreover, we employ existing action classifiers to perform the classification of the proposals generated by MGG, leading to significant improvements compared against the competing methods for the video detection task.\",\"arxivId\":\"1811.11524\",\"authors\":[{\"authorId\":\"46398922\",\"name\":\"Y. Liu\",\"url\":\"https://www.semanticscholar.org/author/46398922\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\",\"url\":\"https://www.semanticscholar.org/author/145499468\"},{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\",\"url\":\"https://www.semanticscholar.org/author/48380246\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\",\"url\":\"https://www.semanticscholar.org/author/46641573\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\",\"url\":\"https://www.semanticscholar.org/author/9546964\"}],\"citationVelocity\":21,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"123331898\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"title\":\"Refinement of Boundary Regression Using Uncertainty in Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1007/978-3-030-58526-6_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"title\":\"Learning Actionness via Long-Range Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.06958\",\"authors\":[{\"authorId\":\"1632971845\",\"name\":\"Guillaume Vaudaux-Ruth\"},{\"authorId\":\"1403862742\",\"name\":\"Adrien Chan-Hon-Tong\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4545cdb909f2be23ce6542defef6091912729648\",\"title\":\"SALAD: Self-Assessment Learning for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/4545cdb909f2be23ce6542defef6091912729648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.09392\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TPAMI.2020.2980824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"title\":\"Comprehensive Instructional Video Analysis: The COIN Dataset and Performance Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1909.07725\",\"authors\":[{\"authorId\":\"40809222\",\"name\":\"Luxuan Li\"},{\"authorId\":\"145868988\",\"name\":\"Tao Kong\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-36718-3_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f27170bf174d81e646492173ba9e9c97753853c\",\"title\":\"Deep Point-wise Prediction for Action Temporal Proposal\",\"url\":\"https://www.semanticscholar.org/paper/8f27170bf174d81e646492173ba9e9c97753853c\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52580548\",\"name\":\"M. Young\"},{\"authorId\":\"153761408\",\"name\":\"Hyung-il Kim\"},{\"authorId\":\"83168173\",\"name\":\"Park Jongyoul\"}],\"doi\":\"10.22648/ETRI.2020.J.350303\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"31c47ff65e56035aa523f48ece1b462df1ed0c7f\",\"title\":\"Trends in Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/31c47ff65e56035aa523f48ece1b462df1ed0c7f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405196499\",\"name\":\"Marcos Baptista-R\\u00edos\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"},{\"authorId\":\"1402975934\",\"name\":\"F. J. Acevedo-Rodr\\u00edguez\"},{\"authorId\":\"1412159037\",\"name\":\"Pilar Mart\\u00edn-Mart\\u00edn\"},{\"authorId\":\"1398470117\",\"name\":\"S. Maldonado-Basc\\u00f3n\"}],\"doi\":\"10.3390/s20102953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"250cff3f869805e76bf0cda34406f5def042148c\",\"title\":\"Unsupervised Action Proposals Using Support Vector Classifiers for Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/250cff3f869805e76bf0cda34406f5def042148c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1905.11799\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"26485115\",\"name\":\"Lianqiang Zhou\"}],\"doi\":\"10.24963/ijcai.2019/130\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37252f8cd1324a972131fc6a92f778835ba2fac3\",\"title\":\"Hallucinating Optical Flow Features for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/37252f8cd1324a972131fc6a92f778835ba2fac3\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2009.07641\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"title\":\"BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"title\":\"Constraining Temporal Relationship for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.04127\",\"authors\":[{\"authorId\":\"51266875\",\"name\":\"Chuming Lin\"},{\"authorId\":\"50683988\",\"name\":\"J. Li\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"20595955\",\"name\":\"Zhipeng Cui\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1609/AAAI.V34I07.6815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2534a3c894c93053341d514967c45c78657969c\",\"title\":\"Fast Learning of Temporal Action Proposal via Dense Boundary Generator\",\"url\":\"https://www.semanticscholar.org/paper/e2534a3c894c93053341d514967c45c78657969c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.01326\",\"authors\":[{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"},{\"authorId\":\"9870507\",\"name\":\"R. Gade\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":\"10.1109/CVPR42600.2020.01314\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"title\":\"A Context-Aware Loss Function for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01432\",\"authors\":[{\"authorId\":\"13657788\",\"name\":\"Y. Bai\"},{\"authorId\":null,\"name\":\"Yingying Wang\"},{\"authorId\":\"8230405\",\"name\":\"Y. Tong\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"150270503\",\"name\":\"Qiyue Liu\"},{\"authorId\":\"48211752\",\"name\":\"Jun-Hui Liu\"}],\"doi\":\"10.1007/978-3-030-58604-1_8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab87795177c3d53913cc91771162420ef75671e3\",\"title\":\"Boundary Content Graph Neural Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/ab87795177c3d53913cc91771162420ef75671e3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91999133\",\"name\":\"Ji-Hwan Kim\"},{\"authorId\":\"3247148\",\"name\":\"Jae-Pil Heo\"}],\"doi\":\"10.1109/ACCESS.2019.2946898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1db07ce91065594751cd51d31f086bc02d42968\",\"title\":\"Learning Coarse and Fine Features for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f1db07ce91065594751cd51d31f086bc02d42968\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2008.11170\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"1694090\",\"name\":\"Christos Tzelepis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14bbd0a4ba94fa495de38dfaf78db5e82b8b7629\",\"title\":\"Boundary Uncertainty in a Single-Stage Temporal Action Localization Network\",\"url\":\"https://www.semanticscholar.org/paper/14bbd0a4ba94fa495de38dfaf78db5e82b8b7629\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.14303\",\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1109/tpami.2020.3038993\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613634071acd170fe5c20600f8d49662a8c3b23f\",\"title\":\"Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/613634071acd170fe5c20600f8d49662a8c3b23f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2038266421\",\"name\":\"Philip H.S. Torr Huazhong University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"2038266423\",\"name\":\"Alibaba Group\"},{\"authorId\":\"51909023\",\"name\":\"U. O. Oxford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50290191\",\"name\":\"Tianyu Li\"},{\"authorId\":\"2004641888\",\"name\":\"Bing Bing\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/s11042-020-09703-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a14f6a0222385bf0173c0737b47a0cce0c9b036\",\"title\":\"Boundary discrimination and proposal evaluation for temporal action proposal generation\",\"url\":\"https://www.semanticscholar.org/paper/7a14f6a0222385bf0173c0737b47a0cce0c9b036\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29850862\",\"name\":\"He-Yen Hsieh\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190975\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d0a1105f231ffc200d7b299fb962d8b673369be\",\"title\":\"Temporal Action Proposal Generation Via Deep Feature Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1105f231ffc200d7b299fb962d8b673369be\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1911.11462\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/cvpr42600.2020.01017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"title\":\"G-TAD: Sub-Graph Localization for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.06080\",\"authors\":[{\"authorId\":\"1409975963\",\"name\":\"Yushuai Hu\"},{\"authorId\":\"143618654\",\"name\":\"Y. Jin\"},{\"authorId\":\"48881611\",\"name\":\"R. Li\"},{\"authorId\":\"47958382\",\"name\":\"XiangXiang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"20541068388f9555b0cbb9b5004b4afe56d8ec66\",\"title\":\"CMSN: Continuous Multi-stage Network and Variable Margin Cosine Loss for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/20541068388f9555b0cbb9b5004b4afe56d8ec66\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.01065\",\"authors\":[{\"authorId\":\"1729393497\",\"name\":\"Ziyang Song\"},{\"authorId\":\"1508368547\",\"name\":\"Z. Yin\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"},{\"authorId\":\"144535741\",\"name\":\"C. Zhang\"},{\"authorId\":\"34739761\",\"name\":\"W. Chi\"},{\"authorId\":\"3338873\",\"name\":\"Yonggen Ling\"},{\"authorId\":\"13936152\",\"name\":\"Shenghao Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef66cdc03eefd0b9f11b021da8bb20164b79a21b\",\"title\":\"Attention-Oriented Action Recognition for Real-Time Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/ef66cdc03eefd0b9f11b021da8bb20164b79a21b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15841516\",\"name\":\"Shuo Chen\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144436744\",\"name\":\"Tao Hu\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1145/3372278.3390680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed38ab8511cd7f6a202730bfd3de566c3622562f\",\"title\":\"Interactivity Proposals for Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/ed38ab8511cd7f6a202730bfd3de566c3622562f\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2011.09158\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"97773539\",\"name\":\"Jiajie Wang\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"98049755\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1471647358\",\"name\":\"Qi Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"42b6d63416f46e9ac2bcdda9a7065f4682f18e93\",\"title\":\"Privileged Knowledge Distillation for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/42b6d63416f46e9ac2bcdda9a7065f4682f18e93\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09883\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1768672172\",\"name\":\"Zhenyu Jiang\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"title\":\"Complementary Boundary Generator with Scale-Invariant Relation Modeling for Temporal Action Localization: Submission to ActivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"93768847\",\"name\":\"Xinghan Wang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00984\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"title\":\"Learning Temporal Co-Attention Models for Unsupervised Video Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144809605\",\"name\":\"Xiaolong Liu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2034194541\",\"name\":\"Jianghu Lu\"},{\"authorId\":\"2034240637\",\"name\":\"Cong Yao\"},{\"authorId\":\"47943518\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/LSP.2020.3037796\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"title\":\"Self-Similarity Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.04145\",\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"49473137\",\"name\":\"Zhixiang Shi\"},{\"authorId\":\"1492113737\",\"name\":\"Jiani Li\"},{\"authorId\":\"50248679\",\"name\":\"Guanshuo Wang\"},{\"authorId\":\"46499930\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"50177639\",\"name\":\"Xiaoping Zhou\"}],\"doi\":\"10.1609/AAAI.V34I07.6711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36e38dbfee27f7a34d184dd58186944636de5258\",\"title\":\"Accurate Temporal Action Proposal Generation with Relation-Aware Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/36e38dbfee27f7a34d184dd58186944636de5258\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2008.03270\",\"authors\":[{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1007/978-3-030-60639-8_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"title\":\"Multi-level Temporal Pyramid Network for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41172535\",\"name\":\"Che Sun\"},{\"authorId\":\"40506635\",\"name\":\"Hao Song\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"40dd38de26834c7d6da8607c6d55a52d0db9e2ba\",\"title\":\"Exploiting Informative Video Segments for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/40dd38de26834c7d6da8607c6d55a52d0db9e2ba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.00707\",\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"9693996\",\"name\":\"Liangfeng Zheng\"},{\"authorId\":\"144654776\",\"name\":\"Kun Bai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/icme46284.2020.9102850\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"title\":\"Scale Matters: Temporal Scale Aggregation Network For Precise Action Localization In Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2006.16166\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"1780000543\",\"name\":\"Helene Haugerud\"},{\"authorId\":\"1670961136\",\"name\":\"Daniel Oh\"},{\"authorId\":\"2146343\",\"name\":\"O. Mohareri\"}],\"doi\":\"10.1007/978-3-030-59716-0_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65c3b0ab81cd7294b22df4cb6c30b2b2a792ce23\",\"title\":\"Automatic Operating Room Surgical Activity Recognition for Robot-Assisted Surgery\",\"url\":\"https://www.semanticscholar.org/paper/65c3b0ab81cd7294b22df4cb6c30b2b2a792ce23\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2008.09837\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2020.3016486\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"086057656b94de8bfd0d50ebe935e3d433f593d3\",\"title\":\"Revisiting Anchor Mechanisms for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/086057656b94de8bfd0d50ebe935e3d433f593d3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2008.07728\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Tao Zhao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c065821de73b6bb87a2a2376134ac9c28008486\",\"title\":\"Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/1c065821de73b6bb87a2a2376134ac9c28008486\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.11306\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"50112704\",\"name\":\"Sumin Lee\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2019.2953187\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"13aa627f35de78af64d1861fceb97c834a769b05\",\"title\":\"SRG: Snippet Relatedness-Based Temporal Action Proposal Generator\",\"url\":\"https://www.semanticscholar.org/paper/13aa627f35de78af64d1861fceb97c834a769b05\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1912.04461\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.00089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a57a186a0b71ed38afaa9d5594b28f942a7b6231\",\"title\":\"Learning to Discriminate Information for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/a57a186a0b71ed38afaa9d5594b28f942a7b6231\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.07517\",\"authors\":[{\"authorId\":\"49606678\",\"name\":\"Jianan Wang\"},{\"authorId\":\"49730189\",\"name\":\"Boyang Li\"},{\"authorId\":\"46515715\",\"name\":\"Xiangyu Fan\"},{\"authorId\":\"1845592115\",\"name\":\"J. Lin\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5cbd60f07a19afc3566376e404a490865e5def\",\"title\":\"Data-efficient Alignment of Multimodal Sequences by Aligning Gradient Updates and Internal Feature Distributions\",\"url\":\"https://www.semanticscholar.org/paper/5f5cbd60f07a19afc3566376e404a490865e5def\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.14598\",\"authors\":[{\"authorId\":\"1753647133\",\"name\":\"Chen Zhao\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b19e442f6d313c211b522a791252de2c2468063b\",\"title\":\"Video Self-Stitching Graph Network for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b19e442f6d313c211b522a791252de2c2468063b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_32\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"44e8ddac792f35105dd4db176345515f531a0b71\",\"title\":\"Bottom-Up Temporal Action Localization with Mutual Regularization\",\"url\":\"https://www.semanticscholar.org/paper/44e8ddac792f35105dd4db176345515f531a0b71\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":53848229,\"doi\":\"10.1109/CVPR.2019.00372\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Feng\"},{\"authorId\":null,\"name\":\"L. Ma\"},{\"authorId\":null,\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"T. Zhang\"},{\"authorId\":null,\"name\":\"J. Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video relocalization via cross gated bilinear matching\",\"url\":\"\",\"venue\":\"ECCV, pages 51\\u201366\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Redmon\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Yolo9000: better\",\"url\":\"\",\"venue\":\"faster, stronger. arXiv preprint\",\"year\":2017},{\"arxivId\":\"1710.06236\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1145/3123266.3123343\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"title\":\"Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1611.05709\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"}],\"doi\":\"10.1109/ICCV.2017.229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34919cf24b78ae1a71c10f5800f4084600ecd36d\",\"title\":\"Factorized Bilinear Models for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/34919cf24b78ae1a71c10f5800f4084600ecd36d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Y. Lin\"},{\"authorId\":null,\"name\":\"P. Dollar\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"K. He\"},{\"authorId\":null,\"name\":\"B. Hariharan\"},{\"authorId\":null,\"name\":\"S. Belongie\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge : Action recognition with a large number of classes Single shot temporal action detection\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1612.03144\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1790580\",\"name\":\"Bharath Hariharan\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2017.106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9b4e05faa194e5022edd9eb9dd07e3d675c2b36\",\"title\":\"Feature Pyramid Networks for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b9b4e05faa194e5022edd9eb9dd07e3d675c2b36\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"153216896\",\"name\":\"D. Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"title\":\"MSR Asia MSM at ActivityNet Challenge 2017: Trimmed Action Recognition, Temporal Action Proposals and Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b42f83a720bd4156113ba5350add2df2673daf0\",\"title\":\"Action Recognition and Detection by Combining Motion and Appearance Features\",\"url\":\"https://www.semanticscholar.org/paper/2b42f83a720bd4156113ba5350add2df2673daf0\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1703.02716\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"title\":\"A Pursuit of Temporal Accuracy in General Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1705.03122\",\"authors\":[{\"authorId\":\"2401865\",\"name\":\"Jonas Gehring\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"},{\"authorId\":\"13759615\",\"name\":\"Denis Yarats\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43428880d75b3a14257c3ee9bda054e61eb869c0\",\"title\":\"Convolutional Sequence to Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/43428880d75b3a14257c3ee9bda054e61eb869c0\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1807.08333\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01270-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"523909d26ea94eaa0dd0285ba6ea0cd00a0aa7ca\",\"title\":\"AutoLoc: Weakly-Supervised Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/523909d26ea94eaa0dd0285ba6ea0cd00a0aa7ca\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Divvala J. Redmon\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ssd : Single shot multibox detector Rectified linear units improve restricted boltzmann machines\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":\"1701.06659\",\"authors\":[{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"22748016\",\"name\":\"A. Ranga\"},{\"authorId\":\"36183106\",\"name\":\"Ambrish Tyagi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e94183191183a368bf07eb544654bae4b3cbf407\",\"title\":\"DSSD : Deconvolutional Single Shot Detector\",\"url\":\"https://www.semanticscholar.org/paper/e94183191183a368bf07eb544654bae4b3cbf407\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1506.02640\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.91\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"title\":\"You Only Look Once: Unified, Real-Time Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1806.02964\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"3004751\",\"name\":\"Chongjing Wang\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-030-01225-0_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49e2b4db35a408e91353578764be9085ac1210da\",\"title\":\"BSN: Boundary Sensitive Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/49e2b4db35a408e91353578764be9085ac1210da\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Feng\"},{\"authorId\":null,\"name\":\"L. Ma\"},{\"authorId\":null,\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"T. Zhang\"},{\"authorId\":null,\"name\":\"J. Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video relocalization via cross gated bilinear matching\",\"url\":\"\",\"venue\":\"ECCV, pages 51\\u201366\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. Roshan Zamir\"},{\"authorId\":null,\"name\":\"G. Toderici\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"ECCV Workshop\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1109/TIP.2015.2456412\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89ff7cbcea8e69b7c3cc62a4226cc3c1d00c9766\",\"title\":\"Human Action Recognition in Unconstrained Videos by Explicit Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/89ff7cbcea8e69b7c3cc62a4226cc3c1d00c9766\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382424098\",\"name\":\"\\u0422\\u0430\\u0440\\u0430\\u0441\\u0430 \\u0428\\u0435\\u0432\\u0447\\u0435\\u043d\\u043a\\u0430\"},{\"authorId\":\"1397452703\",\"name\":\"\\u0412\\u0430\\u0441\\u0438\\u043b\\u044f \\u041a\\u0430\\u0440\\u0430\\u0437\\u0456\\u043d\\u0430\"},{\"authorId\":\"1397452698\",\"name\":\"\\u041e\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u0430 \\u0411\\u043e\\u0433\\u043e\\u043c\\u043e\\u043b\\u044c\\u0446\\u044f\"}],\"doi\":\"10.1093/clinchem/60.1.283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"title\":\"Quo vadis?\",\"url\":\"https://www.semanticscholar.org/paper/dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"venue\":\"Clinical chemistry\",\"year\":2013},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1512.02325\",\"authors\":[{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1007/978-3-319-46448-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"title\":\"SSD: Single Shot MultiBox Detector\",\"url\":\"https://www.semanticscholar.org/paper/4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"K. He\"},{\"authorId\":null,\"name\":\"B. Hariharan\"},{\"authorId\":null,\"name\":\"S. Belongie\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge : Action recognition with a large number of classes Single shot temporal action detection\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Shu\"},{\"authorId\":null,\"name\":\"D. Xie\"},{\"authorId\":null,\"name\":\"B. Rothrock\"},{\"authorId\":null,\"name\":\"S. Todorovic\"},{\"authorId\":null,\"name\":\"S. Chun Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Joint inference of groups\",\"url\":\"\",\"venue\":\"events and human roles in aerial videos. In CVPR, pages 4576\\u20134584\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":\"10.1109/CVPR.2016.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"title\":\"Temporal Action Localization with Pyramid of Score Distribution Features\",\"url\":\"https://www.semanticscholar.org/paper/374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2018.2877936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"title\":\"Toward Efficient Action Recognition: Principal Backpropagation for Training Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1704.04671\",\"authors\":[{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144720255\",\"name\":\"T. Lu\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/CVPR.2017.342\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60ca4a90d751e315a2b143289a5c54488e324949\",\"title\":\"Temporal Action Localization by Structured Maximal Sums\",\"url\":\"https://www.semanticscholar.org/paper/60ca4a90d751e315a2b143289a5c54488e324949\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1807.04821\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-01216-8_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a52d7c53bb0745994e476079bbdea8b8577582a3\",\"title\":\"CTAP: Complementary Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/a52d7c53bb0745994e476079bbdea8b8577582a3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Redmon\"},{\"authorId\":null,\"name\":\"S. Divvala\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"You only look once: Unified\",\"url\":\"\",\"venue\":\"real-time object detection. In CVPR, pages 779\\u2013788\",\"year\":2016},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S.-F. Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Weaklysupervised temporal action localization in untrimmed videos\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V33I01.33018175\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d85117bc69847b64f90424f4858ffc55c4fa3963\",\"title\":\"Localizing Natural Language in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d85117bc69847b64f90424f4858ffc55c4fa3963\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557639\",\"name\":\"V. Nair\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a538b05ebb01a40323997629e171c91aa28b8e2f\",\"title\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2016.341\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f3e06ddedd4e6ac799679b65a20e9170a8b753e\",\"title\":\"Temporal Action Detection Using a Statistical Language Model\",\"url\":\"https://www.semanticscholar.org/paper/5f3e06ddedd4e6ac799679b65a20e9170a8b753e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1007/978-3-642-33715-4_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b071b910f8dc0c64c26730da144cddbedc29ed07\",\"title\":\"Trajectory-Based Modeling of Human Actions with Motion Reference Points\",\"url\":\"https://www.semanticscholar.org/paper/b071b910f8dc0c64c26730da144cddbedc29ed07\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1707.06750\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"title\":\"Temporal Convolution Based Action Proposal: Submission to ActivityNet 2017\",\"url\":\"https://www.semanticscholar.org/paper/af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97398356607115f78d677663a682363eec3302d7\",\"title\":\"Highlight Detection with Pairwise Deep Ranking for First-Person Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/97398356607115f78d677663a682363eec3302d7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1708.02349\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"144091320\",\"name\":\"Guyue Zhang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"10727378\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICCV.2017.610\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5f0167299d73b19d800953dd2859a0af2244a0c5\",\"title\":\"Temporal Context Network for Activity Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5f0167299d73b19d800953dd2859a0af2244a0c5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1505.05957\",\"authors\":[{\"authorId\":\"1844358\",\"name\":\"Tianmin Shu\"},{\"authorId\":\"48811777\",\"name\":\"Dan Xie\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2015.7299088\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b466bb66ee79c8e9bcdb6cf9acb54b864dda735\",\"title\":\"Joint inference of groups, events and human roles in aerial videos\",\"url\":\"https://www.semanticscholar.org/paper/3b466bb66ee79c8e9bcdb6cf9acb54b864dda735\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"35350470\",\"name\":\"Yue Gao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1016/j.neucom.2012.06.044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bc4f309cd5344576907bb1a8f5f317a00188e31\",\"title\":\"Mining spatiotemporal video patterns towards robust action retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3bc4f309cd5344576907bb1a8f5f317a00188e31\",\"venue\":\"Neurocomputing\",\"year\":2013},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1803.11438\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"37378985\",\"name\":\"Wei Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00795\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba7405516e1408f0ee6e0d0a8c6d511ce33c0551\",\"title\":\"Reconstruction Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ba7405516e1408f0ee6e0d0a8c6d511ce33c0551\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Feng\"},{\"authorId\":null,\"name\":\"L. Ma\"},{\"authorId\":null,\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"T. Zhang\"},{\"authorId\":null,\"name\":\"J. Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video relocalization\",\"url\":\"\",\"venue\":\"ECCV, pages 51\\u201366\",\"year\":2018}],\"title\":\"Multi-Granularity Generator for Temporal Action Proposal\",\"topics\":[{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Face Animation Parameter\",\"topicId\":\"1977660\",\"url\":\"https://www.semanticscholar.org/topic/1977660\"},{\"topic\":\"Self-propelled particles\",\"topicId\":\"108857\",\"url\":\"https://www.semanticscholar.org/topic/108857\"},{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"}],\"url\":\"https://www.semanticscholar.org/paper/990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"