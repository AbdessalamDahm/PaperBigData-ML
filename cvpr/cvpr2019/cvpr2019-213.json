"{\"abstract\":\"We propose a framework for learning through drawing. Our goal is to learn the correspondence between spoken words and abstract visual attributes, from a dataset of spoken descriptions of images. Building upon recent findings that GAN representations can be manipulated to edit semantic concepts in the generated output, we propose a new method to use such GAN-generated images to train a model using a triplet loss. To apply the method, we develop Audio CLEVRGAN, a new dataset of audio descriptions of GAN-generated CLEVR images, and we describe a training procedure that creates a curriculum of GAN-generated images that focuses training on image pairs that differ in a specific, informative way. Training is done without additional supervision beyond the spoken captions and the GAN. We find that training that takes advantage of GAN-generated edited examples results in improvements in the model's ability to learn attributes compared to previous results. Our proposed learning framework also results in models that can associate spoken words with some abstract visual concepts such as color and size.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\",\"url\":\"https://www.semanticscholar.org/author/35399640\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\",\"url\":\"https://www.semanticscholar.org/author/39257069\"},{\"authorId\":\"144159726\",\"name\":\"David Bau\",\"url\":\"https://www.semanticscholar.org/author/144159726\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\",\"url\":\"https://www.semanticscholar.org/author/30507748\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\",\"url\":\"https://www.semanticscholar.org/author/145898106\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\",\"url\":\"https://www.semanticscholar.org/author/143805211\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2012.15454\",\"authors\":[{\"authorId\":null,\"name\":\"Wei-Ning Hsu\"},{\"authorId\":null,\"name\":\"David Harwath\"},{\"authorId\":null,\"name\":\"Christopher Song\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"title\":\"Text-Free Image-to-Speech Synthesis Using Learned Segmental Units\",\"url\":\"https://www.semanticscholar.org/paper/5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733076573\",\"name\":\"Tianrui Niu\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"103314054\",\"name\":\"Lingxuan Li\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"}],\"doi\":\"10.1145/3372278.3390684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f87d4df4fbd971aae721c761b0ebf6b3f662eb20\",\"title\":\"Image Synthesis from Locally Related Texts\",\"url\":\"https://www.semanticscholar.org/paper/f87d4df4fbd971aae721c761b0ebf6b3f662eb20\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1911.09602\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"2957796\",\"name\":\"Wei-Ning Hsu\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ec4dab7fe0abeed22dd9ecb25695ab4b66f108b\",\"title\":\"Learning Hierarchical Discrete Linguistic Units from Visually-Grounded Speech\",\"url\":\"https://www.semanticscholar.org/paper/9ec4dab7fe0abeed22dd9ecb25695ab4b66f108b\",\"venue\":\"ICLR\",\"year\":2020}],\"corpusId\":119090137,\"doi\":\"10.1109/CVPR.2019.00213\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"16309504\",\"name\":\"S. Butler\"},{\"authorId\":\"38952681\",\"name\":\"J. Gross\"},{\"authorId\":\"5061680\",\"name\":\"H. Hayne\"}],\"doi\":\"10.1037/0012-1649.31.4.597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8f21fe44f819d4f5be33062261037383bc72ab3\",\"title\":\"The effect of drawing on memory performance in young children.\",\"url\":\"https://www.semanticscholar.org/paper/f8f21fe44f819d4f5be33062261037383bc72ab3\",\"venue\":\"\",\"year\":1995},{\"arxivId\":\"1804.04121\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1400\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"title\":\"The Conversation: Deep Audio-Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1710.10196\",\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"744fe47157477235032f7bb3777800f9f2f45e52\",\"title\":\"Progressive Growing of GANs for Improved Quality, Stability, and Variation\",\"url\":\"https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.6856\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"title\":\"Object Detectors Emerge in Deep Scene CNNs\",\"url\":\"https://www.semanticscholar.org/paper/9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"title\":\"Unsupervised Learning of Spoken Language with Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1703.08136\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"40059964\",\"name\":\"Shane Settle\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.21437/INTERSPEECH.2017-502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93f46618df0a6cd81d9e42361082e7a80fc9adf7\",\"title\":\"Visually Grounded Learning of Keyword Prediction from Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/93f46618df0a6cd81d9e42361082e7a80fc9adf7\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1702.01991\",\"authors\":[{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"},{\"authorId\":\"7805500\",\"name\":\"Lieke Gelderloos\"},{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"}],\"doi\":\"10.18653/v1/P17-1057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4e8117aed23e806fbe7a623a4ff915ef60e6bef\",\"title\":\"Representations of language in a model of visually grounded speech signal\",\"url\":\"https://www.semanticscholar.org/paper/d4e8117aed23e806fbe7a623a4ff915ef60e6bef\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1701.07481\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.18653/v1/P17-1047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9140be329cd4ebbea8113087d65e68569b2f1269\",\"title\":\"Learning Word-Like Units from Joint Audio-Visual Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9140be329cd4ebbea8113087d65e68569b2f1269\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2879705\",\"name\":\"Hendrik Strobelt\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fc35a72375a8f8cfb7679bdf3e51e676618275a8\",\"title\":\"Visualizing and Understanding Generative Adversarial Networks (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/fc35a72375a8f8cfb7679bdf3e51e676618275a8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.03003\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"10698483\",\"name\":\"Jacob Menick\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30ec43601d48236f8983d7cc55bed9cc68262b57\",\"title\":\"Automated Curriculum Learning for Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/30ec43601d48236f8983d7cc55bed9cc68262b57\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1706.03815\",\"authors\":[{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"},{\"authorId\":\"19178849\",\"name\":\"M. Barking\"},{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"}],\"doi\":\"10.18653/v1/K17-1037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d719664b18578445931e9aa3e70e3672c9898ac\",\"title\":\"Encoding of phonology in a recurrent neural model of grounded speech\",\"url\":\"https://www.semanticscholar.org/paper/0d719664b18578445931e9aa3e70e3672c9898ac\",\"venue\":\"CoNLL\",\"year\":2017},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2373952\",\"name\":\"J. Louradour\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8de174ab5419b9d3127695405efd079808e956e8\",\"title\":\"Curriculum learning\",\"url\":\"https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":\"1706.01427\",\"authors\":[{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"143724694\",\"name\":\"D. Raposo\"},{\"authorId\":\"50181861\",\"name\":\"David G. T. Barrett\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"007112213ece771be72cbecfd59f048209facabd\",\"title\":\"A simple neural network module for relational reasoning\",\"url\":\"https://www.semanticscholar.org/paper/007112213ece771be72cbecfd59f048209facabd\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1506.05751\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"title\":\"Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1711.05611\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2018.2858759\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5f1b2df8b4ad9a50671709f062ffd8674bb9dc5\",\"title\":\"Interpreting Deep Visual Representations via Network Dissection\",\"url\":\"https://www.semanticscholar.org/paper/c5f1b2df8b4ad9a50671709f062ffd8674bb9dc5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"},{\"authorId\":\"46317290\",\"name\":\"Qian Zhao\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21d255246cd7ddba24a651fd716950f893ea8eb2\",\"title\":\"Self-Paced Curriculum Learning\",\"url\":\"https://www.semanticscholar.org/paper/21d255246cd7ddba24a651fd716950f893ea8eb2\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144559601\",\"name\":\"Jennifer Drexler\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/GLU.2017-12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a89449e763fea5c9a06c30e4c11072de54f6f49\",\"title\":\"Analysis of Audio-Visual Features for Unsupervised Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6a89449e763fea5c9a06c30e4c11072de54f6f49\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"I. Goodfellow\"},{\"authorId\":null,\"name\":\"D. Metaxas\"},{\"authorId\":null,\"name\":\"A. Odena\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Selfattention generative adversarial networks\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1805.08318,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Laine\"},{\"authorId\":null,\"name\":\"J. Lehtinen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"sually grounded learning of keyword prediction from untran - scribed speech\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145364504\",\"name\":\"D. Roy\"},{\"authorId\":\"144994682\",\"name\":\"A. Pentland\"}],\"doi\":\"10.1016/S0364-0213(01)00061-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98d6a531a741964ea547f5c8533a3b65e04603d9\",\"title\":\"Learning words from sights and sounds: a computational model\",\"url\":\"https://www.semanticscholar.org/paper/98d6a531a741964ea547f5c8533a3b65e04603d9\",\"venue\":\"Cogn. Sci.\",\"year\":2002},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1703.03717\",\"authors\":[{\"authorId\":\"50683297\",\"name\":\"A. Ross\"},{\"authorId\":\"2169240\",\"name\":\"M. Hughes\"},{\"authorId\":\"1388372395\",\"name\":\"Finale Doshi-Velez\"}],\"doi\":\"10.24963/ijcai.2017/371\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7db2afdc5eb5db46cc64185d0a51ed079b0976e8\",\"title\":\"Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations\",\"url\":\"https://www.semanticscholar.org/paper/7db2afdc5eb5db46cc64185d0a51ed079b0976e8\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1803.05268\",\"authors\":[{\"authorId\":\"3296335\",\"name\":\"D. Mascharka\"},{\"authorId\":\"46450184\",\"name\":\"Philip Tran\"},{\"authorId\":\"49902902\",\"name\":\"Ryan Soklaski\"},{\"authorId\":\"2905057\",\"name\":\"A. Majumdar\"}],\"doi\":\"10.1109/CVPR.2018.00519\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd0a7c58964905ccfddbad1614165320ccc56393\",\"title\":\"Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cd0a7c58964905ccfddbad1614165320ccc56393\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1704.05796\",\"authors\":[{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"744464cd6fa8341633cd3b5d378faab18a3b543a\",\"title\":\"Network Dissection: Quantifying Interpretability of Deep Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/744464cd6fa8341633cd3b5d378faab18a3b543a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd000f4a7a64db5e00b200b93cc3f13c9e313c01\",\"title\":\"Attributes as Operators\",\"url\":\"https://www.semanticscholar.org/paper/cd000f4a7a64db5e00b200b93cc3f13c9e313c01\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Harwath\"},{\"authorId\":null,\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Towards visually grounded subword unit discovery\",\"url\":\"\",\"venue\":\"In ICASSP,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2884373\",\"name\":\"J. Elman\"}],\"doi\":\"10.1016/0010-0277(93)90058-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5ddb30bf421bdfdf728b636993dc48b1e879176\",\"title\":\"Learning and development in neural networks: the importance of starting small\",\"url\":\"https://www.semanticscholar.org/paper/d5ddb30bf421bdfdf728b636993dc48b1e879176\",\"venue\":\"Cognition\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Settle H. Kamper\"},{\"authorId\":null,\"name\":\"G. Shakhnarovich\"},{\"authorId\":null,\"name\":\"K. Livescu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"sually grounded learning of keyword prediction from untran - scribed speech\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48281014\",\"name\":\"C. Gong\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"1688428\",\"name\":\"Jie Yang\"}],\"doi\":\"10.1109/TIP.2016.2563981\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e33b4945eb00d474faf11638865d29ad22e23a6\",\"title\":\"Multi-Modal Curriculum Learning for Semi-Supervised Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/9e33b4945eb00d474faf11638865d29ad22e23a6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1807.04225\",\"authors\":[{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"50181861\",\"name\":\"David G. T. Barrett\"},{\"authorId\":\"4690624\",\"name\":\"Ari S. Morcos\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"acc43abe319bca7652a91f7d4ca6187049fb82e4\",\"title\":\"Measuring abstract reasoning in neural networks\",\"url\":\"https://www.semanticscholar.org/paper/acc43abe319bca7652a91f7d4ca6187049fb82e4\",\"venue\":\"ICML\",\"year\":2018}],\"title\":\"Learning Words by Drawing Images\",\"topics\":[{\"topic\":\"Description\",\"topicId\":\"501\",\"url\":\"https://www.semanticscholar.org/topic/501\"},{\"topic\":\"Audio Media\",\"topicId\":\"14912\",\"url\":\"https://www.semanticscholar.org/topic/14912\"},{\"topic\":\"GIANT AXONAL NEUROPATHY 1\",\"topicId\":\"389947\",\"url\":\"https://www.semanticscholar.org/topic/389947\"},{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"Visual Word\",\"topicId\":\"235024\",\"url\":\"https://www.semanticscholar.org/topic/235024\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Triplet state\",\"topicId\":\"60687\",\"url\":\"https://www.semanticscholar.org/topic/60687\"},{\"topic\":\"Hearing Loss, High-Frequency\",\"topicId\":\"463735\",\"url\":\"https://www.semanticscholar.org/topic/463735\"},{\"topic\":\"Area striata structure\",\"topicId\":\"87361\",\"url\":\"https://www.semanticscholar.org/topic/87361\"},{\"topic\":\"Sound card\",\"topicId\":\"644915\",\"url\":\"https://www.semanticscholar.org/topic/644915\"},{\"topic\":\"Silo (dataset)\",\"topicId\":\"130506\",\"url\":\"https://www.semanticscholar.org/topic/130506\"},{\"topic\":\"gallium nitrate\",\"topicId\":\"67462\",\"url\":\"https://www.semanticscholar.org/topic/67462\"}],\"url\":\"https://www.semanticscholar.org/paper/bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"