"{\"abstract\":\"Studies have shown that a dominant class of questions asked by visually impaired users on images of their surroundings involves reading text in the image. But today\\u2019s VQA models can not read! Our paper takes a first step towards addressing this problem. First, we introduce a new \\u201cTextVQA\\u201d dataset to facilitate progress on this important problem. Existing datasets either have a small proportion of questions about text (e.g., the VQA dataset) or are too small (e.g., the VizWiz dataset). TextVQA contains 45,336 questions on 28,408 images that require reasoning about text to answer. Second, we introduce a novel model architecture that reads text in the image, reasons about it in the context of the image and the question, and predicts an answer which might be a deduction based on the text and the image or composed of the strings found in the image. Consequently, we call our approach Look, Read, Reason & Answer (LoRRA). We show that LoRRA outperforms existing state-of-the-art VQA models on our TextVQA dataset. We find that the gap between human performance and machine performance is significantly larger on TextVQA than on VQA 2.0, suggesting that TextVQA is well-suited to benchmark progress along directions complementary to VQA 2.0.\",\"arxivId\":\"1904.08920\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\",\"url\":\"https://www.semanticscholar.org/author/50286460\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\",\"url\":\"https://www.semanticscholar.org/author/2311222\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\",\"url\":\"https://www.semanticscholar.org/author/144826412\"},{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\",\"url\":\"https://www.semanticscholar.org/author/143804072\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\",\"url\":\"https://www.semanticscholar.org/author/39717886\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\",\"url\":\"https://www.semanticscholar.org/author/1746610\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\",\"url\":\"https://www.semanticscholar.org/author/34849128\"}],\"citationVelocity\":37,\"citations\":[{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1911.06258\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/cvpr42600.2020.01001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"title\":\"Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1665150187\",\"name\":\"Xin Qian\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"37298954\",\"name\":\"F. Du\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"73649257\",\"name\":\"J. Chan\"}],\"doi\":\"10.1145/3334480.3382946\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aab7ee416c0eada217b4ebde9778f26845c8f43\",\"title\":\"A Formative Study on Designing Accurate and Natural Figure Captioning Systems\",\"url\":\"https://www.semanticscholar.org/paper/5aab7ee416c0eada217b4ebde9778f26845c8f43\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48499775\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.01246\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7147091d3ce4f2e766fe57700fd891bd01d8ae40\",\"title\":\"Webly Supervised Knowledge Embedding Model for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7147091d3ce4f2e766fe57700fd891bd01d8ae40\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.12917\",\"authors\":[{\"authorId\":\"3442255\",\"name\":\"Zan-Xia Jin\"},{\"authorId\":\"2003456770\",\"name\":\"Heran Wu\"},{\"authorId\":\"46962194\",\"name\":\"C. Yang\"},{\"authorId\":\"31679477\",\"name\":\"Fang Zhou\"},{\"authorId\":\"2005306\",\"name\":\"Jingyan Qin\"},{\"authorId\":\"145628818\",\"name\":\"Lei Xiao\"},{\"authorId\":\"120644708\",\"name\":\"XuCheng Yin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d209f0d94492447713541b28373d9b6cad5edeb9\",\"title\":\"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d209f0d94492447713541b28373d9b6cad5edeb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.12394\",\"authors\":[{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4aa5454addde1542e0d01cfc68e6f5129630964d\",\"title\":\"All-in-One Image-Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/4aa5454addde1542e0d01cfc68e6f5129630964d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932765\",\"name\":\"N. Nguyen\"},{\"authorId\":\"50582171\",\"name\":\"R. Thawonmas\"},{\"authorId\":\"144263221\",\"name\":\"Pujana Paliyawan\"},{\"authorId\":\"35221020\",\"name\":\"H. Pham\"}],\"doi\":\"10.1109/CoG47356.2020.9231771\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0518b4777a7acfcd41fffbcc60e474d12bf60c96\",\"title\":\"JUSTIN: An Audience Participation Game With A Purpose for Collecting Descriptions for Artwork Images\",\"url\":\"https://www.semanticscholar.org/paper/0518b4777a7acfcd41fffbcc60e474d12bf60c96\",\"venue\":\"2020 IEEE Conference on Games (CoG)\",\"year\":2020},{\"arxivId\":\"2012.03662\",\"authors\":[{\"authorId\":\"50218156\",\"name\":\"Zhaokai Wang\"},{\"authorId\":\"7760591\",\"name\":\"Renda Bao\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1fe7a16266cf2316f436688e0df6c6350c885ef\",\"title\":\"Confidence-aware Non-repetitive Multimodal Transformers for TextCaps\",\"url\":\"https://www.semanticscholar.org/paper/b1fe7a16266cf2316f436688e0df6c6350c885ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29545186\",\"name\":\"M. Hosseinzadeh\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00365\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef6db51cb736116266025eb1eab2fb4f36b75310\",\"title\":\"Composed Query Image Retrieval Using Locally Bounded Features\",\"url\":\"https://www.semanticscholar.org/paper/ef6db51cb736116266025eb1eab2fb4f36b75310\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.07966\",\"authors\":[{\"authorId\":\"1380129958\",\"name\":\"Di Qi\"},{\"authorId\":\"143693093\",\"name\":\"L. Su\"},{\"authorId\":\"50185694\",\"name\":\"Jia Song\"},{\"authorId\":\"3474078\",\"name\":\"E. Cui\"},{\"authorId\":\"1490606819\",\"name\":\"Taroon Bharti\"},{\"authorId\":\"35378689\",\"name\":\"Arun Sacheti\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9fd5511b42206a27748f373e0fdb7eb76a23055\",\"title\":\"ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data\",\"url\":\"https://www.semanticscholar.org/paper/a9fd5511b42206a27748f373e0fdb7eb76a23055\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00330\",\"authors\":[{\"authorId\":\"51479145\",\"name\":\"Shailaja Keyur Sampat\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.413\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e0b3a58bf6e89e3756aaf0ad97ae8a8ec8f0955\",\"title\":\"Visuo-Lingustic Question Answering (VLQA) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5e0b3a58bf6e89e3756aaf0ad97ae8a8ec8f0955\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"}],\"doi\":\"10.18653/v1/2020.acl-main.469\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"title\":\"What Does BERT with Vision Look At?\",\"url\":\"https://www.semanticscholar.org/paper/cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.10226\",\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46433486\",\"name\":\"Yanzhao Zhou\"},{\"authorId\":\"103515844\",\"name\":\"Gen Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"39483833\",\"name\":\"Duyu Tang\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cda975be6f9fb55813bb6813b8c7c417331de7bd\",\"title\":\"Deep Reason: A Strong Baseline for Real-World Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cda975be6f9fb55813bb6813b8c7c417331de7bd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.00923\",\"authors\":[{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16fd23b6c6661cfba01c3b9624e6a2617e45bee9\",\"title\":\"Multimodal grid features and cell pointers for Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/16fd23b6c6661cfba01c3b9624e6a2617e45bee9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144382769\",\"name\":\"Viviana Beltr\\u00e1n\"},{\"authorId\":\"1748667\",\"name\":\"N. Journet\"},{\"authorId\":\"1732746\",\"name\":\"Micka\\u00ebl Coustaty\"},{\"authorId\":\"34796546\",\"name\":\"A. Doucet\"}],\"doi\":\"10.1109/ICDARW.2019.40088\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb38a28c53dc97b2b95a7fb2915a39a3f997e4fd\",\"title\":\"Semantic Text Recognition via Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cb38a28c53dc97b2b95a7fb2915a39a3f997e4fd\",\"venue\":\"2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)\",\"year\":2019},{\"arxivId\":\"1908.03557\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"title\":\"VisualBERT: A Simple and Performant Baseline for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144382769\",\"name\":\"Viviana Beltr\\u00e1n\"},{\"authorId\":\"1732746\",\"name\":\"Micka\\u00ebl Coustaty\"},{\"authorId\":\"1748667\",\"name\":\"N. Journet\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"34796546\",\"name\":\"A. Doucet\"}],\"doi\":\"10.1007/978-3-030-59830-3_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a210b0d83ab985228c47013456dfdbbe49831980\",\"title\":\"An Extended Evaluation of the Impact of Different Modules in ST-VQA Systems\",\"url\":\"https://www.semanticscholar.org/paper/a210b0d83ab985228c47013456dfdbbe49831980\",\"venue\":\"ICPRAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"151478793\",\"name\":\"S. Dey\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1016/j.patcog.2020.107656\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe01da1faa5bab1944c7b8b1a9f5b331a0ed91a7\",\"title\":\"Real-time Lexicon-free Scene Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/fe01da1faa5bab1944c7b8b1a9f5b331a0ed91a7\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"2012.04638\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"46583994\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1882479\",\"name\":\"D. Flor\\u00eancio\"},{\"authorId\":\"30602591\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"},{\"authorId\":\"145637095\",\"name\":\"Lei Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"title\":\"TAP: Text-Aware Pre-training for Text-VQA and Text-Caption\",\"url\":\"https://www.semanticscholar.org/paper/8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.00997\",\"authors\":[{\"authorId\":\"1388048026\",\"name\":\"Nitesh Methani\"},{\"authorId\":\"2409493\",\"name\":\"Pritha Ganguly\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"},{\"authorId\":\"46638795\",\"name\":\"Pratyush Kumar\"}],\"doi\":\"10.1109/WACV45572.2020.9093523\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9a9dcb7a9511968219c422d824e3bac69dc45832\",\"title\":\"PlotQA: Reasoning over Scientific Plots\",\"url\":\"https://www.semanticscholar.org/paper/9a9dcb7a9511968219c422d824e3bac69dc45832\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2004.08744\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"title\":\"Are we pretraining it right? Digging deeper into visio-linguistic pretraining\",\"url\":\"https://www.semanticscholar.org/paper/43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.05153\",\"authors\":[{\"authorId\":\"1476704317\",\"name\":\"Qi Zhu\"},{\"authorId\":\"2429278\",\"name\":\"Chenyu Gao\"},{\"authorId\":\"145498819\",\"name\":\"P. Wang\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"952edddbb3438072312756762be1bfde287e1497\",\"title\":\"Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps\",\"url\":\"https://www.semanticscholar.org/paper/952edddbb3438072312756762be1bfde287e1497\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.07735\",\"authors\":[{\"authorId\":\"40016108\",\"name\":\"Aman Chadha\"},{\"authorId\":\"2025073690\",\"name\":\"Gurneet Arora\"},{\"authorId\":\"2025065763\",\"name\":\"Navpreet Kaloty\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"title\":\"iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07542\",\"authors\":[{\"authorId\":\"40373267\",\"name\":\"Xiaoyu Yue\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"1733076657\",\"name\":\"Chenhao Lin\"},{\"authorId\":\"144124181\",\"name\":\"Hongbin Sun\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1007/978-3-030-58529-7_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"566a026da7d2b1eec034017d67c6bb901f5acd85\",\"title\":\"RobustScanner: Dynamically Enhancing Positional Clues for Robust Text Recognition\",\"url\":\"https://www.semanticscholar.org/paper/566a026da7d2b1eec034017d67c6bb901f5acd85\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.00490\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICDAR.2019.00251\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"title\":\"ICDAR 2019 Competition on Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":\"1905.10622\",\"authors\":[{\"authorId\":\"47327595\",\"name\":\"A. Dey\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"03d364f55fe34ba02e767db6a7f54962562b44d1\",\"title\":\"Beyond Visual Semantics: Exploring the Role of Scene Text in Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/03d364f55fe34ba02e767db6a7f54962562b44d1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.04058\",\"authors\":[{\"authorId\":\"48615049\",\"name\":\"Y. Xu\"},{\"authorId\":\"46308159\",\"name\":\"L. Chen\"},{\"authorId\":\"120235436\",\"name\":\"Zhongwei Cheng\"},{\"authorId\":\"71138167\",\"name\":\"Lixin Duan\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"title\":\"Open-Ended Visual Question Answering by Multi-Modal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2001.04732\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"2166891\",\"name\":\"S. Dey\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/WACV45572.2020.9093373\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"title\":\"Fine-grained Image Classification and Retrieval by Combining Visual and Locally Pooled Textual Features\",\"url\":\"https://www.semanticscholar.org/paper/871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2010.02582\",\"authors\":[{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a65b38abc44bd6acb06ebc87e7e4765609d88a3\",\"title\":\"Finding the Evidence: Localization-aware Answer Prediction for Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a65b38abc44bd6acb06ebc87e7e4765609d88a3\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2003.13962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01276\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"title\":\"Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text\",\"url\":\"https://www.semanticscholar.org/paper/c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.03615\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"title\":\"In Defense of Grid Features for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.08899\",\"authors\":[{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f71a7744fa383a2dbfad5959e78c56220d725eb\",\"title\":\"Document Visual Question Answering Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/1f71a7744fa383a2dbfad5959e78c56220d725eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03755\",\"authors\":[{\"authorId\":\"27549522\",\"name\":\"Goonmeet Bajaj\"},{\"authorId\":\"153100367\",\"name\":\"B. Bandyopadhyay\"},{\"authorId\":\"144545992\",\"name\":\"D. Schmidt\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"32264523\",\"name\":\"Christopher W. Myers\"},{\"authorId\":\"143724543\",\"name\":\"S. Parthasarathy\"}],\"doi\":\"10.1109/CVPRW50498.2020.00201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"title\":\"Understanding Knowledge Gaps in Visual Question Answering: Implications for Gap Identification and Testing\",\"url\":\"https://www.semanticscholar.org/paper/e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1907.12861\",\"authors\":[{\"authorId\":\"13726384\",\"name\":\"Ritwick Chaudhry\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"},{\"authorId\":\"2681580\",\"name\":\"Utkarsh Gupta\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"153841978\",\"name\":\"Prann Bansal\"},{\"authorId\":\"33901930\",\"name\":\"A. Joshi\"}],\"doi\":\"10.1109/WACV45572.2020.9093269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d47f20de7195fea82e48315fea52ccf06dc301d3\",\"title\":\"LEAF-QA: Locate, Encode & Attend for Figure Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d47f20de7195fea82e48315fea52ccf06dc301d3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1455114388\",\"name\":\"Hrituraj Singh\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baff151a5f1cb378d3627b88ff7d1b3afd29db45\",\"title\":\"STL-CQA: Structure-based Transformers with Localization and Encoding for Chart Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/baff151a5f1cb378d3627b88ff7d1b3afd29db45\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2005.03492\",\"authors\":[{\"authorId\":\"66273773\",\"name\":\"Xiaoxue Chen\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"49780704\",\"name\":\"Yuanzhi Zhu\"},{\"authorId\":\"30099960\",\"name\":\"Canjie Luo\"},{\"authorId\":\"3008041\",\"name\":\"T. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"708ed0964e998dc12ffb37d93719c481c417d87a\",\"title\":\"Text Recognition in the Wild: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/708ed0964e998dc12ffb37d93719c481c417d87a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"46264522\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICCV.2019.00470\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"title\":\"From Strings to Things: Knowledge-Enabled VQA Model That Can Read and Reason\",\"url\":\"https://www.semanticscholar.org/paper/ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.15381\",\"authors\":[{\"authorId\":\"1841136795\",\"name\":\"Koki Takeshita\"},{\"authorId\":\"66275346\",\"name\":\"Juntaro Shioyama\"},{\"authorId\":\"1809705\",\"name\":\"S. Uchida\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c85a290299b6c5cb309a1c750293ef34d98d24cf\",\"title\":\"Label or Message: A Large-Scale Experimental Survey of Texts and Objects Co-Occurrence\",\"url\":\"https://www.semanticscholar.org/paper/c85a290299b6c5cb309a1c750293ef34d98d24cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.04192\",\"authors\":[{\"authorId\":\"29068663\",\"name\":\"Ruize Wang\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"2193560\",\"name\":\"Piji Li\"},{\"authorId\":\"5006870\",\"name\":\"Haijun Shan\"},{\"authorId\":\"24263694\",\"name\":\"J. Zhang\"},{\"authorId\":\"1409702669\",\"name\":\"Qi Zhang\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c87e0cc7234d9a5fb2a33b8203d7d68c3d85d1d\",\"title\":\"Keep it Consistent: Topic-Aware Storytelling from an Image Stream via Iterative Multi-agent Communication\",\"url\":\"https://www.semanticscholar.org/paper/6c87e0cc7234d9a5fb2a33b8203d7d68c3d85d1d\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093452\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"title\":\"Visual Question Answering on 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1905.12008\",\"authors\":[{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"},{\"authorId\":\"145882781\",\"name\":\"D. Rajan\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"80893448\",\"name\":\"Alexis Asseman\"},{\"authorId\":\"50192121\",\"name\":\"A. Ozcan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2074ecfe2c7e2d2f7fdfb5c0480adb8c398cdf0b\",\"title\":\"Leveraging Medical Visual Question Answering with Supporting Facts\",\"url\":\"https://www.semanticscholar.org/paper/2074ecfe2c7e2d2f7fdfb5c0480adb8c398cdf0b\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00753\",\"authors\":[{\"authorId\":\"2429278\",\"name\":\"Chenyu Gao\"},{\"authorId\":\"1476704317\",\"name\":\"Qi Zhu\"},{\"authorId\":\"1585288737\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"title\":\"Structured Multimodal Attentions for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"113720743\",\"name\":\"Amin Parvaneh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR42600.2020.01006\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"title\":\"Counterfactual Vision and Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151496750\",\"name\":\"Surgan Jandial\"},{\"authorId\":\"9551558\",\"name\":\"Ayush Chopra\"},{\"authorId\":\"10357841\",\"name\":\"Pinkesh Badjatiya\"},{\"authorId\":\"1946040746\",\"name\":\"Pranit Chawla\"},{\"authorId\":\"39230373\",\"name\":\"Mausoom Sarkar\"},{\"authorId\":\"1557631185\",\"name\":\"Balaji Krishnamurthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcf55ad1e7b3b59c72159a51806cee543fbd6574\",\"title\":\"TRACE: Transform Aggregate and Compose Visiolinguistic Representations for Image Search with Text Feedback\",\"url\":\"https://www.semanticscholar.org/paper/dcf55ad1e7b3b59c72159a51806cee543fbd6574\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08325\",\"authors\":[{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1007/978-3-030-58589-1_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558984f821c4b9fb9aacf7441cf9ca6d303be836\",\"title\":\"VQA-LOL: Visual Question Answering under the Lens of Logic\",\"url\":\"https://www.semanticscholar.org/paper/558984f821c4b9fb9aacf7441cf9ca6d303be836\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143647292\",\"name\":\"F. Liu\"},{\"authorId\":\"49560222\",\"name\":\"Guanghui Xu\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"145229535\",\"name\":\"W. Jia\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1145/3394171.3413924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"title\":\"Cascade Reasoning Network for Text-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1908.01801\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"46328947\",\"name\":\"B. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/WACV45572.2020.9093494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"title\":\"Answering Questions about Data Visualizations using Efficient Bimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2006.15631\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"title\":\"Improving VQA and its Explanations by Comparing Competing Explanations\",\"url\":\"https://www.semanticscholar.org/paper/f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.04329\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"147961332\",\"name\":\"R. S. Rezende\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"23f74eff7453a31f75cd34abc04167c4b1ac9acb\",\"title\":\"StacMR: Scene-Text Aware Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/23f74eff7453a31f75cd34abc04167c4b1ac9acb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"46264474\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICDAR.2019.00156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1097cf8cf5961589ff693b069002e7181e24e631\",\"title\":\"OCR-VQA: Visual Question Answering by Reading Text in Images\",\"url\":\"https://www.semanticscholar.org/paper/1097cf8cf5961589ff693b069002e7181e24e631\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145098620\",\"name\":\"M. Ortiz\"},{\"authorId\":\"1683950\",\"name\":\"L. M. Bergasa\"},{\"authorId\":\"144347549\",\"name\":\"R. Arroyo\"},{\"authorId\":\"115023578\",\"name\":\"Sergio \\u00c1lvarez\"},{\"authorId\":\"153051245\",\"name\":\"Aitor Aller\"}],\"doi\":\"10.1007/978-3-030-62579-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60c389da22f6a0ec3467e029842c7c5baf0893d4\",\"title\":\"Towards Fine-Tuning of VQA Models in Public Datasets\",\"url\":\"https://www.semanticscholar.org/paper/60c389da22f6a0ec3467e029842c7c5baf0893d4\",\"venue\":\"WAF\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.12462\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"}],\"doi\":\"10.1007/978-3-030-58536-5_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7442eaaf453e63195cdee037f8e23830b4004027\",\"title\":\"TextCaps: a Dataset for Image Captioning with Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7442eaaf453e63195cdee037f8e23830b4004027\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11696\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":\"2535094\",\"name\":\"Mattia Rigotti\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"1999174380\",\"name\":\"Yair Schiff\"},{\"authorId\":\"49832828\",\"name\":\"R. A. Young\"},{\"authorId\":\"2679155\",\"name\":\"Brian M. Belgodere\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"title\":\"Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924571\",\"name\":\"Jing Wang\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413753\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"021d50ba5ae1c66e9175428f546976798126dd9f\",\"title\":\"Multimodal Attention with Image Text Spatial Relationship for OCR-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/021d50ba5ae1c66e9175428f546976798126dd9f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.00900\",\"authors\":[{\"authorId\":\"46650151\",\"name\":\"Kamran Alipour\"},{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"148376021\",\"name\":\"Xiao Lin\"},{\"authorId\":\"32330143\",\"name\":\"Jurgen P. Schulze\"},{\"authorId\":\"1400198856\",\"name\":\"Yi Yao\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"}],\"doi\":\"10.1109/HCCAI49649.2020.00010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f45cc95e7412bf8989a6c8f043d5fc69eecb910c\",\"title\":\"The Impact of Explanations on AI Competency Prediction in VQA\",\"url\":\"https://www.semanticscholar.org/paper/f45cc95e7412bf8989a6c8f043d5fc69eecb910c\",\"venue\":\"2020 IEEE International Conference on Humanized Computing and Communication with Artificial Intelligence (HCCAI)\",\"year\":2020},{\"arxivId\":\"2001.03339\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d27640ce75557156de13fb827b64446ef9cc0e4\",\"title\":\"Visual Question Answering on 360{\\\\deg} Images.\",\"url\":\"https://www.semanticscholar.org/paper/8d27640ce75557156de13fb827b64446ef9cc0e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51479145\",\"name\":\"Shailaja Keyur Sampat\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"586e5a4b40c7357725882442812866b11fb0bf60\",\"title\":\"Diverse Visuo-Lingustic Question Answering (DVLQA) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/586e5a4b40c7357725882442812866b11fb0bf60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00398\",\"authors\":[{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b40bfcf339de3f0dba08fabb2b58b9368ff4c51a\",\"title\":\"DocVQA: A Dataset for VQA on Document Images\",\"url\":\"https://www.semanticscholar.org/paper/b40bfcf339de3f0dba08fabb2b58b9368ff4c51a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.12146\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"},{\"authorId\":\"5153264\",\"name\":\"A. Schwing\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":\"10.1007/978-3-030-58545-7_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"title\":\"Spatially Aware Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.10215\",\"authors\":[{\"authorId\":\"48631626\",\"name\":\"Xinyu Wang\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"46668045\",\"name\":\"Chun Chet Ng\"},{\"authorId\":\"30099960\",\"name\":\"Canjie Luo\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"46699480\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"35462302\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01014\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"title\":\"On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.10248\",\"authors\":[{\"authorId\":\"40960698\",\"name\":\"Huaizheng Zhang\"},{\"authorId\":\"84065133\",\"name\":\"Y. Luo\"},{\"authorId\":\"1470571795\",\"name\":\"Qiming Ai\"},{\"authorId\":\"35324425\",\"name\":\"Nana Hou\"},{\"authorId\":\"145868453\",\"name\":\"Yonggang Wen\"}],\"doi\":\"10.1145/3394171.3413582\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"570ec4424ca7c2607c446109f8890eaf36f97e16\",\"title\":\"Look, Read and Feel: Benchmarking Ads Understanding with Multimodal Multitask Learning\",\"url\":\"https://www.semanticscholar.org/paper/570ec4424ca7c2607c446109f8890eaf36f97e16\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.04790\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"152422011\",\"name\":\"Aravind Mohan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"1389630028\",\"name\":\"Davide Testuggine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51b461040c381cb1489e55ea4b9686c709818b10\",\"title\":\"The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes\",\"url\":\"https://www.semanticscholar.org/paper/51b461040c381cb1489e55ea4b9686c709818b10\",\"venue\":\"NeurIPS\",\"year\":2020}],\"corpusId\":85553602,\"doi\":\"10.1109/CVPR.2019.00851\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":17,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"af1f7739283bdbd2b7a94903041f6d6afd991907\",\"references\":[{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ivan Krasin\"},{\"authorId\":null,\"name\":\"Tom Duerig\"},{\"authorId\":null,\"name\":\"Neil Alldrin\"},{\"authorId\":null,\"name\":\"Andreas Veit\"},{\"authorId\":null,\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":null,\"name\":\"Serge Belongie\"},{\"authorId\":null,\"name\":\"David Cai\"},{\"authorId\":null,\"name\":\"Zheyun Feng\"},{\"authorId\":null,\"name\":\"Vittorio Ferrari\"},{\"authorId\":null,\"name\":\"Victor Gomes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Openimages: A public dataset for large-scale multi-label and multi-class image classification\",\"url\":\"\",\"venue\":\"Dataset available from https://github. com/openimages,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"2730090\",\"name\":\"L. G. I. Bigorda\"},{\"authorId\":\"2098117\",\"name\":\"A. Nicolaou\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"},{\"authorId\":\"35613969\",\"name\":\"M. Iwamura\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"145532509\",\"name\":\"Lukas Neumann\"},{\"authorId\":\"2510839\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1809705\",\"name\":\"S. Uchida\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"}],\"doi\":\"10.1109/ICDAR.2015.7333942\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b02f729e6d442f6872078f599fc9da5c3605cee\",\"title\":\"ICDAR 2015 competition on Robust Reading\",\"url\":\"https://www.semanticscholar.org/paper/9b02f729e6d442f6872078f599fc9da5c3605cee\",\"venue\":\"2015 13th International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"I. Radosavovic\"},{\"authorId\":null,\"name\":\"G. Gkioxari\"},{\"authorId\":null,\"name\":\"P. Doll\\u00e1r\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and K\",\"url\":\"\",\"venue\":\"He. Detectron. https://github.com/ facebookresearch/detectron\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2219581\",\"name\":\"B. Boser\"},{\"authorId\":\"49869599\",\"name\":\"J. Denker\"},{\"authorId\":\"37274089\",\"name\":\"D. Henderson\"},{\"authorId\":\"32295804\",\"name\":\"R. Howard\"},{\"authorId\":\"34859193\",\"name\":\"W. Hubbard\"},{\"authorId\":\"2307573\",\"name\":\"L. Jackel\"}],\"doi\":\"10.1162/neco.1989.1.4.541\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8e8f3c8d4418c8d62e306538c9c1292635e9d27\",\"title\":\"Backpropagation Applied to Handwritten Zip Code Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8e8f3c8d4418c8d62e306538c9c1292635e9d27\",\"venue\":\"Neural Computation\",\"year\":1989},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1801.08163\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2018.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"title\":\"DVQA: Understanding Data Visualizations via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.01604\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3428769\",\"name\":\"Victor Zhong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e978d832a4d86571e1b52aa1685dc32ccb250f50\",\"title\":\"Dynamic Coattention Networks For Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e978d832a4d86571e1b52aa1685dc32ccb250f50\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1706.02677\",\"authors\":[{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"34837514\",\"name\":\"P. Noordhuis\"},{\"authorId\":\"39033676\",\"name\":\"L. Wesolowski\"},{\"authorId\":\"1717990\",\"name\":\"Aapo Kyrola\"},{\"authorId\":\"3609856\",\"name\":\"Andrew Tulloch\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"title\":\"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\",\"url\":\"https://www.semanticscholar.org/paper/0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147163487\",\"name\":\"R. Smith\"}],\"doi\":\"10.1109/ICDAR.2007.56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dea0d0617241a885152822e145c084d0c5318c23\",\"title\":\"An Overview of the Tesseract OCR Engine\",\"url\":\"https://www.semanticscholar.org/paper/dea0d0617241a885152822e145c084d0c5318c23\",\"venue\":\"Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"50262380\",\"name\":\"Yu Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d6dedf6d25df2a5cd727a019b613953afc9a0300\",\"title\":\"Pythia-A platform for vision & language research\",\"url\":\"https://www.semanticscholar.org/paper/d6dedf6d25df2a5cd727a019b613953afc9a0300\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Goyal\"},{\"authorId\":null,\"name\":\"P. Doll\\u00e1r\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"P. Noordhuis\"},{\"authorId\":null,\"name\":\"L. Wesolowski\"},{\"authorId\":null,\"name\":\"A. Kyrola\"},{\"authorId\":null,\"name\":\"A. Tulloch\"},{\"authorId\":null,\"name\":\"Y. Jia\"},{\"authorId\":null,\"name\":\"K. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Accurate\",\"url\":\"\",\"venue\":\"large minibatch sgd: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"145728969\",\"name\":\"James Yeh\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P17-2034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e28863c7fb963b40a379c5a4e0da00eb031933\",\"title\":\"A Corpus of Natural Language for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9e28863c7fb963b40a379c5a4e0da00eb031933\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1916865\",\"name\":\"Dinesh Raghu\"},{\"authorId\":null,\"name\":\"Nikhil Gupta\"},{\"authorId\":\"2674444\",\"name\":\"Mausam\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fff512a756d2c98de9f1eea8bc92b4ae7d9cf44\",\"title\":\"Hierarchical Pointer Memory Network for Task Oriented Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/7fff512a756d2c98de9f1eea8bc92b4ae7d9cf44\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Jiang\"},{\"authorId\":null,\"name\":\"V. Natarajan\"},{\"authorId\":null,\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"M. Rohrbach\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Pythia v0\",\"url\":\"\",\"venue\":\"1: the winning entry to the vqa challenge 2018. arXiv preprint arXiv:1807.09956\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39719398\",\"name\":\"Anand Mishra\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.5244/C.26.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb5b2df137a4d54c3a9145fa363e66531b491580\",\"title\":\"Scene Text Recognition using Higher Order Language Priors\",\"url\":\"https://www.semanticscholar.org/paper/bb5b2df137a4d54c3a9145fa363e66531b491580\",\"venue\":\"BMVC\",\"year\":2012},{\"arxivId\":\"1602.06023\",\"authors\":[{\"authorId\":\"1701451\",\"name\":\"Ramesh Nallapati\"},{\"authorId\":\"145218984\",\"name\":\"Bowen Zhou\"},{\"authorId\":\"1790831\",\"name\":\"C. D. Santos\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"144028698\",\"name\":\"B. Xiang\"}],\"doi\":\"10.18653/v1/K16-1028\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f37076f426023241f19cdc2fb0a0fd733a6fa7fa\",\"title\":\"Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/f37076f426023241f19cdc2fb0a0fd733a6fa7fa\",\"venue\":\"CoNLL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Wang\"},{\"authorId\":null,\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"C. Shen\"},{\"authorId\":null,\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"van den Hengel. Fvqa: Fact-based visual question answering. IEEE transactions on pattern analysis and machine intelligence\",\"year\":2018},{\"arxivId\":\"1603.07396\",\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"153778850\",\"name\":\"M. Salvato\"},{\"authorId\":\"3386570\",\"name\":\"Eric Kolve\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1007/978-3-319-46493-0_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"title\":\"A Diagram is Worth a Dozen Images\",\"url\":\"https://www.semanticscholar.org/paper/e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1609.07843\",\"authors\":[{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"40518045\",\"name\":\"James Bradbury\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"efbd381493bb9636f489b965a2034d529cd56bcd\",\"title\":\"Pointer Sentinel Mixture Models\",\"url\":\"https://www.semanticscholar.org/paper/efbd381493bb9636f489b965a2034d529cd56bcd\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1805.01216\",\"authors\":[{\"authorId\":\"1916865\",\"name\":\"Dinesh Raghu\"},{\"authorId\":\"1926074\",\"name\":\"Nikhil Gupta\"},{\"authorId\":\"2674444\",\"name\":\"Mausam\"}],\"doi\":\"10.18653/v1/N19-1126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74447bb5f2aa49d4281d82b71774e0d815600981\",\"title\":\"Disentangling Language and Knowledge in Task-Oriented Dialogs\",\"url\":\"https://www.semanticscholar.org/paper/74447bb5f2aa49d4281d82b71774e0d815600981\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1728316\",\"name\":\"K. Wang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1007/978-3-642-15549-9_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d307221fa52e3939d46180cb5921ebbd92c8adb\",\"title\":\"Word Spotting in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/0d307221fa52e3939d46180cb5921ebbd92c8adb\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1807.09956\",\"authors\":[{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"36c3972569a6949ecca90bfa6f8e99883e092845\",\"title\":\"Pythia v0.1: the Winning Entry to the VQA Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/36c3972569a6949ecca90bfa6f8e99883e092845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":\"10.1109/CVPR.2017.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"title\":\"Are You Smarter Than a Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.04368\",\"authors\":[{\"authorId\":\"13070498\",\"name\":\"A. See\"},{\"authorId\":\"35025299\",\"name\":\"Peter J. Liu\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/P17-1099\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"668db48c6a79826456341680ee1175dfc4cced71\",\"title\":\"Get To The Point: Summarization with Pointer-Generator Networks\",\"url\":\"https://www.semanticscholar.org/paper/668db48c6a79826456341680ee1175dfc4cced71\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1603.06393\",\"authors\":[{\"authorId\":\"3016273\",\"name\":\"Jiatao Gu\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"},{\"authorId\":\"144354165\",\"name\":\"V. Li\"}],\"doi\":\"10.18653/v1/P16-1154\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ba30df190664193514d1d309cb673728ed48f449\",\"title\":\"Incorporating Copying Mechanism in Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/ba30df190664193514d1d309cb673728ed48f449\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1607.01759\",\"authors\":[{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":\"10.18653/V1/E17-2068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"892e53fe5cd39f037cb2a961499f42f3002595dd\",\"title\":\"Bag of Tricks for Efficient Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/892e53fe5cd39f037cb2a961499f42f3002595dd\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":\"1601.07140\",\"authors\":[{\"authorId\":\"2799898\",\"name\":\"Andreas Veit\"},{\"authorId\":\"2152992\",\"name\":\"T. Matera\"},{\"authorId\":\"145532509\",\"name\":\"Lukas Neumann\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7325b788320f96f7b152768226f16e390ab6475\",\"title\":\"COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/b7325b788320f96f7b152768226f16e390ab6475\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1910.05085\",\"authors\":[{\"authorId\":\"2973998\",\"name\":\"Fedor Borisyuk\"},{\"authorId\":\"1821267\",\"name\":\"A. Gordo\"},{\"authorId\":\"145422368\",\"name\":\"V. Sivakumar\"}],\"doi\":\"10.1145/3219819.3219861\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fde3ee5f9f8e217a4d6716013315614811820f21\",\"title\":\"Rosetta: Large Scale System for Text Detection and Recognition in Images\",\"url\":\"https://www.semanticscholar.org/paper/fde3ee5f9f8e217a4d6716013315614811820f21\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"144360239\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"2925245\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1866029.1866080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"venue\":\"UIST '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Xu\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ask\",\"url\":\"\",\"venue\":\"attend and answer: Exploring question-guided spatial attention for visual question answering. In European Conference on Computer Vision, pages 451\\u2013466. Springer\",\"year\":2016},{\"arxivId\":\"1603.08148\",\"authors\":[{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3103594\",\"name\":\"Sungjin Ahn\"},{\"authorId\":\"1701451\",\"name\":\"Ramesh Nallapati\"},{\"authorId\":\"145218984\",\"name\":\"Bowen Zhou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.18653/v1/P16-1014\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aa5b35dcf8b024f5352db73cc3944e8fad4f3793\",\"title\":\"Pointing the Unknown Words\",\"url\":\"https://www.semanticscholar.org/paper/aa5b35dcf8b024f5352db73cc3944e8fad4f3793\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1802.05766\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"30a3eee5e9302108416f6234d739373dde68d373\",\"title\":\"Learning to Count Objects in Natural Images for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/30a3eee5e9302108416f6234d739373dde68d373\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1708.01336\",\"authors\":[{\"authorId\":\"144811744\",\"name\":\"L. Jiang\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"3256430\",\"name\":\"Sachin Farfade\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ceac30061d8f7985987448f4712c49eeb98efad2\",\"title\":\"MemexQA: Visual Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ceac30061d8f7985987448f4712c49eeb98efad2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1710.07300\",\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"title\":\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"},{\"authorId\":\"1630291637\",\"name\":\"Delle Scienze Umane\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630311779\",\"name\":\"Profilo IN Uscita\"},{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"}],\"doi\":\"10.1515/9783111413426-013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"title\":\"L\",\"url\":\"https://www.semanticscholar.org/paper/5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"Towards VQA Models That Can Read\",\"topics\":[{\"topic\":\"String (computer science)\",\"topicId\":\"8459\",\"url\":\"https://www.semanticscholar.org/topic/8459\"},{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"Natural deduction\",\"topicId\":\"135105\",\"url\":\"https://www.semanticscholar.org/topic/135105\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/af1f7739283bdbd2b7a94903041f6d6afd991907\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"