"{\"abstract\":\"Deep neural networks have achieved great successes on the image captioning task. However, most of the existing models depend heavily on paired image-sentence datasets, which are very expensive to acquire. In this paper, we make the first attempt to train an image captioning model in an unsupervised manner. Instead of relying on manually labeled image-sentence pairs, our proposed model merely requires an image set, a sentence corpus, and an existing visual concept detector. The sentence corpus is used to teach the captioning model how to generate plausible sentences. Meanwhile, the knowledge in the visual concept detector is distilled into the captioning model to guide the model to recognize the visual concepts in an image. In order to further encourage the generated captions to be semantically consistent with the image, the image and caption are projected into a common latent space so that they can reconstruct each other. Given that the existing sentence corpora are mainly designed for linguistic research and are thus with little reference to image contents, we crawl a large-scale image description corpus of two million natural sentences to facilitate the unsupervised image captioning scenario. Experimental results show that our proposed model is able to produce quite promising results without any caption annotations.\",\"arxivId\":\"1811.10787\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\",\"url\":\"https://www.semanticscholar.org/author/144599697\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\",\"url\":\"https://www.semanticscholar.org/author/145499468\"},{\"authorId\":\"40474876\",\"name\":\"Wei Liu\",\"url\":\"https://www.semanticscholar.org/author/40474876\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\",\"url\":\"https://www.semanticscholar.org/author/33642939\"}],\"citationVelocity\":20,\"citations\":[{\"arxivId\":\"1909.00279\",\"authors\":[{\"authorId\":\"48598711\",\"name\":\"Zhichao Yang\"},{\"authorId\":\"10330431\",\"name\":\"Pengshan Cai\"},{\"authorId\":\"1717629\",\"name\":\"Yansong Feng\"},{\"authorId\":\"144695376\",\"name\":\"Fei Li\"},{\"authorId\":\"2415466\",\"name\":\"Weijiang Feng\"},{\"authorId\":\"114986604\",\"name\":\"Elena Suet-Ying Chiu\"},{\"authorId\":null,\"name\":\"Hong Yu\"}],\"doi\":\"10.18653/v1/D19-1637\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1807377957da486c94f7ae1b99f309330e76655a\",\"title\":\"Generating Classical Chinese Poems from Vernacular Chinese\",\"url\":\"https://www.semanticscholar.org/paper/1807377957da486c94f7ae1b99f309330e76655a\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1903.10658\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICCV.2019.01042\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"title\":\"Unpaired Image Captioning via Scene Graph Alignments\",\"url\":\"https://www.semanticscholar.org/paper/f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.01067\",\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"title\":\"Video Captioning Using Weak Annotation\",\"url\":\"https://www.semanticscholar.org/paper/aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117546241\",\"name\":\"Taiga Kashima\"},{\"authorId\":\"31729722\",\"name\":\"Kento Masui\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.1109/ICIP40778.2020.9190770\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"132aec1160a846cdb7777b3457ff9a9ab15221fa\",\"title\":\"Unsupervised Visual Relationship Inference\",\"url\":\"https://www.semanticscholar.org/paper/132aec1160a846cdb7777b3457ff9a9ab15221fa\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1910.02766\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af35cf0c7d07c3ec090fa19fd38ab2429334128b\",\"title\":\"Adversarial reconstruction for Multi-modal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/af35cf0c7d07c3ec090fa19fd38ab2429334128b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.10072\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"title\":\"Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.07000\",\"authors\":[{\"authorId\":\"145144396\",\"name\":\"Dandan Song\"},{\"authorId\":\"4274864\",\"name\":\"Siyi Ma\"},{\"authorId\":\"2037300711\",\"name\":\"Zhanchen Sun\"},{\"authorId\":\"3389167\",\"name\":\"S. Yang\"},{\"authorId\":\"31364087\",\"name\":\"Lejian Liao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"title\":\"KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413908\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"title\":\"Controllable Video Captioning with an Exemplar Sentence\",\"url\":\"https://www.semanticscholar.org/paper/40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.04592\",\"authors\":[{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"2752573\",\"name\":\"Lisa Beinborn\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.377\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"306ec4956aa2bb4e29a0b5c8b52d1c0e6007a32b\",\"title\":\"Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/306ec4956aa2bb4e29a0b5c8b52d1c0e6007a32b\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1907.09085\",\"authors\":[{\"authorId\":\"2833005\",\"name\":\"Jianbo Yuan\"},{\"authorId\":\"145585312\",\"name\":\"Haofu Liao\"},{\"authorId\":\"48846787\",\"name\":\"R. Luo\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-32226-7_80\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1869383adbeda655aefe4f72c9b7c8e063928da8\",\"title\":\"Automatic Radiology Report Generation based on Multi-view Image Fusion and Medical Concept Enrichment\",\"url\":\"https://www.semanticscholar.org/paper/1869383adbeda655aefe4f72c9b7c8e063928da8\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":\"2003.11743\",\"authors\":[{\"authorId\":\"1491233100\",\"name\":\"Pranav Agarwal\"},{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"1594025086\",\"name\":\"V. Panagiotou\"},{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b430a5384c82beb6102106fbea0a134425a08c23\",\"title\":\"Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models\",\"url\":\"https://www.semanticscholar.org/paper/b430a5384c82beb6102106fbea0a134425a08c23\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"1908.06354\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"title\":\"A Fast and Accurate One-Stage Approach to Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.07075\",\"authors\":[{\"authorId\":\"151473861\",\"name\":\"Amandeep Kumar\"},{\"authorId\":\"144718285\",\"name\":\"S. Ghose\"},{\"authorId\":\"3021776\",\"name\":\"P. Chowdhury\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"},{\"authorId\":\"65727619\",\"name\":\"U. Pal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc1b83b40cf970327d6433e0ed1d6ec4d0140aef\",\"title\":\"UDBNET: Unsupervised Document Binarization Network via Adversarial Game\",\"url\":\"https://www.semanticscholar.org/paper/cc1b83b40cf970327d6433e0ed1d6ec4d0140aef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.13611\",\"authors\":[{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"47382681\",\"name\":\"Peipei Song\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.24963/ijcai.2020/128\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9c3f13969af79ce26d584935e8e39a4423a9d63f\",\"title\":\"Recurrent Relational Memory Network for Unsupervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9c3f13969af79ce26d584935e8e39a4423a9d63f\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037486210\",\"name\":\"Qiaoqiao Yang\"},{\"authorId\":\"1410201319\",\"name\":\"Guangxing Wang\"},{\"authorId\":\"1695975266\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"2037477833\",\"name\":\"Christos Grecos\"},{\"authorId\":\"143823414\",\"name\":\"Peng Ren\"}],\"doi\":\"10.2112/SI102-018.1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"556edd10f961c30fc523f291fe657db56a297850\",\"title\":\"Coastal Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/556edd10f961c30fc523f291fe657db56a297850\",\"venue\":\"Journal of Coastal Research\",\"year\":2020},{\"arxivId\":\"1909.03409\",\"authors\":[{\"authorId\":\"145066132\",\"name\":\"Bin Guo\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"151260226\",\"name\":\"Y. Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Y. Sun\"},{\"authorId\":\"2256618\",\"name\":\"Z. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"title\":\"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TIP.2020.3042086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"title\":\"Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"48697143\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"119594534\",\"name\":\"D. Orel\"},{\"authorId\":\"1656710484\",\"name\":\"Philippe Sordet\"},{\"authorId\":\"1751802\",\"name\":\"K. Aberer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c8f6450b17d8abfd336b7d5a37004e9c715c1d4\",\"title\":\"Upgrading the Newsroom: An Automated Image Selection System for News Articles\",\"url\":\"https://www.semanticscholar.org/paper/2c8f6450b17d8abfd336b7d5a37004e9c715c1d4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.11449\",\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"119594534\",\"name\":\"D. Orel\"},{\"authorId\":\"1656710484\",\"name\":\"Philippe Sordet\"},{\"authorId\":\"1751802\",\"name\":\"K. Aberer\"}],\"doi\":\"10.1145/3396520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84dbf5b9181d15cf518050704c87629bdec2b8c4\",\"title\":\"Upgrading the Newsroom\",\"url\":\"https://www.semanticscholar.org/paper/84dbf5b9181d15cf518050704c87629bdec2b8c4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1903.10118\",\"authors\":[{\"authorId\":\"144362275\",\"name\":\"K. Hagiwara\"},{\"authorId\":\"2374364\",\"name\":\"Yusuke Mukuta\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"604ce3df514d0fddcc944c1741a1217d94aeb19f\",\"title\":\"End-to-End Learning Using Cycle Consistency for Image-to-Caption Transformations\",\"url\":\"https://www.semanticscholar.org/paper/604ce3df514d0fddcc944c1741a1217d94aeb19f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.09042\",\"authors\":[{\"authorId\":\"46398531\",\"name\":\"Yongfei Liu\"},{\"authorId\":\"47241555\",\"name\":\"Bo Wan\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1609/aaai.v34i07.6833\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c6d410891bef95ce4240eaa6d4908feb493527c\",\"title\":\"Learning Cross-modal Context Graph for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7c6d410891bef95ce4240eaa6d4908feb493527c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92612355\",\"name\":\"Seoung-Ho Choi\"},{\"authorId\":\"2004804054\",\"name\":\"Seoung Yeon Jo\"},{\"authorId\":\"47165253\",\"name\":\"S. Jung\"}],\"doi\":\"10.1016/j.icte.2020.08.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1af6068ea47b37648ffe0075242c92a39dfabf8\",\"title\":\"Component based comparative analysis of each module in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a1af6068ea47b37648ffe0075242c92a39dfabf8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1908.05407\",\"authors\":[{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3343031.3350996\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1056e6e84d52cf45017aad544fa0406441abda0\",\"title\":\"Unpaired Cross-lingual Image Caption Generation with Self-Supervised Rewards\",\"url\":\"https://www.semanticscholar.org/paper/c1056e6e84d52cf45017aad544fa0406441abda0\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145066124\",\"name\":\"Bin Guo\"},{\"authorId\":\"46506266\",\"name\":\"Haiying Wang\"},{\"authorId\":\"151260226\",\"name\":\"Yasan Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Yueqi Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"title\":\"1 c-TextGen : Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.05684\",\"authors\":[{\"authorId\":\"46662193\",\"name\":\"V. Mittal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd6df4febb7135007077f835f9c44d12514aa522\",\"title\":\"AttnGrounder: Talking to Cars with Attention\",\"url\":\"https://www.semanticscholar.org/paper/dd6df4febb7135007077f835f9c44d12514aa522\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"49469303\",\"name\":\"Xin-yuan Zhang\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.21\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a32535fb09e35a0f8e24e4d4e9bd33222a5258e1\",\"title\":\"Semantic Matching for Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/a32535fb09e35a0f8e24e4d4e9bd33222a5258e1\",\"venue\":\"EMNLP 2020\",\"year\":2020},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"50172036\",\"name\":\"X. Wu\"},{\"authorId\":\"1993634137\",\"name\":\"Shen Ge\"},{\"authorId\":\"47958349\",\"name\":\"X. Zhang\"},{\"authorId\":\"144934703\",\"name\":\"Wei Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1145/3394171.3414004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"title\":\"Bridging the Gap between Vision and Language Domains for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52203335\",\"name\":\"Yanlong Dong\"},{\"authorId\":\"72095125\",\"name\":\"Y. Zhang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"51434236\",\"name\":\"Zongguo Wang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1016/j.patcog.2020.107573\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02b14bc694560b1ae5005136aa04e686e5690014\",\"title\":\"Unsupervised text-to-image synthesis\",\"url\":\"https://www.semanticscholar.org/paper/02b14bc694560b1ae5005136aa04e686e5690014\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47084642\",\"name\":\"Heng Song\"},{\"authorId\":\"1756644\",\"name\":\"Junwu Zhu\"},{\"authorId\":\"1591599792\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1016/j.compeleceng.2020.106630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"title\":\"avtmNet: Adaptive Visual-Text Merging Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":\"2009.08497\",\"authors\":[{\"authorId\":\"3216509\",\"name\":\"L. Zaadnoordijk\"},{\"authorId\":\"143862012\",\"name\":\"Tarek R. Besold\"},{\"authorId\":\"145234732\",\"name\":\"R. Cusack\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"106c718286812b3cdeb764934ed76b5108d7f7bc\",\"title\":\"The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons from Infant Learning\",\"url\":\"https://www.semanticscholar.org/paper/106c718286812b3cdeb764934ed76b5108d7f7bc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01288\",\"authors\":[{\"authorId\":\"144407296\",\"name\":\"J. Gao\"},{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"2721708\",\"name\":\"P. Yu\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8405576136062ea661febeeedbc5076235d5eb42\",\"title\":\"Unsupervised Cross-lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8405576136062ea661febeeedbc5076235d5eb42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"},{\"authorId\":\"49697077\",\"name\":\"Yue-Lin Sun\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206632\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"03a53b48a2c869658f969856acd2830711dc9ba9\",\"title\":\"Extricating from GroundTruth: An Unpaired Learning Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/03a53b48a2c869658f969856acd2830711dc9ba9\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2003.12633\",\"authors\":[{\"authorId\":\"24339915\",\"name\":\"Davis Gilton\"},{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"145952380\",\"name\":\"R. Willett\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"title\":\"Detection and Description of Change in Visual Streams\",\"url\":\"https://www.semanticscholar.org/paper/dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02201\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.18653/v1/D19-1208\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"a87d5654c41f3dfa7252d079045d7094f601f78e\",\"title\":\"Image Captioning with Very Scarce Supervised Data: Adversarial Semi-Supervised Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/a87d5654c41f3dfa7252d079045d7094f601f78e\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.98\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3263b941d0a77bbd2040612ec774ef063ef64c48\",\"title\":\"Semi-Supervised Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3263b941d0a77bbd2040612ec774ef063ef64c48\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":53771922,\"doi\":\"10.1109/CVPR.2019.00425\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"580fd9a601314ea32dc85ec98267b411dd3465cf\",\"references\":[{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1602.07261\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"122113652\",\"name\":\"Alexander Amir Alemi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"title\":\"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Huang\"},{\"authorId\":null,\"name\":\"Vivek Rathod\"},{\"authorId\":null,\"name\":\"Chen Sun\"},{\"authorId\":null,\"name\":\"Menglong Zhu\"},{\"authorId\":null,\"name\":\"Anoop Korattikara\"},{\"authorId\":null,\"name\":\"Alireza Fathi\"},{\"authorId\":null,\"name\":\"Ian Fischer\"},{\"authorId\":null,\"name\":\"Yang Song\"},{\"authorId\":null,\"name\":\"Sergio Guadarrama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Distill - ing the knowledge in a neural network Long short - term memory\",\"url\":\"\",\"venue\":\"Neural computation\",\"year\":1997},{\"arxivId\":\"1611.10012\",\"authors\":[{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"40303375\",\"name\":\"V. Rathod\"},{\"authorId\":\"145546535\",\"name\":\"Chen Sun\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":\"34786378\",\"name\":\"A. Balan\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"33091759\",\"name\":\"Ian S. Fischer\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"},{\"authorId\":\"49992891\",\"name\":\"Y. Song\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"}],\"doi\":\"10.1109/CVPR.2017.351\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a312a573ef81793d56401e932ef6c9498791a3d1\",\"title\":\"Speed/Accuracy Trade-Offs for Modern Convolutional Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/a312a573ef81793d56401e932ef6c9498791a3d1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"},{\"authorId\":\"144830983\",\"name\":\"Y. Mansour\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a20f0ce0616def7cc9a87446c228906cd5da093b\",\"title\":\"Policy Gradient Methods for Reinforcement Learning with Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":\"1806.06004\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ceabd7ff28ce2d501511da998252aeb938adc98b\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ceabd7ff28ce2d501511da998252aeb938adc98b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144346837\",\"name\":\"Min Yang\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"28106616\",\"name\":\"Yabing Feng\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1145/3132847.3132920\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3844a6cef7960729125722e2d07024058dd9204a\",\"title\":\"Dual Learning for Cross-domain Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3844a6cef7960729125722e2d07024058dd9204a\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1801.07736\",\"authors\":[{\"authorId\":\"26958176\",\"name\":\"W. Fedus\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2555924\",\"name\":\"Andrew M. Dai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d\",\"title\":\"MaskGAN: Better Text Generation via Filling in the ______\",\"url\":\"https://www.semanticscholar.org/paper/7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1603.09016\",\"authors\":[{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPRW.2016.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"title\":\"Rich Image Captioning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":\"1711.00043\",\"authors\":[{\"authorId\":\"1830914\",\"name\":\"Guillaume Lample\"},{\"authorId\":\"8905591\",\"name\":\"Ludovic Denoyer\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e3d772986d176057aca2f5e3eb783da53b559134\",\"title\":\"Unsupervised Machine Translation Using Monolingual Corpora Only\",\"url\":\"https://www.semanticscholar.org/paper/e3d772986d176057aca2f5e3eb783da53b559134\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12094097\",\"name\":\"Pratik P. Rane\"},{\"authorId\":\"118145941\",\"name\":\"A. Sargar\"},{\"authorId\":\"47039181\",\"name\":\"Faiza Shaikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f77a604410d88307ec5c6331c8b6133272fbaa10\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f77a604410d88307ec5c6331c8b6133272fbaa10\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1804.07755\",\"authors\":[{\"authorId\":\"1830914\",\"name\":\"Guillaume Lample\"},{\"authorId\":\"40511414\",\"name\":\"Myle Ott\"},{\"authorId\":\"2480903\",\"name\":\"Alexis Conneau\"},{\"authorId\":\"8905591\",\"name\":\"Ludovic Denoyer\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"}],\"doi\":\"10.18653/v1/D18-1549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48925fef94500cf19ee220ed74217816f1ab5e60\",\"title\":\"Phrase-Based & Neural Unsupervised Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/48925fef94500cf19ee220ed74217816f1ab5e60\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1710.10196\",\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"744fe47157477235032f7bb3777800f9f2f45e52\",\"title\":\"Progressive Growing of GANs for Improved Quality, Stability, and Variation\",\"url\":\"https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ivan Krasin\"},{\"authorId\":null,\"name\":\"Tom Duerig\"},{\"authorId\":null,\"name\":\"Neil Alldrin\"},{\"authorId\":null,\"name\":\"Vittorio Ferrari\"},{\"authorId\":null,\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":null,\"name\":\"Alina Kuznetsova\"},{\"authorId\":null,\"name\":\"Hassan Rom\"},{\"authorId\":null,\"name\":\"Jasper Uijlings\"},{\"authorId\":null,\"name\":\"Stefan Popov\"},{\"authorId\":null,\"name\":\"Shahab Kamali\"},{\"authorId\":null,\"name\":\"Matteo Malloci\"},{\"authorId\":null,\"name\":\"Jordi Pont-Tuset\"},{\"authorId\":null,\"name\":\"Andreas Veit\"},{\"authorId\":null,\"name\":\"Serge Belongie\"},{\"authorId\":null,\"name\":\"Victor Gomes\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Chen Sun\"},{\"authorId\":null,\"name\":\"Gal Chechik\"},{\"authorId\":null,\"name\":\"David Cai\"},{\"authorId\":null,\"name\":\"Zheyun Feng\"},{\"authorId\":null,\"name\":\"Dhyanesh Narayanan\"},{\"authorId\":null,\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Openimages: A public dataset for large-scale multi-label and multi-class image classification\",\"url\":\"\",\"venue\":\"Dataset available from https://storage.googleapis.com/openimages/web/index.html,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. Chen\"},{\"authorId\":null,\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"J. Xiao\"},{\"authorId\":null,\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"S.-F. Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zeroshot visual recognition using semantics-preserving adversarial embedding network\",\"url\":\"\",\"venue\":\"CVPR, volume 2\",\"year\":2018},{\"arxivId\":\"1503.02531\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c908739fbff75f03469d13d4a1a07de3414ee19\",\"title\":\"Distilling the Knowledge in a Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1798462\",\"name\":\"Pierre-Antoine Manzagol\"}],\"doi\":\"10.1145/1390156.1390294\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"843959ffdccf31c6694d135fad07425924f785b1\",\"title\":\"Extracting and composing robust features with denoising autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/843959ffdccf31c6694d135fad07425924f785b1\",\"venue\":\"ICML '08\",\"year\":2008},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1804.00887\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3dc2c3be0796f65154d2106ed4442889c84546df\",\"title\":\"Learning to Guide Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3dc2c3be0796f65154d2106ed4442889c84546df\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Szegedy\"},{\"authorId\":null,\"name\":\"S. Ioffe\"},{\"authorId\":null,\"name\":\"V. Vanhoucke\"},{\"authorId\":null,\"name\":\"A. A. Alemi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Inception-v4\",\"url\":\"\",\"venue\":\"inception-resnet and the impact of residual connections on learning. In AAAI, volume 4, page 12\",\"year\":2017},{\"arxivId\":\"1803.11439\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"144188763\",\"name\":\"Jian Yao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00834\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"title\":\"Regularizing RNNs for Caption Generation by Reconstructing the Past with the Present\",\"url\":\"https://www.semanticscholar.org/paper/85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"title\":\"A Semi-supervised Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1710.11041\",\"authors\":[{\"authorId\":\"2347956\",\"name\":\"M. Artetxe\"},{\"authorId\":\"3255091\",\"name\":\"Gorka Labaka\"},{\"authorId\":\"1733049\",\"name\":\"Eneko Agirre\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2a7afbb5609a723f8eea91bfde4b02579b048d6\",\"title\":\"Unsupervised Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/c2a7afbb5609a723f8eea91bfde4b02579b048d6\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":\"1809.11096\",\"authors\":[{\"authorId\":\"144588497\",\"name\":\"A. Brock\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22aab110058ebbd198edb1f1e7b4f69fb13c0613\",\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/22aab110058ebbd198edb1f1e7b4f69fb13c0613\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"},{\"authorId\":\"145606490\",\"name\":\"E. Klein\"},{\"authorId\":\"3213150\",\"name\":\"E. Loper\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a65f23d990231d461418067c808b09d84c19b2c\",\"title\":\"Natural Language Processing with Python\",\"url\":\"https://www.semanticscholar.org/paper/7a65f23d990231d461418067c808b09d84c19b2c\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1705.00930\",\"authors\":[{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"2717138\",\"name\":\"W. T. Hsu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2017.64\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"828a7b3122ebd5b8b0c617902bc04ac5a6c60240\",\"title\":\"Show, Adapt and Tell: Adversarial Training of Cross-Domain Image Captioner\",\"url\":\"https://www.semanticscholar.org/paper/828a7b3122ebd5b8b0c617902bc04ac5a6c60240\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002}],\"title\":\"Unsupervised Image Captioning\",\"topics\":[{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"The Sentence\",\"topicId\":\"1280747\",\"url\":\"https://www.semanticscholar.org/topic/1280747\"},{\"topic\":\"Speech corpus\",\"topicId\":\"68755\",\"url\":\"https://www.semanticscholar.org/topic/68755\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Sentence boundary disambiguation\",\"topicId\":\"857515\",\"url\":\"https://www.semanticscholar.org/topic/857515\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/580fd9a601314ea32dc85ec98267b411dd3465cf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"