"{\"abstract\":\"The human visual system excels at biasing the stereoscopic visual signals by the attention mechanisms. Traditional methods relying on the low-level features and depth relevant information for stereoscopic video saliency prediction have fundamental limitations. For example, it is cumbersome to model the interactions between multiple visual cues including spatial, temporal, and depth information as a result of the sophistication. In this paper, we argue that the high-level features are crucial and resort to the deep learning framework to learn the saliency map of stereoscopic videos. Driven by spatio-temporal coherence from consecutive frames, the model first imitates the mechanism of saliency by taking advantage of the 3D convolutional neural network. Subsequently, the saliency originated from the intrinsic depth is derived based on the correlations between left and right views in a data-driven manner. Finally, a Convolutional Long Short-Term Memory (Conv-LSTM) based fusion network is developed to model the instantaneous interactions between spatio-temporal and depth attributes, such that the ultimate stereoscopic saliency maps over time are produced. Moreover, we establish a new large-scale stereoscopic video saliency dataset (SVS) including 175 stereoscopic video sequences and their fixation density annotations, aiming to comprehensively study the intrinsic attributes for stereoscopic video saliency detection. Extensive experiments show that our proposed model can achieve superior performance compared to the state-of-the-art methods on the newly built dataset for stereoscopic videos.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\",\"url\":\"https://www.semanticscholar.org/author/30024940\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\",\"url\":\"https://www.semanticscholar.org/author/72541446\"},{\"authorId\":null,\"name\":\"Shiqi Wang\",\"url\":null},{\"authorId\":\"47320103\",\"name\":\"Shi-kai Li\",\"url\":\"https://www.semanticscholar.org/author/47320103\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\",\"url\":\"https://www.semanticscholar.org/author/1687386\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\",\"url\":\"https://www.semanticscholar.org/author/145054089\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2048571\",\"name\":\"Junlin Zhang\"},{\"authorId\":null,\"name\":\"Xu Wang\"}],\"doi\":\"10.1007/978-3-030-37734-2_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4723c24bfcfea72a56204492c79bd41e13973f2a\",\"title\":\"Light Field Salient Object Detection via Hybrid Priors\",\"url\":\"https://www.semanticscholar.org/paper/4723c24bfcfea72a56204492c79bd41e13973f2a\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"145931655\",\"name\":\"Jianmin Jiang\"}],\"doi\":\"10.1109/TIP.2020.2985531\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"917666c6ff2993f75dd77009ca41e69c81369707\",\"title\":\"Learning to Explore Saliency for Stereoscopic Videos Via Component-Based Interaction\",\"url\":\"https://www.semanticscholar.org/paper/917666c6ff2993f75dd77009ca41e69c81369707\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020}],\"corpusId\":198184676,\"doi\":\"10.1109/CVPR.2019.00998\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"},{\"authorId\":\"1723081\",\"name\":\"J. Li\"},{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"121797042\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"134585167\",\"name\":\"P. le Callet\"}],\"doi\":\"10.1109/TIP.2017.2721112\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dec6c4ac770bf890ce52fbfc2ce13814e4db5874\",\"title\":\"Visual Attention Modeling for Stereoscopic Video: A Benchmark and Computational Model\",\"url\":\"https://www.semanticscholar.org/paper/dec6c4ac770bf890ce52fbfc2ce13814e4db5874\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1109/CRV.2005.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3371e9c3ba2e7b284f4fb82c382a7a43d99489f\",\"title\":\"An attentional framework for stereo vision\",\"url\":\"https://www.semanticscholar.org/paper/a3371e9c3ba2e7b284f4fb82c382a7a43d99489f\",\"venue\":\"The 2nd Canadian Conference on Computer and Robot Vision (CRV'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2765755\",\"name\":\"Christel Chamaret\"},{\"authorId\":\"134717171\",\"name\":\"Sylvain Godeffroy\"},{\"authorId\":\"145146449\",\"name\":\"P. Lopez\"},{\"authorId\":\"21120270\",\"name\":\"Olivier Le Meur\"}],\"doi\":\"10.1117/12.837532\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"adc5eb2b0b9d26c08075f511dd67c7d5118e32e5\",\"title\":\"Adaptive 3D rendering based on region-of-interest\",\"url\":\"https://www.semanticscholar.org/paper/adc5eb2b0b9d26c08075f511dd67c7d5118e32e5\",\"venue\":\"Electronic Imaging\",\"year\":2010},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143669225\",\"name\":\"Q. Tu\"},{\"authorId\":\"1736046\",\"name\":\"A. Men\"},{\"authorId\":\"3334296\",\"name\":\"Zhuqing Jiang\"},{\"authorId\":\"145371439\",\"name\":\"Feng Ye\"},{\"authorId\":\"144841441\",\"name\":\"J. Xu\"}],\"doi\":\"10.1016/j.image.2015.07.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37044a449c4bfa1e2c96caa7cb989188344059dd\",\"title\":\"Video saliency detection incorporating temporal information in compressed domain\",\"url\":\"https://www.semanticscholar.org/paper/37044a449c4bfa1e2c96caa7cb989188344059dd\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"40474871\",\"name\":\"Wei Liu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68002a95c1adc6a17b2f73a72e8a9f00603e20e7\",\"title\":\"Observed Human Motion Ground-truth Zero-Velocity Res-GRU LSTM-3 LR Ours\",\"url\":\"https://www.semanticscholar.org/paper/68002a95c1adc6a17b2f73a72e8a9f00603e20e7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3350185\",\"name\":\"C. Lang\"},{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"2447444\",\"name\":\"Karthik Yadati\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1007/978-3-642-33709-3_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6166927f1fc3eea4b20a280ed898359e87eb332d\",\"title\":\"Depth Matters: Influence of Depth Cues on Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/6166927f1fc3eea4b20a280ed898359e87eb332d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"47909587\",\"name\":\"Y. Liu\"},{\"authorId\":\"36027198\",\"name\":\"Feifei Ren\"},{\"authorId\":\"47539861\",\"name\":\"J. Zhang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25c65c87968b94631d3dcca253478d9f50806be3\",\"title\":\"Video Saliency Detection via Dynamic Consistent Spatio-Temporal Attention Modelling\",\"url\":\"https://www.semanticscholar.org/paper/25c65c87968b94631d3dcca253478d9f50806be3\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"3238659\",\"name\":\"Zhaoting Ye\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TIP.2016.2628583\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3ed9103b9f9eee87ee0b1d3430b44c32bc140bc\",\"title\":\"Learning to Detect Video Saliency With HEVC Features\",\"url\":\"https://www.semanticscholar.org/paper/d3ed9103b9f9eee87ee0b1d3430b44c32bc140bc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1803.04842\",\"authors\":[{\"authorId\":\"1398288379\",\"name\":\"A. Banitalebi-Dehkordi\"},{\"authorId\":\"49617585\",\"name\":\"M. Pourazad\"},{\"authorId\":\"1687935\",\"name\":\"P. Nasiopoulos\"}],\"doi\":\"10.1007/s11042-016-4155-y\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d38a6ce1f01d2d51da65291f532b773e27b4bf21\",\"title\":\"A learning-based visual saliency prediction model for stereoscopic 3D video (LBVS-3D)\",\"url\":\"https://www.semanticscholar.org/paper/d38a6ce1f01d2d51da65291f532b773e27b4bf21\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931368\",\"name\":\"Haksub Kim\"},{\"authorId\":\"38107409\",\"name\":\"S. Lee\"},{\"authorId\":\"1747569\",\"name\":\"A. Bovik\"}],\"doi\":\"10.1109/TIP.2014.2303640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e63fba0516ef8af03c4fcb364aec5530bb81f753\",\"title\":\"Saliency Prediction on Stereoscopic Videos\",\"url\":\"https://www.semanticscholar.org/paper/e63fba0516ef8af03c4fcb364aec5530bb81f753\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":\"1702.00871\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1109/TIP.2017.2754941\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927e0a7b1f06102725a026f690077654fa53c76e\",\"title\":\"Video Salient Object Detection via Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/927e0a7b1f06102725a026f690077654fa53c76e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1411.1045\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"title\":\"Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on ImageNet\",\"url\":\"https://www.semanticscholar.org/paper/652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"2753356\",\"name\":\"J. Wang\"},{\"authorId\":\"40557752\",\"name\":\"Jing Li\"},{\"authorId\":\"2982651\",\"name\":\"Romuald P\\u00e9pion\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/QoMEX.2014.6982288\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e423c379335e112520795006a810ff3cb7883672\",\"title\":\"An eye tracking database for stereoscopic video\",\"url\":\"https://www.semanticscholar.org/paper/e423c379335e112520795006a810ff3cb7883672\",\"venue\":\"2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"2753356\",\"name\":\"J. Wang\"},{\"authorId\":\"1758088\",\"name\":\"M. Narwaria\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TIP.2014.2305100\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fea00573f62c3d0fac1c5e1011b02b156f56ba5f\",\"title\":\"Saliency detection for stereoscopic images\",\"url\":\"https://www.semanticscholar.org/paper/fea00573f62c3d0fac1c5e1011b02b156f56ba5f\",\"venue\":\"2013 Visual Communications and Image Processing (VCIP)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72436419\",\"name\":\"\\ud55c\\ubcf4\\ud615\"},{\"authorId\":\"70063817\",\"name\":\"\\ud64d\\uc2b9\\ud6c8\"},{\"authorId\":\"66219957\",\"name\":\"\\ub178\\ud604\\uc6b0\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da574437bde83aaa879f6285cf0a2676c85219bf\",\"title\":\"Learning Deconvolution Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/da574437bde83aaa879f6285cf0a2676c85219bf\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/TPAMI.2011.272\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"title\":\"Context-Aware Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1109/CVPR.2014.358\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145955205\",\"name\":\"R. J. Watt\"}],\"doi\":\"10.1364/JOSAA.4.002006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e6fcd89eaa3a4d610887969b445fb109e153827\",\"title\":\"Scanning from coarse to fine spatial scales in the human visual system after the onset of a stimulus.\",\"url\":\"https://www.semanticscholar.org/paper/7e6fcd89eaa3a4d610887969b445fb109e153827\",\"venue\":\"Journal of the Optical Society of America. A, Optics and image science\",\"year\":1987},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICME.2013.6607572\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d24fda5e12ff14eaf553723547a2400bf0c20be\",\"title\":\"Video saliency incorporating spatiotemporal cues and uncertainty weighting\",\"url\":\"https://www.semanticscholar.org/paper/2d24fda5e12ff14eaf553723547a2400bf0c20be\",\"venue\":\"ICME\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144207007\",\"name\":\"E. Potapova\"},{\"authorId\":\"1682587\",\"name\":\"M. Zillich\"},{\"authorId\":\"1742533\",\"name\":\"M. Vincze\"}],\"doi\":\"10.1007/978-3-642-23968-7_14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0f9570406426ea35e7c2dd6baf60329128dbc26\",\"title\":\"Learning What Matters: Combining Probabilistic Models of 2D and 3D Saliency Cues\",\"url\":\"https://www.semanticscholar.org/paper/e0f9570406426ea35e7c2dd6baf60329128dbc26\",\"venue\":\"ICVS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9718787\",\"name\":\"Rahma Kalboussi\"},{\"authorId\":\"3461934\",\"name\":\"M. Abdellaoui\"},{\"authorId\":\"1766272\",\"name\":\"A. Douik\"}],\"doi\":\"10.1109/IPAS.2016.7880113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"438e58e1eb1dac9bb8d57fe78163e191eb1428fe\",\"title\":\"A spatiotemporal model for video saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/438e58e1eb1dac9bb8d57fe78163e191eb1428fe\",\"venue\":\"2016 International Image Processing, Applications and Systems (IPAS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"184ffa4a4c36051de56e07d785e5b53928d8c472\",\"title\":\"DeepVS: A Deep Learning Based Video Saliency Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/184ffa4a4c36051de56e07d785e5b53928d8c472\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"35794245\",\"name\":\"X. Wang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"}],\"doi\":\"10.1007/978-3-319-48896-7_57\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a75f5d6a50656ddffff9f1ea6b427077a1f6252\",\"title\":\"Deep Learning Features Inspired Saliency Detection of 3D Images\",\"url\":\"https://www.semanticscholar.org/paper/2a75f5d6a50656ddffff9f1ea6b427077a1f6252\",\"venue\":\"PCM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782447\",\"name\":\"Yury Gitman\"},{\"authorId\":\"34966076\",\"name\":\"M. Erofeev\"},{\"authorId\":\"1776883\",\"name\":\"D. Vatolin\"},{\"authorId\":\"2575557\",\"name\":\"Bolshakov Andrey\"},{\"authorId\":\"152750350\",\"name\":\"A. Fedorov\"}],\"doi\":\"10.1109/ICIP.2014.7025220\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"68b03a697e25285d4e6456252b418bdf8646e532\",\"title\":\"Semiautomatic visual-attention modeling and its application to video compression\",\"url\":\"https://www.semanticscholar.org/paper/68b03a697e25285d4e6456252b418bdf8646e532\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014}],\"title\":\"Learning to Explore Intrinsic Saliency for Stereoscopic Video\",\"topics\":[{\"topic\":\"Stereoscopy\",\"topicId\":\"8813\",\"url\":\"https://www.semanticscholar.org/topic/8813\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Big data\",\"topicId\":\"20355\",\"url\":\"https://www.semanticscholar.org/topic/20355\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Information theory\",\"topicId\":\"43685\",\"url\":\"https://www.semanticscholar.org/topic/43685\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Biasing\",\"topicId\":\"64879\",\"url\":\"https://www.semanticscholar.org/topic/64879\"},{\"topic\":\"Spatiotemporal database\",\"topicId\":\"248637\",\"url\":\"https://www.semanticscholar.org/topic/248637\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Data system\",\"topicId\":\"346026\",\"url\":\"https://www.semanticscholar.org/topic/346026\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"}],\"url\":\"https://www.semanticscholar.org/paper/273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"