"{\"abstract\":\"Defenses against adversarial examples, when using the ImageNet dataset, are historically easy to defeat. The common understanding is that a combination of simple image transformations and other various defenses are insufficient to provide the necessary protection when the obfuscated gradient is taken into account. In this paper, we explore the idea of stochastically combining a large number of individually weak defenses into a single barrage of randomized transformations to build a strong defense against adversarial attacks. We show that, even after accounting for obfuscated gradients, the Barrage of Random Transforms (BaRT) is a resilient defense against even the most difficult attacks, such as PGD. BaRT achieves up to a 24x improvement in accuracy compared to previous work, and has even extended effectiveness out to a previously untested maximum adversarial perturbation of \\u03b5=32.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"34885007\",\"name\":\"Edward Raff\",\"url\":\"https://www.semanticscholar.org/author/34885007\"},{\"authorId\":\"40214038\",\"name\":\"J. Sylvester\",\"url\":\"https://www.semanticscholar.org/author/40214038\"},{\"authorId\":\"28948354\",\"name\":\"S. Forsyth\",\"url\":\"https://www.semanticscholar.org/author/28948354\"},{\"authorId\":\"37260244\",\"name\":\"M. McLean\",\"url\":\"https://www.semanticscholar.org/author/37260244\"}],\"citationVelocity\":17,\"citations\":[{\"arxivId\":\"2009.05244\",\"authors\":[{\"authorId\":\"80977068\",\"name\":\"Shao-Yuan Lo\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4aca8d9185be9c52157400f887987872eddd1ba\",\"title\":\"Defending Against Multiple and Unforeseen Adversarial Videos\",\"url\":\"https://www.semanticscholar.org/paper/b4aca8d9185be9c52157400f887987872eddd1ba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.02936\",\"authors\":[{\"authorId\":\"144132989\",\"name\":\"Ankita Shukla\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"143660674\",\"name\":\"S. Anand\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"894049d95431cc66b30c9984eb5bef415aae59df\",\"title\":\"GraCIAS: Grassmannian of Corrupted Images for Adversarial Security\",\"url\":\"https://www.semanticscholar.org/paper/894049d95431cc66b30c9984eb5bef415aae59df\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115621601\",\"name\":\"Yueqiao Li\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"98227702\",\"name\":\"Jun Zhu\"},{\"authorId\":\"1491231425\",\"name\":\"Jun Zhou\"}],\"doi\":\"10.1109/ICIST49303.2020.9202177\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ac7669e6e4488080d046a9c07078ffcbaddbab1\",\"title\":\"Boosting the Robustness of Capsule Networks with Diverse Ensemble\",\"url\":\"https://www.semanticscholar.org/paper/3ac7669e6e4488080d046a9c07078ffcbaddbab1\",\"venue\":\"2020 10th International Conference on Information Science and Technology (ICIST)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":null,\"name\":\"Kun Xu\"},{\"authorId\":\"12072757\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"643685f9eaaab64974c4e6b9d95f59b754f8638f\",\"title\":\"MIXUP INFERENCE: BETTER EXPLOITING MIXUP\",\"url\":\"https://www.semanticscholar.org/paper/643685f9eaaab64974c4e6b9d95f59b754f8638f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152442933\",\"name\":\"Andreas B\\u00e4r\"},{\"authorId\":\"1651133619\",\"name\":\"Marvin Klingner\"},{\"authorId\":\"1845888030\",\"name\":\"Serin Varghese\"},{\"authorId\":\"2026269\",\"name\":\"Fabian H\\u00fcger\"},{\"authorId\":\"51132547\",\"name\":\"Peter Schlicht\"},{\"authorId\":\"150319095\",\"name\":\"T. Fingscheidt\"}],\"doi\":\"10.1109/CVPRW50498.2020.00174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61bafbc63bcf9bc9534fe3e85afb6db1f49d1ee\",\"title\":\"Robust Semantic Segmentation by Redundant Networks With a Layer-Specific Loss Contribution and Majority Vote\",\"url\":\"https://www.semanticscholar.org/paper/e61bafbc63bcf9bc9534fe3e85afb6db1f49d1ee\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3256307\",\"name\":\"M. A. A. K. Jalwana\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/cvpr42600.2020.00956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb128a1da39e6bdd2a284e18bcdb3f6aafa6f078\",\"title\":\"Attack to Explain Deep Representation\",\"url\":\"https://www.semanticscholar.org/paper/fb128a1da39e6bdd2a284e18bcdb3f6aafa6f078\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.15386\",\"authors\":[{\"authorId\":null,\"name\":\"Yuhang Wu\"},{\"authorId\":null,\"name\":\"Sunpreet S. Arora\"},{\"authorId\":null,\"name\":\"Yanhong Wu\"},{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df326f0b6d109282f41bc5cc1fbd125437b65341\",\"title\":\"Beating Attackers At Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions\",\"url\":\"https://www.semanticscholar.org/paper/df326f0b6d109282f41bc5cc1fbd125437b65341\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.11515\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":null,\"name\":\"Kun Xu\"},{\"authorId\":\"47055094\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1b9d5d4cf17f5ceaf2d6798ffd594fd1d017eaa\",\"title\":\"Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/e1b9d5d4cf17f5ceaf2d6798ffd594fd1d017eaa\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2005.07998\",\"authors\":[{\"authorId\":\"151444358\",\"name\":\"Maungmaung Aprilpyone\"},{\"authorId\":\"12745074\",\"name\":\"Hitoshi Kiya\"}],\"doi\":\"10.1109/ICIP40778.2020.9190904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c45132f8a83a85a15eb8c88d00a8e5c941972ef6\",\"title\":\"Encryption Inspired Adversarial Defense For Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/c45132f8a83a85a15eb8c88d00a8e5c941972ef6\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143934191\",\"name\":\"R. Theagarajan\"},{\"authorId\":\"144452270\",\"name\":\"B. Bhanu\"}],\"doi\":\"10.1109/CVPRW50498.2020.00414\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"659815bc880a2fa6d617cf1545ab5f0bcbcb5eda\",\"title\":\"Defending Black Box Facial Recognition Classifiers Against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/659815bc880a2fa6d617cf1545ab5f0bcbcb5eda\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2012.07006\",\"authors\":[{\"authorId\":\"2000296491\",\"name\":\"Yi Zeng\"},{\"authorId\":\"77498003\",\"name\":\"H. Qiu\"},{\"authorId\":\"16042895\",\"name\":\"Shangwei Guo\"},{\"authorId\":\"51049314\",\"name\":\"Tianwei Zhang\"},{\"authorId\":\"144326259\",\"name\":\"M. Qiu\"},{\"authorId\":\"72558235\",\"name\":\"B. Thuraisingham\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"35d5395b90a69e9994cb208b91776df6233ea3e3\",\"title\":\"DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks using Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/35d5395b90a69e9994cb208b91776df6233ea3e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73914059\",\"name\":\"Suleyman Suleymanzade\"}],\"doi\":\"10.32010/26166127.2020.3.1.46.53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"715fe3d4ed0448d63ce90532110de9ac6f132ad9\",\"title\":\"DEFENDING STRATEGIES AGAINST ADVERSARIAL ATTACKS IN RETRIEVAL SYSTEMS\",\"url\":\"https://www.semanticscholar.org/paper/715fe3d4ed0448d63ce90532110de9ac6f132ad9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151444358\",\"name\":\"Maungmaung Aprilpyone\"},{\"authorId\":\"2114395\",\"name\":\"Y. Kinoshita\"},{\"authorId\":\"12745074\",\"name\":\"Hitoshi Kiya\"}],\"doi\":\"10.1109/ACCESS.2019.2958358\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"78dce67a3db608991dea3186d2871e0927a34761\",\"title\":\"Adversarial Robustness by One Bit Double Quantization for Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/78dce67a3db608991dea3186d2871e0927a34761\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2006.10679\",\"authors\":[{\"authorId\":\"27776425\",\"name\":\"Lokender Tiwari\"},{\"authorId\":\"1703003796\",\"name\":\"Anish Madan\"},{\"authorId\":\"143660674\",\"name\":\"S. Anand\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4438dff07df2514c881573f4af87c9f424532699\",\"title\":\"Dissecting Deep Networks into an Ensemble of Generative Classifiers for Robust Predictions\",\"url\":\"https://www.semanticscholar.org/paper/4438dff07df2514c881573f4af87c9f424532699\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29db0507155a7a120a0a25bef5320dd74f71bb14\",\"title\":\"ATLPA:ADVERSARIAL TOLERANT LOGIT PAIRING\",\"url\":\"https://www.semanticscholar.org/paper/29db0507155a7a120a0a25bef5320dd74f71bb14\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.00801\",\"authors\":[{\"authorId\":\"151444358\",\"name\":\"Maungmaung Aprilpyone\"},{\"authorId\":\"12745074\",\"name\":\"Hitoshi Kiya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31f9a4fb569600a94e887a8f8c8b5ca33847fe48\",\"title\":\"Block-wise Image Transformation with Secret Key for Adversarially Robust Defense\",\"url\":\"https://www.semanticscholar.org/paper/31f9a4fb569600a94e887a8f8c8b5ca33847fe48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040982\",\"name\":\"O. Taran\"},{\"authorId\":\"3074253\",\"name\":\"Shideh Rezaeifar\"},{\"authorId\":\"2189106\",\"name\":\"T. Holotyak\"},{\"authorId\":\"9428112\",\"name\":\"S. Voloshynovskiy\"}],\"doi\":\"10.1186/s13635-020-00106-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2706fd666c955839324ee0b8dee005ab232d52f4\",\"title\":\"Machine learning through cryptographic glasses: combating adversarial attacks by key-based diversified aggregation\",\"url\":\"https://www.semanticscholar.org/paper/2706fd666c955839324ee0b8dee005ab232d52f4\",\"venue\":\"EURASIP J. Inf. Secur.\",\"year\":2020},{\"arxivId\":\"2003.00883\",\"authors\":[{\"authorId\":\"1515315817\",\"name\":\"Camilo Pestana\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46641911\",\"name\":\"W. Liu\"},{\"authorId\":\"47400552\",\"name\":\"David Glance\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47bbe8c5d5bb184e293129705b6a0e15e744a289\",\"title\":\"Adversarial Perturbations Prevail in the Y-Channel of the YCbCr Color Space\",\"url\":\"https://www.semanticscholar.org/paper/47bbe8c5d5bb184e293129705b6a0e15e744a289\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14456\",\"authors\":[{\"authorId\":null,\"name\":\"Jayendra Kantipudi\"},{\"authorId\":null,\"name\":\"Shiv Ram Dubey\"},{\"authorId\":null,\"name\":\"Soumendu Chakraborty\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5f9d358d3ceaab245bd8f7483331c55767bbe5b\",\"title\":\"Color Channel Perturbation Attacks for Fooling Convolutional Neural Networks and A Defense Against Such Attacks\",\"url\":\"https://www.semanticscholar.org/paper/e5f9d358d3ceaab245bd8f7483331c55767bbe5b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.14856\",\"authors\":[{\"authorId\":\"3256307\",\"name\":\"M. A. A. K. Jalwana\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/ACCESS.2020.3005961\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df703f9143e1ac5e3cd26a89e4ea8d6c398a7379\",\"title\":\"Orthogonal Deep Models as Defense Against Black-Box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/df703f9143e1ac5e3cd26a89e4ea8d6c398a7379\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.02675\",\"authors\":[{\"authorId\":\"1515315817\",\"name\":\"Camilo Pestana\"},{\"authorId\":\"40584023\",\"name\":\"Wei Liu\"},{\"authorId\":\"47400552\",\"name\":\"David Glance\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7702d9175917fe27884a471d08803755a5d2c55c\",\"title\":\"Defense-friendly Images in Adversarial Attacks: Dataset and Metrics for Perturbation Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/7702d9175917fe27884a471d08803755a5d2c55c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00753\",\"authors\":[{\"authorId\":\"150308094\",\"name\":\"Samuel Henrique Silva\"},{\"authorId\":\"71756373\",\"name\":\"Peyman Najafirad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a53dd7f3a7590a2058372410820c8086be109ec8\",\"title\":\"Opportunities and Challenges in Deep Learning Adversarial Robustness: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/a53dd7f3a7590a2058372410820c8086be109ec8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32030020\",\"name\":\"Faiq Khalid\"},{\"authorId\":\"2465674\",\"name\":\"S. Rehman\"},{\"authorId\":\"145063983\",\"name\":\"Muhammad Shafique\"}],\"doi\":\"10.1007/978-3-030-45541-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93ccf07247123e4c3fa5e08ad056f76cac5786b1\",\"title\":\"Overview of Security for Smart Cyber-Physical Systems\",\"url\":\"https://www.semanticscholar.org/paper/93ccf07247123e4c3fa5e08ad056f76cac5786b1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.10047\",\"authors\":[{\"authorId\":\"47413491\",\"name\":\"B. Kim\"},{\"authorId\":\"1999757665\",\"name\":\"Bryce Chudomelka\"},{\"authorId\":\"48491085\",\"name\":\"Jinyoung Park\"},{\"authorId\":\"144323862\",\"name\":\"Jaewoo Kang\"},{\"authorId\":\"34826473\",\"name\":\"Youngjoon Hong\"},{\"authorId\":\"46695699\",\"name\":\"H. Kim\"}],\"doi\":\"10.1007/978-3-030-58545-7_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de849ce7e7d379d80f563cf02b09a4264ec81cea\",\"title\":\"Robust Neural Networks inspired by Strong Stability Preserving Runge-Kutta methods\",\"url\":\"https://www.semanticscholar.org/paper/de849ce7e7d379d80f563cf02b09a4264ec81cea\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.10876\",\"authors\":[{\"authorId\":\"145460048\",\"name\":\"K. Mahmood\"},{\"authorId\":\"1753362334\",\"name\":\"Deniz Gurevin\"},{\"authorId\":\"144534186\",\"name\":\"Marten van Dijk\"},{\"authorId\":\"143671628\",\"name\":\"P. H. Nguyen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ba3895d1e76b920aaedb019267caaf73735966e0\",\"title\":\"Beware the Black-Box: on the Robustness of Recent Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/ba3895d1e76b920aaedb019267caaf73735966e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.11300\",\"authors\":[{\"authorId\":\"47183448\",\"name\":\"F. Lin\"},{\"authorId\":\"71819486\",\"name\":\"Rohit Mittapalli\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"93728539\",\"name\":\"Daniel Bolya\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc9b3a04b0275f2cc28a5a432771cbd93850c496\",\"title\":\"Likelihood Landscapes: A Unifying Principle Behind Many Adversarial Defenses\",\"url\":\"https://www.semanticscholar.org/paper/bc9b3a04b0275f2cc28a5a432771cbd93850c496\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.07331\",\"authors\":[{\"authorId\":\"2894529\",\"name\":\"Tianchu Guo\"},{\"authorId\":\"71222753\",\"name\":\"Yongchao Liu\"},{\"authorId\":\"49461512\",\"name\":\"Hui Zhang\"},{\"authorId\":\"2818017\",\"name\":\"Xiabing Liu\"},{\"authorId\":\"9942811\",\"name\":\"Youngjun Kwak\"},{\"authorId\":\"65778811\",\"name\":\"Byung In Yoo\"},{\"authorId\":\"1764869\",\"name\":\"J. Han\"},{\"authorId\":\"36995891\",\"name\":\"C. Choi\"}],\"doi\":\"10.1109/ICCVW.2019.00144\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9d4c15896be40d99f4f0254fcd602ac441d81ea\",\"title\":\"A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone\",\"url\":\"https://www.semanticscholar.org/paper/c9d4c15896be40d99f4f0254fcd602ac441d81ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1911.11219\",\"authors\":[{\"authorId\":\"50365745\",\"name\":\"C. Xiao\"},{\"authorId\":\"46882430\",\"name\":\"C. Zheng\"}],\"doi\":\"10.1109/cvpr42600.2020.00049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43a8b2fd651c3783723f4265d7641f9601a5a6f4\",\"title\":\"One Man\\u2019s Trash Is Another Man\\u2019s Treasure: Resisting Adversarial Examples by Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/43a8b2fd651c3783723f4265d7641f9601a5a6f4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4155554\",\"name\":\"J. Rounds\"},{\"authorId\":\"16173321\",\"name\":\"Addie Kingsland\"},{\"authorId\":\"11947551\",\"name\":\"M. Henry\"},{\"authorId\":\"102754720\",\"name\":\"Kayla Duskin\"}],\"doi\":\"10.1109/CVPRW50498.2020.00403\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40aa6edeca8232cb30f0beea660ac8c63ad2d04c\",\"title\":\"Probing for Artifacts: Detecting Imagenet Model Evasions\",\"url\":\"https://www.semanticscholar.org/paper/40aa6edeca8232cb30f0beea660ac8c63ad2d04c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2012.01558\",\"authors\":[{\"authorId\":\"1845893318\",\"name\":\"Nikhil Kapoor\"},{\"authorId\":\"152442933\",\"name\":\"Andreas B\\u00e4r\"},{\"authorId\":\"1845888030\",\"name\":\"Serin Varghese\"},{\"authorId\":\"152259974\",\"name\":\"J. Schneider\"},{\"authorId\":\"2026269\",\"name\":\"Fabian H\\u00fcger\"},{\"authorId\":\"51132547\",\"name\":\"Peter Schlicht\"},{\"authorId\":\"150319095\",\"name\":\"T. Fingscheidt\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b57e9e096f1a3a72defb3480d2d19c73c4e22d34\",\"title\":\"From a Fourier-Domain Perspective on Adversarial Examples to a Wiener Filter Defense for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b57e9e096f1a3a72defb3480d2d19c73c4e22d34\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.00467\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"98182791\",\"name\":\"Xian Yang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"1739163379\",\"name\":\"Jun Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"title\":\"Bag of Tricks for Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.08016\",\"authors\":[{\"authorId\":\"48493356\",\"name\":\"Daniel Kang\"},{\"authorId\":\"49697236\",\"name\":\"Yi Sun\"},{\"authorId\":\"3422872\",\"name\":\"Dan Hendrycks\"},{\"authorId\":\"143889051\",\"name\":\"T. Brown\"},{\"authorId\":\"5164568\",\"name\":\"J. Steinhardt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c5b068ce6dff86bf152312b99f3360456a00faf\",\"title\":\"Testing Robustness Against Unforeseen Adversaries\",\"url\":\"https://www.semanticscholar.org/paper/1c5b068ce6dff86bf152312b99f3360456a00faf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.00461\",\"authors\":[{\"authorId\":\"24029368\",\"name\":\"Abdullah Hamdi\"},{\"authorId\":\"144559363\",\"name\":\"S. Rojas\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-58610-2_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b58bad96a5722c92c81decdb335c302d369b6cfc\",\"title\":\"AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/b58bad96a5722c92c81decdb335c302d369b6cfc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.01701\",\"authors\":[{\"authorId\":\"77498003\",\"name\":\"H. Qiu\"},{\"authorId\":\"2000296491\",\"name\":\"Yi Zeng\"},{\"authorId\":\"51049314\",\"name\":\"Tianwei Zhang\"},{\"authorId\":\"2000210625\",\"name\":\"Yong Jiang\"},{\"authorId\":\"144326259\",\"name\":\"M. Qiu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"716e66d7325d5948bb9715190dd4cdff5cc48513\",\"title\":\"FenceBox: A Platform for Defeating Adversarial Examples with Data Augmentation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/716e66d7325d5948bb9715190dd4cdff5cc48513\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":198119553,\"doi\":\"10.1109/CVPR.2019.00669\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"17f2f3f7e58b916175d495109bc74b2757ef952a\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2221048\",\"name\":\"J\\u00e9r\\u00f4me Darbon\"},{\"authorId\":\"152569576\",\"name\":\"A. Cunha\"},{\"authorId\":\"1746335\",\"name\":\"T. Chan\"},{\"authorId\":\"1782265\",\"name\":\"S. Osher\"},{\"authorId\":\"144351514\",\"name\":\"G. Jensen\"}],\"doi\":\"10.1109/ISBI.2008.4541250\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92a20aa459d9879a0611b3c138437262f96702fc\",\"title\":\"Fast nonlocal filtering applied to electron cryomicroscopy\",\"url\":\"https://www.semanticscholar.org/paper/92a20aa459d9879a0611b3c138437262f96702fc\",\"venue\":\"2008 5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro\",\"year\":2008},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1709.00609\",\"authors\":[{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"1716261\",\"name\":\"G. Fumera\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":\"10.1109/TKDE.2013.57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d319e2f19306e5fde837afac4e214209f42deb1\",\"title\":\"Security Evaluation of Pattern Classifiers under Attack\",\"url\":\"https://www.semanticscholar.org/paper/2d319e2f19306e5fde837afac4e214209f42deb1\",\"venue\":\"IEEE Transactions on Knowledge and Data Engineering\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1815078\",\"name\":\"S. Avidan\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"}],\"doi\":\"10.1145/1275808.1276390\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f242db0766b638cb8df5bfc906fe8b04293db542\",\"title\":\"Seam carving for content-aware image resizing\",\"url\":\"https://www.semanticscholar.org/paper/f242db0766b638cb8df5bfc906fe8b04293db542\",\"venue\":\"SIGGRAPH '07\",\"year\":2007},{\"arxivId\":\"1704.01664\",\"authors\":[{\"authorId\":\"145409594\",\"name\":\"Cheng Ju\"},{\"authorId\":\"10712403\",\"name\":\"Aur\\u00e9lien Bibaut\"},{\"authorId\":\"145099512\",\"name\":\"M. Laan\"}],\"doi\":\"10.1080/02664763.2018.1441383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2a56c13463b021d5f6af4f9f93aa3a5a31cf82d\",\"title\":\"The relative performance of ensemble methods with deep convolutional neural networks for image classification\",\"url\":\"https://www.semanticscholar.org/paper/d2a56c13463b021d5f6af4f9f93aa3a5a31cf82d\",\"venue\":\"Journal of applied statistics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1683740\",\"name\":\"A. Chambolle\"}],\"doi\":\"10.1023/B:JMIV.0000011325.36760.1e\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62d5a86c91d938016d89a9a4718e6c6d17aabcf6\",\"title\":\"An Algorithm for Total Variation Minimization and Applications\",\"url\":\"https://www.semanticscholar.org/paper/62d5a86c91d938016d89a9a4718e6c6d17aabcf6\",\"venue\":\"Journal of Mathematical Imaging and Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2272441\",\"name\":\"A. Demontis\"},{\"authorId\":\"40631285\",\"name\":\"Marco Melis\"},{\"authorId\":\"77543631\",\"name\":\"Maura Pintor\"},{\"authorId\":\"40844378\",\"name\":\"M. Jagielski\"},{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"38737581\",\"name\":\"Alina Oprea\"},{\"authorId\":\"1398550766\",\"name\":\"C. Nita-Rotaru\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bac2716cd208cb8041650a001ab72ba81b559cd\",\"title\":\"Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks\",\"url\":\"https://www.semanticscholar.org/paper/8bac2716cd208cb8041650a001ab72ba81b559cd\",\"venue\":\"USENIX Security Symposium\",\"year\":2019},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1707.03501\",\"authors\":[{\"authorId\":\"5291972\",\"name\":\"Jiajun Lu\"},{\"authorId\":\"10444286\",\"name\":\"Hussein Sibai\"},{\"authorId\":\"13502555\",\"name\":\"E. Fabry\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31fcc9db03db98481f6ae9fffaef67d20480cba6\",\"title\":\"NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/31fcc9db03db98481f6ae9fffaef67d20480cba6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.10272\",\"authors\":[{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6effa092456e30e7e54954fd28b755e0a75b52b8\",\"title\":\"Evaluating and Understanding the Robustness of Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/6effa092456e30e7e54954fd28b755e0a75b52b8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.03247\",\"authors\":[{\"authorId\":\"48757909\",\"name\":\"Rosanne Liu\"},{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"34890911\",\"name\":\"Piero Molino\"},{\"authorId\":\"9927844\",\"name\":\"Felipe Petroski Such\"},{\"authorId\":\"51011732\",\"name\":\"E. Frank\"},{\"authorId\":\"145645206\",\"name\":\"A. Sergeev\"},{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51cdeeef710d1c84e10beadc8480c137ffe8d328\",\"title\":\"An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution\",\"url\":\"https://www.semanticscholar.org/paper/51cdeeef710d1c84e10beadc8480c137ffe8d328\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1803.06373\",\"authors\":[{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"title\":\"Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1510.05328\",\"authors\":[{\"authorId\":\"2728925\",\"name\":\"Pedro Tabacof\"},{\"authorId\":\"145487017\",\"name\":\"E. Valle\"}],\"doi\":\"10.1109/IJCNN.2016.7727230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa43256e67bf6f855683f76aa728e56bbcba119a\",\"title\":\"Exploring the space of adversarial images\",\"url\":\"https://www.semanticscholar.org/paper/fa43256e67bf6f855683f76aa728e56bbcba119a\",\"venue\":\"2016 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2016},{\"arxivId\":\"1801.08926\",\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":\"33072734\",\"name\":\"N. Moran\"},{\"authorId\":\"50304331\",\"name\":\"Solomon Garber\"},{\"authorId\":\"39432646\",\"name\":\"Antonella DiLillo\"},{\"authorId\":\"1770857\",\"name\":\"J. Storer\"}],\"doi\":\"10.1109/CVPR.2018.00894\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f5e602bf3d59d2ea1553f06a94e9e94880af065d\",\"title\":\"Deflecting Adversarial Attacks with Pixel Deflection\",\"url\":\"https://www.semanticscholar.org/paper/f5e602bf3d59d2ea1553f06a94e9e94880af065d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1612.07767\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Li\"},{\"authorId\":\"3141988\",\"name\":\"F. Li\"}],\"doi\":\"10.1109/ICCV.2017.615\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dfbbc101cf9e7359a336df25dab90d66e249255\",\"title\":\"Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics\",\"url\":\"https://www.semanticscholar.org/paper/7dfbbc101cf9e7359a336df25dab90d66e249255\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1707.07397\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"143883029\",\"name\":\"Kevin Kwok\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"title\":\"Synthesizing Robust Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":\"10.1145/3243734.3264418\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"570cd3a4f2353c7391410d567a1615b7284d412d\",\"title\":\"Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/570cd3a4f2353c7391410d567a1615b7284d412d\",\"venue\":\"CCS\",\"year\":2018},{\"arxivId\":\"1712.02976\",\"authors\":[{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"151483845\",\"name\":\"Ming Liang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"48566726\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/CVPR.2018.00191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"title\":\"Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser\",\"url\":\"https://www.semanticscholar.org/paper/ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59d9318f07331ec15e54fe2a4218bc4a5c247a38\",\"title\":\"Foolbox: A Python toolbox to benchmark the robustness of machine learning models\",\"url\":\"https://www.semanticscholar.org/paper/59d9318f07331ec15e54fe2a4218bc4a5c247a38\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1707.04131\",\"authors\":[{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"title\":\"Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models\",\"url\":\"https://www.semanticscholar.org/paper/8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1805.12514\",\"authors\":[{\"authorId\":\"145970408\",\"name\":\"E. Wong\"},{\"authorId\":\"143826285\",\"name\":\"F. Schmidt\"},{\"authorId\":\"2708564\",\"name\":\"J. H. Metzen\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"20f85256555ad612148e52f9363e52f9d661728b\",\"title\":\"Scaling provable adversarial defenses\",\"url\":\"https://www.semanticscholar.org/paper/20f85256555ad612148e52f9363e52f9d661728b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743073\",\"name\":\"L. Kuncheva\"},{\"authorId\":\"144299701\",\"name\":\"C. Whitaker\"}],\"doi\":\"10.1023/A:1022859003006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2642e2ddaf39596405369f7c61e74aa95e836694\",\"title\":\"Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/2642e2ddaf39596405369f7c61e74aa95e836694\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1804.03286\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"06b98537324dbf11c7de2040e519b4d110f5d622\",\"title\":\"On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses\",\"url\":\"https://www.semanticscholar.org/paper/06b98537324dbf11c7de2040e519b4d110f5d622\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145529981\",\"name\":\"S. G. Chang\"},{\"authorId\":\"144923779\",\"name\":\"B. Yu\"},{\"authorId\":\"145876744\",\"name\":\"M. Vetterli\"}],\"doi\":\"10.1109/83.862633\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04f7769cf0908101af532b02428928baccb2c4d3\",\"title\":\"Adaptive wavelet thresholding for image denoising and compression\",\"url\":\"https://www.semanticscholar.org/paper/04f7769cf0908101af532b02428928baccb2c4d3\",\"venue\":\"IEEE Trans. Image Process.\",\"year\":2000},{\"arxivId\":\"1711.00851\",\"authors\":[{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"51026953\",\"name\":\"E. Wong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b23012689e0f17912fb38d4984775e567cff8d6\",\"title\":\"Provable defenses against adversarial examples via the convex outer adversarial polytope\",\"url\":\"https://www.semanticscholar.org/paper/4b23012689e0f17912fb38d4984775e567cff8d6\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1801.09344\",\"authors\":[{\"authorId\":\"2655157\",\"name\":\"Aditi Raghunathan\"},{\"authorId\":\"5164568\",\"name\":\"J. Steinhardt\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"title\":\"Certified Defenses against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1707.08945\",\"authors\":[{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"1825256\",\"name\":\"Kevin Eykholt\"},{\"authorId\":\"35064352\",\"name\":\"E. Fernandes\"},{\"authorId\":\"1769675\",\"name\":\"T. Kohno\"},{\"authorId\":\"38620893\",\"name\":\"B. Li\"},{\"authorId\":\"49428285\",\"name\":\"Atul Prakash\"},{\"authorId\":\"145416145\",\"name\":\"A. Rahmati\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d295a620fc10a7a656dc693e1b1bf668d1508a8e\",\"title\":\"Robust Physical-World Attacks on Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/d295a620fc10a7a656dc693e1b1bf668d1508a8e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1704.01155\",\"authors\":[{\"authorId\":\"50231973\",\"name\":\"Weilin Xu\"},{\"authorId\":\"145685504\",\"name\":\"David Evans\"},{\"authorId\":\"1791105\",\"name\":\"Y. Qi\"}],\"doi\":\"10.14722/ndss.2018.23198\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"title\":\"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"venue\":\"NDSS\",\"year\":2018},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35965590\",\"name\":\"Ben Weiss\"}],\"doi\":\"10.1145/1179352.1141918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba791fc6f34fed7a2cf8b7f174a19ee87fb05012\",\"title\":\"Fast median and bilateral filtering\",\"url\":\"https://www.semanticscholar.org/paper/ba791fc6f34fed7a2cf8b7f174a19ee87fb05012\",\"venue\":\"ACM Trans. Graph.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1785052\",\"name\":\"K. Zuiderveld\"}],\"doi\":\"10.1016/B978-0-12-336156-1.50061-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"726c95fa3bd47401befc7513b6e52d1c806f26af\",\"title\":\"Contrast Limited Adaptive Histogram Equalization\",\"url\":\"https://www.semanticscholar.org/paper/726c95fa3bd47401befc7513b6e52d1c806f26af\",\"venue\":\"Graphics Gems\",\"year\":1994},{\"arxivId\":\"1803.06567\",\"authors\":[{\"authorId\":\"1729912\",\"name\":\"Krishnamurthy Dvijotham\"},{\"authorId\":\"49860489\",\"name\":\"Robert Stanforth\"},{\"authorId\":\"2071666\",\"name\":\"Sven Gowal\"},{\"authorId\":\"2554720\",\"name\":\"Timothy A. Mann\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d35663a80199b173d8cbd12dbf2300a9f86a021\",\"title\":\"A Dual Approach to Scalable Verification of Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/8d35663a80199b173d8cbd12dbf2300a9f86a021\",\"venue\":\"UAI\",\"year\":2018},{\"arxivId\":\"1711.00117\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"2139712\",\"name\":\"Mayank Rana\"},{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"title\":\"Countering Adversarial Images using Input Transformations\",\"url\":\"https://www.semanticscholar.org/paper/e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1706.04701\",\"authors\":[{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"145604979\",\"name\":\"J. Wei\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"title\":\"Adversarial Example Defense: Ensembles of Weak Defenses are not Strong\",\"url\":\"https://www.semanticscholar.org/paper/6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"venue\":\"WOOT\",\"year\":2017}],\"title\":\"Barrage of Random Transforms for Adversarially Robust Defense\",\"topics\":[{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Heuristic\",\"topicId\":\"4146\",\"url\":\"https://www.semanticscholar.org/topic/4146\"},{\"topic\":\"Randomness\",\"topicId\":\"726\",\"url\":\"https://www.semanticscholar.org/topic/726\"},{\"topic\":\"Randomized algorithm\",\"topicId\":\"3442\",\"url\":\"https://www.semanticscholar.org/topic/3442\"},{\"topic\":\"Obfuscation (software)\",\"topicId\":\"66164\",\"url\":\"https://www.semanticscholar.org/topic/66164\"}],\"url\":\"https://www.semanticscholar.org/paper/17f2f3f7e58b916175d495109bc74b2757ef952a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"