"{\"abstract\":\"There are substantial instruction videos on the Internet, which enables us to acquire knowledge for completing various tasks. However, most existing datasets for instruction video analysis have the limitations in diversity and scale, which makes them far from many real-world applications where more diverse activities occur. Moreover, it still remains a great challenge to organize and harness such data. To address these problems, we introduce a large-scale dataset called \\u201cCOIN\\\" for COmprehensive INstruction video analysis. Organized with a hierarchical structure, the COIN dataset contains 11,827 videos of 180 tasks in 12 domains (e.g., vehicles, gadgets, etc.) related to our daily life. With a new developed toolbox, all the videos are annotated effectively with a series of step descriptions and the corresponding temporal boundaries. Furthermore, we propose a simple yet effective method to capture the dependencies among different steps, which can be easily plugged into conventional proposal-based action detection methods for localizing important steps in instruction videos. In order to provide a benchmark for instruction video analysis, we evaluate plenty of approaches on the COIN dataset under different evaluation criteria. We expect the introduction of the COIN dataset will promote the future in-depth research on instruction video analysis for the community.\",\"arxivId\":\"1903.02874\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\",\"url\":\"https://www.semanticscholar.org/author/35299091\"},{\"authorId\":\"50792340\",\"name\":\"Dajun Ding\",\"url\":\"https://www.semanticscholar.org/author/50792340\"},{\"authorId\":\"39358728\",\"name\":\"Yongming Rao\",\"url\":\"https://www.semanticscholar.org/author/39358728\"},{\"authorId\":\"145473095\",\"name\":\"Y. Zheng\",\"url\":\"https://www.semanticscholar.org/author/145473095\"},{\"authorId\":\"2118333\",\"name\":\"Danyang Zhang\",\"url\":\"https://www.semanticscholar.org/author/2118333\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\",\"url\":\"https://www.semanticscholar.org/author/48096213\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\",\"url\":\"https://www.semanticscholar.org/author/1697700\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\",\"url\":\"https://www.semanticscholar.org/author/49640256\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":\"2007.00394\",\"authors\":[{\"authorId\":\"1410307807\",\"name\":\"Yizhak Ben-Shabat\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"947b868aa1c38940df280ebeb8077d4e729fb988\",\"title\":\"The IKEA ASM Dataset: Understanding People Assembling Furniture through Actions, Objects and Pose\",\"url\":\"https://www.semanticscholar.org/paper/947b868aa1c38940df280ebeb8077d4e729fb988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1890358\",\"name\":\"Dejiao Niu\"},{\"authorId\":\"46399019\",\"name\":\"Yawen Liu\"},{\"authorId\":\"49282929\",\"name\":\"Tao Cai\"},{\"authorId\":\"101480226\",\"name\":\"X. Zheng\"},{\"authorId\":\"145128226\",\"name\":\"T. Liu\"},{\"authorId\":\"1455606505\",\"name\":\"Shijie Zhou\"}],\"doi\":\"10.1007/978-981-15-1899-7_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c64289dc9620fe8a8cd419fede38e43c8997d13\",\"title\":\"A Novel Distributed Duration-Aware LSTM for Large Scale Sequential Data Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4c64289dc9620fe8a8cd419fede38e43c8997d13\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"50218246\",\"name\":\"Z. Wang\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TIP.2019.2914577\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4a63cc3651fcc9894375068f9ec48e70b938de2\",\"title\":\"Learning Semantics-Preserving Attention and Contextual Interaction for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4a63cc3651fcc9894375068f9ec48e70b938de2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144816684\",\"name\":\"K. Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"title\":\"Learning Video Representations using Contrastive Bidirectional Transformer\",\"url\":\"https://www.semanticscholar.org/paper/025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.15781\",\"authors\":[{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58574-7_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"title\":\"LEMMA: A Multi-view Dataset for Learning Multi-agent Multi-task Activities\",\"url\":\"https://www.semanticscholar.org/paper/cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.06430\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.00990\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb40df31aa7177c9d009478479db61c39caebd54\",\"title\":\"End-to-End Learning of Visual Representations From Uncurated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb40df31aa7177c9d009478479db61c39caebd54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.09392\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TPAMI.2020.2980824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"title\":\"Comprehensive Instructional Video Analysis: The COIN Dataset and Performance Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1007/978-3-030-58526-6_28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"title\":\"Learning Actionness via Long-Range Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.07231\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00877\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"title\":\"ActBERT: Learning Global-Local Video-Text Representations\",\"url\":\"https://www.semanticscholar.org/paper/8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98591550\",\"name\":\"F. Fereidoonian\"},{\"authorId\":\"3209726\",\"name\":\"F. Firouzi\"},{\"authorId\":\"26437099\",\"name\":\"B. Farahani\"}],\"doi\":\"10.1109/COINS49042.2020.9191417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eee2b5f1ab9eaff1f23f5dc08ccde0980829e258\",\"title\":\"Human Activity Recognition: From Sensors to Applications\",\"url\":\"https://www.semanticscholar.org/paper/eee2b5f1ab9eaff1f23f5dc08ccde0980829e258\",\"venue\":\"2020 International Conference on Omni-layer Intelligent Systems (COINS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47897687\",\"name\":\"H. Tan\"},{\"authorId\":\"47297550\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"}],\"doi\":\"10.1016/J.CVIU.2020.103107\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d79912ee3469c1c93f2c726f9a9b4baf7682ec5f\",\"title\":\"A comprehensive survey of procedural video datasets\",\"url\":\"https://www.semanticscholar.org/paper/d79912ee3469c1c93f2c726f9a9b4baf7682ec5f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47126776\",\"name\":\"E. Elhamifar\"},{\"authorId\":\"33752816\",\"name\":\"Dat Huynh\"}],\"doi\":\"10.1007/978-3-030-58520-4_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a01cd69bd4a0ccd328425248514c5f2d9d277eef\",\"title\":\"Self-supervised Multi-task Procedure Learning from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/a01cd69bd4a0ccd328425248514c5f2d9d277eef\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.01172\",\"authors\":[{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2068265\",\"name\":\"Danfei Xu\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-58621-8_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71992656ff50c56adcbe6e99fca7eecac446d70a\",\"title\":\"Procedure Planning in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/71992656ff50c56adcbe6e99fca7eecac446d70a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50754085\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"49479171\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":\"10.1109/cvpr42600.2020.01254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1a780c6219996c8481c117056efcf071cbfbd15\",\"title\":\"Screencast Tutorial Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b1a780c6219996c8481c117056efcf071cbfbd15\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.13594\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"title\":\"Speech2Action: Cross-Modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.05710\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"title\":\"Look Before you Speak: Visually Contextualized Utterances\",\"url\":\"https://www.semanticscholar.org/paper/b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.04208\",\"authors\":[{\"authorId\":\"153000035\",\"name\":\"M. Bain\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"152853748\",\"name\":\"A. Brown\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"title\":\"Condensed Movies: Story Based Retrieval with Contextual Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.10229\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00081\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"title\":\"Intra- and Inter-Action Understanding via Temporal Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.06353\",\"authors\":[{\"authorId\":\"35347136\",\"name\":\"Huaishao Luo\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"15086992\",\"name\":\"H. Huang\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"66782928\",\"name\":\"Tianrui Li\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"},{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4243555758433880a67b15b50f752b1e2a8c4609\",\"title\":\"UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation\",\"url\":\"https://www.semanticscholar.org/paper/4243555758433880a67b15b50f752b1e2a8c4609\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.07728\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Tao Zhao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c065821de73b6bb87a2a2376134ac9c28008486\",\"title\":\"Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/1c065821de73b6bb87a2a2376134ac9c28008486\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"title\":\"Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.07665\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1749325163\",\"name\":\"Zanlin Ni\"},{\"authorId\":\"2415109\",\"name\":\"Jiahuan Zhou\"},{\"authorId\":\"2118333\",\"name\":\"Danyang Zhang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"115957649\",\"name\":\"Y. Wu\"},{\"authorId\":\"49178343\",\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00986\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d47e67c04e884cc83fff781ee9157f07acc0a558\",\"title\":\"Uncertainty-Aware Score Distribution Learning for Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/d47e67c04e884cc83fff781ee9157f07acc0a558\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.03684\",\"authors\":[{\"authorId\":\"153825694\",\"name\":\"D. Fried\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"152361825\",\"name\":\"S. Clark\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"}],\"doi\":\"10.18653/v1/2020.acl-main.231\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"23edba4188492f39a7aefebbd7267a6a8d9ddb74\",\"title\":\"Learning to Segment Actions from Observation and Narration\",\"url\":\"https://www.semanticscholar.org/paper/23edba4188492f39a7aefebbd7267a6a8d9ddb74\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314993\",\"name\":\"Wei-ying Wang\"},{\"authorId\":\"1994473516\",\"name\":\"Jieting Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413890\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b116c8cd44a34f440f260a890e0600b61d92c262\",\"title\":\"VideoIC: A Video Interactive Comments Dataset and Multimodal Multitask Learning for Comments Generation\",\"url\":\"https://www.semanticscholar.org/paper/b116c8cd44a34f440f260a890e0600b61d92c262\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3215589\",\"name\":\"F. Putze\"},{\"authorId\":\"2042310709\",\"name\":\"Merlin Burri\"},{\"authorId\":\"1380237732\",\"name\":\"Lisa-Marie Vortmann\"},{\"authorId\":\"94063590\",\"name\":\"T. Schultz\"}],\"doi\":\"10.1145/3395035.3425206\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35224094c416bea1228d100dd1cd98dda507eec7\",\"title\":\"Model-based Prediction of Exogeneous and Endogeneous Attention Shifts During an Everyday Activity\",\"url\":\"https://www.semanticscholar.org/paper/35224094c416bea1228d100dd1cd98dda507eec7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.09606\",\"authors\":[{\"authorId\":\"145800141\",\"name\":\"A. Lin\"},{\"authorId\":\"1675319352\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144478564\",\"name\":\"Elnaz Nouri\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"1780951\",\"name\":\"Debadeepta Dey\"},{\"authorId\":\"66648221\",\"name\":\"B. Dolan\"}],\"doi\":\"10.18653/v1/2020.acl-main.440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96c4c061426fe19a021e2e68690d35f19aa40aa2\",\"title\":\"A Recipe for Creating Multimodal Aligned Datasets for Sequential Tasks\",\"url\":\"https://www.semanticscholar.org/paper/96c4c061426fe19a021e2e68690d35f19aa40aa2\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1904.01766\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"49588480\",\"name\":\"A. Myers\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2019.00756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c41a11c0e9b8b92b4faaf97749841170b760760a\",\"title\":\"VideoBERT: A Joint Model for Video and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/c41a11c0e9b8b92b4faaf97749841170b760760a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.01598\",\"authors\":[{\"authorId\":\"151504088\",\"name\":\"X. Ding\"},{\"authorId\":\"151488319\",\"name\":\"N. Wang\"},{\"authorId\":\"49779747\",\"name\":\"Xinbo Gao\"},{\"authorId\":\"1492114961\",\"name\":\"Jie Li\"},{\"authorId\":\"72541556\",\"name\":\"X. Wang\"},{\"authorId\":\"121698214\",\"name\":\"Tongliang Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"title\":\"Weakly Supervised Temporal Action Localization with Segment-Level Labels\",\"url\":\"https://www.semanticscholar.org/paper/5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Weiying Wang\"},{\"authorId\":null,\"name\":\"Yongcheng Wang\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.18653/v1/D19-1517\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"34e7db6ffcdfeffc29eab0622384ed412d9b4558\",\"title\":\"YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/34e7db6ffcdfeffc29eab0622384ed412d9b4558\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2005.00706\",\"authors\":[{\"authorId\":\"40027632\",\"name\":\"F. F. Xu\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"3109653\",\"name\":\"Junyi Du\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"title\":\"A Benchmark for Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"venue\":\"NLPBT\",\"year\":2020}],\"corpusId\":71147568,\"doi\":\"10.1109/CVPR.2019.00130\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hu Yueyu\"},{\"authorId\":null,\"name\":\"Li Yanghao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsu - pervised learning from narrated instruction videos Quo vadis , action recognition ? A newmodel and the kinetics dataset\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00623\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aeac614f10cb2a5dc000fdee30d857bbe5456ce5\",\"title\":\"Finding \\\"It\\\": Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/aeac614f10cb2a5dc000fdee30d857bbe5456ce5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00627\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96ce111119624888be47d998cf87c9df18988c4d\",\"title\":\"Action Sets: Weakly Supervised Action Segmentation Without Ordering Constraints\",\"url\":\"https://www.semanticscholar.org/paper/96ce111119624888be47d998cf87c9df18988c4d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1803.10699\",\"authors\":[{\"authorId\":\"144529493\",\"name\":\"Li Ding\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/CVPR.2018.00681\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c6ce420976f958e7582a2f452c3a541faa82074\",\"title\":\"Weakly-Supervised Action Segmentation with Iterative Soft Boundary Assignment\",\"url\":\"https://www.semanticscholar.org/paper/6c6ce420976f958e7582a2f452c3a541faa82074\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145438759\",\"name\":\"S. Avila\"},{\"authorId\":\"40374569\",\"name\":\"A. P. Lopes\"},{\"authorId\":\"2632049\",\"name\":\"A. Luz\"},{\"authorId\":\"1840904\",\"name\":\"A. Ara\\u00fajo\"}],\"doi\":\"10.1016/j.patrec.2010.08.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c18b4d6767d5a5fa69a1c12bf141f85670fee1b6\",\"title\":\"VSUMM: A mechanism designed to produce static video summaries and a novel evaluation method\",\"url\":\"https://www.semanticscholar.org/paper/c18b4d6767d5a5fa69a1c12bf141f85670fee1b6\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2011},{\"arxivId\":\"1706.03123\",\"authors\":[{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/TIP.2017.2708902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc7c8974c3990c9c7b6d20cfd748e3315c44bd26\",\"title\":\"Diversity-Aware Multi-Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/bc7c8974c3990c9c7b6d20cfd748e3315c44bd26\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1605.08110\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"title\":\"Video Summarization with Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1703.09788\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e10a5e0baf2aa87d804795af071808a9377cc80a\",\"title\":\"Towards Automatic Learning of Procedures From Web Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/e10a5e0baf2aa87d804795af071808a9377cc80a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41030694\",\"name\":\"Huanyu Yu\"},{\"authorId\":\"3392007\",\"name\":\"Shuo Cheng\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"7272302\",\"name\":\"Minsi Wang\"},{\"authorId\":\"40430880\",\"name\":\"J. Zhang\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/CVPR.2018.00629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5876f67129a80a1ee753f715efcd2e2109bf432\",\"title\":\"Fine-Grained Video Captioning for Sports Narrative\",\"url\":\"https://www.semanticscholar.org/paper/f5876f67129a80a1ee753f715efcd2e2109bf432\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1707.09240\",\"authors\":[{\"authorId\":\"22192824\",\"name\":\"Sam Toyer\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/DICTA.2017.8227441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0316a95dbe8d945e04215575beafc9201244d142\",\"title\":\"Human Pose Forecasting via Deep Markov Models\",\"url\":\"https://www.semanticscholar.org/paper/0316a95dbe8d945e04215575beafc9201244d142\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66767677\",\"name\":\"R. Nadolski\"},{\"authorId\":\"144675543\",\"name\":\"P. Kirschner\"},{\"authorId\":\"107670968\",\"name\":\"J. V. Van Merri\\u00ebnboer\"}],\"doi\":\"10.1348/000709904X22403\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b2726aafb02589d751e043cad146349b5e51e01\",\"title\":\"Optimizing the number of steps in learning tasks for complex skills.\",\"url\":\"https://www.semanticscholar.org/paper/3b2726aafb02589d751e043cad146349b5e51e01\",\"venue\":\"The British journal of educational psychology\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bourdev , Rob Fergus , Lorenzo Torre - sani , and Manohar Paluri . Learning spatiotemporal features with 3 d convolutional networks\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"49106279\",\"name\":\"A. B. Arslan\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/CVPR.2014.105\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"185f078accb52be4faa13e4f470a9909cc6fe814\",\"title\":\"The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/185f078accb52be4faa13e4f470a9909cc6fe814\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.02834\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"46184233\",\"name\":\"N. Louis\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1288aaf45ff85916ccef13668ceba421273a3c36\",\"title\":\"Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/1288aaf45ff85916ccef13668ceba421273a3c36\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5823721\",\"name\":\"H. Sienkiewicz\"}],\"doi\":\"10.1007/BF02663715\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8defab03d769e552c4f7397bdd3adbc920122aa\",\"title\":\"Quo Vadis?\",\"url\":\"https://www.semanticscholar.org/paper/e8defab03d769e552c4f7397bdd3adbc920122aa\",\"venue\":\"American Association of Industrial Nurses journal\",\"year\":1967},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145892975\",\"name\":\"S. Stein\"},{\"authorId\":\"6435894\",\"name\":\"S. Mckenna\"}],\"doi\":\"10.1145/2493432.2493482\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e018fa4a1c893f964f76cee8ff735573974f87cc\",\"title\":\"Combining embedded accelerometers with computer vision for recognizing food preparation activities\",\"url\":\"https://www.semanticscholar.org/paper/e018fa4a1c893f964f76cee8ff735573974f87cc\",\"venue\":\"UbiComp\",\"year\":2013},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2012.6247801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49435aab7cdf259335725acc96691f755e436f55\",\"title\":\"A database for fine grained activity detection of cooking activities\",\"url\":\"https://www.semanticscholar.org/paper/49435aab7cdf259335725acc96691f755e436f55\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1804.00819\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/CVPR.2018.00911\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35ed258aede3df17ee20a6635364cb5fd2461049\",\"title\":\"End-to-End Dense Video Captioning with Masked Transformer\",\"url\":\"https://www.semanticscholar.org/paper/35ed258aede3df17ee20a6635364cb5fd2461049\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.07475\",\"authors\":[{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b673ffe63c5d0723009042f0f922f19f093b7e34\",\"title\":\"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b673ffe63c5d0723009042f0f922f19f093b7e34\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1703.02521\",\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.116\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35f1bcff4552632419742bbb6e1927ef5e998eb4\",\"title\":\"Unsupervised Visual-Linguistic Reference Resolution in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/35f1bcff4552632419742bbb6e1927ef5e998eb4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"2757535\",\"name\":\"Jordi Vallmitjana\"},{\"authorId\":\"1690152\",\"name\":\"Amanda Stent\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"}],\"doi\":\"10.1109/CVPR.2015.7299154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"title\":\"TVSum: Summarizing web videos using titles\",\"url\":\"https://www.semanticscholar.org/paper/cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47126776\",\"name\":\"E. Elhamifar\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"144797536\",\"name\":\"S. Sastry\"}],\"doi\":\"10.1109/TPAMI.2015.2511748\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa4e585fcef87e4a5ac09d9c7c0e56ffbe9b83c7\",\"title\":\"Dissimilarity-Based Sparse Subset Selection\",\"url\":\"https://www.semanticscholar.org/paper/aa4e585fcef87e4a5ac09d9c7c0e56ffbe9b83c7\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-10584-0_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"title\":\"Creating Summaries from User Videos\",\"url\":\"https://www.semanticscholar.org/paper/799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Xiong\"},{\"authorId\":null,\"name\":\"Z. Wang\"},{\"authorId\":null,\"name\":\"Y. Qiao\"},{\"authorId\":null,\"name\":\"D. Lin\"},{\"authorId\":null,\"name\":\"X. Tang\"},{\"authorId\":null,\"name\":\"L. Val Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning spatiotemporal features with 3 d convolutional networks Action recognition with improved trajectories\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721801\",\"name\":\"C. Fellbaum\"}],\"doi\":\"10.2307/417141\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d87ceda3042f781c341ac17109d1e94a717f5f60\",\"title\":\"WordNet : an electronic lexical database\",\"url\":\"https://www.semanticscholar.org/paper/d87ceda3042f781c341ac17109d1e94a717f5f60\",\"venue\":\"\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. RJ\"},{\"authorId\":null,\"name\":\"K. PA\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and van Merri\\u00ebnboer JJ\",\"url\":\"\",\"venue\":\"Optimizing the number of steps in learning tasks for complex skills. British Journal of Educational Psychology, 75(2):223\\u2013 237\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2363529\",\"name\":\"Pradipto Das\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"38972663\",\"name\":\"Richard F. Doell\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2013.340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"title\":\"A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching\",\"url\":\"https://www.semanticscholar.org/paper/a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1805.06875\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00771\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"80184c6a88fc97a09393b7336bc2ddb12e9b1030\",\"title\":\"NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning\",\"url\":\"https://www.semanticscholar.org/paper/80184c6a88fc97a09393b7336bc2ddb12e9b1030\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Du Tran\"},{\"authorId\":null,\"name\":\"D. Lubomir\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bourdev , Rob Fergus , Lorenzo Torre - sani , and Manohar Paluri . Learning spatiotemporal features with 3 d convolutional networks\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2015},{\"arxivId\":\"1506.09215\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"143688116\",\"name\":\"Nishant Agrawal\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":\"10.1109/CVPR.2016.495\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e17ba2b5d0769e7f2602d859ea77a153846cf27d\",\"title\":\"Unsupervised Learning from Narrated Instruction Videos\",\"url\":\"https://www.semanticscholar.org/paper/e17ba2b5d0769e7f2602d859ea77a153846cf27d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1506.08438\",\"authors\":[{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/ICCV.2015.509\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"71d114b58379b99cb96f01fbb9d1667d970ed53c\",\"title\":\"Unsupervised Semantic Parsing of Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/71d114b58379b99cb96f01fbb9d1667d970ed53c\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. Roshan Zamir\"},{\"authorId\":null,\"name\":\"G. Toderici\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"http: //crcv.ucf.edu/THUMOS14/,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382424098\",\"name\":\"\\u0422\\u0430\\u0440\\u0430\\u0441\\u0430 \\u0428\\u0435\\u0432\\u0447\\u0435\\u043d\\u043a\\u0430\"},{\"authorId\":\"1397452703\",\"name\":\"\\u0412\\u0430\\u0441\\u0438\\u043b\\u044f \\u041a\\u0430\\u0440\\u0430\\u0437\\u0456\\u043d\\u0430\"},{\"authorId\":\"1397452698\",\"name\":\"\\u041e\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u0430 \\u0411\\u043e\\u0433\\u043e\\u043c\\u043e\\u043b\\u044c\\u0446\\u044f\"}],\"doi\":\"10.1093/clinchem/60.1.283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"title\":\"Quo vadis?\",\"url\":\"https://www.semanticscholar.org/paper/dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"venue\":\"Clinical chemistry\",\"year\":2013}],\"title\":\"COIN: A Large-Scale Dataset for Comprehensive Instructional Video Analysis\",\"topics\":[{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Internet\",\"topicId\":\"7952\",\"url\":\"https://www.semanticscholar.org/topic/7952\"},{\"topic\":\"Effective method\",\"topicId\":\"17681\",\"url\":\"https://www.semanticscholar.org/topic/17681\"},{\"topic\":\"Yao graph\",\"topicId\":\"229931\",\"url\":\"https://www.semanticscholar.org/topic/229931\"}],\"url\":\"https://www.semanticscholar.org/paper/e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"