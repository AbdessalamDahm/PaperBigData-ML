"{\"abstract\":\"The goal of human action anticipation is to predict future actions. Ideally, in real-world applications such as video surveillance and self-driving systems, future actions should not only be predicted with high accuracy but also at arbitrary and variable time-horizons ranging from short- to long-term predictions. Current work mostly focuses on predicting the next action and thus long-term prediction is achieved by recursive prediction of each next action, which is both inefficient and accumulates errors. In this paper, we propose a novel time-conditioned method for efficient and effective long-term action anticipation. There are two key ingredients to our approach. First, by explicitly conditioning our anticipation network on time allows to efficiently anticipate also long-term actions. And second, we propose an attended temporal feature and a time-conditioned skip connection to extract relevant and useful information from observations for effective anticipation. We conduct extensive experiments on the large-scale Epic-Kitchen and the 50Salads Datasets. Experimental results show that the proposed method is capable of anticipating future actions at both short-term and long-term, and achieves state-of-the-art performance.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\",\"url\":\"https://www.semanticscholar.org/author/143969578\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\",\"url\":\"https://www.semanticscholar.org/author/1739548\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\",\"url\":\"https://www.semanticscholar.org/author/48920094\"}],\"citationVelocity\":12,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1782428\",\"name\":\"S. An\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"3417987\",\"name\":\"F. Boussaid\"}],\"doi\":\"10.1109/TIP.2019.2937757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e61c5b48a5dd496990b73ac401686413f39f1928\",\"title\":\"Learning Latent Global Network for Skeleton-Based Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e61c5b48a5dd496990b73ac401686413f39f1928\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.01142\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"title\":\"Long-Term Anticipation of Activities with Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986765\",\"name\":\"Y. Gu\"},{\"authorId\":\"49353848\",\"name\":\"Meiqin Liu\"},{\"authorId\":\"46320777\",\"name\":\"Weihua Sheng\"},{\"authorId\":\"144897720\",\"name\":\"Yongsheng Ou\"},{\"authorId\":\"48514206\",\"name\":\"Y. Li\"}],\"doi\":\"10.1007/s10514-020-09943-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b40e9b64eed008384511a9f635b64e198b8d2369\",\"title\":\"Sensor fusion based manipulative action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b40e9b64eed008384511a9f635b64e198b8d2369\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.09540\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2019.00151\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ae19f940eed7521339078dd4ab5a01f371039e2a\",\"title\":\"Uncertainty-Aware Anticipation of Activities\",\"url\":\"https://www.semanticscholar.org/paper/ae19f940eed7521339078dd4ab5a01f371039e2a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2008.04888\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/978-3-030-58536-5_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49dcefd14e92f3ffd5871abf78ee8ca5067fbb49\",\"title\":\"Adversarial Generative Grammars for Human Activity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49dcefd14e92f3ffd5871abf78ee8ca5067fbb49\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04608\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":\"10.1109/TIP.2020.3021497\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"08bf24e179aff7971ba95aed185c8e13da9f8ce4\",\"title\":\"Forecasting Future Action Sequences With Attention: A New Approach to Weakly Supervised Action Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/08bf24e179aff7971ba95aed185c8e13da9f8ce4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292395\",\"name\":\"B. Wang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR42600.2020.00116\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7d8d5c55581563723a98f6090fd122fb376de81\",\"title\":\"Active Vision for Early Recognition of Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/f7d8d5c55581563723a98f6090fd122fb376de81\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.00548\",\"authors\":[{\"authorId\":\"1388594887\",\"name\":\"Dominik Rivoir\"},{\"authorId\":\"2462340\",\"name\":\"S. Bodenstedt\"},{\"authorId\":\"40917135\",\"name\":\"Isabel Funke\"},{\"authorId\":\"150996210\",\"name\":\"F. Bechtolsheim\"},{\"authorId\":\"113945674\",\"name\":\"M. Distler\"},{\"authorId\":\"143997715\",\"name\":\"J. Weitz\"},{\"authorId\":\"47515221\",\"name\":\"S. Speidel\"}],\"doi\":\"10.1007/978-3-030-59716-0_72\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"084577134a1e5a8e21355a1217c29c44976a07da\",\"title\":\"Rethinking Anticipation Tasks: Uncertainty-aware Anticipation of Sparse Surgical Instrument Usage for Context-aware Assistance\",\"url\":\"https://www.semanticscholar.org/paper/084577134a1e5a8e21355a1217c29c44976a07da\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"1902.00505\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1609/AAAI.V34I07.6861\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e5b4aa57f9cd48438eac3407a49232fb1e52d89\",\"title\":\"Differentiable Grammars for Videos\",\"url\":\"https://www.semanticscholar.org/paper/5e5b4aa57f9cd48438eac3407a49232fb1e52d89\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643682004\",\"name\":\"He Zhao\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1007/978-3-030-58526-6_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd941a3cb2664715269cbbd30a4df6828799ac01\",\"title\":\"On Diverse Asynchronous Activity Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/bd941a3cb2664715269cbbd30a4df6828799ac01\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.10370\",\"authors\":[{\"authorId\":\"2581371\",\"name\":\"B. Seddik\"},{\"authorId\":\"2536574\",\"name\":\"N. B. Amara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"248d264cc75fc589a2c3dc0f1a5153a57a0b4fe1\",\"title\":\"Visual Methods for Sign Language Recognition: A Modality-Based Review\",\"url\":\"https://www.semanticscholar.org/paper/248d264cc75fc589a2c3dc0f1a5153a57a0b4fe1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26923471\",\"name\":\"T. Chalen\"},{\"authorId\":\"3164610\",\"name\":\"B. Vintimilla\"}],\"doi\":\"10.1109/LA-CCI47412.2019.9037051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d98987f6ccada446e6dc50b02446e2027c06eec\",\"title\":\"Towards Action Prediction Applying Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2d98987f6ccada446e6dc50b02446e2027c06eec\",\"venue\":\"2019 IEEE Latin American Conference on Computational Intelligence (LA-CCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2008.09234\",\"authors\":[{\"authorId\":\"8842741\",\"name\":\"Romero Morais\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"be1d3bc257bedcab177ae3f75c373219de81902d\",\"title\":\"Learning to Abstract and Predict Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/be1d3bc257bedcab177ae3f75c373219de81902d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.06079\",\"authors\":[{\"authorId\":\"15716390\",\"name\":\"Julian Tanke\"},{\"authorId\":\"39847768\",\"name\":\"A. Weber\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b86de05029a16086c3b7cc6db3858db1d9e60194\",\"title\":\"Human Motion Anticipation with Symbolic Label\",\"url\":\"https://www.semanticscholar.org/paper/b86de05029a16086c3b7cc6db3858db1d9e60194\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15489\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cb65b26e407e7464223e9568010965fe73ae61f\",\"title\":\"Video Representation Learning with Visual Tempo Consistency\",\"url\":\"https://www.semanticscholar.org/paper/3cb65b26e407e7464223e9568010965fe73ae61f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03530\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"150352016\",\"name\":\"Yanzhou Su\"},{\"authorId\":\"144941515\",\"name\":\"Y. Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2de59074948bca0c0a4919bba03229477f65e821\",\"title\":\"TTPP: Temporal Transformer with Progressive Prediction for Efficient Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2de59074948bca0c0a4919bba03229477f65e821\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7466378\",\"name\":\"Jia-xin Cai\"},{\"authorId\":\"34651153\",\"name\":\"J. Hu\"},{\"authorId\":\"1737903652\",\"name\":\"Xin Tang\"},{\"authorId\":\"34985695\",\"name\":\"Tzu-Yi Hung\"},{\"authorId\":\"30915941\",\"name\":\"Y. Tan\"}],\"doi\":\"10.1016/j.neucom.2020.03.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46463edcb809186ca8cd003d02c67567235b3317\",\"title\":\"Deep historical long short-term memory network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/46463edcb809186ca8cd003d02c67567235b3317\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2007.00095\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"title\":\"Deep Learning for Vision-based Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1907.01172\",\"authors\":[{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2068265\",\"name\":\"Danfei Xu\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-58621-8_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71992656ff50c56adcbe6e99fca7eecac446d70a\",\"title\":\"Procedure Planning in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/71992656ff50c56adcbe6e99fca7eecac446d70a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":182212726,\"doi\":\"10.1109/CVPR.2019.01016\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"references\":[{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1007/s11263-013-0683-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b72756c4d4237a857e1a764c876e82a82edd128c\",\"title\":\"Max-Margin Early Event Detectors\",\"url\":\"https://www.semanticscholar.org/paper/b72756c4d4237a857e1a764c876e82a82edd128c\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"26559284\",\"name\":\"M. Hasan\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICCV.2017.616\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25403c52a7c3092866773b0e765ab55841d3cb67\",\"title\":\"Joint Prediction of Activity Labels and Starting Times in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/25403c52a7c3092866773b0e765ab55841d3cb67\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/CVPR.2017.390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa3e3f4f1159e3af45a32eb0b3e206204d201721\",\"title\":\"Deep Sequential Context Networks for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa3e3f4f1159e3af45a32eb0b3e206204d201721\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1782428\",\"name\":\"S. An\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"3417987\",\"name\":\"F. Boussaid\"}],\"doi\":\"10.1109/TIP.2018.2812099\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef761435c1af2b3e5caba5e8bbbf5aeab69d934e\",\"title\":\"Learning Clip Representations for Skeleton-Based 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ef761435c1af2b3e5caba5e8bbbf5aeab69d934e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9920529\",\"name\":\"Yihang Lou\"},{\"authorId\":\"144615187\",\"name\":\"Y. Bai\"},{\"authorId\":\"48210884\",\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"}],\"doi\":\"10.1109/CVPR.2019.00335\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85a2ba580f6faa73f38672b0517cbcdeb84cf6c5\",\"title\":\"VERI-Wild: A Large Dataset and a New Method for Vehicle Re-Identification in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/85a2ba580f6faa73f38672b0517cbcdeb84cf6c5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/WACV.2016.7477586\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65355cbb581a219bd7461d48b3afd115263ea760\",\"title\":\"Recognition of ongoing complex activities by sequence prediction over a hierarchical label space\",\"url\":\"https://www.semanticscholar.org/paper/65355cbb581a219bd7461d48b3afd115263ea760\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.18\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"title\":\"Anticipating Visual Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145892975\",\"name\":\"S. Stein\"},{\"authorId\":\"6435894\",\"name\":\"S. Mckenna\"}],\"doi\":\"10.1145/2493432.2493482\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"e018fa4a1c893f964f76cee8ff735573974f87cc\",\"title\":\"Combining embedded accelerometers with computer vision for recognizing food preparation activities\",\"url\":\"https://www.semanticscholar.org/paper/e018fa4a1c893f964f76cee8ff735573974f87cc\",\"venue\":\"UbiComp\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1007/978-3-030-01219-9_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bec3c3e6bb9c738dad942f00fc69848018c3b1cc\",\"title\":\"Part-Activated Deep Reinforcement Learning for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/bec3c3e6bb9c738dad942f00fc69848018c3b1cc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.15607/RSS.2013.IX.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6907faab99d8304e9dc5baf05d5e5aca28737a1\",\"title\":\"Anticipating Human Activities using Object Affordances for Reactive Robotic Response\",\"url\":\"https://www.semanticscholar.org/paper/e6907faab99d8304e9dc5baf05d5e5aca28737a1\",\"venue\":\"Robotics: Science and Systems\",\"year\":2013},{\"arxivId\":\"1802.06822\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01219-9_33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"title\":\"Online Detection of Action Start in Untrimmed, Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/CVPR.2016.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"title\":\"Learning Activity Progression in LSTMs for Activity Detection and Early Detection\",\"url\":\"https://www.semanticscholar.org/paper/e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1782428\",\"name\":\"S. An\"},{\"authorId\":\"2795743\",\"name\":\"Farid Boussa\\u00efd\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"}],\"doi\":\"10.1007/978-3-319-48881-3_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd1e4e2dd60e1d3f895df67b2af7a9fe08696312\",\"title\":\"Human Interaction Prediction Using Deep Temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/bd1e4e2dd60e1d3f895df67b2af7a9fe08696312\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1103/PHYSREVD.94.065007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edbdb4de4367d245cb5f78d77de68464f9bdcde1\",\"title\":\"Learning a Deep Model for Human Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/edbdb4de4367d245cb5f78d77de68464f9bdcde1\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/CVPR.2018.00871\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e2f163e8a94d7a8597cabe73e7503d6b3bd7bec\",\"title\":\"SSNet: Scale Selection Network for Online 3D Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5e2f163e8a94d7a8597cabe73e7503d6b3bd7bec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1408.3809\",\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/978-3-319-10605-2_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e129ee3aaca9c9c2ddd7365c5ce09fd6017d2a36\",\"title\":\"HOPC: Histogram of Oriented Principal Components of 3D Pointclouds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e129ee3aaca9c9c2ddd7365c5ce09fd6017d2a36\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"1680626\",\"name\":\"Dmitry Kit\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1007/978-3-319-10602-1_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37a3ab75f3b2138ded342abd1362072c36ac4d25\",\"title\":\"A Discriminative Model with Multiple Temporal Scales for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/37a3ab75f3b2138ded342abd1362072c36ac4d25\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1708.00945\",\"authors\":[{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"1713084\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.132\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c3a7658e36422d997c255bda838008a477528dbe\",\"title\":\"Predicting Human Activities Using Stochastic Grammar\",\"url\":\"https://www.semanticscholar.org/paper/c3a7658e36422d997c255bda838008a477528dbe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"2708745\",\"name\":\"Tsung-Chuan Chen\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1007/978-3-319-10578-9_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2edc655b678da8fac7db70c3389070eba8727c5\",\"title\":\"A Hierarchical Representation for Future Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e2edc655b678da8fac7db70c3389070eba8727c5\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8520539\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"2139431\",\"name\":\"Lianyang Ma\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"}],\"doi\":\"10.1007/978-3-319-46448-0_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be969951dc48f0fd209024a58afeca0d7f12cef3\",\"title\":\"Real-Time RGB-D Activity Prediction by Soft Regression\",\"url\":\"https://www.semanticscholar.org/paper/be969951dc48f0fd209024a58afeca0d7f12cef3\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1611.05267\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"49447925\",\"name\":\"M. Flynn\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1109/CVPR.2017.113\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"title\":\"Temporal Convolutional Networks for Action Segmentation and Detection\",\"url\":\"https://www.semanticscholar.org/paper/210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1902.03084\",\"authors\":[{\"authorId\":\"38728795\",\"name\":\"J. Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2898954\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf4d31f2ca45ddaac2c2905c2820df919ac7192\",\"title\":\"Skeleton-Based Online Action Prediction Using Scale Selection Network\",\"url\":\"https://www.semanticscholar.org/paper/aaf4d31f2ca45ddaac2c2905c2820df919ac7192\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1707.04818\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.92\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"title\":\"RED: Reinforced Encoder-Decoder Networks for Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2011.6126349\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76be79c45335db6d08efcde7843ae298765d4d63\",\"title\":\"Human activity prediction: Early recognition of ongoing activities from streaming videos\",\"url\":\"https://www.semanticscholar.org/paper/76be79c45335db6d08efcde7843ae298765d4d63\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/ICCV.2017.621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcefb761034daeef1e735cf0a1787bc379ae0673\",\"title\":\"Learning Action Recognition Model from Depth and Skeleton Videos\",\"url\":\"https://www.semanticscholar.org/paper/bcefb761034daeef1e735cf0a1787bc379ae0673\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1804.00892\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00560\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"title\":\"When will you do what? - Anticipating Temporal Occurrences of Activities\",\"url\":\"https://www.semanticscholar.org/paper/33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"49106279\",\"name\":\"A. B. Arslan\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/CVPR.2014.105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"185f078accb52be4faa13e4f470a9909cc6fe814\",\"title\":\"The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/185f078accb52be4faa13e4f470a9909cc6fe814\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"2139431\",\"name\":\"Lianyang Ma\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"},{\"authorId\":\"144419119\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TPAMI.2018.2863279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9b958c2494b7ba08b5b460f19a06814dba8aee0\",\"title\":\"Early Action Prediction by Soft Regression\",\"url\":\"https://www.semanticscholar.org/paper/c9b958c2494b7ba08b5b460f19a06814dba8aee0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1706.08276\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/TPAMI.2017.2771306\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5b83d6b4a3c1093edc9138ab9dfe4e965a80261\",\"title\":\"Skeleton-Based Action Recognition Using Spatio-Temporal LSTM Network with Trust Gates\",\"url\":\"https://www.semanticscholar.org/paper/d5b83d6b4a3c1093edc9138ab9dfe4e965a80261\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1608.05267\",\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1782428\",\"name\":\"S. An\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"3417987\",\"name\":\"F. Boussaid\"}],\"doi\":\"10.1109/TMM.2017.2778559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83f8c54605689f093199bea52fdabaa9902ff4aa\",\"title\":\"Leveraging Structural Context Models and Ranking Score Fusion for Human Interaction Prediction\",\"url\":\"https://www.semanticscholar.org/paper/83f8c54605689f093199bea52fdabaa9902ff4aa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018}],\"title\":\"Time-Conditioned Action Anticipation in One Shot\",\"topics\":[{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Closed-circuit television\",\"topicId\":\"34046\",\"url\":\"https://www.semanticscholar.org/topic/34046\"},{\"topic\":\"Recursion (computer science)\",\"topicId\":\"2419\",\"url\":\"https://www.semanticscholar.org/topic/2419\"},{\"topic\":\"Conditioning (Psychology)\",\"topicId\":\"4885\",\"url\":\"https://www.semanticscholar.org/topic/4885\"}],\"url\":\"https://www.semanticscholar.org/paper/3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"