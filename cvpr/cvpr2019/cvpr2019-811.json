"{\"abstract\":\"Recent studies have witnessed the successes of using 3D CNNs for video action recognition. However, most 3D models are built upon RGB and optical flow streams, which may not fully exploit pose dynamics, i.e., an important cue of modeling human actions. To fill this gap, we propose a concise Pose-Action 3D Machine (PA3D), which can effectively encode multiple pose modalities within a unified 3D framework, and consequently learn spatio-temporal pose representations for action recognition. More specifically, we introduce a novel temporal pose convolution to aggregate spatial poses over frames. Unlike the classical temporal convolution, our operation can explicitly learn the pose motions that are discriminative to recognize human actions. Extensive experiments on three popular benchmarks (i.e., JHMDB, HMDB, and Charades) show that, PA3D outperforms the recent pose-based approaches. Furthermore, PA3D is highly complementary to the recent 3D CNNs, e.g., I3D. Multi-stream fusion achieves the state-of-the-art performance on all evaluated data sets.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\",\"url\":\"https://www.semanticscholar.org/author/47837986\"},{\"authorId\":null,\"name\":\"Yali Wang\",\"url\":null},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\",\"url\":\"https://www.semanticscholar.org/author/9247990\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\",\"url\":\"https://www.semanticscholar.org/author/143970608\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"31634716\",\"name\":\"Huosheng Xie\"},{\"authorId\":\"2042838335\",\"name\":\"Hongwen Luo\"},{\"authorId\":\"11662913\",\"name\":\"J. Lin\"},{\"authorId\":\"37092569\",\"name\":\"Ning Yang\"}],\"doi\":\"10.1177/1748302620983661\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e170ec3e0ff8a5ccaaacda27f7820df7cd04529\",\"title\":\"A novel algorithm of fast CPR quality evaluation based on kinect\",\"url\":\"https://www.semanticscholar.org/paper/7e170ec3e0ff8a5ccaaacda27f7820df7cd04529\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.08708\",\"authors\":[{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"1385119825\",\"name\":\"Christian Roncal\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1007/978-3-030-58607-2_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a718341f5db00071de408a4bd52e92541052e13\",\"title\":\"Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical Attention Pooling and Affective Mapping\",\"url\":\"https://www.semanticscholar.org/paper/3a718341f5db00071de408a4bd52e92541052e13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40370451\",\"name\":\"H. Kim\"},{\"authorId\":\"10263579\",\"name\":\"Seokmok Park\"},{\"authorId\":\"1820264163\",\"name\":\"Hyeokjin Park\"},{\"authorId\":\"9238090\",\"name\":\"J. Paik\"}],\"doi\":\"10.3390/s20143894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d76a567188604c227000de1d8e44fe64a176c654\",\"title\":\"Enhanced Action Recognition Using Multiple Stream Deep Learning with Optical Flow and Weighted Sum\",\"url\":\"https://www.semanticscholar.org/paper/d76a567188604c227000de1d8e44fe64a176c654\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2010.09982\",\"authors\":[{\"authorId\":\"1993669388\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"31267246\",\"name\":\"L. Zhang\"},{\"authorId\":\"1993529318\",\"name\":\"Junke Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3394171.3413502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"title\":\"Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1911.12509\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"title\":\"Action Recognition via Pose-Based Graph Convolutional Networks with Intermediate Dense Supervision\",\"url\":\"https://www.semanticscholar.org/paper/9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.04627\",\"authors\":[{\"authorId\":\"38403207\",\"name\":\"L. Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"title\":\"Hallucinating Statistical Moment and Subspace Descriptors from Object and Saliency Detectors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10250\",\"authors\":[{\"authorId\":\"41131768\",\"name\":\"Zhenhua Wang\"},{\"authorId\":\"31170827\",\"name\":\"J. Meng\"},{\"authorId\":\"2019493593\",\"name\":\"Jin Zhou\"},{\"authorId\":\"2004175\",\"name\":\"Dongyan Guo\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"1739956171\",\"name\":\"Jianhua Zhang\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"1739189491\",\"name\":\"Shengyong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"title\":\"LAGNet: Logic-Aware Graph Network for Human Interaction Understanding\",\"url\":\"https://www.semanticscholar.org/paper/2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.07787\",\"authors\":[{\"authorId\":\"81226618\",\"name\":\"Jinmiao Cai\"},{\"authorId\":\"2855391\",\"name\":\"N. Jiang\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49104090\",\"name\":\"Kui Jia\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2664de9388332008077c54278c4f59025dc0bab\",\"title\":\"JOLO-GCN: Mining Joint-Centered Light-Weight Information for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2664de9388332008077c54278c4f59025dc0bab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15829\",\"authors\":[{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"48708586\",\"name\":\"Zijian Wang\"},{\"authorId\":\"1852415\",\"name\":\"Zheng Zhang\"},{\"authorId\":\"51278862\",\"name\":\"Mahsa Baktashmotlagh\"}],\"doi\":\"10.1145/3394171.3413897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c312bbdb66bd72643c57213cb167250cadb384a0\",\"title\":\"Adversarial Bipartite Graph Learning for Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/c312bbdb66bd72643c57213cb167250cadb384a0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.13042\",\"authors\":[{\"authorId\":\"31463937\",\"name\":\"Haodong Duan\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"49663328\",\"name\":\"Wentao Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_40\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"title\":\"Omni-sourced Webly-supervised Learning for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":198909890,\"doi\":\"10.1109/CVPR.2019.00811\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"references\":[{\"arxivId\":\"1312.4659\",\"authors\":[{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":\"10.1109/CVPR.2014.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"title\":\"DeepPose: Human Pose Estimation via Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1602.00134\",\"authors\":[{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"20569810\",\"name\":\"V. Ramakrishna\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2016.511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"864e7db59f2ccfec1ee9f6eba79566ac7b0634df\",\"title\":\"Convolutional Pose Machines\",\"url\":\"https://www.semanticscholar.org/paper/864e7db59f2ccfec1ee9f6eba79566ac7b0634df\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1712.06316\",\"authors\":[{\"authorId\":\"1792573\",\"name\":\"Yue Luo\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"29988001\",\"name\":\"Zhouxia Wang\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"48211971\",\"name\":\"J. Liu\"},{\"authorId\":\"33520260\",\"name\":\"Jiahao Pang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00546\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"038251b7c6ffee94181dd6584ae2a923a6b0be07\",\"title\":\"LSTM Pose Machines\",\"url\":\"https://www.semanticscholar.org/paper/038251b7c6ffee94181dd6584ae2a923a6b0be07\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1802.09232\",\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"}],\"doi\":\"10.1109/CVPR.2018.00539\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4f5c848b41160ac665d1991529a67a3208061e\",\"title\":\"2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3d4f5c848b41160ac665d1991529a67a3208061e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49963740\",\"name\":\"Y. Du\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2015.7298714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1839e17555160bd897b978c48b8ebd13dd21445f\",\"title\":\"Hierarchical recurrent neural network for skeleton based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1839e17555160bd897b978c48b8ebd13dd21445f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.02897\",\"authors\":[{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"145682405\",\"name\":\"J. Charles\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2015.222\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f22f25904f85c657e10fcc262653ebb6187193f9\",\"title\":\"Flowing ConvNets for Human Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f22f25904f85c657e10fcc262653ebb6187193f9\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1801.07455\",\"authors\":[{\"authorId\":\"1979911\",\"name\":\"S. Yan\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"title\":\"Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1406.2984\",\"authors\":[{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"49147969\",\"name\":\"A. Jain\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12ecc2d786080f638a01b9999518e9386baa157d\",\"title\":\"Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/12ecc2d786080f638a01b9999518e9386baa157d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1812.08008\",\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"2915997\",\"name\":\"T. \\u0160imon\"},{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2017.143\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e8db1519245426f3a78752a3d8360484f4626b1\",\"title\":\"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields\",\"url\":\"https://www.semanticscholar.org/paper/9e8db1519245426f3a78752a3d8360484f4626b1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.04037\",\"authors\":[{\"authorId\":\"145042308\",\"name\":\"U. Iqbal\"},{\"authorId\":\"3370510\",\"name\":\"Martin Garbade\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/FG.2017.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5c48fb5d8f1403f8aa5392045fcdfd79b37a934\",\"title\":\"Pose for Action - Action for Pose\",\"url\":\"https://www.semanticscholar.org/paper/c5c48fb5d8f1403f8aa5392045fcdfd79b37a934\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014}],\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"topics\":[{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Human Metabolome Database\",\"topicId\":\"214982\",\"url\":\"https://www.semanticscholar.org/topic/214982\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"3D modeling\",\"topicId\":\"1179\",\"url\":\"https://www.semanticscholar.org/topic/1179\"},{\"topic\":\"Aggregate data\",\"topicId\":\"54317\",\"url\":\"https://www.semanticscholar.org/topic/54317\"}],\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"