"{\"abstract\":\"Neural style transfer has drawn considerable attention from both academic and industrial field. Although visual effect and efficiency have been significantly improved, existing methods are unable to coordinate spatial distribution of visual attention between the content image and stylized image, or render diverse level of detail via different brush strokes. In this paper, we tackle these limitations by developing an attention-aware multi-stroke style transfer model. We first propose to assemble self-attention mechanism into a style-agnostic reconstruction autoencoder framework, from which the attention map of a content image can be derived. By performing multi-scale style swap on content features and style features, we produce multiple feature maps reflecting different stroke patterns. A flexible fusion strategy is further presented to incorporate the salient characteristics from the attention map, which allows integrating multiple stroke patterns into different spatial regions of the output image harmoniously. We demonstrate the effectiveness of our method, as well as generate comparable stylized images with multiple stroke patterns against the state-of-the-art methods.\",\"arxivId\":\"1901.05127\",\"authors\":[{\"authorId\":\"144779803\",\"name\":\"Y. Yao\",\"url\":\"https://www.semanticscholar.org/author/144779803\"},{\"authorId\":\"40363985\",\"name\":\"Jianqiang Ren\",\"url\":\"https://www.semanticscholar.org/author/40363985\"},{\"authorId\":\"65863521\",\"name\":\"Xuansong Xie\",\"url\":\"https://www.semanticscholar.org/author/65863521\"},{\"authorId\":\"40474857\",\"name\":\"Weidong Liu\",\"url\":\"https://www.semanticscholar.org/author/40474857\"},{\"authorId\":\"1715826\",\"name\":\"Y. Liu\",\"url\":\"https://www.semanticscholar.org/author/1715826\"},{\"authorId\":null,\"name\":\"Jun Wang\",\"url\":null}],\"citationVelocity\":13,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144699282\",\"name\":\"Guo Mei\"},{\"authorId\":\"144646896\",\"name\":\"Min Xiao\"},{\"authorId\":\"1409974064\",\"name\":\"Fang Yu\"}],\"doi\":\"10.1007/978-981-15-3863-6_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88ad87cb9970fa722276d2f05a2cb0dbc86a07bc\",\"title\":\"Research on Deep Learning Algorithm and Application Based on Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/88ad87cb9970fa722276d2f05a2cb0dbc86a07bc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145002408\",\"name\":\"C. Guo\"},{\"authorId\":\"1476821330\",\"name\":\"Tianxiang Bai\"},{\"authorId\":\"39911726\",\"name\":\"Yue Lu\"},{\"authorId\":\"3396678\",\"name\":\"Yilun Lin\"},{\"authorId\":\"48338794\",\"name\":\"G. Xiong\"},{\"authorId\":\"145782486\",\"name\":\"Xiao Wang\"},{\"authorId\":\"47939505\",\"name\":\"Fei-yue Wang\"}],\"doi\":\"10.1109/CASE48305.2020.9216814\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e45464478d8e1fae9c4845706ba520b99f796165\",\"title\":\"Skywork-daVinci: A Novel CPSS-based Painting Support System\",\"url\":\"https://www.semanticscholar.org/paper/e45464478d8e1fae9c4845706ba520b99f796165\",\"venue\":\"2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94294263\",\"name\":\"F. Chen\"},{\"authorId\":\"2246399\",\"name\":\"J. Liu\"},{\"authorId\":\"40956020\",\"name\":\"Dongzhou Gou\"},{\"authorId\":null,\"name\":\"Xinran Zhang\"},{\"authorId\":\"11042636\",\"name\":\"Liang-yi Chen\"},{\"authorId\":\"47405681\",\"name\":\"Hongen Liao\"}],\"doi\":\"10.1016/j.compmedimag.2020.101743\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d080645d085b8b0fcfcfe0041fdb5bc450ddbd01\",\"title\":\"An accurate and universal approach for short-exposure-time microscopy image enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d080645d085b8b0fcfcfe0041fdb5bc450ddbd01\",\"venue\":\"Comput. Medical Imaging Graph.\",\"year\":2020},{\"arxivId\":\"2009.08003\",\"authors\":[{\"authorId\":\"49873367\",\"name\":\"Yingying Deng\"},{\"authorId\":\"1443761295\",\"name\":\"Fan Tang\"},{\"authorId\":\"38690089\",\"name\":\"Weiming Dong\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"151487472\",\"name\":\"Chongyang Ma\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c6aa5974edccd33117bdd1f6d2a8b6b3d0b44da\",\"title\":\"Arbitrary Video Style Transfer via Multi-Channel Correlation\",\"url\":\"https://www.semanticscholar.org/paper/6c6aa5974edccd33117bdd1f6d2a8b6b3d0b44da\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28918194\",\"name\":\"C. Bartz\"},{\"authorId\":\"1772598\",\"name\":\"Nitisha Jain\"},{\"authorId\":\"3264110\",\"name\":\"Ralf Krestel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e11eb518d20e2009f0c4ae4e957b7c8ce4d139b\",\"title\":\"Automatic Matching of Paintings and Descriptions in Art-Historic Archives using Multimodal Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9e11eb518d20e2009f0c4ae4e957b7c8ce4d139b\",\"venue\":\"AI4HI\",\"year\":2020},{\"arxivId\":\"1910.12056\",\"authors\":[{\"authorId\":\"47641579\",\"name\":\"Chunjin Song\"},{\"authorId\":\"47039766\",\"name\":\"Z. Wu\"},{\"authorId\":\"32025363\",\"name\":\"Yang Zhou\"},{\"authorId\":\"34077629\",\"name\":\"Minglun Gong\"},{\"authorId\":\"100821859\",\"name\":\"H. Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0573e04d6534e639db634cbd78bda60b3866380\",\"title\":\"ETNet: Error Transition Network for Arbitrary Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/d0573e04d6534e639db634cbd78bda60b3866380\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824743\",\"name\":\"W. Wang\"},{\"authorId\":\"1474586426\",\"name\":\"Shuai Yang\"},{\"authorId\":\"1697982\",\"name\":\"Jizheng Xu\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1109/TIP.2020.3024018\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afdbaa80e2dc9b98017dd990615ed5982768caaa\",\"title\":\"Consistent Video Style Transfer via Relaxation and Regularization\",\"url\":\"https://www.semanticscholar.org/paper/afdbaa80e2dc9b98017dd990615ed5982768caaa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1910.13093\",\"authors\":[{\"authorId\":\"40994845\",\"name\":\"Zixuan Huang\"},{\"authorId\":\"47539380\",\"name\":\"J. Zhang\"},{\"authorId\":null,\"name\":\"Jing Liao\"}],\"doi\":\"10.1111/cgf.13853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05b2cd49b6cb6e9cb70523a024d9c807ef8bff10\",\"title\":\"Style Mixer: Semantic\\u2010aware Multi\\u2010Style Transfer Network\",\"url\":\"https://www.semanticscholar.org/paper/05b2cd49b6cb6e9cb70523a024d9c807ef8bff10\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"2012.11193\",\"authors\":[{\"authorId\":\"27054843\",\"name\":\"Xuanhong Chen\"},{\"authorId\":\"151469283\",\"name\":\"Ziang Liu\"},{\"authorId\":\"46705821\",\"name\":\"Ting Qiu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1993664884\",\"name\":\"Naiyuan Liu\"},{\"authorId\":\"3261985\",\"name\":\"Xi-Wei Hu\"},{\"authorId\":\"2034199719\",\"name\":\"Yuhan Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb4e989fdc46f7b26c754099e4e44c2df1e56ef9\",\"title\":\"Image Translation via Fine-grained Knowledge Transfer\",\"url\":\"https://www.semanticscholar.org/paper/fb4e989fdc46f7b26c754099e4e44c2df1e56ef9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.05471\",\"authors\":[{\"authorId\":\"49543209\",\"name\":\"Xiaochang Liu\"},{\"authorId\":\"3601471\",\"name\":\"Xuan-yi Li\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"103234888\",\"name\":\"P. Hall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"391d560a30884a77cf8d0edc1e17bfc20dc9d706\",\"title\":\"Geometric Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/391d560a30884a77cf8d0edc1e17bfc20dc9d706\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71283867\",\"name\":\"Hui-Huang Zhao\"},{\"authorId\":\"9262057\",\"name\":\"Jinghua Zheng\"},{\"authorId\":null,\"name\":\"Yaonan Wang\"},{\"authorId\":\"2474758\",\"name\":\"Xiaofang Yuan\"},{\"authorId\":\"80472686\",\"name\":\"Y. Li\"}],\"doi\":\"10.1016/j.compeleceng.2020.106655\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94ccaef0d9103c97e5605b68d802a4d52a680405\",\"title\":\"Portrait style transfer using deep convolutional neural networks and facial segmentation\",\"url\":\"https://www.semanticscholar.org/paper/94ccaef0d9103c97e5605b68d802a4d52a680405\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":\"1911.06102\",\"authors\":[{\"authorId\":\"9407490\",\"name\":\"Yugang Chen\"},{\"authorId\":\"152385295\",\"name\":\"M. Chen\"},{\"authorId\":\"1388734273\",\"name\":\"Chaoyue Song\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"}],\"doi\":\"10.1007/978-3-030-37731-1_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"600b9eced5b9c399cf510dd3d908e97a61fd325f\",\"title\":\"CartoonRenderer: An Instance-based Multi-Style Cartoon Image Translator\",\"url\":\"https://www.semanticscholar.org/paper/600b9eced5b9c399cf510dd3d908e97a61fd325f\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145473299\",\"name\":\"Z. Hu\"},{\"authorId\":\"25714033\",\"name\":\"Jia Jia\"},{\"authorId\":\"1739750592\",\"name\":\"Bei Liu\"},{\"authorId\":\"3424070\",\"name\":\"Y. Bu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":\"10.1145/3394171.3413853\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0068c483b4d955139e9bc30d3bdcc59c32feeeaa\",\"title\":\"Aesthetic-Aware Image Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/0068c483b4d955139e9bc30d3bdcc59c32feeeaa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144851083\",\"name\":\"Zheng Xie\"},{\"authorId\":\"143976851\",\"name\":\"Zhiquan Wen\"},{\"authorId\":\"49270464\",\"name\":\"Jing Liu\"},{\"authorId\":\"144530683\",\"name\":\"Zhiqiang Liu\"},{\"authorId\":\"1490938677\",\"name\":\"Xixian Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1007/978-3-030-58598-3_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a04f4e4e6c2b756638091b2c4ce69719bd10a37\",\"title\":\"Deep Transferring Quantization\",\"url\":\"https://www.semanticscholar.org/paper/9a04f4e4e6c2b756638091b2c4ce69719bd10a37\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.08175\",\"authors\":[{\"authorId\":\"1994681152\",\"name\":\"Xuanhong Chen\"},{\"authorId\":\"95110480\",\"name\":\"Xirui Yan\"},{\"authorId\":\"1993664884\",\"name\":\"Naiyuan Liu\"},{\"authorId\":\"46705821\",\"name\":\"Ting Qiu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"}],\"doi\":\"10.1145/3394171.3413770\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e726e15beb49a7d6a75d1aa6f5487b3ed82876f4\",\"title\":\"Anisotropic Stroke Control for Multiple Artists Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/e726e15beb49a7d6a75d1aa6f5487b3ed82876f4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878726607\",\"name\":\"Ting Zhu\"},{\"authorId\":\"153318498\",\"name\":\"Shiguang Liu\"}],\"doi\":\"10.1109/ICME46284.2020.9102931\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10fbbf59e409a40229c29910e9c2e39d8afc6edc\",\"title\":\"Detail-Preserving Arbitrary Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/10fbbf59e409a40229c29910e9c2e39d8afc6edc\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2006.01431\",\"authors\":[{\"authorId\":\"1506975125\",\"name\":\"Minxuan Lin\"},{\"authorId\":\"1443761295\",\"name\":\"Fan Tang\"},{\"authorId\":\"38690089\",\"name\":\"Weiming Dong\"},{\"authorId\":\"50079039\",\"name\":\"Xiao Li\"},{\"authorId\":\"151487472\",\"name\":\"Chongyang Ma\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e13b85ae8321347cf401d469a2256a0a449e7ffd\",\"title\":\"Distribution Aligned Multimodal and Multi-Domain Image Stylization\",\"url\":\"https://www.semanticscholar.org/paper/e13b85ae8321347cf401d469a2256a0a449e7ffd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.02467\",\"authors\":[{\"authorId\":\"9243738\",\"name\":\"Yan-qi Bai\"},{\"authorId\":\"2613860\",\"name\":\"Y. Guo\"},{\"authorId\":\"92883267\",\"name\":\"Jinjie Wei\"},{\"authorId\":\"1455895851\",\"name\":\"Lin Lu\"},{\"authorId\":\"145490563\",\"name\":\"Rui Wang\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"}],\"doi\":\"10.1109/ICIP40778.2020.9190892\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6ef5d606e2bd6f063e72081ca19fde2b6e9e7b8c\",\"title\":\"Fake Generated Painting Detection Via Frequency Analysis\",\"url\":\"https://www.semanticscholar.org/paper/6ef5d606e2bd6f063e72081ca19fde2b6e9e7b8c\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2315023\",\"name\":\"Jiachuan Sheng\"},{\"authorId\":\"1423480256\",\"name\":\"Caifeng Song\"},{\"authorId\":\"2447899\",\"name\":\"J. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/ACCESS.2019.2952616\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df18e3f9e28cc01bd46bda437031f928cf17b5dc\",\"title\":\"Convolutional Neural Network Style Transfer Towards Chinese Paintings\",\"url\":\"https://www.semanticscholar.org/paper/df18e3f9e28cc01bd46bda437031f928cf17b5dc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2001.07466\",\"authors\":[{\"authorId\":\"1490486190\",\"name\":\"Zhentan Zheng\"},{\"authorId\":\"2995416\",\"name\":\"Jianyi Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0ea9bc8a7446aa7f636ecfed7955605e54b2c92\",\"title\":\"P$^2$-GAN: Efficient Style Transfer Using Single Style Image\",\"url\":\"https://www.semanticscholar.org/paper/e0ea9bc8a7446aa7f636ecfed7955605e54b2c92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40643755\",\"name\":\"P. Li\"},{\"authorId\":\"51457354\",\"name\":\"Dan Zhang\"},{\"authorId\":\"120470808\",\"name\":\"Lei Zhao\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"},{\"authorId\":\"51260042\",\"name\":\"Dongming Lu\"}],\"doi\":\"10.1109/ACCESS.2020.3034653\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cff1bf8462ee9d6de22ffb52ab3cc3443b32d37\",\"title\":\"Style Permutation for Diversified Arbitrary Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/6cff1bf8462ee9d6de22ffb52ab3cc3443b32d37\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1910.07862\",\"authors\":[{\"authorId\":\"37750191\",\"name\":\"L. Wang\"},{\"authorId\":\"39359197\",\"name\":\"J. Li\"},{\"authorId\":\"143645360\",\"name\":\"N. Yang\"},{\"authorId\":\"39952531\",\"name\":\"Xin Li\"}],\"doi\":\"10.1088/1367-2630/ab1310\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f61bc7b5721f5cd477549068314aa7249a113a\",\"title\":\"Identifying extra high frequency gravitational waves generated from oscillons with cuspy potentials using deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/33f61bc7b5721f5cd477549068314aa7249a113a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47039766\",\"name\":\"Z. Wu\"},{\"authorId\":\"47641579\",\"name\":\"Chunjin Song\"},{\"authorId\":\"32025363\",\"name\":\"Yang Zhou\"},{\"authorId\":\"34077629\",\"name\":\"Minglun Gong\"},{\"authorId\":\"40586368\",\"name\":\"Hui Huang\"}],\"doi\":\"10.1609/aaai.v34i07.6914\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77320f9c001fdd40471cd1a7d3381dced2c45985\",\"title\":\"EFANet: Exchangeable Feature Alignment Network for Arbitrary Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/77320f9c001fdd40471cd1a7d3381dced2c45985\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400984858\",\"name\":\"A. Dorn\"},{\"authorId\":\"1712974\",\"name\":\"J. L. D\\u00edaz\"},{\"authorId\":\"145692288\",\"name\":\"G. Koch\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0c8a2a79f8eaf404ab93f834b0cfd7700014ad4\",\"title\":\"Language Resource and Evaluation Conference 11 \\u2013 16 May 2020\",\"url\":\"https://www.semanticscholar.org/paper/b0c8a2a79f8eaf404ab93f834b0cfd7700014ad4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.01642\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e6fd339e247604e00f4ca40de44438a96835471\",\"title\":\"Learning to Transfer Visual Effects from Videos to Images\",\"url\":\"https://www.semanticscholar.org/paper/0e6fd339e247604e00f4ca40de44438a96835471\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.13219\",\"authors\":[{\"authorId\":\"49873367\",\"name\":\"Yingying Deng\"},{\"authorId\":\"1443761295\",\"name\":\"Fan Tang\"},{\"authorId\":\"38690089\",\"name\":\"Weiming Dong\"},{\"authorId\":\"22578070\",\"name\":\"W. Sun\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3394171.3414015\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2395bf6c6a4ea9620ca959cb952252e02c30332\",\"title\":\"Arbitrary Style Transfer via Multi-Adaptation Network\",\"url\":\"https://www.semanticscholar.org/paper/e2395bf6c6a4ea9620ca959cb952252e02c30332\",\"venue\":\"ACM Multimedia\",\"year\":2020}],\"corpusId\":58007009,\"doi\":\"10.1109/CVPR.2019.00156\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"85f309e0958a70231c993c4b353fb6412cbcb7bb\",\"references\":[{\"arxivId\":\"1703.06868\",\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/ICCV.2017.167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"be0ef77fb0345c5851bb5d297f3ed84ae3c581ee\",\"title\":\"Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization\",\"url\":\"https://www.semanticscholar.org/paper/be0ef77fb0345c5851bb5d297f3ed84ae3c581ee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.01895\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2177528\",\"name\":\"Geoffrey Oxholm\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/CVPR.2017.759\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38ef32149e8a72c9c800b21faef29980be97d739\",\"title\":\"Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/38ef32149e8a72c9c800b21faef29980be97d739\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.03130\",\"authors\":[{\"authorId\":\"3146592\",\"name\":\"Zhouhan Lin\"},{\"authorId\":\"2521552\",\"name\":\"Minwei Feng\"},{\"authorId\":\"1790831\",\"name\":\"C. D. Santos\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144028698\",\"name\":\"B. Xiang\"},{\"authorId\":\"145218984\",\"name\":\"Bowen Zhou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204a4a70428f3938d2c538a4d74c7ae0416306d8\",\"title\":\"A Structured Self-attentive Sentence Embedding\",\"url\":\"https://www.semanticscholar.org/paper/204a4a70428f3938d2c538a4d74c7ae0416306d8\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1611.07865\",\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"}],\"doi\":\"10.1109/CVPR.2017.397\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acc529f6f65fbdbae1aff14682168b5132143f28\",\"title\":\"Controlling Perceptual Factors in Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/acc529f6f65fbdbae1aff14682168b5132143f28\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bff8898e3ebb1ab67fd20b5db00c6cb1938e6c3\",\"title\":\"Learning to combine foveal glimpses with a third-order Boltzmann machine\",\"url\":\"https://www.semanticscholar.org/paper/0bff8898e3ebb1ab67fd20b5db00c6cb1938e6c3\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":\"1701.08893\",\"authors\":[{\"authorId\":\"31663839\",\"name\":\"Pierre Wilmot\"},{\"authorId\":\"2178086\",\"name\":\"E. Risser\"},{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02b01b4ea3dce27400d6479cb4a6dc188b4eae04\",\"title\":\"Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses\",\"url\":\"https://www.semanticscholar.org/paper/02b01b4ea3dce27400d6479cb4a6dc188b4eae04\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Bylinskii\"},{\"authorId\":null,\"name\":\"T. Judd\"},{\"authorId\":null,\"name\":\"A. Oliva\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and F\",\"url\":\"\",\"venue\":\"Durand. What do different evaluation metrics tell us about saliency models? TPAMI\",\"year\":2018},{\"arxivId\":\"1803.02155\",\"authors\":[{\"authorId\":\"38759328\",\"name\":\"Peter Shaw\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"}],\"doi\":\"10.18653/v1/N18-2074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8efcc854d97dfc2a42b83316a2109f9d166e43f\",\"title\":\"Self-Attention with Relative Position Representations\",\"url\":\"https://www.semanticscholar.org/paper/c8efcc854d97dfc2a42b83316a2109f9d166e43f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1705.08086\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"83083c5760bd1b58e5f827e57415e5ed676ef3bc\",\"title\":\"Universal Style Transfer via Feature Transforms\",\"url\":\"https://www.semanticscholar.org/paper/83083c5760bd1b58e5f827e57415e5ed676ef3bc\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1705.04058\",\"authors\":[{\"authorId\":\"9633703\",\"name\":\"Yongcheng Jing\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"7357719\",\"name\":\"Zunlei Feng\"},{\"authorId\":\"3764313\",\"name\":\"Jingwen Ye\"},{\"authorId\":\"144646841\",\"name\":\"M. Song\"}],\"doi\":\"10.1109/TVCG.2019.2921336\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0760764dc573b519f76d5a79531d49af333c67a\",\"title\":\"Neural Style Transfer: A Review\",\"url\":\"https://www.semanticscholar.org/paper/b0760764dc573b519f76d5a79531d49af333c67a\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":\"1701.01036\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"}],\"doi\":\"10.24963/ijcai.2017/310\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cafd077d239411f7f23f63955d51c0e59c7b996\",\"title\":\"Demystifying Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/8cafd077d239411f7f23f63955d51c0e59c7b996\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1805.03857\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1967781\",\"name\":\"Ziyi Lin\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00860\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e0df8fe29381154c06b6b488cf32b6f6627b394f\",\"title\":\"Avatar-Net: Multi-scale Zero-Shot Style Transfer by Feature Decoration\",\"url\":\"https://www.semanticscholar.org/paper/e0df8fe29381154c06b6b488cf32b6f6627b394f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.6447\",\"authors\":[{\"authorId\":\"39102205\",\"name\":\"Tianjun Xiao\"},{\"authorId\":\"2636690\",\"name\":\"Yichong Xu\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":\"2478181\",\"name\":\"Jiaxing Zhang\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":null,\"name\":\"Zheng Zhang\"}],\"doi\":\"10.1109/CVPR.2015.7298685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d5fd29a02f7fc50f7c36f1a74563d529620aa66\",\"title\":\"The application of two-level attention models in deep convolutional neural network for fine-grained image classification\",\"url\":\"https://www.semanticscholar.org/paper/7d5fd29a02f7fc50f7c36f1a74563d529620aa66\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"},{\"authorId\":\"2129170\",\"name\":\"Chengen Guo\"},{\"authorId\":null,\"name\":\"Yizhou Wang\"},{\"authorId\":\"2001080\",\"name\":\"Zijian Xu\"}],\"doi\":\"10.1007/s11263-005-4638-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f180b69bd93792da50fd95661c4f8e1b1e781dc8\",\"title\":\"What are Textons?\",\"url\":\"https://www.semanticscholar.org/paper/f180b69bd93792da50fd95661c4f8e1b1e781dc8\",\"venue\":\"Int. J. Comput. Vis.\",\"year\":2005},{\"arxivId\":\"1603.03417\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"47606739\",\"name\":\"V. Lebedev\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"title\":\"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images\",\"url\":\"https://www.semanticscholar.org/paper/ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"More results of our attention-aware multi-stroke style transfer method (Set 1). The 1st row is the content images\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S.-C. Zhu\"},{\"authorId\":null,\"name\":\"C.-E. Guo\"},{\"authorId\":null,\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Z\",\"url\":\"\",\"venue\":\"Xu. What are textons? In ICCV\",\"year\":2005},{\"arxivId\":\"1612.04337\",\"authors\":[{\"authorId\":\"11126631\",\"name\":\"Tian Qi Chen\"},{\"authorId\":\"144314176\",\"name\":\"M. Schmidt\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"790ca7b0a0076d1bb5a8161713f79ab1aef725b6\",\"title\":\"Fast Patch-based Style Transfer of Arbitrary Style\",\"url\":\"https://www.semanticscholar.org/paper/790ca7b0a0076d1bb5a8161713f79ab1aef725b6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1406.6247\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a756d4d25511d92a45d0f4545fa819de993851d\",\"title\":\"Recurrent Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8a756d4d25511d92a45d0f4545fa819de993851d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1604.04382\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1007/978-3-319-46487-9_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"102a2096ba2e2947dc252445f764e7583b557680\",\"title\":\"Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/102a2096ba2e2947dc252445f764e7583b557680\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d0eeb46fc5ec778a62bb94aa2ef261b08e6f8c6\",\"title\":\"Texture Synthesis Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0d0eeb46fc5ec778a62bb94aa2ef261b08e6f8c6\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1805.08318\",\"authors\":[{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"},{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"title\":\"Self-Attention Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1802.07101\",\"authors\":[{\"authorId\":\"9633703\",\"name\":\"Yongcheng Jing\"},{\"authorId\":\"144378549\",\"name\":\"Yang Liu\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"7357719\",\"name\":\"Zunlei Feng\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"},{\"authorId\":\"1727111\",\"name\":\"Mingli Song\"}],\"doi\":\"10.1007/978-3-030-01261-8_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"357613f3d6c3db33e91654ecef2dff701251a2de\",\"title\":\"Stroke Controllable Fast Style Transfer with Adaptive Receptive Fields\",\"url\":\"https://www.semanticscholar.org/paper/357613f3d6c3db33e91654ecef2dff701251a2de\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1617780012\",\"name\":\"Citt\\u00e0 DI Torino\"},{\"authorId\":\"1620911036\",\"name\":\"Determinazione Dirigenziale\"},{\"authorId\":\"1620917356\",\"name\":\"N. Cronologico\"}],\"doi\":\"10.1515/9783111438443-006\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"444537108d9171272bfbb0eccd7a3855ada66b0d\",\"title\":\"N\",\"url\":\"https://www.semanticscholar.org/paper/444537108d9171272bfbb0eccd7a3855ada66b0d\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Xu\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ask\",\"url\":\"\",\"venue\":\"attend and answer: Exploring question-guided spatial attention for visual question answering. In ECCV\",\"year\":2016}],\"title\":\"Attention-Aware Multi-Stroke Style Transfer\",\"topics\":[{\"topic\":\"Autoencoder\",\"topicId\":\"433939\",\"url\":\"https://www.semanticscholar.org/topic/433939\"},{\"topic\":\"Visual effects\",\"topicId\":\"69332\",\"url\":\"https://www.semanticscholar.org/topic/69332\"},{\"topic\":\"Level of detail\",\"topicId\":\"14055\",\"url\":\"https://www.semanticscholar.org/topic/14055\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Paging\",\"topicId\":\"23151\",\"url\":\"https://www.semanticscholar.org/topic/23151\"}],\"url\":\"https://www.semanticscholar.org/paper/85f309e0958a70231c993c4b353fb6412cbcb7bb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"