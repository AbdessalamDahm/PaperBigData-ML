"{\"abstract\":\"In this paper, we introduce a new problem of manipulating a given video by inserting other videos into it. Our main task is, given an object video and a scene video, to insert the object video at a user-specified location in the scene video so that the resulting video looks realistic. We aim to handle different object motions and complex backgrounds without expensive segmentation annotations. As it is difficult to collect training pairs for this problem, we synthesize fake training pairs that can provide helpful supervisory signals when training a neural network with unpaired real data. The proposed network architecture can take both real and fake pairs as input and perform both supervised and unsupervised training in an adversarial learning scheme. To synthesize a realistic video, the network renders each frame based on the current input and previous frames. Within this framework, we observe that injecting noise into previous frames while generating the current frame stabilizes training. We conduct experiments on real-world videos in object tracking and person re-identification benchmark datasets. Experimental results demonstrate that the proposed algorithm is able to synthesize long sequences of realistic videos with a given object video inserted.\",\"arxivId\":\"1903.06571\",\"authors\":[{\"authorId\":\"2350325\",\"name\":\"D. Lee\",\"url\":\"https://www.semanticscholar.org/author/2350325\"},{\"authorId\":\"1945962\",\"name\":\"T. Pfister\",\"url\":\"https://www.semanticscholar.org/author/1945962\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\",\"url\":\"https://www.semanticscholar.org/author/37144787\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"153142893\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCV.2019.00767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"title\":\"View-LSTM: Novel-View Video Synthesis Through View Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73488896\",\"name\":\"Maria Priisalu\"},{\"authorId\":\"1948653\",\"name\":\"C. Paduraru\"},{\"authorId\":\"7254236\",\"name\":\"Aleksis Pirinen\"},{\"authorId\":null,\"name\":\"Cristian\"},{\"authorId\":null,\"name\":\"Sminchisescu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71c78d42796f7a79ee3e017681c4595a525cdbbc\",\"title\":\"Semantic Synthesis of Pedestrian Locomotion\",\"url\":\"https://www.semanticscholar.org/paper/71c78d42796f7a79ee3e017681c4595a525cdbbc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73316684\",\"name\":\"Guoqing Hao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b14b6957354cc8bcfd87187baa340ff9b3c41cc\",\"title\":\"HAO ET AL.: HARMONIZATION WITH ATTENTION-BASED DEEP FEATURE MODULATION1 Image Harmonization with Attention-based Deep Feature Modulation\",\"url\":\"https://www.semanticscholar.org/paper/4b14b6957354cc8bcfd87187baa340ff9b3c41cc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1109/TPAMI.2019.2958083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"title\":\"Recurrent Temporal Aggregation Framework for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1905.13066\",\"authors\":[{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"title\":\"Align-and-Attend Network for Globally and Locally Coherent Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.07169\",\"authors\":[{\"authorId\":\"51462848\",\"name\":\"L. Liu\"},{\"authorId\":\"15909044\",\"name\":\"M. Muelly\"},{\"authorId\":\"121806097\",\"name\":\"J. Deng\"},{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/ICCV.2019.00617\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9de50870d5a8399c22f116d5f0ff32b694284ede\",\"title\":\"Generative Modeling for Small-Data Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/9de50870d5a8399c22f116d5f0ff32b694284ede\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.07683\",\"authors\":[{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3343031.3350864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"title\":\"Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation\",\"url\":\"https://www.semanticscholar.org/paper/e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2008.08701\",\"authors\":[{\"authorId\":\"48480265\",\"name\":\"Jin Sun\"},{\"authorId\":\"1388323535\",\"name\":\"Hadar Averbuch-Elor\"},{\"authorId\":\"49110495\",\"name\":\"Q. Wang\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1007/978-3-030-58523-5_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ea0f1ff8fffef3bc4606b79f2edbbd94b6c6e54\",\"title\":\"Hidden Footprints: Learning Contextual Walkability from 3D Human Trails\",\"url\":\"https://www.semanticscholar.org/paper/3ea0f1ff8fffef3bc4606b79f2edbbd94b6c6e54\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.11690\",\"authors\":[{\"authorId\":\"1527095795\",\"name\":\"Yandong Li\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.00839\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f5e1e0e9ad9207f8b869f699c13220037ca3e28\",\"title\":\"BachGAN: High-Resolution Image Synthesis From Salient Object Layout\",\"url\":\"https://www.semanticscholar.org/paper/2f5e1e0e9ad9207f8b869f699c13220037ca3e28\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.11369\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"461470832f30d7dcca7d58dc399190f70462ee55\",\"title\":\"Object Discovery with a Copy-Pasting GAN\",\"url\":\"https://www.semanticscholar.org/paper/461470832f30d7dcca7d58dc399190f70462ee55\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.06406\",\"authors\":[{\"authorId\":\"30176430\",\"name\":\"Xiaodong Cun\"},{\"authorId\":\"145956876\",\"name\":\"Chi-Man Pun\"}],\"doi\":\"10.1109/TIP.2020.2975979\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e882ca005070f2c5931665f0c10ba9e63fad29bf\",\"title\":\"Improving the Harmony of the Composite Image by Spatial-Separated Attention Module\",\"url\":\"https://www.semanticscholar.org/paper/e882ca005070f2c5931665f0c10ba9e63fad29bf\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.09209\",\"authors\":[{\"authorId\":\"145184140\",\"name\":\"Yifan Wang\"},{\"authorId\":\"1396759259\",\"name\":\"Brian Curless\"},{\"authorId\":\"116149486\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-030-58607-2_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d28d43eaf2b99ef914f7a00a551a85ba3ee6a904\",\"title\":\"People as Scene Probes\",\"url\":\"https://www.semanticscholar.org/paper/d28d43eaf2b99ef914f7a00a551a85ba3ee6a904\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":80628325,\"doi\":\"10.1109/CVPR.2019.01030\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"bcad284af2a484d508a695dc534b0363812b1993\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.05831\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8299168\",\"name\":\"Y. Zou\"},{\"authorId\":\"2459821\",\"name\":\"Sungryull Sohn\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f230cacc511b17b491bf3d90015bbbf85b9ef6af\",\"title\":\"Learning to Generate Long-term Future via Hierarchical Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f230cacc511b17b491bf3d90015bbbf85b9ef6af\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"150426657\",\"name\":\"\\u62d3\\u6d77 \\u6749\\u5c71\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e8a5f27e7805f8de84ea008d59452ff864271696\",\"title\":\"\\u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\u201d\\u306e\\u5b66\\u7fd2\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/e8a5f27e7805f8de84ea008d59452ff864271696\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1511.04136\",\"authors\":[{\"authorId\":\"39774417\",\"name\":\"Longyin Wen\"},{\"authorId\":\"1910738\",\"name\":\"Dawei Du\"},{\"authorId\":\"1773408\",\"name\":\"Zhaowei Cai\"},{\"authorId\":\"98899797\",\"name\":\"Z. Lei\"},{\"authorId\":\"39643145\",\"name\":\"Ming-Ching Chang\"},{\"authorId\":\"3245785\",\"name\":\"H. Qi\"},{\"authorId\":\"153239384\",\"name\":\"Jongwoo Lim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1794837\",\"name\":\"Siwei Lyu\"}],\"doi\":\"10.1016/j.cviu.2020.102907\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f97056221a9e0e8d5f9c7c25d193dac046080ca\",\"title\":\"UA-DETRAC: A new benchmark and protocol for multi-object detection and tracking\",\"url\":\"https://www.semanticscholar.org/paper/8f97056221a9e0e8d5f9c7c25d193dac046080ca\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"1609.01775\",\"authors\":[{\"authorId\":\"2788204\",\"name\":\"Ergys Ristani\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"3423187\",\"name\":\"Roger S. Zou\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"},{\"authorId\":\"145086151\",\"name\":\"Carlo Tomasi\"}],\"doi\":\"10.1007/978-3-319-48881-3_2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"85aefde69e916523d9587b6abd01419420039474\",\"title\":\"Performance Measures and a Data Set for Multi-target, Multi-camera Tracking\",\"url\":\"https://www.semanticscholar.org/paper/85aefde69e916523d9587b6abd01419420039474\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1706.06982\",\"authors\":[{\"authorId\":\"19251410\",\"name\":\"Matthew Tesfaldet\"},{\"authorId\":\"2575536\",\"name\":\"M. Brubaker\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"}],\"doi\":\"10.1109/CVPR.2018.00701\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"380f159cf407d2aa52232b8f7f29ae2405c35c65\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Texture Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/380f159cf407d2aa52232b8f7f29ae2405c35c65\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.00848\",\"authors\":[{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":null,\"name\":\"Thomas Breuel\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b69badabc3fddc9710faa44c530473397303b0b9\",\"title\":\"Unsupervised Image-to-Image Translation Networks\",\"url\":\"https://www.semanticscholar.org/paper/b69badabc3fddc9710faa44c530473397303b0b9\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2821692\",\"name\":\"Jui-Ting Chien\"},{\"authorId\":\"35181285\",\"name\":\"Chia-Jung Chou\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"}],\"doi\":\"10.1109/ICCVW.2017.30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7750d24f5861551ea8a9b371f8f9e5c404a6e81f\",\"title\":\"Detecting Nonexistent Pedestrians\",\"url\":\"https://www.semanticscholar.org/paper/7750d24f5861551ea8a9b371f8f9e5c404a6e81f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1752496\",\"name\":\"M. Gangnet\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"}],\"doi\":\"10.1145/1201775.882269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dbc8145124d338a96ee59bc745f0bbce1f00c76\",\"title\":\"Poisson image editing\",\"url\":\"https://www.semanticscholar.org/paper/6dbc8145124d338a96ee59bc745f0bbce1f00c76\",\"venue\":\"SIGGRAPH '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3155984\",\"name\":\"Ben Benfold\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/CVPR.2011.5995667\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b1e33f60514a307054de5642a13051c1e1438b6\",\"title\":\"Stable multi-target tracking in real-time surveillance video\",\"url\":\"https://www.semanticscholar.org/paper/5b1e33f60514a307054de5642a13051c1e1438b6\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1812.02350\",\"authors\":[{\"authorId\":\"2350325\",\"name\":\"D. Lee\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"143785523\",\"name\":\"Jinwei Gu\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"02e7edc4b45a8903f5c41aa0ab5606fb15dfae54\",\"title\":\"Context-aware Synthesis and Placement of Object Instances\",\"url\":\"https://www.semanticscholar.org/paper/02e7edc4b45a8903f5c41aa0ab5606fb15dfae54\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1798462\",\"name\":\"Pierre-Antoine Manzagol\"}],\"doi\":\"10.1145/1390156.1390294\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"843959ffdccf31c6694d135fad07425924f785b1\",\"title\":\"Extracting and composing robust features with denoising autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/843959ffdccf31c6694d135fad07425924f785b1\",\"venue\":\"ICML '08\",\"year\":2008},{\"arxivId\":\"1705.10915\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"3468723\",\"name\":\"Vighnesh Birodkar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a8d3ad2b400bcebc9f17b309901ca5ef2e95315\",\"title\":\"Unsupervised Learning of Disentangled Representations from Video\",\"url\":\"https://www.semanticscholar.org/paper/1a8d3ad2b400bcebc9f17b309901ca5ef2e95315\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1802.02611\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":\"10.1007/978-3-030-01234-2_49\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"title\":\"Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1708.00284\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"87068304\",\"name\":\"L. Lee\"},{\"authorId\":\"143716171\",\"name\":\"Wei Dai\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"title\":\"Dual Motion GAN for Future-Flow Embedded Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1808.07535\",\"authors\":[{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"1564426583\",\"name\":\"Thomas E. Huang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"160c6e028067c4badfd0c43d44724b87526cc746\",\"title\":\"Learning Hierarchical Semantic Image Manipulation through Structured Representations\",\"url\":\"https://www.semanticscholar.org/paper/160c6e028067c4badfd0c43d44724b87526cc746\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"35130187\",\"name\":\"Xiaolong Zhu\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2017.745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"title\":\"Real-Time Neural Style Transfer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1804.04732\",\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1007/978-3-030-01219-9_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60104351ac65115503c9e92e856bcab6a13b0ce8\",\"title\":\"Multimodal Unsupervised Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/60104351ac65115503c9e92e856bcab6a13b0ce8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.02767\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e4845fb1e624965d4f036d7fd32e8dcdd2408148\",\"title\":\"YOLOv3: An Incremental Improvement\",\"url\":\"https://www.semanticscholar.org/paper/e4845fb1e624965d4f036d7fd32e8dcdd2408148\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1708.04538\",\"authors\":[{\"authorId\":\"37003547\",\"name\":\"M. Ruder\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/s11263-018-1089-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8270cfa97e74ee341938685a66a9b75cb65abc17\",\"title\":\"Artistic Style Transfer for Videos and Spherical Images\",\"url\":\"https://www.semanticscholar.org/paper/8270cfa97e74ee341938685a66a9b75cb65abc17\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1706.08033\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"title\":\"Decomposing Motion and Content for Natural Video Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1808.05174\",\"authors\":[{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1007/978-3-030-01228-1_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ad3c383a79e85159098112127300dfd08c21319\",\"title\":\"Recycle-GAN: Unsupervised Video Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/8ad3c383a79e85159098112127300dfd08c21319\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1803.01837\",\"authors\":[{\"authorId\":\"2511674\",\"name\":\"Chen-Hsuan Lin\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"}],\"doi\":\"10.1109/CVPR.2018.00985\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9e7e54896e7ee201d7e8c7f973818f58371e1fd5\",\"title\":\"ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing\",\"url\":\"https://www.semanticscholar.org/paper/9e7e54896e7ee201d7e8c7f973818f58371e1fd5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.11586\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6eda0c16d226976506396653d14044c185eaf3e\",\"title\":\"Toward Multimodal Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/d6eda0c16d226976506396653d14044c185eaf3e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39774417\",\"name\":\"Longyin Wen\"},{\"authorId\":\"1910738\",\"name\":\"Dawei Du\"},{\"authorId\":\"1773408\",\"name\":\"Zhaowei Cai\"},{\"authorId\":\"145754448\",\"name\":\"Z. Lei\"},{\"authorId\":\"39643145\",\"name\":\"Ming-Ching Chang\"},{\"authorId\":\"144097734\",\"name\":\"H. Qi\"},{\"authorId\":\"153239384\",\"name\":\"Jongwoo Lim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1794837\",\"name\":\"Siwei Lyu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"50137d663802224e683951c48970496b38b02141\",\"title\":\"DETRAC: A New Benchmark and Protocol for Multi-Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/50137d663802224e683951c48970496b38b02141\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1808.07371\",\"authors\":[{\"authorId\":\"1715365\",\"name\":\"C. Chan\"},{\"authorId\":\"2361255\",\"name\":\"Shiry Ginosar\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2019.00603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"title\":\"Everybody Dance Now\",\"url\":\"https://www.semanticscholar.org/paper/e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1804.02047\",\"authors\":[{\"authorId\":\"49436226\",\"name\":\"Xi Ouyang\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"40299877\",\"name\":\"Yifan Jiang\"},{\"authorId\":\"2088535\",\"name\":\"C. Li\"},{\"authorId\":\"33481412\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"98bda8768fd4a384695ecc736876a87f51c4ca0e\",\"title\":\"Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/98bda8768fd4a384695ecc736876a87f51c4ca0e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ting-Chun Wang\"},{\"authorId\":null,\"name\":\"Ming-Yu Liu\"},{\"authorId\":null,\"name\":\"Jun-Yan Zhu\"},{\"authorId\":null,\"name\":\"Guilin Liu\"},{\"authorId\":null,\"name\":\"Andrew Tao\"},{\"authorId\":null,\"name\":\"Jan Kautz\"},{\"authorId\":null,\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video-tovideo synthesis\",\"url\":\"\",\"venue\":\"In Neural Information Processing Systems,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pascal Vincent\"},{\"authorId\":null,\"name\":\"Hugo Larochelle\"},{\"authorId\":null,\"name\":\"Yoshua Bengio\"},{\"authorId\":null,\"name\":\"Pierre-Antoine Manzagol\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Extracting and composing robust 10069  features with denoising autoencoders\",\"url\":\"\",\"venue\":\"In International Conference on Machine Learning,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pascal Vincent\"},{\"authorId\":null,\"name\":\"Hugo Larochelle\"},{\"authorId\":null,\"name\":\"Yoshua Bengio\"},{\"authorId\":null,\"name\":\"Pierre-Antoine Manzagol\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Extracting and composing robust 10061 features with denoising autoencoders\",\"url\":\"\",\"venue\":\"In International Conference on Machine Learning,\",\"year\":2008}],\"title\":\"Inserting Videos Into Videos\",\"topics\":[{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Image noise\",\"topicId\":\"18959\",\"url\":\"https://www.semanticscholar.org/topic/18959\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Loss function\",\"topicId\":\"3650\",\"url\":\"https://www.semanticscholar.org/topic/3650\"},{\"topic\":\"Rendering (computer graphics)\",\"topicId\":\"15667\",\"url\":\"https://www.semanticscholar.org/topic/15667\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/bcad284af2a484d508a695dc534b0363812b1993\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"