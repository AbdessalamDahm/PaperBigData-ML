"{\"abstract\":\"Recently, data-driven deep saliency models have achieved high performance and have outperformed classical saliency models, as demonstrated by results on datasets such as the MIT300 and SALICON. Yet, there remains a large gap between the performance of these models and the inter-human baseline. Some outstanding questions include what have these models learned, how and where they fail, and how they can be improved. This article attempts to answer these questions by analyzing the representations learned by individual neurons located at the intermediate layers of deep saliency models. To this end, we follow the steps of existing deep saliency models, that is borrowing a pre-trained model of object recognition to encode the visual features and learning a decoder to infer the saliency. We consider two cases when the encoder is used as a fixed feature extractor and when it is fine-tuned, and compare the inner representations of the network. To study how the learned representations depend on the task, we fine-tune the same network using the same image set but for two different tasks: saliency prediction versus scene classification. Our analyses reveal that: 1) some visual regions (e.g. head, text, symbol, vehicle) are already encoded within various layers of the network pre-trained for object recognition, 2) using modern datasets, we find that fine-tuning pre-trained models for saliency prediction makes them favor some categories (e.g. head) over some others (e.g. text), 3) although deep models of saliency outperform classical models on natural images, the converse is true for synthetic stimuli (e.g. pop-out search arrays), an evidence of significant difference between human and data-driven saliency models, and 4) we confirm that, after-fine tuning, the change in inner-representations is mostly due to the task and not the domain shift in the data\",\"arxivId\":\"1903.02501\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\",\"url\":\"https://www.semanticscholar.org/author/47287647\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\",\"url\":\"https://www.semanticscholar.org/author/2319672\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\",\"url\":\"https://www.semanticscholar.org/author/3177797\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\",\"url\":\"https://www.semanticscholar.org/author/145071344\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\",\"url\":\"https://www.semanticscholar.org/author/3251678\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"72322372\",\"name\":\"Yucang Liang\"},{\"authorId\":\"48830922\",\"name\":\"S. Li\"},{\"authorId\":\"24794859\",\"name\":\"Chungang Yan\"},{\"authorId\":\"1716059\",\"name\":\"M. Li\"},{\"authorId\":\"119577279\",\"name\":\"Changjun Jiang\"}],\"doi\":\"10.1016/j.neucom.2020.08.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d55705658df55e13709518a1e65247224349ffb9\",\"title\":\"Explaining the black-box model: A survey of local interpretation methods for deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d55705658df55e13709518a1e65247224349ffb9\",\"venue\":\"Neurocomputing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387992157\",\"name\":\"Memoona Tahira\"},{\"authorId\":\"1387992189\",\"name\":\"Sobas Mehboob\"},{\"authorId\":\"31321802\",\"name\":\"Anis Ur Rahman\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf6570f81e505d049dd28fd3e12e15121db5af0e\",\"title\":\"CrowdFix: An Eyetracking Data-set of Human Crowd Video\",\"url\":\"https://www.semanticscholar.org/paper/cf6570f81e505d049dd28fd3e12e15121db5af0e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67321830\",\"name\":\"Weijie Wei\"},{\"authorId\":\"3211706\",\"name\":\"Zhusong Liu\"},{\"authorId\":\"47033364\",\"name\":\"Lijin Huang\"},{\"authorId\":\"1395583740\",\"name\":\"Alexis Nebout\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"153913573\",\"name\":\"T. Zhang\"},{\"authorId\":\"7897836\",\"name\":\"J. Wang\"},{\"authorId\":\"119556705\",\"name\":\"Li-hua Xu\"}],\"doi\":\"10.1016/j.neucom.2020.06.125\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce2cf6e39d5c03d7d224eda614ad803a1347d145\",\"title\":\"Predicting atypical visual saliency for autism spectrum disorder via scale-adaptive inception module and discriminative region enhancement loss\",\"url\":\"https://www.semanticscholar.org/paper/ce2cf6e39d5c03d7d224eda614ad803a1347d145\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.15942\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"1720831208\",\"name\":\"Bo Liu\"},{\"authorId\":\"1778450\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0af86c8fe633e71aeb38561165609bc14d699290\",\"title\":\"Human versus Machine Attention in Deep Reinforcement Learning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0af86c8fe633e71aeb38561165609bc14d699290\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.02618\",\"authors\":[{\"authorId\":\"1387992157\",\"name\":\"Memoona Tahira\"},{\"authorId\":\"1387992189\",\"name\":\"Sobas Mehboob\"},{\"authorId\":\"31321802\",\"name\":\"A. U. Rahman\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/ACCESS.2019.2956840\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b141eabff673e534644f68929d4efcad2c34c74\",\"title\":\"CrowdFix: An Eyetracking Dataset of Real Life Crowd Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b141eabff673e534644f68929d4efcad2c34c74\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICCV.2019.00862\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"title\":\"Human Attention in Image Captioning: Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21120270\",\"name\":\"Olivier Le Meur\"},{\"authorId\":\"1993250191\",\"name\":\"Tugdual Le Pen\"},{\"authorId\":\"1993250955\",\"name\":\"R\\u00e9mi Cozot\"}],\"doi\":\"10.1371/journal.pone.0239980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52ab2027e9e9939f5fbad8652b8c017821a4c545\",\"title\":\"Can we accurately predict where we look at paintings?\",\"url\":\"https://www.semanticscholar.org/paper/52ab2027e9e9939f5fbad8652b8c017821a4c545\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134310797\",\"name\":\"Luis A. Leiva\"},{\"authorId\":\"46364507\",\"name\":\"Y. Xue\"},{\"authorId\":\"1977519209\",\"name\":\"Avya Bansal\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1977535062\",\"name\":\"Tu\\u00f0\\u00e7e K\\u00f6ro\\u00f0lu\"},{\"authorId\":\"1977523763\",\"name\":\"Jingzhou Du\"},{\"authorId\":\"3229795\",\"name\":\"N. Dayama\"},{\"authorId\":\"2663734\",\"name\":\"Antti Oulasvirta\"}],\"doi\":\"10.1145/3379503.3403557\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a74c3af655784448f353620b86a2cf69e937ed8\",\"title\":\"Understanding Visual Saliency in Mobile User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/7a74c3af655784448f353620b86a2cf69e937ed8\",\"venue\":\"MobileHCI\",\"year\":2020},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":70349976,\"doi\":\"10.1109/CVPR.2019.01045\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"38410376deedfdfc32e53b7369b9ea2297fa521f\",\"references\":[{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/ICCV.2017.513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"title\":\"Understanding Low- and High-Level Contributions to Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Boix\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"S . Hochreiter and J . Schmidhuber . Long short - term memory\",\"url\":\"\",\"venue\":\"Neural computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1748811\",\"name\":\"Christopher G. Healey\"},{\"authorId\":\"1687080\",\"name\":\"J. Enns\"}],\"doi\":\"10.1109/TVCG.2011.127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc2d776a124cb78281ff00d24773bd3153eebfde\",\"title\":\"Attention and Visual Memory in Visualization and Computer Graphics\",\"url\":\"https://www.semanticscholar.org/paper/fc2d776a124cb78281ff00d24773bd3153eebfde\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2012},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1506.06579\",\"authors\":[{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"},{\"authorId\":\"151414531\",\"name\":\"Anh M Nguyen\"},{\"authorId\":\"34459632\",\"name\":\"Thomas J. Fuchs\"},{\"authorId\":\"1747909\",\"name\":\"Hod Lipson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b5a24639fa80056d1a17b15f6997d10e76cc731\",\"title\":\"Understanding Neural Networks Through Deep Visualization\",\"url\":\"https://www.semanticscholar.org/paper/1b5a24639fa80056d1a17b15f6997d10e76cc731\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1704.05796\",\"authors\":[{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.354\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"744464cd6fa8341633cd3b5d378faab18a3b543a\",\"title\":\"Network Dissection: Quantifying Interpretability of Deep Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/744464cd6fa8341633cd3b5d378faab18a3b543a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Laurent Itti\"},{\"authorId\":null,\"name\":\"Christof Koch\"},{\"authorId\":null,\"name\":\"Ernst Niebur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"icon : Reducing the semantic gap in saliency prediction by adapting deep neural networks\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE International Conference on Computer Vision\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.07122\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"title\":\"Multi-Scale Context Aggregation by Dilated Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1610.01708\",\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2817047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"title\":\"A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Harel\"},{\"authorId\":null,\"name\":\"Christof Koch\"},{\"authorId\":null,\"name\":\"Pietro Perona\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graphbased visual saliency\",\"url\":\"\",\"venue\":\"In Advances in neural information processing systems,\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Jiang\"},{\"authorId\":null,\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"M. S. Kankanhalli\"},{\"authorId\":null,\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Going deeper with convolutions Deep visual attention prediction\",\"url\":\"\",\"venue\":\"IEEE Trans . Image Process\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcella Cornia\"},{\"authorId\":null,\"name\":\"Lorenzo Baraldi\"},{\"authorId\":null,\"name\":\"Giuseppe Serra\"},{\"authorId\":null,\"name\":\"Rita Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Predicting Human Eye Fixations via an LSTMbased Saliency\",\"url\":\"\",\"venue\":\"Attentive Model. IEEE Transactions on Image Processing,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1705.02544\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"title\":\"Deep Visual Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David Bau\"},{\"authorId\":null,\"name\":\"Bolei Zhou\"},{\"authorId\":null,\"name\":\"Aditya Khosla\"},{\"authorId\":null,\"name\":\"Aude Oliva\"},{\"authorId\":null,\"name\":\"Antonio Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Network dissection: Quantifying inter- 10213  pretability of deep visual representations\",\"url\":\"\",\"venue\":\"In Computer Vision and Pattern Recognition,\",\"year\":2017},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"123371831\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2017.2723009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f986968735459e789890f24b6b277b0920a9725d\",\"title\":\"Places: A 10 Million Image Database for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f986968735459e789890f24b6b277b0920a9725d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David Bau\"},{\"authorId\":null,\"name\":\"Bolei Zhou\"},{\"authorId\":null,\"name\":\"Aditya Khosla\"},{\"authorId\":null,\"name\":\"Aude Oliva\"},{\"authorId\":null,\"name\":\"Antonio Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Network dissection: Quantifying inter- 10205 pretability of deep visual representations\",\"url\":\"\",\"venue\":\"In Computer Vision and Pattern Recognition,\",\"year\":2017},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006}],\"title\":\"Understanding and Visualizing Deep Visual Saliency Models\",\"topics\":[{\"topic\":\"Outline of object recognition\",\"topicId\":\"34569\",\"url\":\"https://www.semanticscholar.org/topic/34569\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Randomness extractor\",\"topicId\":\"653542\",\"url\":\"https://www.semanticscholar.org/topic/653542\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"Synthetic data\",\"topicId\":\"16840\",\"url\":\"https://www.semanticscholar.org/topic/16840\"}],\"url\":\"https://www.semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"