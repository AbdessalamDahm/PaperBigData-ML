"{\"abstract\":\"Video inpainting aims to fill spatio-temporal holes with plausible content in a video. Despite tremendous progress of deep neural networks for image inpainting, it is challenging to extend these methods to the video domain due to the additional time dimension. In this work, we propose a novel deep network architecture for fast video inpainting. Built upon an image-based encoder-decoder model, our framework is designed to collect and refine information from neighbor frames and synthesize still-unknown regions. At the same time, the output is enforced to be temporally consistent by a recurrent feedback and a temporal memory module. Compared with the state-of-the-art image inpainting algorithm, our method produces videos that are much more semantically correct and temporally smooth. In contrast to the prior video completion method which relies on time-consuming optimization, our method runs in near real-time while generating competitive video results. Finally, we applied our framework to video retargeting task, and obtain visually pleasing results.\",\"arxivId\":\"1905.01639\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\",\"url\":\"https://www.semanticscholar.org/author/24028009\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\",\"url\":\"https://www.semanticscholar.org/author/2262209\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\",\"url\":\"https://www.semanticscholar.org/author/1926578\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\",\"url\":\"https://www.semanticscholar.org/author/98758720\"}],\"citationVelocity\":15,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1844606652\",\"name\":\"Ryo Shimamura\"},{\"authorId\":\"145515373\",\"name\":\"Qi Feng\"},{\"authorId\":\"34789394\",\"name\":\"Y. Koyama\"},{\"authorId\":\"1844432504\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"1844564460\",\"name\":\"Satoru Fukayama\"},{\"authorId\":\"1783855\",\"name\":\"M. Hamasaki\"},{\"authorId\":\"1720652\",\"name\":\"Masataka Goto\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":\"10.1007/s00371-020-01918-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"015834dcf31d4d6156cf67bd4f947feaac58584a\",\"title\":\"Audio\\u2013visual object removal in 360-degree videos\",\"url\":\"https://www.semanticscholar.org/paper/015834dcf31d4d6156cf67bd4f947feaac58584a\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1909.07957\",\"authors\":[{\"authorId\":\"49724177\",\"name\":\"Hao-Tian Zhang\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"1680236\",\"name\":\"J. Collomosse\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.1109/ICCV.2019.00281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"title\":\"An Internal Learning Approach to Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"153362999\",\"name\":\"Y. Jung\"},{\"authorId\":\"2771818\",\"name\":\"Fran\\u00e7ois Rameau\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"153116390\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1145/3343031.3350895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"844c7955f70beee9b4ccf08d27f41cd873d2116d\",\"title\":\"Video Retargeting: Trade-off between Content Preservation and Spatio-temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/844c7955f70beee9b4ccf08d27f41cd873d2116d\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2002.04433\",\"authors\":[{\"authorId\":\"40326718\",\"name\":\"Hossein Javidnia\"},{\"authorId\":\"1491819441\",\"name\":\"Franccois Piti'e\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ae806b54bf2e9872607ddbd03727f613ded7c588\",\"title\":\"Background Matting\",\"url\":\"https://www.semanticscholar.org/paper/ae806b54bf2e9872607ddbd03727f613ded7c588\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.06476\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"145017741\",\"name\":\"Po-Yu Wu\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc067fbc52333475b1b320de158b9fb219b916fb\",\"title\":\"Deep Long Audio Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/cc067fbc52333475b1b320de158b9fb219b916fb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.01835\",\"authors\":[{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"1873347743\",\"name\":\"Ayush Saraf\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"},{\"authorId\":\"2891193\",\"name\":\"Johannes Kopf\"}],\"doi\":\"10.1007/978-3-030-58610-2_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fed1bccd50dd8df173a1c53e50967eae3668b623\",\"title\":\"Flow-edge Guided Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/fed1bccd50dd8df173a1c53e50967eae3668b623\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.03712\",\"authors\":[{\"authorId\":\"40588607\",\"name\":\"Indra Deep Mastan\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ddd6b363bfece7a508c3751a0f012592bd04bdb\",\"title\":\"DeepCFL: Deep Contextual Features Learning from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/6ddd6b363bfece7a508c3751a0f012592bd04bdb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.12588\",\"authors\":[{\"authorId\":\"24282778\",\"name\":\"R. Zhang\"},{\"authorId\":\"39848690\",\"name\":\"Wei Li\"},{\"authorId\":\"49161455\",\"name\":\"P. Wang\"},{\"authorId\":\"51226237\",\"name\":\"Chenye Guan\"},{\"authorId\":\"145791861\",\"name\":\"J. Fang\"},{\"authorId\":null,\"name\":\"Yuhang Song\"},{\"authorId\":\"34331831\",\"name\":\"J. Yu\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"152261442\",\"name\":\"Wei-wei Xu\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6982\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a736563e276d74f425222d7bcf7d3641c5cf999b\",\"title\":\"AutoRemover: Automatic Object Removal for Autonomous Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/a736563e276d74f425222d7bcf7d3641c5cf999b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2023709844\",\"name\":\"Paula Arguello\"},{\"authorId\":\"2543467\",\"name\":\"David Morales\"},{\"authorId\":\"52132924\",\"name\":\"Y. Fonseca\"},{\"authorId\":\"50575545\",\"name\":\"Henry Arguello\"}],\"doi\":\"10.1109/ColCACI50549.2020.9247929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"923ced9cffa6e85a62793f4a8e3a7b7eb9ace04f\",\"title\":\"Video-Tensor Completion using a Deep Learning approach\",\"url\":\"https://www.semanticscholar.org/paper/923ced9cffa6e85a62793f4a8e3a7b7eb9ace04f\",\"venue\":\"2020 IEEE Colombian Conference on Applications of Computational Intelligence (IEEE ColCACI 2020)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40146519\",\"name\":\"Day-Fann Shen\"},{\"authorId\":\"1563901977\",\"name\":\"Jian-Jhih Guo\"},{\"authorId\":\"2870365\",\"name\":\"Guo-Shiang Lin\"},{\"authorId\":\"102549560\",\"name\":\"Jen-Yung Lin\"}],\"doi\":\"10.1016/j.cmpb.2020.105414\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f68a262eb8131c4f9cc7d97bcaed71766036b68\",\"title\":\"Content-aware specular reflection suppression based on adaptive image inpainting and neural network for endoscopic images\",\"url\":\"https://www.semanticscholar.org/paper/8f68a262eb8131c4f9cc7d97bcaed71766036b68\",\"venue\":\"Comput. Methods Programs Biomed.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482675\",\"name\":\"Z. \\u00c1. Milacski\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"32414762\",\"name\":\"A. L\\u00f6rincz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42d7856dc20be6b0b6584ec6ee09d558025150bb\",\"title\":\"VideoOneNet: Bidirectional Convolutional Recurrent OneNet with Trainable Data Steps for Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/42d7856dc20be6b0b6584ec6ee09d558025150bb\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1806.03589\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2019.00457\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a997f1ecd85e1467d11252741d188fac8db22722\",\"title\":\"Free-Form Image Inpainting With Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/a997f1ecd85e1467d11252741d188fac8db22722\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.11587\",\"authors\":[{\"authorId\":\"48601846\",\"name\":\"S. Lee\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"152156220\",\"name\":\"DaeYeun Won\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/ICCV.2019.00451\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9722b480623aecfc31369908faafcfdf2dc424b5\",\"title\":\"Copy-and-Paste Networks for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/9722b480623aecfc31369908faafcfdf2dc424b5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116235388\",\"name\":\"Hyesook Son\"},{\"authorId\":\"144844038\",\"name\":\"Yun Jang\"}],\"doi\":\"10.1109/ACCESS.2020.3022774\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"204e97ff6f82837d70666d24d54de04426c9e69b\",\"title\":\"Partial Convolutional LSTM for Spatiotemporal Prediction of Incomplete Data\",\"url\":\"https://www.semanticscholar.org/paper/204e97ff6f82837d70666d24d54de04426c9e69b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.10247\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":\"10.1109/ICCV.2019.00916\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"title\":\"Free-Form Video Inpainting With 3D Gated Convolution and Temporal PatchGAN\",\"url\":\"https://www.semanticscholar.org/paper/e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.08718\",\"authors\":[{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"48601846\",\"name\":\"S. Lee\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/ICCV.2019.00450\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f9a9906dd2214c6c67205955ab61a93f30b38014\",\"title\":\"Onion-Peel Networks for Deep Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/f9a9906dd2214c6c67205955ab61a93f30b38014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.00346\",\"authors\":[{\"authorId\":\"50096784\",\"name\":\"Ce Wang\"},{\"authorId\":\"145668226\",\"name\":\"S. Zhou\"},{\"authorId\":\"46504246\",\"name\":\"Zhi-wei Cheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"847748ff022accaa73323cf34593fcae8c9f42af\",\"title\":\"First image then video: A two-stage network for spatiotemporal video denoising\",\"url\":\"https://www.semanticscholar.org/paper/847748ff022accaa73323cf34593fcae8c9f42af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05721\",\"authors\":[{\"authorId\":\"100895685\",\"name\":\"Ang Li\"},{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"50175298\",\"name\":\"M. Gong\"},{\"authorId\":\"145663352\",\"name\":\"Jianzhong Qi\"},{\"authorId\":\"143758471\",\"name\":\"Rui Zhang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"50278164\",\"name\":\"R. Kotagiri\"}],\"doi\":\"10.1007/978-3-030-58548-8_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e198f21b3d052a809d3198ace4de78be32ee843c\",\"title\":\"Short-Term and Long-Term Context Aggregation Network for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/e198f21b3d052a809d3198ace4de78be32ee843c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15327\",\"authors\":[{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"122024152\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"title\":\"Compositional Video Synthesis with Action Graphs\",\"url\":\"https://www.semanticscholar.org/paper/cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13066\",\"authors\":[{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"title\":\"Align-and-Attend Network for Globally and Locally Coherent Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/794a1f2939e886a6c1ef7ef600ac43bc5414a416\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.11838\",\"authors\":[{\"authorId\":\"2121274\",\"name\":\"Chenyang Lei\"},{\"authorId\":\"152136086\",\"name\":\"Yazhou Xing\"},{\"authorId\":\"1559427865\",\"name\":\"Qifeng Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6716353f880fd7cb2be30d82c3f1dcd3abaebd98\",\"title\":\"Blind Video Temporal Consistency via Deep Video Prior\",\"url\":\"https://www.semanticscholar.org/paper/6716353f880fd7cb2be30d82c3f1dcd3abaebd98\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1908.07683\",\"authors\":[{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3343031.3350864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"title\":\"Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation\",\"url\":\"https://www.semanticscholar.org/paper/e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2002.11433\",\"authors\":[{\"authorId\":\"49421615\",\"name\":\"Yifan Liu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"3712271\",\"name\":\"Changqian Yu\"},{\"authorId\":\"46583677\",\"name\":\"J. Wang\"}],\"doi\":\"10.1007/978-3-030-58607-2_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"936e50633074705f85a2d11fbfb68fe87cb202ad\",\"title\":\"Efficient Semantic Video Segmentation with Per-frame Inference\",\"url\":\"https://www.semanticscholar.org/paper/936e50633074705f85a2d11fbfb68fe87cb202ad\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10247\",\"authors\":[{\"authorId\":\"5764695\",\"name\":\"Y. Zeng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1007/978-3-030-58517-4_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7f89feee68b6856c0a980a5888b42d18231be07\",\"title\":\"Learning Joint Spatial-Temporal Transformations for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/f7f89feee68b6856c0a980a5888b42d18231be07\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-58583-9_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4ae2e88c470975209769abe12c895dcf0b534d5\",\"title\":\"Proposal-Based Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/e4ae2e88c470975209769abe12c895dcf0b534d5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04950\",\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"1382637019\",\"name\":\"Mostafa El-Khamy\"},{\"authorId\":\"35462690\",\"name\":\"Jungwon Lee\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d52448d649ce5d35189abdeecdc62db647b4246\",\"title\":\"HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0d52448d649ce5d35189abdeecdc62db647b4246\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.12391\",\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"2073462\",\"name\":\"D. Bull\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3670d55a696dea9234660149b490e22fb5c2a3a5\",\"title\":\"Artificial Intelligence in the Creative Industries: A Review\",\"url\":\"https://www.semanticscholar.org/paper/3670d55a696dea9234660149b490e22fb5c2a3a5\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":146121459,\"doi\":\"10.1109/CVPR.2019.00594\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"references\":[{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30991253\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"8004695\",\"name\":\"V. Caselles\"},{\"authorId\":\"34688079\",\"name\":\"C. Ballester\"}],\"doi\":\"10.1145/344779.344972\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"title\":\"Image inpainting\",\"url\":\"https://www.semanticscholar.org/paper/4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"venue\":\"SIGGRAPH '00\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Yu\"},{\"authorId\":null,\"name\":\"Z. Lin\"},{\"authorId\":null,\"name\":\"J. Yang\"},{\"authorId\":null,\"name\":\"X. Shen\"},{\"authorId\":null,\"name\":\"X. Lu\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and T\",\"url\":\"\",\"venue\":\"S. Huang. Generative image inpainting with contextual attention\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702012\",\"name\":\"C. Ballester\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"8004695\",\"name\":\"V. Caselles\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"144959292\",\"name\":\"J. Verdera\"}],\"doi\":\"10.1109/83.935036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75bc9595744b133a86c2f2da9b207b4206b88dd4\",\"title\":\"Filling-in by joint interpolation of vector fields and gray levels\",\"url\":\"https://www.semanticscholar.org/paper/75bc9595744b133a86c2f2da9b207b4206b88dd4\",\"venue\":\"IEEE Trans. Image Process.\",\"year\":2001},{\"arxivId\":\"1607.07539\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1696291\",\"name\":\"Chen Chen\"},{\"authorId\":\"33494814\",\"name\":\"Teck-Yian Lim\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/CVPR.2017.728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"title\":\"Semantic Image Inpainting with Deep Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1806.03589\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2019.00457\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a997f1ecd85e1467d11252741d188fac8db22722\",\"title\":\"Free-Form Image Inpainting With Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/a997f1ecd85e1467d11252741d188fac8db22722\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2016.85\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05e9e85b5137016c93d042170e82f77bb551a108\",\"title\":\"A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/05e9e85b5137016c93d042170e82f77bb551a108\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.00675\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1413064976\",\"name\":\"S. Caelles\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"title\":\"The 2017 DAVIS Challenge on Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. A. Patwardhan\"},{\"authorId\":null,\"name\":\"G. Sapiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and M\",\"url\":\"\",\"venue\":\"Bertalm\\u0131\\u0301o. Video inpainting under constrained camera motion. IEEE Transactions on Image Processing, 16(2):545\\u2013553\",\"year\":2007},{\"arxivId\":\"1703.09211\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2017.126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d5b4144124f47a6357e6390dc6c0f8806ac54f5\",\"title\":\"Coherent Online Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/2d5b4144124f47a6357e6390dc6c0f8806ac54f5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2810911\",\"name\":\"K. Patwardhan\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"}],\"doi\":\"10.1109/ICIP.2005.1529993\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30cc16168a7a10a35b66bb98787ba9f2babcb655\",\"title\":\"Video inpainting of occluding and occluded objects\",\"url\":\"https://www.semanticscholar.org/paper/30cc16168a7a10a35b66bb98787ba9f2babcb655\",\"venue\":\"IEEE International Conference on Image Processing 2005\",\"year\":2005},{\"arxivId\":\"1611.09969\",\"authors\":[{\"authorId\":\"143702938\",\"name\":\"C. Yang\"},{\"authorId\":\"144834702\",\"name\":\"X. Lu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"2733405\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2017.434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b\",\"title\":\"High-Resolution Image Inpainting Using Multi-scale Neural Patch Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1809.00461\",\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"84426766\",\"name\":\"Dingcheng Yue\"},{\"authorId\":\"21160992\",\"name\":\"Yuchen Liang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/978-3-030-01228-1_36\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f054fdd7a36b569eae7627cf12a4d81322dea022\",\"title\":\"YouTube-VOS: Sequence-to-Sequence Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f054fdd7a36b569eae7627cf12a4d81322dea022\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1506.04214\",\"authors\":[{\"authorId\":\"3008587\",\"name\":\"Xingjian Shi\"},{\"authorId\":\"2192200\",\"name\":\"Zhourong Chen\"},{\"authorId\":\"49528584\",\"name\":\"Hao Wang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"145771919\",\"name\":\"W. Wong\"},{\"authorId\":\"2183294\",\"name\":\"Wang-chun Woo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"title\":\"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\",\"url\":\"https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1708.02731\",\"authors\":[{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"2704403\",\"name\":\"Jinsun Park\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/ICCV.2017.488\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9375b274d247589f4fff3b63531135be80ed4488\",\"title\":\"Weakly- and Self-Supervised Learning for Content-Aware Deep Image Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/9375b274d247589f4fff3b63531135be80ed4488\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2810911\",\"name\":\"K. Patwardhan\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"}],\"doi\":\"10.1109/TIP.2006.888343\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56210467fe8e222e3b1d5fb940d466bb983cf66a\",\"title\":\"Video Inpainting Under Constrained Camera Motion\",\"url\":\"https://www.semanticscholar.org/paper/56210467fe8e222e3b1d5fb940d466bb983cf66a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"38824925\",\"name\":\"A. Finkelstein\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"}],\"doi\":\"10.1145/1576246.1531330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"title\":\"PatchMatch: a randomized correspondence algorithm for structural image editing\",\"url\":\"https://www.semanticscholar.org/paper/744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382424098\",\"name\":\"\\u0422\\u0430\\u0440\\u0430\\u0441\\u0430 \\u0428\\u0435\\u0432\\u0447\\u0435\\u043d\\u043a\\u0430\"},{\"authorId\":\"1397452703\",\"name\":\"\\u0412\\u0430\\u0441\\u0438\\u043b\\u044f \\u041a\\u0430\\u0440\\u0430\\u0437\\u0456\\u043d\\u0430\"},{\"authorId\":\"1397452698\",\"name\":\"\\u041e\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u0430 \\u0411\\u043e\\u0433\\u043e\\u043c\\u043e\\u043b\\u044c\\u0446\\u044f\"}],\"doi\":\"10.1093/clinchem/60.1.283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"title\":\"Quo vadis?\",\"url\":\"https://www.semanticscholar.org/paper/dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"venue\":\"Clinical chemistry\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. A. Efros\"},{\"authorId\":null,\"name\":\"T. K. Leung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Texture synthesis by nonparametric sampling\",\"url\":\"\",\"venue\":\"iccv, page 1033. IEEE\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"},{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"}],\"doi\":\"10.1145/2980179.2982398\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"title\":\"Temporally coherent completion of dynamic video\",\"url\":\"https://www.semanticscholar.org/paper/cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"},{\"authorId\":\"20592981\",\"name\":\"E. Ofek\"},{\"authorId\":\"7838848\",\"name\":\"Weina Ge\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"}],\"doi\":\"10.1109/TPAMI.2006.141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46d031105223d2c0a8ad99e7fc0e6210e1e22596\",\"title\":\"Full-frame video stabilization with motion inpainting\",\"url\":\"https://www.semanticscholar.org/paper/46d031105223d2c0a8ad99e7fc0e6210e1e22596\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2006},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5823721\",\"name\":\"H. Sienkiewicz\"}],\"doi\":\"10.1007/BF02663715\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8defab03d769e552c4f7397bdd3adbc920122aa\",\"title\":\"Quo Vadis?\",\"url\":\"https://www.semanticscholar.org/paper/e8defab03d769e552c4f7397bdd3adbc920122aa\",\"venue\":\"American Association of Industrial Nurses journal\",\"year\":1967},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145603921\",\"name\":\"Miguel Granados\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"1763640\",\"name\":\"O. Grau\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/j.1467-8659.2012.03000.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b09ea83a2c84150477ca85a6a0da0920ce64ef32\",\"title\":\"How Not to Be Seen \\u2014 Object Removal from Videos of Crowded Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b09ea83a2c84150477ca85a6a0da0920ce64ef32\",\"venue\":\"Comput. Graph. Forum\",\"year\":2012},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1801.07892\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00577\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"title\":\"Generative Image Inpainting with Contextual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.02371\",\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00931\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"title\":\"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume\",\"url\":\"https://www.semanticscholar.org/paper/d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.07723\",\"authors\":[{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01252-6_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a417a16473e2bcb1c98cd7814bc106760925e60\",\"title\":\"Image Inpainting for Irregular Holes Using Partial Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/2a417a16473e2bcb1c98cd7814bc106760925e60\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40505733\",\"name\":\"Takaaki Shiratori\"},{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":\"10.1109/CVPR.2006.330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"120ae23e82225a114111770e10f382d1bc8e0e86\",\"title\":\"Video Completion by Motion Field Transfer\",\"url\":\"https://www.semanticscholar.org/paper/120ae23e82225a114111770e10f382d1bc8e0e86\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":\"1808.00449\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01267-0_11\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"title\":\"Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743988\",\"name\":\"Yonatan Wexler\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611618\",\"name\":\"M. Irani\"}],\"doi\":\"10.1109/CVPR.2004.1315022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec1e2e0165473dbb8ec52a8eba009968ea915b8d\",\"title\":\"Space-time video completion\",\"url\":\"https://www.semanticscholar.org/paper/ec1e2e0165473dbb8ec52a8eba009968ea915b8d\",\"venue\":\"CVPR 2004\",\"year\":2004},{\"arxivId\":\"1503.05528\",\"authors\":[{\"authorId\":\"1902919\",\"name\":\"A. Newson\"},{\"authorId\":\"1713633\",\"name\":\"Andr\\u00e9s Almansa\"},{\"authorId\":\"3284350\",\"name\":\"M. Fradet\"},{\"authorId\":\"1796594\",\"name\":\"Y. Gousseau\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1137/140954933\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a57afd150ab309f868c9030cddfc0fd896f67308\",\"title\":\"Video Inpainting of Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/a57afd150ab309f868c9030cddfc0fd896f67308\",\"venue\":\"SIAM J. Imaging Sci.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39990338\",\"name\":\"S. Iizuka\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/3072959.3073659\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d21ebaab3f715dc7178966ff146711882e6a6fee\",\"title\":\"Globally and locally consistent image completion\",\"url\":\"https://www.semanticscholar.org/paper/d21ebaab3f715dc7178966ff146711882e6a6fee\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145603921\",\"name\":\"Miguel Granados\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1007/978-3-642-33718-5_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c98babf5607e8eaa77e7f78120302a93e7a34454\",\"title\":\"Background Inpainting for Videos with Dynamic Objects and a Free-Moving Camera\",\"url\":\"https://www.semanticscholar.org/paper/c98babf5607e8eaa77e7f78120302a93e7a34454\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1621190045\",\"name\":\"Yu-Qin Cao\"},{\"authorId\":\"1617945342\",\"name\":\"Lei Yuan\"},{\"authorId\":\"1618266074\",\"name\":\"Qin Zhao\"},{\"authorId\":\"1617846354\",\"name\":\"Jian-Lin Yuan\"},{\"authorId\":\"1618093177\",\"name\":\"Yung-Fu Chang\"},{\"authorId\":\"1618081648\",\"name\":\"Xin-Tian Wen\"},{\"authorId\":\"1618259371\",\"name\":\"Rui Wu\"},{\"authorId\":\"1617850008\",\"name\":\"Xiao-Bo Huang\"},{\"authorId\":\"1617935592\",\"name\":\"Xin-Feng Han\"},{\"authorId\":\"1618215030\",\"name\":\"Xiao-Ping Ma\"},{\"authorId\":\"1618230784\",\"name\":\"San-Jie Cao\"}],\"doi\":\"10.1515/9783111419787-003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1f2981c3146fbd9300bd8fbfd0401ba65f8ce5a\",\"title\":\"H\",\"url\":\"https://www.semanticscholar.org/paper/f1f2981c3146fbd9300bd8fbfd0401ba65f8ce5a\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824}],\"title\":\"Deep Video Inpainting\",\"topics\":[{\"topic\":\"Inpainting\",\"topicId\":\"146260\",\"url\":\"https://www.semanticscholar.org/topic/146260\"},{\"topic\":\"Temporal logic\",\"topicId\":\"480\",\"url\":\"https://www.semanticscholar.org/topic/480\"},{\"topic\":\"Digital video\",\"topicId\":\"44670\",\"url\":\"https://www.semanticscholar.org/topic/44670\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Memory module\",\"topicId\":\"182030\",\"url\":\"https://www.semanticscholar.org/topic/182030\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Retargeting\",\"topicId\":\"112399\",\"url\":\"https://www.semanticscholar.org/topic/112399\"},{\"topic\":\"Real-time computing\",\"topicId\":\"172684\",\"url\":\"https://www.semanticscholar.org/topic/172684\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Decoder Device Component\",\"topicId\":\"197115\",\"url\":\"https://www.semanticscholar.org/topic/197115\"},{\"topic\":\"Encoder Device Component\",\"topicId\":\"55437\",\"url\":\"https://www.semanticscholar.org/topic/55437\"},{\"topic\":\"Real-time clock\",\"topicId\":\"121831\",\"url\":\"https://www.semanticscholar.org/topic/121831\"},{\"topic\":\"Neural Network Simulation\",\"topicId\":\"6986\",\"url\":\"https://www.semanticscholar.org/topic/6986\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Frame (physical object)\",\"topicId\":\"4537\",\"url\":\"https://www.semanticscholar.org/topic/4537\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"videocassette\",\"topicId\":\"20721\",\"url\":\"https://www.semanticscholar.org/topic/20721\"}],\"url\":\"https://www.semanticscholar.org/paper/5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"