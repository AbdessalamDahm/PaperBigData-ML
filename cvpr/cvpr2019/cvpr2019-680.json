"{\"abstract\":\"Learning effective fusion of multi-modality features is at the heart of visual question answering. We propose a novel method of dynamically fuse multi-modal features with intra- and inter-modality information flow, which alternatively pass dynamic information between and across the visual and language modalities. It can robustly capture the high-level interactions between language and vision domains, thus significantly improves the performance of visual question answering. We also show that, the proposed dynamic intra modality attention flow conditioned on the other modality can dynamically modulate the intra-modality attention of the current modality, which is vital for multimodality feature fusion. Experimental evaluations on the VQA 2.0 dataset show that the proposed method achieves the state-of-the-art VQA performance. Extensive ablation studies are carried out for the comprehensive analysis of the proposed method.\",\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\",\"url\":\"https://www.semanticscholar.org/author/144579865\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\",\"url\":\"https://www.semanticscholar.org/author/47893312\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\",\"url\":\"https://www.semanticscholar.org/author/30156979\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\",\"url\":\"https://www.semanticscholar.org/author/50676465\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\",\"url\":\"https://www.semanticscholar.org/author/2887562\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\",\"url\":\"https://www.semanticscholar.org/author/49212307\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\",\"url\":\"https://www.semanticscholar.org/author/48631549\"}],\"citationVelocity\":40,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"title\":\"Bilinear Graph Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.03063\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":\"10.3233/FAIA200412\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3e9336a1be4fc269a987656aab16d2791515917f\",\"title\":\"Weak Supervision helps Emergence of Word-Object Alignment and improves Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/3e9336a1be4fc269a987656aab16d2791515917f\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2007.02036\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"48920375\",\"name\":\"T. Pham\"},{\"authorId\":\"97531942\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/cvpr42600.2020.01012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"title\":\"Modality Shifting Attention Network for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.05253\",\"authors\":[{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"2337079\",\"name\":\"Jihao Liu\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"47332302\",\"name\":\"Qian Zhang\"},{\"authorId\":\"47363390\",\"name\":\"Shiming Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1007/978-3-030-58517-4_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"190af79b11123ece9f7853813cc8eb47743290cd\",\"title\":\"Learning Where to Focus for Efficient Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/190af79b11123ece9f7853813cc8eb47743290cd\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144638992\",\"name\":\"Xinzhe Han\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153645460\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58545-7_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"title\":\"Interpretable Visual Reasoning via Probabilistic Formulation Under Natural Supervision\",\"url\":\"https://www.semanticscholar.org/paper/2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.07000\",\"authors\":[{\"authorId\":\"145144396\",\"name\":\"Dandan Song\"},{\"authorId\":\"4274864\",\"name\":\"Siyi Ma\"},{\"authorId\":\"2037300711\",\"name\":\"Zhanchen Sun\"},{\"authorId\":\"3389167\",\"name\":\"S. Yang\"},{\"authorId\":\"31364087\",\"name\":\"Lejian Liao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"title\":\"KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"title\":\"Efficient Attention Mechanism for Handling All the Interactions between Many Inputs with Application to Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118023258\",\"name\":\"X. Wei\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"2694924\",\"name\":\"Y. Li\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"1684705122\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/CVPR42600.2020.01095\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"caabcf61499e00c78d8ee692b8939caf98544a9c\",\"title\":\"Multi-Modality Cross Attention Network for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/caabcf61499e00c78d8ee692b8939caf98544a9c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2009.11382\",\"authors\":[{\"authorId\":\"1596814397\",\"name\":\"Peng Gao\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01c4cbf23457b8c650d3487096a90f695b9177cf\",\"title\":\"Multi-Pass Transformer for Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/01c4cbf23457b8c650d3487096a90f695b9177cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32791167\",\"name\":\"Chenchen Jing\"},{\"authorId\":\"150352923\",\"name\":\"Yuwei Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6776\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"title\":\"Overcoming Language Priors in VQA via Decomposed Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48079662\",\"name\":\"Sungho Park\"},{\"authorId\":\"145864562\",\"name\":\"Sunhee Hwang\"},{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1109/ACCESS.2020.3041503\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"title\":\"Fair-VQA: Fairness-Aware Visual Question Answering Through Sensitive Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49352657\",\"name\":\"Long-Fei Xie\"},{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"}],\"doi\":\"10.1007/978-3-030-59830-3_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6fa32942c85a7283abd1c8fbd4bae11f73853cf\",\"title\":\"Gate-Fusion Transformer for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e6fa32942c85a7283abd1c8fbd4bae11f73853cf\",\"venue\":\"ICPRAI\",\"year\":2020},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.13073\",\"authors\":[{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e8d117d098ac59d90bf7814d889e814b52637f22\",\"title\":\"A Novel Attention-based Aggregation Function to Combine Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/e8d117d098ac59d90bf7814d889e814b52637f22\",\"venue\":\"ICPR 2020\",\"year\":2020},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2002.12204\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":\"10.1109/cvpr42600.2020.01077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"title\":\"Visual Commonsense R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.04289\",\"authors\":[{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2019.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"title\":\"Multi-Modality Latent Interaction Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.05840\",\"authors\":[{\"authorId\":\"36325868\",\"name\":\"L. Shi\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"51263928\",\"name\":\"Songxiang Liu\"},{\"authorId\":\"153933134\",\"name\":\"Peng Gao\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053595\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad6500f4e4548be232e8027cfa648577e8e0ca4b\",\"title\":\"Multi-Layer Content Interaction Through Quaternion Product for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad6500f4e4548be232e8027cfa648577e8e0ca4b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2006.05669\",\"authors\":[{\"authorId\":\"1490860633\",\"name\":\"Shuoyao Wang\"},{\"authorId\":\"152867073\",\"name\":\"Diwei Zhu\"}],\"doi\":\"10.24963/ijcai.2020/637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"590da60c5ee04448f4c154f56de59c6ba7ed0e8c\",\"title\":\"Interpretable Multimodal Learning for Intelligent Regulation in Online Payment Systems\",\"url\":\"https://www.semanticscholar.org/paper/590da60c5ee04448f4c154f56de59c6ba7ed0e8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700248\",\"name\":\"S. Li\"},{\"authorId\":\"88486572\",\"name\":\"S. Wang\"},{\"authorId\":\"1452344220\",\"name\":\"Jun Du\"},{\"authorId\":\"153121150\",\"name\":\"Meng Li\"}],\"doi\":\"10.1109/EITT.2019.00026\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6942d4d1b850604dc881a9520dff4a3d2b93cee6\",\"title\":\"The Characteristics of Attention Flow of MOOC Students and Their Prediction of Academic Persistence\",\"url\":\"https://www.semanticscholar.org/paper/6942d4d1b850604dc881a9520dff4a3d2b93cee6\",\"venue\":\"2019 Eighth International Conference on Educational Innovation through Technology (EITT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2347900\",\"name\":\"Huiwei Zhou\"},{\"authorId\":\"151465205\",\"name\":\"Bizun Lei\"},{\"authorId\":\"46270894\",\"name\":\"Z. Liu\"},{\"authorId\":\"46271578\",\"name\":\"Zhuang Liu\"}],\"doi\":\"10.18653/v1/W19-5047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b21eea97afe0c6a7a74c18f717c70528b9c4b7c1\",\"title\":\"DUT-BIM at MEDIQA 2019: Utilizing Transformer Network and Medical Domain-Specific Contextualized Representations for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b21eea97afe0c6a7a74c18f717c70528b9c4b7c1\",\"venue\":\"BioNLP@ACL\",\"year\":2019},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09592\",\"authors\":[{\"authorId\":\"47043894\",\"name\":\"Ruixue Tang\"},{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"32794831\",\"name\":\"W. Zhang\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1007/978-3-030-58529-7_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff560bbf5c11894379d7e808683d553e3d1f08c2\",\"title\":\"Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ff560bbf5c11894379d7e808683d553e3d1f08c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2008.10238\",\"authors\":[{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"30559382\",\"name\":\"S. Yoon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"1753686270\",\"name\":\"Young-Joon Lee\"},{\"authorId\":\"3315036\",\"name\":\"S. Kang\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1007/978-3-030-58604-1_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"425278984b2be6b5412e264c7a200b797018ae8f\",\"title\":\"VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/425278984b2be6b5412e264c7a200b797018ae8f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39105519\",\"name\":\"Matthew Ricci\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1016/j.cobeha.2020.08.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"519af509d69d15fede74f64bef8a7833d47fdd28\",\"title\":\"Same-different conceptualization: a machine vision perspective\",\"url\":\"https://www.semanticscholar.org/paper/519af509d69d15fede74f64bef8a7833d47fdd28\",\"venue\":\"Current Opinion in Behavioral Sciences\",\"year\":2021},{\"arxivId\":\"1911.11390\",\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1007/978-3-030-58586-0_14\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"468d5c15df63892ff06fb94c7b5cad0242685d02\",\"title\":\"Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs\",\"url\":\"https://www.semanticscholar.org/paper/468d5c15df63892ff06fb94c7b5cad0242685d02\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.02951\",\"authors\":[{\"authorId\":\"1935410\",\"name\":\"M. Rahnemoonfar\"},{\"authorId\":\"39734189\",\"name\":\"Tashnim J. S. Chowdhury\"},{\"authorId\":\"1381535116\",\"name\":\"Argho Sarkar\"},{\"authorId\":\"1411385478\",\"name\":\"D. Varshney\"},{\"authorId\":\"1505798397\",\"name\":\"Masoud Yari\"},{\"authorId\":\"1789429\",\"name\":\"R. Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"title\":\"FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.13077\",\"authors\":[{\"authorId\":\"143672098\",\"name\":\"Bei Liu\"},{\"authorId\":\"47272083\",\"name\":\"Zhicheng Huang\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"46842344\",\"name\":\"Z. Chen\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1e282859d38e97397920f66dd2df5ea6dd09f00\",\"title\":\"Learning Rich Image Region Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b1e282859d38e97397920f66dd2df5ea6dd09f00\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314993\",\"name\":\"Wei-ying Wang\"},{\"authorId\":\"1994473516\",\"name\":\"Jieting Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413890\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b116c8cd44a34f440f260a890e0600b61d92c262\",\"title\":\"VideoIC: A Video Interactive Comments Dataset and Multimodal Multitask Learning for Comments Generation\",\"url\":\"https://www.semanticscholar.org/paper/b116c8cd44a34f440f260a890e0600b61d92c262\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.09315\",\"authors\":[{\"authorId\":\"2026322565\",\"name\":\"Minghang Zheng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"47866340\",\"name\":\"Hao Dong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7019995948c0a2127501f24ee9632904466d7913\",\"title\":\"End-to-End Object Detection with Adaptive Clustering Transformer\",\"url\":\"https://www.semanticscholar.org/paper/7019995948c0a2127501f24ee9632904466d7913\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01725\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1859082176\",\"name\":\"Salman Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"title\":\"Attention Guided Semantic Relationship Parsing for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"48079221\",\"name\":\"Sungho Park\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1016/j.neucom.2020.03.098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e48298519b5ff583e585a65eeea3ac10556adf\",\"title\":\"Selective residual learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72e48298519b5ff583e585a65eeea3ac10556adf\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2006.03184\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"22205368\",\"name\":\"Akshay Chaturvedi\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"48421321\",\"name\":\"U. Garain\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf2f8c8686cff2643270ed2d61f12d4661cbb75a\",\"title\":\"Pick-Object-Attack: Type-Specific Adversarial Attack for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/cf2f8c8686cff2643270ed2d61f12d4661cbb75a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12917\",\"authors\":[{\"authorId\":\"3442255\",\"name\":\"Zan-Xia Jin\"},{\"authorId\":\"2003456770\",\"name\":\"Heran Wu\"},{\"authorId\":\"46962194\",\"name\":\"C. Yang\"},{\"authorId\":\"31679477\",\"name\":\"Fang Zhou\"},{\"authorId\":\"2005306\",\"name\":\"Jingyan Qin\"},{\"authorId\":\"145628818\",\"name\":\"Lei Xiao\"},{\"authorId\":\"120644708\",\"name\":\"XuCheng Yin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d209f0d94492447713541b28373d9b6cad5edeb9\",\"title\":\"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d209f0d94492447713541b28373d9b6cad5edeb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1990265392\",\"name\":\"Leigang Qu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413961\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"922d677867e1aa2a7cca05241af4746a0be04dd0\",\"title\":\"Context-Aware Multi-View Summarization Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/922d677867e1aa2a7cca05241af4746a0be04dd0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.02582\",\"authors\":[{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a65b38abc44bd6acb06ebc87e7e4765609d88a3\",\"title\":\"Finding the Evidence: Localization-aware Answer Prediction for Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a65b38abc44bd6acb06ebc87e7e4765609d88a3\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7501eb6d58b1f347140402171df7b3291496ab2\",\"title\":\"Connective Cognition Network for Directional Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a7501eb6d58b1f347140402171df7b3291496ab2\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143647292\",\"name\":\"F. Liu\"},{\"authorId\":\"49560222\",\"name\":\"Guanghui Xu\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"145229535\",\"name\":\"W. Jia\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1145/3394171.3413924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"title\":\"Cascade Reasoning Network for Text-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"27798809\",\"name\":\"F.-Y. Wang\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"}],\"doi\":\"10.1007/978-3-030-63820-7_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0b687bc54ee671296a9a33be57ac771c1f913a7\",\"title\":\"Learning from the Guidance: Knowledge Embedded Meta-learning for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0b687bc54ee671296a9a33be57ac771c1f913a7\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921879239\",\"name\":\"Shirong He\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20174897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52cae3e1df7ef76854645abf250db9282d01f27\",\"title\":\"An Effective Dense Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e52cae3e1df7ef76854645abf250db9282d01f27\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.02918\",\"authors\":[{\"authorId\":\"1864097171\",\"name\":\"Xubin Zhong\"},{\"authorId\":\"144116132\",\"name\":\"Changxing Ding\"},{\"authorId\":\"50123957\",\"name\":\"Xian Qu\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"title\":\"Polysemy Deciphering Network for Robust Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"1752876325\",\"name\":\"Yi Cai\"},{\"authorId\":\"150068355\",\"name\":\"Changmeng Zheng\"},{\"authorId\":\"47740571\",\"name\":\"J. Chen\"},{\"authorId\":\"1701688\",\"name\":\"Ho-fung Leung\"},{\"authorId\":\"145138436\",\"name\":\"Qing Li\"}],\"doi\":\"10.18653/v1/2020.acl-main.642\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ede49ec0dd27849e57152d5116770bcbe3e01874\",\"title\":\"Aligned Dual Channel Graph Convolutional Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ede49ec0dd27849e57152d5116770bcbe3e01874\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.06258\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/cvpr42600.2020.01001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"title\":\"Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.07251\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15586721\",\"name\":\"Yingying Zhuang\"},{\"authorId\":\"47958013\",\"name\":\"Xingxing Zhang\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6769\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b42cb7889053f5c89380c82604aa33fd6270894\",\"title\":\"DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0b42cb7889053f5c89380c82604aa33fd6270894\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50580169\",\"name\":\"Y. Chen\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"}],\"doi\":\"10.1109/CVPR42600.2020.00307\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78f69364531794550130389342b7bc0ff785b7e9\",\"title\":\"Image Search With Text Feedback by Visiolinguistic Attention Learning\",\"url\":\"https://www.semanticscholar.org/paper/78f69364531794550130389342b7bc0ff785b7e9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.08897\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49051904\",\"name\":\"P. Yao\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"833560cd68a3e3d1be1bc650756dd6c679798551\",\"title\":\"Normalized and Geometry-Aware Self-Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/833560cd68a3e3d1be1bc650756dd6c679798551\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.04405\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2019.01039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2dc698077cb178286c737484dcf67c5ab19314d0\",\"title\":\"Language-Conditioned Graph Networks for Relational Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2dc698077cb178286c737484dcf67c5ab19314d0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08923\",\"authors\":[{\"authorId\":\"7694093\",\"name\":\"Chenyu You\"},{\"authorId\":\"119895609\",\"name\":\"Nuo Chen\"},{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1752879605\",\"name\":\"Dongchao Yang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbd9ad40c303115757cb880a7d38ec4d9431f982\",\"title\":\"Towards Data Distillation for End-to-end Spoken Conversational Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bbd9ad40c303115757cb880a7d38ec4d9431f982\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"QUESTION ANSWERING\"},{\"authorId\":null,\"name\":\"Chenyu You\"},{\"authorId\":null,\"name\":\"Nuo Chen\"},{\"authorId\":\"1993647038\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1752879605\",\"name\":\"Dongchao Yang\"},{\"authorId\":null,\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbd9ad40c303115757cb880a7d38ec4d9431f982\",\"title\":\"Text Feature Embeddings ... Speech Feature Embeddings ... Teacher Student L CMRC Module Encoding Layer : Attention Layer : Output Layer : Cross Attention : Context :\",\"url\":\"https://www.semanticscholar.org/paper/bbd9ad40c303115757cb880a7d38ec4d9431f982\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.08001\",\"authors\":[{\"authorId\":\"2526520\",\"name\":\"Keqi Wang\"},{\"authorId\":\"1596814397\",\"name\":\"Peng Gao\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"1382516613\",\"name\":\"Qian Guo\"},{\"authorId\":\"1771193\",\"name\":\"Yuhua Qian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb3cac279c005d522b32e6235ad346265eee82cf\",\"title\":\"Extreme Low-Light Imaging with Multi-granulation Cooperative Networks\",\"url\":\"https://www.semanticscholar.org/paper/bb3cac279c005d522b32e6235ad346265eee82cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50031180\",\"name\":\"Xiaofeng Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"2753987\",\"name\":\"Fengmao Lv\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"}],\"doi\":\"10.1007/978-3-030-58589-1_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"title\":\"TRRNet: Tiered Relation Reasoning for Compositional Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.13135\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"47527626\",\"name\":\"Peng Su\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"2011378\",\"name\":\"Z. Fu\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"title\":\"Contrastive Visual-Linguistic Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.12770\",\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"1492191087\",\"name\":\"Swati Suman\"},{\"authorId\":\"152800923\",\"name\":\"A. Ekbal\"}],\"doi\":\"10.1016/J.ESWA.2020.113993\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"title\":\"Hierarchical Deep Multi-modal Network for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1912.00574\",\"authors\":[{\"authorId\":\"119937438\",\"name\":\"Zhaoyang Lyu\"},{\"authorId\":\"143763507\",\"name\":\"Ching-Yun Ko\"},{\"authorId\":\"33470361\",\"name\":\"Z. Kong\"},{\"authorId\":\"1873081\",\"name\":\"N. Wong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"144599985\",\"name\":\"L. Daniel\"}],\"doi\":\"10.1609/AAAI.V34I04.5944\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a948ff0c0eba359e141f5dcee1f8f8cfccc7f7a7\",\"title\":\"Fastened CROWN: Tightened Neural Network Robustness Certificates\",\"url\":\"https://www.semanticscholar.org/paper/a948ff0c0eba359e141f5dcee1f8f8cfccc7f7a7\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.03848\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03598364626c419d3a2578b5c22403f0dd246e99\",\"title\":\"Spatio-Temporal Scene Graphs for Video Dialog\",\"url\":\"https://www.semanticscholar.org/paper/03598364626c419d3a2578b5c22403f0dd246e99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"2746394\",\"name\":\"M. Westera\"},{\"authorId\":\"1807810\",\"name\":\"Gemma Boleda\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7155b150abf033bc3a0c24e16202777c9d41367\",\"title\":\"Humans Meet Models on Object Naming: A New Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e7155b150abf033bc3a0c24e16202777c9d41367\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1452350213\",\"name\":\"Murari Mandal\"},{\"authorId\":\"1452345632\",\"name\":\"Vansh Dhar\"},{\"authorId\":\"1753599262\",\"name\":\"Abhishek Mishra\"},{\"authorId\":\"2658342\",\"name\":\"Santosh Kumar Vipparthi\"},{\"authorId\":\"1407758842\",\"name\":\"M. Abdel-Mottaleb\"}],\"doi\":\"10.1109/TIP.2020.3037472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5192ac5066566a5b9ff2aba1484bb185ea135d25\",\"title\":\"3DCD: Scene Independent End-to-End Spatiotemporal Feature Learning Framework for Change Detection in Unseen Videos\",\"url\":\"https://www.semanticscholar.org/paper/5192ac5066566a5b9ff2aba1484bb185ea135d25\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2005.08646\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"24263694\",\"name\":\"J. Zhang\"},{\"authorId\":\"2011378\",\"name\":\"Z. Fu\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"49724425\",\"name\":\"H. Zhang\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15fe6bb38c22a1d765bf57ffd7e6654edcfa4768\",\"title\":\"Character Matters: Video Story Understanding with Character-Aware Relations\",\"url\":\"https://www.semanticscholar.org/paper/15fe6bb38c22a1d765bf57ffd7e6654edcfa4768\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02097\",\"authors\":[{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"144865339\",\"name\":\"Bo Pang\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/D19-1155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b6e6822eabe2f64192a1965c23e38043866319c\",\"title\":\"Decoupled Box Proposal and Featurization with Ultrafine-Grained Semantic Labels Improve Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3b6e6822eabe2f64192a1965c23e38043866319c\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2006.06195\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50580345\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"title\":\"Large-Scale Adversarial Training for Vision-and-Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2358244\",\"name\":\"Naotsuna Fujimori\"},{\"authorId\":\"1809999\",\"name\":\"R. Endo\"},{\"authorId\":\"48230523\",\"name\":\"Yoshihiko Kawai\"},{\"authorId\":\"48281114\",\"name\":\"T. Mochizuki\"}],\"doi\":\"10.1007/978-3-030-41299-9_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0b5627630177a11ed1aa9e42a0a76ceedaa8ba0\",\"title\":\"Modality-Specific Learning Rate Control for Multimodal Classification\",\"url\":\"https://www.semanticscholar.org/paper/d0b5627630177a11ed1aa9e42a0a76ceedaa8ba0\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112995179\",\"name\":\"L. Chen\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"50775044\",\"name\":\"Jiawei He\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCVW.2019.00177\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"347748443be69ffceb2fb345df9b41448f2974ad\",\"title\":\"Object Grounding via Iterative Context Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/347748443be69ffceb2fb345df9b41448f2974ad\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2002.11894\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"title\":\"Unshuffling Data for Improved Generalization\",\"url\":\"https://www.semanticscholar.org/paper/fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12831\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"2513111\",\"name\":\"Zhecan Wang\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16f82c1dae2f6e5149c1be95165d7081f08298b6\",\"title\":\"Weakly-supervised VisualBERT: Pre-training without Parallel Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/16f82c1dae2f6e5149c1be95165d7081f08298b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.11740\",\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1007/978-3-030-58577-8_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"title\":\"UNITER: UNiversal Image-TExt Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.11014\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a9015e511ec3da873f6114eeb542905a92d7d62\",\"title\":\"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA\",\"url\":\"https://www.semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.13262\",\"authors\":[{\"authorId\":\"39209233\",\"name\":\"Siwen Luo\"},{\"authorId\":\"2046142\",\"name\":\"S. Han\"},{\"authorId\":\"33053279\",\"name\":\"Kaiyuan Sun\"},{\"authorId\":\"48422087\",\"name\":\"Josiah Poon\"}],\"doi\":\"10.1007/978-3-030-63830-6_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"title\":\"REXUP: I REason, I EXtract, I UPdate with Structured Compositional Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2008.01180\",\"authors\":[{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"143903550\",\"name\":\"M. Timm\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1007/978-3-030-58452-8_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86f0fb3791761cdb5e9108721a536d752641d4bf\",\"title\":\"Describing Textures using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/86f0fb3791761cdb5e9108721a536d752641d4bf\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":54700454,\"doi\":\"10.1109/CVPR.2019.00680\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":13,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"references\":[{\"arxivId\":\"1901.03495\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"49968574\",\"name\":\"Jiangmiao Pang\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"2447593\",\"name\":\"Shuai Yi\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e819237bb25b1a070bcb2802de0aad73975447f\",\"title\":\"FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0e819237bb25b1a070bcb2802de0aad73975447f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1708.01988\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"47718789\",\"name\":\"Wei Yang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f222282574666658dc0408176805cbe21348477d\",\"title\":\"Identity-Aware Textual-Visual Matching with Latent Co-attention\",\"url\":\"https://www.semanticscholar.org/paper/f222282574666658dc0408176805cbe21348477d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1808.02632\",\"authors\":[{\"authorId\":\"144579867\",\"name\":\"P. Gao\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"88479495\",\"name\":\"S. Li\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"391af839051826ec317a6ea61010734baf536551\",\"title\":\"Question-Guided Hybrid Convolution for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/391af839051826ec317a6ea61010734baf536551\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.11575\",\"authors\":[{\"authorId\":\"1805197\",\"name\":\"H. Hu\"},{\"authorId\":\"30107062\",\"name\":\"Jiayuan Gu\"},{\"authorId\":null,\"name\":\"Zheng Zhang\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/CVPR.2018.00378\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6a0aaefce8a27a8727d896fa444ba27558b2d381\",\"title\":\"Relation Networks for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/6a0aaefce8a27a8727d896fa444ba27558b2d381\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Gulcehre Chung\"},{\"authorId\":null,\"name\":\"K. Cho\"},{\"authorId\":null,\"name\":\"Y. Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"\",\"venue\":\"IEEE International Conference on Computer Vision\",\"year\":null},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.03122\",\"authors\":[{\"authorId\":\"2401865\",\"name\":\"Jonas Gehring\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"},{\"authorId\":\"13759615\",\"name\":\"Denis Yarats\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43428880d75b3a14257c3ee9bda054e61eb869c0\",\"title\":\"Convolutional Sequence to Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/43428880d75b3a14257c3ee9bda054e61eb869c0\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jin-Hwa Kim\"},{\"authorId\":null,\"name\":\"Kyoung Woon On\"},{\"authorId\":null,\"name\":\"Woosang Lim\"},{\"authorId\":null,\"name\":\"Jeonghee Kim\"},{\"authorId\":null,\"name\":\"Jung-Woo Ha\"},{\"authorId\":null,\"name\":\"Byoung-Tak Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hadamard product for low-rank bilinear pooling\",\"url\":\"\",\"venue\":\"In International Conference on Learning Representations,\",\"year\":2017},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1511.06062\",\"authors\":[{\"authorId\":\"145644823\",\"name\":\"Y. Gao\"},{\"authorId\":\"3258919\",\"name\":\"Oscar Beijbom\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.41\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"title\":\"Compact Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"47332302\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d1aa129f861445e80e7f82b3f9607306658f4d4\",\"title\":\"Video Object Detection with Locally-Weighted Deformable Neighbors\",\"url\":\"https://www.semanticscholar.org/paper/3d1aa129f861445e80e7f82b3f9607306658f4d4\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1901.00785\",\"authors\":[{\"authorId\":\"1690316178\",\"name\":\"Kui Xu\"},{\"authorId\":\"40072288\",\"name\":\"Zhe Wang\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"2628174\",\"name\":\"Q. Zhang\"}],\"doi\":\"10.1609/aaai.v33i01.33011230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff7e12dd8ec3333ce42793b18f182d03aee61844\",\"title\":\"A^2-Net: Molecular Structure Estimation from Cryo-EM Density Volumes\",\"url\":\"https://www.semanticscholar.org/paper/ff7e12dd8ec3333ce42793b18f182d03aee61844\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Ben-younes\"},{\"authorId\":null,\"name\":\"R. Cadene\"},{\"authorId\":null,\"name\":\"M. Cord\"},{\"authorId\":null,\"name\":\"N. Thome\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"MU- TAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"\",\"venue\":\"In IEEE International Conference on Computer Vision,\",\"year\":2017},{\"arxivId\":\"1702.00887\",\"authors\":[{\"authorId\":\"38367242\",\"name\":\"Yoon Kim\"},{\"authorId\":\"47472547\",\"name\":\"Carl Denton\"},{\"authorId\":\"144294755\",\"name\":\"Luong Hoang\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13d9323a8716131911bfda048a40e2cde1a76a46\",\"title\":\"Structured Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/13d9323a8716131911bfda048a40e2cde1a76a46\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1412.3555\",\"authors\":[{\"authorId\":\"8270717\",\"name\":\"J. Chung\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"title\":\"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peter Anderson\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Chris Buehler\"},{\"authorId\":null,\"name\":\"Damien Teney\"},{\"authorId\":null,\"name\":\"Mark Johnson\"},{\"authorId\":null,\"name\":\"Stephen Gould\"},{\"authorId\":null,\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Bottom-up and top-down attention for image captioning and 4328  6646  visual question answering\",\"url\":\"\",\"venue\":\"In IEEE Conference on Computer Vision and Pattern Recognition,\",\"year\":2018},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1802.05766\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30a3eee5e9302108416f6234d739373dde68d373\",\"title\":\"Learning to Count Objects in Natural Images for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/30a3eee5e9302108416f6234d739373dde68d373\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1708.02071\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"49339267\",\"name\":\"Yanpeng Zhao\"},{\"authorId\":\"24027493\",\"name\":\"Shuaiyi Huang\"},{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1109/ICCV.2017.145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5823d18cd378898b12de537862d996443ce9c9e8\",\"title\":\"Structured Attentions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5823d18cd378898b12de537862d996443ce9c9e8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.02155\",\"authors\":[{\"authorId\":\"38759328\",\"name\":\"Peter Shaw\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"}],\"doi\":\"10.18653/v1/N18-2074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8efcc854d97dfc2a42b83316a2109f9d166e43f\",\"title\":\"Self-Attention with Relative Position Representations\",\"url\":\"https://www.semanticscholar.org/paper/c8efcc854d97dfc2a42b83316a2109f9d166e43f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1611.01604\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3428769\",\"name\":\"Victor Zhong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e978d832a4d86571e1b52aa1685dc32ccb250f50\",\"title\":\"Dynamic Coattention Networks For Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e978d832a4d86571e1b52aa1685dc32ccb250f50\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1608.06993\",\"authors\":[{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":\"10.1109/CVPR.2017.243\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"title\":\"Densely Connected Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"152274574\",\"name\":\"Gang Sun\"},{\"authorId\":\"145344139\",\"name\":\"Enhua Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2913372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df67d46e78aae0d2fccfb6212d101a342259c01b\",\"title\":\"Squeeze-and-Excitation Networks\",\"url\":\"https://www.semanticscholar.org/paper/df67d46e78aae0d2fccfb6212d101a342259c01b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peter Anderson\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Chris Buehler\"},{\"authorId\":null,\"name\":\"Damien Teney\"},{\"authorId\":null,\"name\":\"Mark Johnson\"},{\"authorId\":null,\"name\":\"Stephen Gould\"},{\"authorId\":null,\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Bottom-up and top-down attention for image captioning and 6639 visual question answering\",\"url\":\"\",\"venue\":\"In IEEE Conference on Computer Vision and Pattern Recognition,\",\"year\":2018},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Delta Force: Angel Falls\",\"topicId\":\"5868781\",\"url\":\"https://www.semanticscholar.org/topic/5868781\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Information flow (information theory)\",\"topicId\":\"26661\",\"url\":\"https://www.semanticscholar.org/topic/26661\"},{\"topic\":\"Stacking\",\"topicId\":\"100839\",\"url\":\"https://www.semanticscholar.org/topic/100839\"}],\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"