"{\"abstract\":\"Egocentric interaction recognition aims to recognize the camera wearer's interactions with the interactor who faces the camera wearer in egocentric videos. In such a human-human interaction analysis problem, it is crucial to explore the relations between the camera wearer and the interactor. However, most existing works directly model the interactions as a whole and lack modeling the relations between the two interacting persons. To exploit the strong relations for egocentric interaction recognition, we introduce a dual relation modeling framework which learns to model the relations between the camera wearer and the interactor based on the individual action representations of the two persons. Specifically, we develop a novel interactive LSTM module, the key component of our framework, to explicitly model the relations between the two interacting persons based on their individual action representations, which are collaboratively learned with an interactor attention module and a global-local motion module. Experimental results on three egocentric interaction datasets show the effectiveness of our method and advantage over state-of-the-arts.\",\"arxivId\":\"1905.13586\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\",\"url\":\"https://www.semanticscholar.org/author/47892681\"},{\"authorId\":\"50204657\",\"name\":\"Yijun Cai\",\"url\":\"https://www.semanticscholar.org/author/50204657\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\",\"url\":\"https://www.semanticscholar.org/author/3333315\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49952482\",\"name\":\"Jibin Gao\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"7588999\",\"name\":\"J. Pan\"},{\"authorId\":\"2971945\",\"name\":\"Chengying Gao\"},{\"authorId\":null,\"name\":\"Yaowei Wang\"},{\"authorId\":\"8434337\",\"name\":\"W. Zeng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1007/978-3-030-58577-8_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20e6a5d5295740952356a1fb2ae33c5550141219\",\"title\":\"An Asymmetric Modeling for Action Assessment\",\"url\":\"https://www.semanticscholar.org/paper/20e6a5d5295740952356a1fb2ae33c5550141219\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ajeeta Rajkumar Khatri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2152989920c63cfd7ce2342fe93ef41d472b6eba\",\"title\":\"Interaction Recognition in a Paired Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/2152989920c63cfd7ce2342fe93ef41d472b6eba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"},{\"authorId\":\"143624101\",\"name\":\"R. Zhao\"},{\"authorId\":\"145974119\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144847940\",\"name\":\"K. Lam\"}],\"doi\":\"10.1109/LSP.2020.3011326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c232519f402375a404ac74f02451807c3fa3aa3c\",\"title\":\"Progressive Motion Representation Distillation With Two-Branch Networks for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c232519f402375a404ac74f02451807c3fa3aa3c\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005105\",\"name\":\"Youngkyoon Jang\"},{\"authorId\":\"49300666\",\"name\":\"Brian T. Sullivan\"},{\"authorId\":\"40626572\",\"name\":\"Casimir J H Ludwig\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1109/ICCVW.2019.00547\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"title\":\"EPIC-Tent: An Egocentric Video Dataset for Camping Tent Assembly\",\"url\":\"https://www.semanticscholar.org/paper/e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2003.10663\",\"authors\":[{\"authorId\":\"2598007\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/ICME46284.2020.9102717\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d706c38381ec095c8e456b0b0387ae212e0581be\",\"title\":\"Modeling Cross-View Interaction Consistency for Paired Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d706c38381ec095c8e456b0b0387ae212e0581be\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020}],\"corpusId\":173187977,\"doi\":\"10.1109/CVPR.2019.00812\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1016/j.patcog.2015.06.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"deff6aa150d631a6e15a6fd9e33846f8416b36bd\",\"title\":\"Understanding social relationships in egocentric vision\",\"url\":\"https://www.semanticscholar.org/paper/deff6aa150d631a6e15a6fd9e33846f8416b36bd\",\"venue\":\"Pattern Recognit.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2396114\",\"name\":\"T. Moreira\"},{\"authorId\":\"8343623\",\"name\":\"D. Menotti\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1109/ICASSP.2017.7952632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c29f21f0b098123e523df17b23fdc4a82940cabe\",\"title\":\"First-person action recognition through Visual Rhythm texture description\",\"url\":\"https://www.semanticscholar.org/paper/c29f21f0b098123e523df17b23fdc4a82940cabe\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1709.06495\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/ICCVW.2017.276\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5155499812dafee92316bdbca5937f0e134514f3\",\"title\":\"Convolutional Long Short-Term Memory Networks for Recognizing First Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5155499812dafee92316bdbca5937f0e134514f3\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"MS Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":null,\"title\":\"Thomas J Fuchs\",\"url\":\"\",\"venue\":\"Lu Xia, Jake K Aggarwal, and Larry Matthies. Robot-centric activity prediction from firstperson videos: What will they do to me? In ACM/IEEE International Conference on Human-Robot Interaction, pages 295\\u2013302\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"145052333\",\"name\":\"Kang Zheng\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3206025.3206041\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"title\":\"Recognizing Actions in Wearable-Camera Videos by Training Classifiers on Fixed-Camera Videos\",\"url\":\"https://www.semanticscholar.org/paper/b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2013.352\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"title\":\"First-Person Activity Recognition: What Are They Doing to Me?\",\"url\":\"https://www.semanticscholar.org/paper/aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2008.4587735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"560171665e78c9341c0a735be437ee7f99bb2f2c\",\"title\":\"Action recognition by learning mid-level motion features\",\"url\":\"https://www.semanticscholar.org/paper/560171665e78c9341c0a735be437ee7f99bb2f2c\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2014.91\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"089ad5baacbac0aad7076a675bec1d07ffc11307\",\"title\":\"From Ego to Nos-Vision: Detecting Social Relationships in First-Person Views\",\"url\":\"https://www.semanticscholar.org/paper/089ad5baacbac0aad7076a675bec1d07ffc11307\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/CVPR.2011.5995406\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8848d1abd31873594fc372e0022789f153112174\",\"title\":\"Fast unsupervised ego-action learning for first-person sports videos\",\"url\":\"https://www.semanticscholar.org/paper/8848d1abd31873594fc372e0022789f153112174\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"81053474\",\"name\":\"K. Ramakrishnan\"}],\"doi\":\"10.1109/CVPRW.2014.82\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc7ddb6aa5eec694d8d4abfbe16fa295577dfbbf\",\"title\":\"Action and Interaction Recognition in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc7ddb6aa5eec694d8d4abfbe16fa295577dfbbf\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1703.01040\",\"authors\":[{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2017.63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6c95b567701f38fe3d87bbd56e3da9ad5ee35ca\",\"title\":\"Learning Robot Activities from First-Person Human Videos Using Convolutional Future Regression\",\"url\":\"https://www.semanticscholar.org/paper/b6c95b567701f38fe3d87bbd56e3da9ad5ee35ca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1605.03688\",\"authors\":[{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"444eba373d46c9f7d58cad74989ec9109b0d5219\",\"title\":\"Going Deeper into First-Person Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/444eba373d46c9f7d58cad74989ec9109b0d5219\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1704.07813\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"144735789\",\"name\":\"M. Brown\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"35238678\",\"name\":\"D. Lowe\"}],\"doi\":\"10.1109/CVPR.2017.700\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3abf64d10a5d9a426d864bcfd68daed370d6904c\",\"title\":\"Unsupervised Learning of Depth and Ego-Motion from Video\",\"url\":\"https://www.semanticscholar.org/paper/3abf64d10a5d9a426d864bcfd68daed370d6904c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2017.176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"title\":\"Modeling Sub-Event Dynamics in First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"102595883\",\"name\":\"Chen Yu\"}],\"doi\":\"10.1109/ICCV.2015.226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ef40f47e6f20c87391dd77b6e8c081709e1b8bd\",\"title\":\"Lending A Hand: Detecting Hands and Recognizing Activities in Complex Egocentric Interactions\",\"url\":\"https://www.semanticscholar.org/paper/7ef40f47e6f20c87391dd77b6e8c081709e1b8bd\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"},{\"authorId\":\"144905246\",\"name\":\"X. Parra\"}],\"doi\":\"10.1016/j.cviu.2015.10.015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aedf720dd1f0c015cfc67230cf90762b7275ab5\",\"title\":\"Robust multi-dimensional motion features for first-person vision activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/4aedf720dd1f0c015cfc67230cf90762b7275ab5\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1606.07419\",\"authors\":[{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"3422774\",\"name\":\"Ashvin Nair\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cf83c619423a1504f26495d5f6a495054c46462\",\"title\":\"Learning to Poke by Poking: Experiential Learning of Intuitive Physics\",\"url\":\"https://www.semanticscholar.org/paper/8cf83c619423a1504f26495d5f6a495054c46462\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/CVPR.2016.287\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"title\":\"First Person Action Recognition Using Deep Learned Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"34459632\",\"name\":\"Thomas J. Fuchs\"},{\"authorId\":\"47839689\",\"name\":\"L. Xia\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1145/2696454.2696462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d7670e2a55b5a9fae609eed08777da71e0b92ee\",\"title\":\"Robot-Centric Activity Prediction from First-Person Videos: What Will They Do to Me?\",\"url\":\"https://www.semanticscholar.org/paper/3d7670e2a55b5a9fae609eed08777da71e0b92ee\",\"venue\":\"2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72436419\",\"name\":\"\\ud55c\\ubcf4\\ud615\"},{\"authorId\":\"70063817\",\"name\":\"\\ud64d\\uc2b9\\ud6c8\"},{\"authorId\":\"66219957\",\"name\":\"\\ub178\\ud604\\uc6b0\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da574437bde83aaa879f6285cf0a2676c85219bf\",\"title\":\"Learning Deconvolution Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/da574437bde83aaa879f6285cf0a2676c85219bf\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47839689\",\"name\":\"L. Xia\"},{\"authorId\":\"2964199\",\"name\":\"I. Gori\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/WACV.2015.54\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdec872a07a2ad5b3d43eaf95c960b88728aeba5\",\"title\":\"Robot-centric Activity Recognition from First-Person RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdec872a07a2ad5b3d43eaf95c960b88728aeba5\",\"venue\":\"2015 IEEE Winter Conference on Applications of Computer Vision\",\"year\":2015},{\"arxivId\":\"1711.05523\",\"authors\":[{\"authorId\":\"30161970\",\"name\":\"Reza Kahani\"},{\"authorId\":\"97703279\",\"name\":\"A. Talebpour\"},{\"authorId\":\"1405144816\",\"name\":\"Ahmad Mahmoudi-Aznaveh\"}],\"doi\":\"10.1007/s11042-019-7429-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1158affc69155d8de216d131a80a233be2a7ff9c\",\"title\":\"A correlation based feature representation for first-person activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1158affc69155d8de216d131a80a233be2a7ff9c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1704.07804\",\"authors\":[{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab6b8671d3baef80f87ad76a3e4ce452aa1b6467\",\"title\":\"SfM-Net: Learning of Structure and Motion from Video\",\"url\":\"https://www.semanticscholar.org/paper/ab6b8671d3baef80f87ad76a3e4ce452aa1b6467\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.6505\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2015.7298691\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"title\":\"Pooled motion features for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1804.01984\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"48587831\",\"name\":\"K. Gong\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/TPAMI.2018.2820063\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"83f80b0c517f60eaec01442eb58a6ffb8bd8ab60\",\"title\":\"Look into Person: Joint Body Parsing & Pose Estimation Network and a New Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/83f80b0c517f60eaec01442eb58a6ffb8bd8ab60\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/IROS.2017.8205953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e8a3b6c6f1521d222ebf71bfa53f9f8dd75312\",\"title\":\"Learning robot activities from first-person human videos using convolutional future regression\",\"url\":\"https://www.semanticscholar.org/paper/e0e8a3b6c6f1521d222ebf71bfa53f9f8dd75312\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":\"1506.02025\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"title\":\"Spatial Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2016.288\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16461bc1f06c781b5357cb1157248d28dc3672a0\",\"title\":\"Recognizing Micro-Actions and Reactions from Paired Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/16461bc1f06c781b5357cb1157248d28dc3672a0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144489175\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2016.210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"title\":\"Cascaded Interactional Targeting Network for Egocentric Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2012.6247805\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"title\":\"Social interactions: A first-person perspective\",\"url\":\"https://www.semanticscholar.org/paper/014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012}],\"title\":\"Deep Dual Relation Modeling for Egocentric Interaction Recognition\",\"topics\":[{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"