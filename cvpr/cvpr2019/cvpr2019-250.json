"{\"abstract\":\"Video frame interpolation is a long-studied problem in the video processing field. Recently, deep learning approaches have been applied to this problem, showing impressive results on low-resolution benchmarks. However, these methods do not scale-up favorably to high resolutions. Specifically, when the motion exceeds a typical number of pixels, their interpolation quality is degraded. Moreover, their run time renders them impractical for real-time applications. In this paper we propose IM-Net: an interpolated motion neural network. We use an economic structured architecture and end-to-end training with multi-scale tailored losses. In particular, we formulate interpolated motion estimation as classification rather than regression. IM-Net outperforms previous methods by more than 1.3dB (PSNR) on a high resolution version of the recently introduced Vimeo triplet dataset. Moreover, the network runs in less than 33msec on a single GPU for HD resolution.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3035324\",\"name\":\"Tomer Peleg\",\"url\":\"https://www.semanticscholar.org/author/3035324\"},{\"authorId\":\"15589668\",\"name\":\"P. Szekely\",\"url\":\"https://www.semanticscholar.org/author/15589668\"},{\"authorId\":\"40462685\",\"name\":\"Doron Sabo\",\"url\":\"https://www.semanticscholar.org/author/40462685\"},{\"authorId\":\"3059895\",\"name\":\"O. Sendik\",\"url\":\"https://www.semanticscholar.org/author/3059895\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49889937\",\"name\":\"Yimeng Zhang\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"1993581583\",\"name\":\"Bo Wu\"},{\"authorId\":\"30910424\",\"name\":\"A. Walid\"}],\"doi\":\"10.1145/3394171.3413527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"title\":\"Video Synthesis via Transform-Based Tensor Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.13170\",\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.1109/CVPR42600.2020.00293\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"title\":\"Space-Time-Aware Multi-Resolution Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.01233\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"48206011\",\"name\":\"Hee-won Kim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"97866501\",\"name\":\"Bumjun Park\"},{\"authorId\":\"152283843\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"48388801\",\"name\":\"S. Kim\"},{\"authorId\":\"46973317\",\"name\":\"J. Jeong\"},{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"1585142097\",\"name\":\"Zhiyong Gaon\"},{\"authorId\":\"2812984\",\"name\":\"G. Chen\"},{\"authorId\":\"7774660\",\"name\":\"Yunhua Lu\"},{\"authorId\":\"46585842\",\"name\":\"R. Duan\"},{\"authorId\":\"150321531\",\"name\":\"Tong Liu\"},{\"authorId\":\"47059427\",\"name\":\"L. Zhang\"},{\"authorId\":\"120878650\",\"name\":\"Woonsung Park\"},{\"authorId\":\"47596916\",\"name\":\"M. Kim\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"104101992\",\"name\":\"L. Aloni\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"116295634\",\"name\":\"Ze Pan\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"}],\"doi\":\"10.1109/ICCVW.2019.00421\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3247a8640db63c638a1386493a87202aa2a0b15b\",\"title\":\"AIM 2019 Challenge on Video Temporal Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/3247a8640db63c638a1386493a87202aa2a0b15b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00434\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5981bb0678578dcf75536bdc476a38a7e501a301\",\"title\":\"PoSNet: 4x Video Frame Interpolation Using Position-Specific Flow\",\"url\":\"https://www.semanticscholar.org/paper/5981bb0678578dcf75536bdc476a38a7e501a301\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00433\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2141bb1226997c49123731d97b484ca19696485a\",\"title\":\"Robust Temporal Super-Resolution for Dynamic Motion Videos\",\"url\":\"https://www.semanticscholar.org/paper/2141bb1226997c49123731d97b484ca19696485a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.11481\",\"authors\":[{\"authorId\":\"1490999400\",\"name\":\"Haojie Liu\"},{\"authorId\":\"1491637046\",\"name\":\"Kang Liao\"},{\"authorId\":\"2212400\",\"name\":\"Chunyu Lin\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50f7c1fecdd2ef2ed1fafaac3b5b2f3b434050e0\",\"title\":\"Pseudo-LiDAR Point Cloud Interpolation Based on 3D Motion Representation and Spatial Supervision\",\"url\":\"https://www.semanticscholar.org/paper/50f7c1fecdd2ef2ed1fafaac3b5b2f3b434050e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12680\",\"authors\":[{\"authorId\":\"7000208\",\"name\":\"Yu-yu Guo\"},{\"authorId\":\"49117537\",\"name\":\"Lei Bi\"},{\"authorId\":\"2130901\",\"name\":\"Euijoon Ahn\"},{\"authorId\":\"11675891\",\"name\":\"D. Feng\"},{\"authorId\":\"49110419\",\"name\":\"Q. Wang\"},{\"authorId\":\"46454386\",\"name\":\"Jinman Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.00478\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57561a45ccde67ea6e3db870e4994106e4d61a69\",\"title\":\"A Spatiotemporal Volumetric Interpolation Network for 4D Dynamic Medical Image\",\"url\":\"https://www.semanticscholar.org/paper/57561a45ccde67ea6e3db870e4994106e4d61a69\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.04149\",\"authors\":[{\"authorId\":\"1597361648\",\"name\":\"Xiaoyu Li\"},{\"authorId\":\"1723442179\",\"name\":\"Bo Zhang\"},{\"authorId\":\"1851024702\",\"name\":\"Jing Liao\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"title\":\"Deep Sketch-guided Cartoon Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1914700964\",\"name\":\"Shurui Gui\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"47261253\",\"name\":\"Q. Chen\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.01402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"title\":\"FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation\",\"url\":\"https://www.semanticscholar.org/paper/48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753738047\",\"name\":\"Kshitija Pandya\"},{\"authorId\":\"1753737879\",\"name\":\"Disha Varshney\"},{\"authorId\":\"1753607722\",\"name\":\"Ashray Aggarwal\"},{\"authorId\":\"115827410\",\"name\":\"Anil Singh Parihar\"}],\"doi\":\"10.1109/ICICCS48265.2020.9120989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"682e288a5870f182e0f92bb4735f5659dff8b94c\",\"title\":\"An Analytical Study of CNN-based Video Frame Interpolation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/682e288a5870f182e0f92bb4735f5659dff8b94c\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":\"1909.07137\",\"authors\":[{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"151502853\",\"name\":\"Kang Liao\"},{\"authorId\":\"2212400\",\"name\":\"Chunyu Lin\"},{\"authorId\":\"152621482\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"}],\"doi\":\"10.3390/s20061573\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de3775c0499d036da4097ae3ab89db00a10c5c6e\",\"title\":\"PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/de3775c0499d036da4097ae3ab89db00a10c5c6e\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1912.07213\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"107606159\",\"name\":\"Jihyong Oh\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":\"10.1609/AAAI.V34I07.6788\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c4801dd2249f912c655887bc0bb6a53ddbab7f\",\"title\":\"FISR: Deep Joint Frame Interpolation and Super-Resolution with A Multi-scale Temporal Loss\",\"url\":\"https://www.semanticscholar.org/paper/09c4801dd2249f912c655887bc0bb6a53ddbab7f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1626101034\",\"name\":\"Nguyen Van Thang\"},{\"authorId\":\"1390764531\",\"name\":\"Kyujoong Lee\"},{\"authorId\":\"3090069\",\"name\":\"Hyuk-Jae Lee\"}],\"doi\":\"10.1109/ACCESS.2020.2982039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"title\":\"A Stacked Deep MEMC Network for Frame Rate Up Conversion and its Application to HEVC\",\"url\":\"https://www.semanticscholar.org/paper/1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.08070\",\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db79a9a20acb3c15256655d52bb40e8831bb2345\",\"title\":\"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/db79a9a20acb3c15256655d52bb40e8831bb2345\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"},{\"authorId\":\"92733026\",\"name\":\"Soon-chul Kwon\"},{\"authorId\":\"1773696\",\"name\":\"Ji-Sang Yoo\"}],\"doi\":\"10.3390/sym11101251\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"title\":\"A Fast 4K Video Frame Interpolation Using a Multi-Scale Optical Flow Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":\"2007.11762\",\"authors\":[{\"authorId\":\"35793956\",\"name\":\"Zhixiang Chi\"},{\"authorId\":\"49456126\",\"name\":\"R. Nasiri\"},{\"authorId\":\"2114344\",\"name\":\"Z. Liu\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"},{\"authorId\":\"37932469\",\"name\":\"K. Plataniotis\"}],\"doi\":\"10.1007/978-3-030-58583-9_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e07d015d548162756e479934b245299e4aa737d0\",\"title\":\"All at Once: Temporally Adaptive Multi-Frame Interpolation with Advanced Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e07d015d548162756e479934b245299e4aa737d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.01280\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"title\":\"Revisiting Adaptive Convolutions for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08872\",\"authors\":[{\"authorId\":\"1573986321\",\"name\":\"Liad Pollak Zuckerman\"},{\"authorId\":\"1944189\",\"name\":\"S. Bagon\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1007/978-3-030-58571-6_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02772404c8c6e1903a00798ce01492bc6820f665\",\"title\":\"Across Scales \\\\& Across Dimensions: Temporal Super-Resolution using Deep Internal Learning\",\"url\":\"https://www.semanticscholar.org/paper/02772404c8c6e1903a00798ce01492bc6820f665\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":196198618,\"doi\":\"10.1109/CVPR.2019.00250\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"089f2072c95c244f3b7f4df404562bb4afe24448\",\"references\":[{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739537\",\"name\":\"Suk-Ju Kang\"},{\"authorId\":\"48917779\",\"name\":\"Kyoung-Rok Cho\"},{\"authorId\":\"145155116\",\"name\":\"Y. H. Kim\"}],\"doi\":\"10.1109/TCE.2007.4429281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dda4fdf1c77d5ad873da0602c3596e0f28b0c00\",\"title\":\"Motion Compensated Frame Rate Up-Conversion Using Extended Bilateral Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/9dda4fdf1c77d5ad873da0602c3596e0f28b0c00\",\"venue\":\"IEEE Transactions on Consumer Electronics\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3346215\",\"name\":\"R. Castagno\"},{\"authorId\":\"1684728\",\"name\":\"P. Haavisto\"},{\"authorId\":\"144763839\",\"name\":\"G. Ramponi\"}],\"doi\":\"10.1109/76.538926\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f16f2ce968d4caf85bf13eba8417bfb5e6edfa32\",\"title\":\"A method for motion adaptive frame rate up-conversion\",\"url\":\"https://www.semanticscholar.org/paper/f16f2ce968d4caf85bf13eba8417bfb5e6edfa32\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39261035\",\"name\":\"Xin Huang\"},{\"authorId\":\"2362189\",\"name\":\"L. Rak\\u00eat\"},{\"authorId\":\"2138281\",\"name\":\"H. V. Luong\"},{\"authorId\":\"143923065\",\"name\":\"Mads Nielsen\"},{\"authorId\":\"1752860\",\"name\":\"F. Lauze\"},{\"authorId\":\"1709891\",\"name\":\"S. Forchhammer\"}],\"doi\":\"10.1109/MMSP.2011.6093771\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93050f5639817a7aa714384025a036432a2258bf\",\"title\":\"Multi-hypothesis transform domain Wyner-Ziv video coding including optical flow\",\"url\":\"https://www.semanticscholar.org/paper/93050f5639817a7aa714384025a036432a2258bf\",\"venue\":\"2011 IEEE 13th International Workshop on Multimedia Signal Processing\",\"year\":2011},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2334811\",\"name\":\"Byeong-Doo Choi\"},{\"authorId\":\"1868900\",\"name\":\"Jong-Woo Han\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"},{\"authorId\":\"143687281\",\"name\":\"S. Ko\"}],\"doi\":\"10.1109/TCSVT.2007.893835\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7424c2072a5a48040879846a08feaccb03ac9895\",\"title\":\"Motion-Compensated Frame Interpolation Using Bilateral Motion Estimation and Adaptive Overlapped Block Motion Compensation\",\"url\":\"https://www.semanticscholar.org/paper/7424c2072a5a48040879846a08feaccb03ac9895\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"},{\"authorId\":\"37108776\",\"name\":\"Philip Lenz\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2012.6248074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42\",\"title\":\"Are we ready for autonomous driving? The KITTI vision benchmark suite\",\"url\":\"https://www.semanticscholar.org/paper/de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1506.06825\",\"authors\":[{\"authorId\":\"48001135\",\"name\":\"J. Flynn\"},{\"authorId\":\"1725327\",\"name\":\"Ivan Neulander\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1109/CVPR.2016.595\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"title\":\"Deep Stereo: Learning to Predict New Views from the World's Imagery\",\"url\":\"https://www.semanticscholar.org/paper/73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2501208\",\"name\":\"T. Stich\"},{\"authorId\":\"49591135\",\"name\":\"C. Linz\"},{\"authorId\":\"145811354\",\"name\":\"G. Albuquerque\"},{\"authorId\":\"1686739\",\"name\":\"M. Magnor\"}],\"doi\":\"10.1111/j.1467-8659.2008.01323.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ce1fabd5dc610cb015e78b7bd1dce9e45906f25\",\"title\":\"View and Time Interpolation in Image Space\",\"url\":\"https://www.semanticscholar.org/paper/0ce1fabd5dc610cb015e78b7bd1dce9e45906f25\",\"venue\":\"Comput. Graph. Forum\",\"year\":2008},{\"arxivId\":\"1501.00092\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2015.2439281\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"title\":\"Image Super-Resolution Using Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"750cc7813da3559dfd653cfbbf56ca3356b3162f\",\"title\":\"Deep Convolutional Neural Network for Image Deconvolution\",\"url\":\"https://www.semanticscholar.org/paper/750cc7813da3559dfd653cfbbf56ca3356b3162f\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"143911112\",\"name\":\"Wei Han\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2015.50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27fc88ebb3e325a062a6ff48a7a76611af1ecd5a\",\"title\":\"Deep Networks for Image Super-Resolution with Sparse Prior\",\"url\":\"https://www.semanticscholar.org/paper/27fc88ebb3e325a062a6ff48a7a76611af1ecd5a\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19277254\",\"name\":\"Bo-Won Jeon\"},{\"authorId\":\"50044938\",\"name\":\"G. Lee\"},{\"authorId\":\"6161208\",\"name\":\"S. Lee\"},{\"authorId\":\"102442672\",\"name\":\"R. Park\"}],\"doi\":\"10.1109/TCE.2003.1233761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19db3269b4b101e190a82f9184f26ae8f9979f34\",\"title\":\"Coarse-to-fine frame interpolation for frame rate up-conversion using pyramid structure\",\"url\":\"https://www.semanticscholar.org/paper/19db3269b4b101e190a82f9184f26ae8f9979f34\",\"venue\":\"IEEE Trans. Consumer Electron.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39261035\",\"name\":\"Xin Huang\"},{\"authorId\":\"1709891\",\"name\":\"S. Forchhammer\"}],\"doi\":\"10.1016/j.image.2011.06.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c1eeac59bfcac1944fae6c0c4cd754618a6d8bb\",\"title\":\"Cross-band noise model refinement for transform domain Wyner-Ziv video coding\",\"url\":\"https://www.semanticscholar.org/paper/5c1eeac59bfcac1944fae6c0c4cd754618a6d8bb\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2012},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1804.00884\",\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/CVPR.2018.00059\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"title\":\"PhaseNet for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6161208\",\"name\":\"S. Lee\"},{\"authorId\":\"1776600\",\"name\":\"Ohjae Kwon\"},{\"authorId\":\"102442672\",\"name\":\"R. Park\"}],\"doi\":\"10.1109/TCE.2003.1233759\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8194376c6a515792cfe9526c2798784c35632951\",\"title\":\"Weighted-adaptive motion-compensated frame rate up-conversion\",\"url\":\"https://www.semanticscholar.org/paper/8194376c6a515792cfe9526c2798784c35632951\",\"venue\":\"IEEE Trans. Consumer Electron.\",\"year\":2003},{\"arxivId\":\"1707.07958\",\"authors\":[{\"authorId\":\"7838570\",\"name\":\"Damien Fourure\"},{\"authorId\":\"2003050\",\"name\":\"R. Emonet\"},{\"authorId\":\"1687778\",\"name\":\"\\u00c9lisa Fromont\"},{\"authorId\":\"1706185\",\"name\":\"D. Muselet\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":\"10.5244/C.31.181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fb5d9c589ea53f25b981673a7a750e854e7d687\",\"title\":\"Residual Conv-Deconv Grid Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1fb5d9c589ea53f25b981673a7a750e854e7d687\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1711.06045\",\"authors\":[{\"authorId\":\"3038326\",\"name\":\"Joost R. van Amersfoort\"},{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"145987822\",\"name\":\"A. Acosta\"},{\"authorId\":\"35163474\",\"name\":\"Francisco Massa\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"145372820\",\"name\":\"J. Caballero\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d6569a94dd0a2446bfdbc4e026d69a0eb69743f\",\"title\":\"Frame Interpolation with Multi-Scale Deep Loss Functions and Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8d6569a94dd0a2446bfdbc4e026d69a0eb69743f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10593-2_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0504945cc2d03550fecb6ff02e637f9421107c25\",\"title\":\"Learning a Deep Convolutional Network for Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/0504945cc2d03550fecb6ff02e637f9421107c25\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1707.05425\",\"authors\":[{\"authorId\":\"31606239\",\"name\":\"Jin Yamanaka\"},{\"authorId\":\"32380938\",\"name\":\"S. Kuwashima\"},{\"authorId\":\"145375983\",\"name\":\"T. Kurita\"}],\"doi\":\"10.1007/978-3-319-70096-0_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"625fb0b495bda4beea7e9191751b71c174e28878\",\"title\":\"Fast and Accurate Image Super Resolution by Deep CNN with Skip Connection and Network in Network\",\"url\":\"https://www.semanticscholar.org/paper/625fb0b495bda4beea7e9191751b71c174e28878\",\"venue\":\"ICONIP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1803.10967\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"40405236\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2018.00183\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65fadccad0fc743876a259c2b779622636c2ffde\",\"title\":\"Context-Aware Synthesis for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/65fadccad0fc743876a259c2b779622636c2ffde\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"IM-Net for High Resolution Video Frame Interpolation\",\"topics\":[{\"topic\":\"Motion interpolation\",\"topicId\":\"21402\",\"url\":\"https://www.semanticscholar.org/topic/21402\"},{\"topic\":\"Ephrin Type-B Receptor 1, human\",\"topicId\":\"203497\",\"url\":\"https://www.semanticscholar.org/topic/203497\"},{\"topic\":\"Interpolation Imputation Technique\",\"topicId\":\"25559\",\"url\":\"https://www.semanticscholar.org/topic/25559\"}],\"url\":\"https://www.semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"