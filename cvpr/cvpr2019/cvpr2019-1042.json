"{\"abstract\":\"Recent years have witnessed the growing interest in visual quality assessment (VQA) for 360\\u00b0 video. Unfortunately, the existing VQA approaches do not consider the facts that: 1) Observers only see viewports of 360\\u00b0 video, rather than patches or whole 360\\u00b0 frames. 2) Within the viewport, only salient regions can be perceived by observers with high resolution. Thus, this paper proposes a viewport-based convolutional neural network (V-CNN) approach for VQA on 360\\u00b0 video, considering both auxiliary tasks of viewport proposal and viewport saliency prediction. Our V-CNN approach is composed of two stages, i.e., viewport proposal and VQA. In the first stage, the viewport proposal network (VP-net) is developed to yield several potential viewports, seen as the first auxiliary task. In the second stage, a viewport quality network (VQ-net) is designed to rate the VQA score for each proposed viewport, in which the saliency map of the viewport is predicted and then utilized in VQA score rating. Consequently, another auxiliary task of viewport saliency prediction can be achieved. More importantly, the main task of VQA on 360\\u00b0 video can be accomplished via integrating the VQA scores of all viewports. The experiments validate the effectiveness of our V-CNN approach in significantly advancing the state-of-the-art performance of VQA on 360\\u00b0 video. In addition, our approach achieves comparable performance in two auxiliary tasks. The code of our V-CNN approach is available at https://github.com/Archer-Tatsu/V-CNN.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"49673074\",\"name\":\"C. Li\",\"url\":\"https://www.semanticscholar.org/author/49673074\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\",\"url\":\"https://www.semanticscholar.org/author/1743773\"},{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\",\"url\":\"https://www.semanticscholar.org/author/150188542\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\",\"url\":\"https://www.semanticscholar.org/author/15661018\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\",\"url\":\"https://www.semanticscholar.org/author/144978572\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2705863\",\"name\":\"C. Ozcinar\"},{\"authorId\":\"1409495745\",\"name\":\"Nevrez Imamoglu\"},{\"authorId\":\"144812978\",\"name\":\"Weimin Wang\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1007/s11760-020-01769-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30b517573f4efec43e3ecae7ab3ef5f0019ed32f\",\"title\":\"Delivery of omnidirectional video using saliency prediction and optimal bitrate allocation\",\"url\":\"https://www.semanticscholar.org/paper/30b517573f4efec43e3ecae7ab3ef5f0019ed32f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.00161\",\"authors\":[{\"authorId\":\"49235564\",\"name\":\"M. Xu\"},{\"authorId\":\"32462959\",\"name\":\"Chen Li\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/JSTSP.2020.2966864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"title\":\"State-of-the-Art in 360\\u00b0 Video/Image Processing: Perception, Assessment and Compression\",\"url\":\"https://www.semanticscholar.org/paper/42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19421779\",\"name\":\"Stephan Fremerey\"},{\"authorId\":\"13313232\",\"name\":\"Steve Goering\"},{\"authorId\":\"1693378632\",\"name\":\"Rakesh Rao Ramachandra Rao\"},{\"authorId\":\"1473513920\",\"name\":\"Rachel L. Huang\"},{\"authorId\":\"2403648\",\"name\":\"Alexander Raake\"}],\"doi\":\"10.1109/MMSP48831.2020.9287065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d560ac5d31959c696d411f12f870e135bc1cc580\",\"title\":\"Subjective Test Dataset and Meta-data-based Models for 360\\u00b0 Streaming Video Quality\",\"url\":\"https://www.semanticscholar.org/paper/d560ac5d31959c696d411f12f870e135bc1cc580\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"2010.11347\",\"authors\":[{\"authorId\":\"1410024154\",\"name\":\"Fenghe Hu\"},{\"authorId\":\"3336211\",\"name\":\"Yansha Deng\"},{\"authorId\":\"3381122\",\"name\":\"A. Aghvami\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f10bc7c43251f8aa1ffe801cffb5b5df6e614889\",\"title\":\"Correlation-aware Cooperative Multigroup Broadcast 360{\\\\deg} Video Delivery Network: A Hierarchical Deep Reinforcement Learning Approach.\",\"url\":\"https://www.semanticscholar.org/paper/f10bc7c43251f8aa1ffe801cffb5b5df6e614889\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71980378\",\"name\":\"P. S. Shinde\"},{\"authorId\":\"102863544\",\"name\":\"Y. Dongre\"}],\"doi\":\"10.1109/ICCUBEA47591.2019.9129297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e4a3c0bfe05d9f80543536c38e22d5325739312\",\"title\":\"Objective Video Quality Assessment Based On SURF Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/6e4a3c0bfe05d9f80543536c38e22d5325739312\",\"venue\":\"2019 5th International Conference On Computing, Communication, Control And Automation (ICCUBEA)\",\"year\":2019},{\"arxivId\":\"2002.09140\",\"authors\":[{\"authorId\":null,\"name\":\"Jiahua Xu\"},{\"authorId\":\"145172487\",\"name\":\"W. Zhou\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"}],\"doi\":\"10.1109/tcsvt.2020.3015186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"940ff8a09a7120a6ff3980ccbedccd9e0c39f01c\",\"title\":\"Blind Omnidirectional Image Quality Assessment with Viewport Oriented Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/940ff8a09a7120a6ff3980ccbedccd9e0c39f01c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82702431\",\"name\":\"Xiongli Chai\"},{\"authorId\":\"143749716\",\"name\":\"Feng Shao\"}],\"doi\":\"10.1016/j.ijleo.2020.165887\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3bd832b5d4f1af0038a1a93dcac8d4e39f0115f\",\"title\":\"Blind quality assessment of omnidirectional videos using spatio-temporal convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/c3bd832b5d4f1af0038a1a93dcac8d4e39f0115f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679729\",\"name\":\"R. Azevedo\"},{\"authorId\":\"2959338\",\"name\":\"N. Birkbeck\"},{\"authorId\":\"67276364\",\"name\":\"Ivan Janatra\"},{\"authorId\":\"3428155\",\"name\":\"Balu Adsumilli\"},{\"authorId\":\"1423349315\",\"name\":\"Pascal Frossard\"}],\"doi\":\"10.1109/icme46284.2020.9102936\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c024ad8a9f08d085da51e308bd6fc001650c36d8\",\"title\":\"A Viewport-Driven Multi-Metric Fusion Approach for 360-Degree Video Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/c024ad8a9f08d085da51e308bd6fc001650c36d8\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020}],\"corpusId\":195508857,\"doi\":\"10.1109/CVPR.2019.01042\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"8d8ff98a5740febb0e03972b7ff6686171f46557\",\"references\":[{\"arxivId\":\"1807.10990\",\"authors\":[{\"authorId\":\"40144368\",\"name\":\"Chen Li\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"51151110\",\"name\":\"Xinzhe Du\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1145/3240508.3240581\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e12ca3d372d2f989616035c92df90f76183d0172\",\"title\":\"Bridge the Gap Between VQA and Human Behavior on Omnidirectional Video: A Large-Scale Dataset and a Deep Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/e12ca3d372d2f989616035c92df90f76183d0172\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1801.10130\",\"authors\":[{\"authorId\":\"2056266\",\"name\":\"T. Cohen\"},{\"authorId\":\"31784839\",\"name\":\"M. Geiger\"},{\"authorId\":\"32602330\",\"name\":\"Jonas K\\u00f6hler\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce2845cadc5233ff0a647aa22ae3bbe646258890\",\"title\":\"Spherical CNNs\",\"url\":\"https://www.semanticscholar.org/paper/ce2845cadc5233ff0a647aa22ae3bbe646258890\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1612.01697\",\"authors\":[{\"authorId\":\"1774736\",\"name\":\"S. Bosse\"},{\"authorId\":\"2352484\",\"name\":\"D. Maniry\"},{\"authorId\":\"145034054\",\"name\":\"K. M\\u00fcller\"},{\"authorId\":\"1745395\",\"name\":\"T. Wiegand\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1109/TIP.2017.2760518\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"798d3e2daba161280da523c856d6a11f655d7200\",\"title\":\"Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/798d3e2daba161280da523c856d6a11f655d7200\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49515937\",\"name\":\"F. Li\"},{\"authorId\":\"7465771\",\"name\":\"Huihui Bai\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"}],\"doi\":\"10.1109/APSIPA.2017.8282085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5b1e58668f6f29da892c68009441262d8620e79\",\"title\":\"Visual attention guided eye movements for 360 degree images\",\"url\":\"https://www.semanticscholar.org/paper/b5b1e58668f6f29da892c68009441262d8620e79\",\"venue\":\"2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33886466\",\"name\":\"D. Healy\"},{\"authorId\":\"1923670\",\"name\":\"D. Rockmore\"},{\"authorId\":\"2748571\",\"name\":\"P. Kostelec\"},{\"authorId\":\"153600536\",\"name\":\"S. Moore\"}],\"doi\":\"10.1007/S00041-003-0018-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71c9da706ad7e28752348497a46f7079a6b2d8f8\",\"title\":\"FFTs for the\\n2-Sphere-Improvements and\\nVariations\",\"url\":\"https://www.semanticscholar.org/paper/71c9da706ad7e28752348497a46f7079a6b2d8f8\",\"venue\":\"\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403256\",\"name\":\"Xavier Corbillon\"},{\"authorId\":\"36517415\",\"name\":\"F. Simone\"},{\"authorId\":\"1835841\",\"name\":\"G. Simon\"}],\"doi\":\"10.1145/3083187.3083215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b64310dd13e71e6b192ca70c76a3ab65143614c\",\"title\":\"360-Degree Video Head Movement Dataset\",\"url\":\"https://www.semanticscholar.org/paper/3b64310dd13e71e6b192ca70c76a3ab65143614c\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"184ffa4a4c36051de56e07d785e5b53928d8c472\",\"title\":\"DeepVS: A Deep Learning Based Video Saliency Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/184ffa4a4c36051de56e07d785e5b53928d8c472\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144878796\",\"name\":\"Vladyslav Zakharchenko\"},{\"authorId\":\"2886433\",\"name\":\"Kwang Pyo Choi\"},{\"authorId\":\"2439939\",\"name\":\"J. Park\"}],\"doi\":\"10.1117/12.2235885\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b9ddb8d7887002c72fc3da58030d77dd8b967f51\",\"title\":\"Quality metric for spherical panoramic video\",\"url\":\"https://www.semanticscholar.org/paper/b9ddb8d7887002c72fc3da58030d77dd8b967f51\",\"venue\":\"Optical Engineering + Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Harel\"},{\"authorId\":null,\"name\":\"Christof Koch\"},{\"authorId\":null,\"name\":\"Pietro Perona\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graphbased visual saliency\",\"url\":\"\",\"venue\":\"In Advances in Neural Information Processing Systems,\",\"year\":2007},{\"arxivId\":\"1804.03943\",\"authors\":[{\"authorId\":\"27618918\",\"name\":\"Heoun-taek Lim\"},{\"authorId\":\"3009805\",\"name\":\"Hak Gu Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICASSP.2018.8461317\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0878c130430a078916bfc5297720a268fb40b1df\",\"title\":\"VR IQA NET: Deep Virtual Reality Image Quality Assessment Using Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/0878c130430a078916bfc5297720a268fb40b1df\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"40144368\",\"name\":\"Chen Li\"},{\"authorId\":\"1737311\",\"name\":\"Yufan Liu\"},{\"authorId\":\"144325130\",\"name\":\"X. Deng\"},{\"authorId\":\"2892103\",\"name\":\"Jiaxin Lu\"}],\"doi\":\"10.1109/ICME.2017.8019351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93942f3533eafff75b4ca66e0de360df4e86bcab\",\"title\":\"A subjective visual quality assessment method of panoramic videos\",\"url\":\"https://www.semanticscholar.org/paper/93942f3533eafff75b4ca66e0de360df4e86bcab\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10423740\",\"name\":\"Evgeniy Upenik\"},{\"authorId\":\"3424404\",\"name\":\"Martin Rer\\u00e1bek\"},{\"authorId\":\"1681498\",\"name\":\"T. Ebrahimi\"}],\"doi\":\"10.1109/QoMEX.2017.7965660\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"862988c81a687391228eeffc613c8552d0a43dd2\",\"title\":\"On the performance of objective metrics for omnidirectional visual content\",\"url\":\"https://www.semanticscholar.org/paper/862988c81a687391228eeffc613c8552d0a43dd2\",\"venue\":\"2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"8132902\",\"name\":\"Zhihao Tan\"},{\"authorId\":\"34191590\",\"name\":\"Z. Wang\"},{\"authorId\":\"1689674\",\"name\":\"S. Yang\"}],\"doi\":\"10.1145/3083187.3083210\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"337f5ff3b7fbc9a9bea8468eb703e4d9941a1e3b\",\"title\":\"A Dataset for Exploring User Behaviors in VR Spherical Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/337f5ff3b7fbc9a9bea8468eb703e4d9941a1e3b\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":\"1707.03123\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/ICCVW.2017.275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10816358c78a6f7372620e4f59b54ba1c69c2022\",\"title\":\"SaltiNet: Scan-Path Prediction on 360 Degree Images Using Saliency Volumes\",\"url\":\"https://www.semanticscholar.org/paper/10816358c78a6f7372620e4f59b54ba1c69c2022\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00559\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.01320\",\"authors\":[{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"50993085\",\"name\":\"Chun-Hung Chao\"},{\"authorId\":\"46181955\",\"name\":\"Jin-Dong Dong\"},{\"authorId\":\"2486384\",\"name\":\"Hao-Kai Wen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2018.00154\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"title\":\"Cube Padding for Weakly-Supervised Saliency Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40186773\",\"name\":\"P. Lebreton\"},{\"authorId\":\"2403648\",\"name\":\"Alexander Raake\"}],\"doi\":\"10.1016/j.image.2018.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbf3427b2a427cf156146e5b48ec3b55a15f33c2\",\"title\":\"GBVS360, BMS360, ProSal: Extending existing saliency prediction models from 2D to omnidirectional images\",\"url\":\"https://www.semanticscholar.org/paper/bbf3427b2a427cf156146e5b48ec3b55a15f33c2\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alex Davies\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oculus Rift vs. HTC Vive vs. PlayStation VR\",\"url\":\"\",\"venue\":\"https://www.tomshardware.co.uk/ vive-rift-playstation-vr-comparison,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145960240\",\"name\":\"Xiaoyu Xiu\"},{\"authorId\":\"2046044\",\"name\":\"Yuwen He\"},{\"authorId\":\"145185458\",\"name\":\"Y. Ye\"},{\"authorId\":\"34017441\",\"name\":\"B. Vishwanath\"}],\"doi\":\"10.1109/VCIP.2017.8305084\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"531d04b39f5087e51ca7f950376f85099abdd8ee\",\"title\":\"An evaluation framework for 360-degree video compression\",\"url\":\"https://www.semanticscholar.org/paper/531d04b39f5087e51ca7f950376f85099abdd8ee\",\"venue\":\"2017 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145847451\",\"name\":\"Huyen T. T. Tran\"},{\"authorId\":\"144419388\",\"name\":\"N. P. Ngoc\"},{\"authorId\":\"35881635\",\"name\":\"Cuong Manh Bui\"},{\"authorId\":\"38056521\",\"name\":\"M. Pham\"},{\"authorId\":\"145511287\",\"name\":\"T. Thang\"}],\"doi\":\"10.1109/ICUFN.2017.7993736\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d9985e07f56a996db117208cdc6c9e7afc89c64\",\"title\":\"An evaluation of quality metrics for 360 videos\",\"url\":\"https://www.semanticscholar.org/paper/1d9985e07f56a996db117208cdc6c9e7afc89c64\",\"venue\":\"2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711485\",\"name\":\"K. Seshadrinathan\"},{\"authorId\":\"2510315\",\"name\":\"R. Soundararajan\"},{\"authorId\":\"1393477616\",\"name\":\"Alan Conrad Bovik\"},{\"authorId\":\"1392690388\",\"name\":\"L. Cormack\"}],\"doi\":\"10.1109/TIP.2010.2042111\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fbc5ff6378caf42df5dc916cc92001e683fae56\",\"title\":\"Study of Subjective and Objective Quality Assessment of Video\",\"url\":\"https://www.semanticscholar.org/paper/2fbc5ff6378caf42df5dc916cc92001e683fae56\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143663559\",\"name\":\"F. Lopes\"},{\"authorId\":\"145601383\",\"name\":\"J. Ascenso\"},{\"authorId\":\"145636822\",\"name\":\"A. Rodrigues\"},{\"authorId\":\"40103951\",\"name\":\"M. P. Queluz\"}],\"doi\":\"10.1117/12.2321679\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e1ea192f8dd4d674dacaec1e8768edb81f6793b\",\"title\":\"Subjective and objective quality assessment of omnidirectional video\",\"url\":\"https://www.semanticscholar.org/paper/0e1ea192f8dd4d674dacaec1e8768edb81f6793b\",\"venue\":\"Optical Engineering + Applications\",\"year\":2018},{\"arxivId\":\"1703.06870\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35113211\",\"name\":\"Yashas Rai\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"1871505\",\"name\":\"P. Guillotel\"}],\"doi\":\"10.1109/QoMEX.2017.7965659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c80a801ac6e22a6aff5e83454e9bc8ab72ec6489\",\"title\":\"Which saliency weighting for omni directional image quality assessment?\",\"url\":\"https://www.semanticscholar.org/paper/c80a801ac6e22a6aff5e83454e9bc8ab72ec6489\",\"venue\":\"2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50591329\",\"name\":\"Shu Yang\"},{\"authorId\":\"3389588\",\"name\":\"Junzhe Zhao\"},{\"authorId\":\"40570471\",\"name\":\"T. Jiang\"},{\"authorId\":\"46584932\",\"name\":\"J. Wang\"},{\"authorId\":\"47562133\",\"name\":\"T. Rahim\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"},{\"authorId\":\"1940506\",\"name\":\"Z. Xu\"},{\"authorId\":\"144506604\",\"name\":\"Z. Fei\"}],\"doi\":\"10.1109/VCIP.2017.8305133\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fcb1aac401a5052630d3f0416546f47efcfd41df\",\"title\":\"An objective assessment method based on multi-level factors for panoramic videos\",\"url\":\"https://www.semanticscholar.org/paper/fcb1aac401a5052630d3f0416546f47efcfd41df\",\"venue\":\"2017 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23233941\",\"name\":\"Yule Sun\"},{\"authorId\":\"25631570\",\"name\":\"Ang Lu\"},{\"authorId\":\"143854840\",\"name\":\"L. Yu\"}],\"doi\":\"10.1109/LSP.2017.2720693\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"360256f07d4239964d929dcd3d8df0415cf3fbf7\",\"title\":\"Weighted-to-Spherically-Uniform Quality Evaluation for Omnidirectional Video\",\"url\":\"https://www.semanticscholar.org/paper/360256f07d4239964d929dcd3d8df0415cf3fbf7\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B Choi\"},{\"authorId\":null,\"name\":\"Wang\"},{\"authorId\":null,\"name\":\"Y Hannuksela\"},{\"authorId\":null,\"name\":\"A Lim\"},{\"authorId\":null,\"name\":\"Murtaza\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Information technology-coded representation of immersive media (MPEG-I)-part 2: Omnidirectional media format. ISO/IEC\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/TPAMI.2015.2473844\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"title\":\"Exploiting Surroundedness for Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145316303\",\"name\":\"E. J. David\"},{\"authorId\":\"1398172020\",\"name\":\"Jes\\u00fas Guti\\u00e9rrez-Cill\\u00e1n\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1145/3204949.3208139\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ac847ccb66557ef523d61f1371fafca526a5553\",\"title\":\"A dataset of head and eye movements for 360\\u00b0 videos\",\"url\":\"https://www.semanticscholar.org/paper/7ac847ccb66557ef523d61f1371fafca526a5553\",\"venue\":\"MMSys\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31808445\",\"name\":\"J. Snyder\"}],\"doi\":\"10.3133/pp1395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27bc00d177cdc325e49053043e52a455e16a491a\",\"title\":\"Map Projections: A Working Manual\",\"url\":\"https://www.semanticscholar.org/paper/27bc00d177cdc325e49053043e52a455e16a491a\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144248905\",\"name\":\"M. Yu\"},{\"authorId\":\"2052685\",\"name\":\"H. Lakshman\"},{\"authorId\":\"1739786\",\"name\":\"B. Girod\"}],\"doi\":\"10.1109/ISMAR.2015.12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3c9a67d5c1aadcabf6c6c25ce9729f077c9f302\",\"title\":\"A Framework to Evaluate Omnidirectional Video Coding Schemes\",\"url\":\"https://www.semanticscholar.org/paper/b3c9a67d5c1aadcabf6c6c25ce9729f077c9f302\",\"venue\":\"2015 IEEE International Symposium on Mixed and Augmented Reality\",\"year\":2015},{\"arxivId\":\"1710.10755\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2858783\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"title\":\"Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"38107409\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/CVPR.2017.213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"269014f9c4d9f0b8de729e2013374fea04fbaad1\",\"title\":\"Deep Learning of Human Visual Sensitivity in Image Quality Assessment Framework\",\"url\":\"https://www.semanticscholar.org/paper/269014f9c4d9f0b8de729e2013374fea04fbaad1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69548810\",\"name\":\"W. C. Brenke\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bbe0d245f94bf63fa1d1522735fdd9e7583dd07\",\"title\":\"Plane and spherical trigonometry : with tables to four and five places\",\"url\":\"https://www.semanticscholar.org/paper/4bbe0d245f94bf63fa1d1522735fdd9e7583dd07\",\"venue\":\"\",\"year\":1943},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39838894\",\"name\":\"Yihui He\"},{\"authorId\":\"50875121\",\"name\":\"X. Zhang\"},{\"authorId\":\"1794486\",\"name\":\"M. Savvides\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"197c406b95340dfcdef542db532e0f7a967b9cda\",\"title\":\"Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/197c406b95340dfcdef542db532e0f7a967b9cda\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69325962\",\"name\":\"Joseph Bernhardt Rosenbach\"},{\"authorId\":\"69331781\",\"name\":\"Edwin A. Whitman\"},{\"authorId\":\"69487068\",\"name\":\"David Moskovitz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"feba5f74148383ca27783d52420cf17401adc76e\",\"title\":\"Plane and spherical trigonometry : with tables\",\"url\":\"https://www.semanticscholar.org/paper/feba5f74148383ca27783d52420cf17401adc76e\",\"venue\":\"\",\"year\":1937},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"144818403\",\"name\":\"Qi Ma\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2008.4587715\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"title\":\"Spatio-temporal Saliency detection using phase spectrum of quaternion fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B Choi\"},{\"authorId\":null,\"name\":\"YK Wang\"},{\"authorId\":null,\"name\":\"MM Hannuksela\"},{\"authorId\":null,\"name\":\"Y Lim\"},{\"authorId\":null,\"name\":\"A Murtaza\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Information technology\\u2013coded representation of immersive media (MPEG-I)\\u2013part 2: Omnidirectional media\",\"url\":\"\",\"venue\":\"format. ISO/IEC,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y Ye\"},{\"authorId\":null,\"name\":\"E Alshina\"},{\"authorId\":null,\"name\":\"J Boyce\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Algorithm descriptions of projection format conversion and video quality metrics in 360Lib\",\"url\":\"\",\"venue\":\"Joint Video Exploration Team of ITU-T SG,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Piotr Doll\\u00e1r, and Ross Girshick. Mask R-CNN\",\"url\":\"\",\"venue\":\"IEEE International Conference on Computer Vision\",\"year\":2017}],\"title\":\"Viewport Proposal CNN for 360\\u00b0 Video Quality Assessment\",\"topics\":[{\"topic\":\"Viewport\",\"topicId\":\"144719\",\"url\":\"https://www.semanticscholar.org/topic/144719\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Etoposide\",\"topicId\":\"21913\",\"url\":\"https://www.semanticscholar.org/topic/21913\"},{\"topic\":\"Aleurites (plant)\",\"topicId\":\"35020\",\"url\":\"https://www.semanticscholar.org/topic/35020\"},{\"topic\":\"Stage level 2\",\"topicId\":\"6361\",\"url\":\"https://www.semanticscholar.org/topic/6361\"},{\"topic\":\"Stage level 1\",\"topicId\":\"10918\",\"url\":\"https://www.semanticscholar.org/topic/10918\"},{\"topic\":\"Vector quantization\",\"topicId\":\"14152\",\"url\":\"https://www.semanticscholar.org/topic/14152\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"No Man's Sky\",\"topicId\":\"2639092\",\"url\":\"https://www.semanticscholar.org/topic/2639092\"},{\"topic\":\"Frame (physical object)\",\"topicId\":\"4537\",\"url\":\"https://www.semanticscholar.org/topic/4537\"},{\"topic\":\"Ephrin Type-B Receptor 1, human\",\"topicId\":\"203497\",\"url\":\"https://www.semanticscholar.org/topic/203497\"},{\"topic\":\"observers\",\"topicId\":\"1682770\",\"url\":\"https://www.semanticscholar.org/topic/1682770\"},{\"topic\":\"Image resolution\",\"topicId\":\"881\",\"url\":\"https://www.semanticscholar.org/topic/881\"},{\"topic\":\"Neuroleptic Malignant Syndrome\",\"topicId\":\"21055\",\"url\":\"https://www.semanticscholar.org/topic/21055\"},{\"topic\":\"Biological Neural Networks\",\"topicId\":\"13105\",\"url\":\"https://www.semanticscholar.org/topic/13105\"},{\"topic\":\"funding grant\",\"topicId\":\"36180\",\"url\":\"https://www.semanticscholar.org/topic/36180\"},{\"topic\":\"Area striata structure\",\"topicId\":\"87361\",\"url\":\"https://www.semanticscholar.org/topic/87361\"}],\"url\":\"https://www.semanticscholar.org/paper/8d8ff98a5740febb0e03972b7ff6686171f46557\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"