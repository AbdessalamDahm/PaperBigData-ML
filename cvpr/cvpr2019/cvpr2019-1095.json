"{\"abstract\":\"Image captioning is an ambiguous problem, with many suitable captions for an image. To address ambiguity, beam search is the de facto method for sampling multiple captions. However, beam search is computationally expensive and known to produce generic captions. To address this concern, some variational auto-encoder (VAE) and generative adversarial net (GAN) based methods have been proposed. Though diverse, GAN and VAE are less accurate. In this paper, we first predict a meaningful summary of the image, then generate the caption based on that summary. We use part-of-speech as summaries, since our summary should drive caption generation. We achieve the trifecta: (1) High accuracy for the diverse captions as evaluated by standard captioning metrics and user studies; (2) Faster computation of diverse captions compared to beam search and diverse beam search; and (3) High diversity as evaluated by counting novel sentences, distinct n-grams and mutual overlap (i.e., mBleu-4) scores.\",\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\",\"url\":\"https://www.semanticscholar.org/author/31121723\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\",\"url\":\"https://www.semanticscholar.org/author/29956361\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\",\"url\":\"https://www.semanticscholar.org/author/39709900\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\",\"url\":\"https://www.semanticscholar.org/author/2068227\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\",\"url\":\"https://www.semanticscholar.org/author/144016256\"}],\"citationVelocity\":18,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50627194\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"143924106\",\"name\":\"R. Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.3390/s20174761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4f1217919ef803a0549822039f5328ea78f80ff\",\"title\":\"Indoor Scene Change Captioning Based on Multimodality Data\",\"url\":\"https://www.semanticscholar.org/paper/c4f1217919ef803a0549822039f5328ea78f80ff\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1811.10652\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2019.00850\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e59cf8c3becbedced0089028a1cddac8b19b251\",\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"url\":\"https://www.semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2002.11848\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"title\":\"Analysis of diversity-accuracy tradeoff in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"145211780\",\"name\":\"Bin Fan\"},{\"authorId\":\"1380311632\",\"name\":\"Shinming Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.18653/v1/D19-1213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"title\":\"Guiding the Flowing of Semantics: Interpretable Video Captioning via POS Tag\",\"url\":\"https://www.semanticscholar.org/paper/ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1811.07662\",\"authors\":[{\"authorId\":\"47833739\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2112160\",\"name\":\"Y. Li\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00859\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23e943809c131c50dc90c1d308373febc60b9029\",\"title\":\"Intention Oriented Image Captions With Guiding Objects\",\"url\":\"https://www.semanticscholar.org/paper/23e943809c131c50dc90c1d308373febc60b9029\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/ICCV.2019.00901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"title\":\"Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40469481\",\"name\":\"T. Nogueira\"},{\"authorId\":\"32535425\",\"name\":\"C. Vinhal\"},{\"authorId\":\"1491425913\",\"name\":\"G\\u00e9lson da Cruz J\\u00fanior\"},{\"authorId\":\"2569769\",\"name\":\"Matheus Rudolfo Diedrich Ullmann\"}],\"doi\":\"10.1007/s11042-020-09539-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48f17b2b08aebd16e711f5c7ca9e773fe6639dc3\",\"title\":\"Reference-based model using multimodal gated recurrent units for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/48f17b2b08aebd16e711f5c7ca9e773fe6639dc3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eccfd6174709c285d62b11fb3da9b68d485ca883\",\"title\":\"Integrating Rule-based Entity Masking into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eccfd6174709c285d62b11fb3da9b68d485ca883\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2002.06661\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"title\":\"Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings\",\"url\":\"https://www.semanticscholar.org/paper/87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2007.06877\",\"authors\":[{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-58452-8_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"title\":\"Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets\",\"url\":\"https://www.semanticscholar.org/paper/e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.02917\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"3214848\",\"name\":\"Arash Vahdat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c97dfad7a023fbec97a901dae02b73e2e8e0fff1\",\"title\":\"NCP-VAE: Variational Autoencoders with Noise Contrastive Priors\",\"url\":\"https://www.semanticscholar.org/paper/c97dfad7a023fbec97a901dae02b73e2e8e0fff1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02339\",\"authors\":[{\"authorId\":\"2031911881\",\"name\":\"Edwin G. Ng\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"title\":\"Understanding Guided Image Captioning Performance across Domains\",\"url\":\"https://www.semanticscholar.org/paper/0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"title\":\"Attacking Image Captioning Towards Accuracy-Preserving Target Words Removal\",\"url\":\"https://www.semanticscholar.org/paper/0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.04919\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"58a77455b1c38afe1eab4bec664bd866eba1573d\",\"title\":\"Towards Diverse and Accurate Image Captions via Reinforcing Determinantal Point Process\",\"url\":\"https://www.semanticscholar.org/paper/58a77455b1c38afe1eab4bec664bd866eba1573d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.11690\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2562211\",\"name\":\"Xiaoyu Shen\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"54a42098b34c2602305b03fe07b7db82b789f5db\",\"title\":\"Integrating Image Captioning with Rule-based Entity Masking\",\"url\":\"https://www.semanticscholar.org/paper/54a42098b34c2602305b03fe07b7db82b789f5db\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"2012.07000\",\"authors\":[{\"authorId\":\"145144396\",\"name\":\"Dandan Song\"},{\"authorId\":\"4274864\",\"name\":\"Siyi Ma\"},{\"authorId\":\"2037300711\",\"name\":\"Zhanchen Sun\"},{\"authorId\":\"3389167\",\"name\":\"S. Yang\"},{\"authorId\":\"31364087\",\"name\":\"Lejian Liao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"title\":\"KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.14386\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57ace777e00c0df5d0b729990eed12ed6b0dcfe9\",\"title\":\"Controlling Length in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/57ace777e00c0df5d0b729990eed12ed6b0dcfe9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12551031\",\"name\":\"P. Li\"},{\"authorId\":\"26659900\",\"name\":\"Xinde Li\"},{\"authorId\":\"48568708\",\"name\":\"Xiaobin Li\"},{\"authorId\":\"1900890711\",\"name\":\"Hong Pan\"},{\"authorId\":\"51071590\",\"name\":\"M. O. Khyam\"},{\"authorId\":\"1398730731\",\"name\":\"Md. Noor-A.-Rahim\"},{\"authorId\":\"2426877\",\"name\":\"S. S. Ge\"}],\"doi\":\"10.1016/J.PATCOG.2020.107680\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b7af5e66c07318cdc3b2b1186bb199e1380e98\",\"title\":\"Place perception from the fusion of different image representation\",\"url\":\"https://www.semanticscholar.org/paper/38b7af5e66c07318cdc3b2b1186bb199e1380e98\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.10502\",\"authors\":[{\"authorId\":\"3021793\",\"name\":\"Hossein Hajipour\"},{\"authorId\":\"3407762\",\"name\":\"Apratim Bhattacharyya\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7f6f4ced1901c5ce78aa2d09ca16d5088220a1f\",\"title\":\"SampleFix: Learning to Correct Programs by Sampling Diverse Fixes\",\"url\":\"https://www.semanticscholar.org/paper/b7f6f4ced1901c5ce78aa2d09ca16d5088220a1f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134654394\",\"name\":\"Ren C. Luo\"},{\"authorId\":\"34373093\",\"name\":\"Yu-Ting Hsu\"},{\"authorId\":\"123191934\",\"name\":\"Yu-Cheng Wen\"},{\"authorId\":\"151486060\",\"name\":\"Huan-Jun Ye\"}],\"doi\":\"10.1109/ICPHYS.2019.8780171\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f10ee8e986c7e1a3f85c28b3e34eb8d5ffcb14ae\",\"title\":\"Visual Image Caption Generation for Service Robotics and Industrial Applications\",\"url\":\"https://www.semanticscholar.org/paper/f10ee8e986c7e1a3f85c28b3e34eb8d5ffcb14ae\",\"venue\":\"2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS)\",\"year\":2019},{\"arxivId\":\"1909.10470\",\"authors\":[{\"authorId\":\"46258988\",\"name\":\"Vishvak S. Murahari\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"}],\"doi\":\"10.18653/v1/D19-1152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f4a35e0beeed69799cd9418387e109d64f50c81\",\"title\":\"Improving Generative Visual Dialog by Answering Diverse Questions\",\"url\":\"https://www.semanticscholar.org/paper/2f4a35e0beeed69799cd9418387e109d64f50c81\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92538707\",\"name\":\"Qi Zheng\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR42600.2020.01311\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"title\":\"Syntax-Aware Action Targeting for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1885314583\",\"name\":\"Made Raharja Surya Mahadi\"},{\"authorId\":\"9347718\",\"name\":\"Anditya Arifianto\"},{\"authorId\":\"9308183\",\"name\":\"K. N. Ramadhani\"}],\"doi\":\"10.1109/ICoICT49345.2020.9166244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"538b261dbdffc4745cb217128c001ef1e63dc6b6\",\"title\":\"Adaptive Attention Generation for Indonesian Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/538b261dbdffc4745cb217128c001ef1e63dc6b6\",\"venue\":\"2020 8th International Conference on Information and Communication Technology (ICoICT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413908\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"title\":\"Controllable Video Captioning with an Exemplar Sentence\",\"url\":\"https://www.semanticscholar.org/paper/40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702778\",\"name\":\"H. Zhang\"},{\"authorId\":\"2913523\",\"name\":\"Diedie Qiu\"},{\"authorId\":\"50477983\",\"name\":\"R. Wu\"},{\"authorId\":\"103624776\",\"name\":\"Dong-Hong Ji\"},{\"authorId\":\"49461429\",\"name\":\"Guangli Li\"},{\"authorId\":\"9201022\",\"name\":\"Zhenyu Niu\"},{\"authorId\":\"50289773\",\"name\":\"Tao Li\"}],\"doi\":\"10.1007/S00500-019-03973-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f7104056642c03263508957f20505a1dbba03ce\",\"title\":\"Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images\",\"url\":\"https://www.semanticscholar.org/paper/7f7104056642c03263508957f20505a1dbba03ce\",\"venue\":\"Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"1626610869\",\"name\":\"Yu Zheng\"},{\"authorId\":\"1692580\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/TMM.2020.2976552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"title\":\"Integrating Part of Speech Guidance for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021}],\"corpusId\":53739686,\"doi\":\"10.1109/CVPR.2019.01095\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Jang\"},{\"authorId\":null,\"name\":\"S. Gu\"},{\"authorId\":null,\"name\":\"B. Poole\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Categorical reparameterization with gumbel-softmax. 2017\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"title\":\"Situation Recognition: Visual Semantic Role Labeling for Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.00314\",\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-1198\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"title\":\"Object Counts! Bringing Explicit Detections Back into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1805.09019\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"title\":\"CNN+CNN: Convolutional Decoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"venue\":\"CVPR 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3358971\",\"name\":\"Ashwin K. Vijayakumar\"},{\"authorId\":\"37824829\",\"name\":\"M. Cogswell\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b1e3f7218f1c0f0db56bf2bd9475521454693a1\",\"title\":\"Diverse Beam Search for Improved Description of Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/1b1e3f7218f1c0f0db56bf2bd9475521454693a1\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1803.01271\",\"authors\":[{\"authorId\":\"35836381\",\"name\":\"Shaojie Bai\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"921196c32213a229245a9705ee4768bc941e7a26\",\"title\":\"An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/921196c32213a229245a9705ee4768bc941e7a26\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.3115/1610075.1610162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"146b3649b693ae591c8953c0aae5264512c26ea3\",\"title\":\"Solving the Problem of Cascading Errors: Approximate Bayesian Inference for Linguistic Annotation Pipelines\",\"url\":\"https://www.semanticscholar.org/paper/146b3649b693ae591c8953c0aae5264512c26ea3\",\"venue\":\"EMNLP\",\"year\":2006},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.323\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00583\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"title\":\"Convolutional Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.00861\",\"authors\":[{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"title\":\"Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1711.07068\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"82247c9e74ddebb4dce65560ee69620579358f2d\",\"title\":\"Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space\",\"url\":\"https://www.semanticscholar.org/paper/82247c9e74ddebb4dce65560ee69620579358f2d\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1704.03470\",\"authors\":[{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"19353632\",\"name\":\"J. Huang\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/TPAMI.2018.2797921\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"title\":\"Learning Two-Branch Neural Networks for Image-Text Matching Tasks\",\"url\":\"https://www.semanticscholar.org/paper/f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1611.01144\",\"authors\":[{\"authorId\":\"145116380\",\"name\":\"Eric Jang\"},{\"authorId\":\"2046135\",\"name\":\"Shixiang Gu\"},{\"authorId\":\"16443937\",\"name\":\"Ben Poole\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"29e944711a354c396fad71936f536e83025b6ce0\",\"title\":\"Categorical Reparameterization with Gumbel-Softmax\",\"url\":\"https://www.semanticscholar.org/paper/29e944711a354c396fad71936f536e83025b6ce0\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1705.03122\",\"authors\":[{\"authorId\":\"2401865\",\"name\":\"Jonas Gehring\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"},{\"authorId\":\"13759615\",\"name\":\"Denis Yarats\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43428880d75b3a14257c3ee9bda054e61eb869c0\",\"title\":\"Convolutional Sequence to Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/43428880d75b3a14257c3ee9bda054e61eb869c0\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700980\",\"name\":\"Kevin Gimpel\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8679859bf0ad6ca4253603d05462838957733fb\",\"title\":\"A Systematic Exploration of Diversity in Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/e8679859bf0ad6ca4253603d05462838957733fb\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.445\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"topics\":[{\"topic\":\"Beam search\",\"topicId\":\"215017\",\"url\":\"https://www.semanticscholar.org/topic/215017\"},{\"topic\":\"Usability testing\",\"topicId\":\"34160\",\"url\":\"https://www.semanticscholar.org/topic/34160\"},{\"topic\":\"Analysis of algorithms\",\"topicId\":\"13372\",\"url\":\"https://www.semanticscholar.org/topic/13372\"},{\"topic\":\"Autoencoder\",\"topicId\":\"433939\",\"url\":\"https://www.semanticscholar.org/topic/433939\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"N-gram\",\"topicId\":\"236768\",\"url\":\"https://www.semanticscholar.org/topic/236768\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"sentence\",\"topicId\":\"3969\",\"url\":\"https://www.semanticscholar.org/topic/3969\"},{\"topic\":\"Grams\",\"topicId\":\"311947\",\"url\":\"https://www.semanticscholar.org/topic/311947\"},{\"topic\":\"Part-of-speech tagging\",\"topicId\":\"82770\",\"url\":\"https://www.semanticscholar.org/topic/82770\"},{\"topic\":\"Ephrin Type-B Receptor 1, human\",\"topicId\":\"203497\",\"url\":\"https://www.semanticscholar.org/topic/203497\"},{\"topic\":\"Variational principle\",\"topicId\":\"20709\",\"url\":\"https://www.semanticscholar.org/topic/20709\"},{\"topic\":\"Caption\",\"topicId\":\"785579\",\"url\":\"https://www.semanticscholar.org/topic/785579\"},{\"topic\":\"Encoder Device Component\",\"topicId\":\"55437\",\"url\":\"https://www.semanticscholar.org/topic/55437\"},{\"topic\":\"gram\",\"topicId\":\"49\",\"url\":\"https://www.semanticscholar.org/topic/49\"},{\"topic\":\"Safety-net Providers\",\"topicId\":\"2996066\",\"url\":\"https://www.semanticscholar.org/topic/2996066\"},{\"topic\":\"Generic Drugs\",\"topicId\":\"25912\",\"url\":\"https://www.semanticscholar.org/topic/25912\"},{\"topic\":\"Sampling - Surgical action\",\"topicId\":\"2142\",\"url\":\"https://www.semanticscholar.org/topic/2142\"}],\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}\n"